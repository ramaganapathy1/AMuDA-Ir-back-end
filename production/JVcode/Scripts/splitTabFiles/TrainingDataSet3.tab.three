v.srinivasa rajkumar educational	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t.delhi	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
technology i.i.t.delhi presents	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
presents a video	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
comp.sc & engg	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
high level programming	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
level programming languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds imperative functional	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
important and logic	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
imperative and functional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
respects so imperative	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
state based languages	0.00495804014246	1.0	3.9978021978	3.16992500144	0.0000000000	True
languages where state	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
value based languages	0.0	0.0	0.0	1.58496250072	0.0000000000	False
languages much closer	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
notion of variables	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
variables in functional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
variables in mathematics	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
quantities in physics	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
quantities like acceleration	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
based languages means	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
trimaxes though unlike	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
talking of continuous	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
talking of discrete	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
case of functional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
languages the notion	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
mathematics which means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
history of languages	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	True
high level languages	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
hundreds and hundreds	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
hundreds of programming	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
impossible to study	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
fifties and sixties	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sixties a large	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
represent the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
basic control structures	0.00826340023744	0.0	4.99633699634	6.33985000288	0.2928416486	True
structures the exploration	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
basic data structures	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
structures in order	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
order to obtain	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
obtain clean readable	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
clean readable programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
programs efficiently implement	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implement able programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
programs um efficient	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
efficient running programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things were fixed	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
seventies and eighties	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
exploration of programming	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
extension of pascal	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
pascal most important	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
ada it combines	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
combines the module	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
features of modula	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
modula and adds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
adds more features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features like concurrency	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
important feature exception	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
feature exception handling	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
exception handling generics	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
generics or polymorphism	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
module based language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sense the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
control structure remain	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
extend the language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
arrow mark denote	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
denote the decendency	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
decendency in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
terms of similarity	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
small talk eighty	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
talk eighty control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
eighty control structures	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
structures or syntax	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
simula the basic	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
basic extensional feature	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
feature of simula	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
notion of class	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
class or objects	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of features	0.00268840666323	0.0	0.0	3.16992500144	0.0000000000	False
language of sequential	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sixties were sequential	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
biolarge their exploration	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
features what kind	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
state of art	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
art large amount	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
amount of work	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
basic functional languages	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
early functional languages	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
structures and controls	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
controls and control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
structures then languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
caml actually signify	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
signify the addition	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features in fact	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fact the syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
lisp like language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
introduction of modules	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
introduction of exceptional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
handling the introduction	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
powerful data abstraction	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
data abstraction mechanisms	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
lisp is lisp	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
study the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
features of languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
thing like language	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
design a language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language what kinds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of issues	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
pascal has taught	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of unified	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
unified unified primitives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
primitives for expressing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms and data	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
thing about pascal	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
sixty like languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms are written	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
dialect of pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
pascal or algol	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language easily learnable	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
people are taught	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
set of primitive	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
absolutely clear syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
highly readable programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
readability that means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
means by readability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
readability it means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
read the source	0.00495804014246	0.0	5.9978021978	0.0	0.0000000000	False
piece of software	0.00465502408195	0.0	3.99706959707	6.33985000288	0.3506493506	False
fixed what hsppens	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
software have bugs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
years and years	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
years after means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
bug is detected	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
understand the algorithms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
source code contained	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
write the person	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
person or persons	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
written this software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
maintain the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
software in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
years the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
extend the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
adding new features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features by adding	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
reason so part	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
detection and correction	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
correction of bugs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
software as years	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
team that wrote	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
wrote the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language should provide	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support for abstraction	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
abstraction the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
basic abstraction mechanisms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
abstractions or things	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
things like procedures	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
functions in pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
loops loop statements	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kind of data	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
abstraction that pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
abstraction that means	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
sequence of elements	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
single logical unit	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
unit um records	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
records variant records	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
abstraction data abstraction	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sets of data	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
unit so combinations	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
combinations of operations	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
operations and data	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
provide the notion	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
variables and change	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
types and instantiate	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds of algorithms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stacks it doesn	0.0	0.0	0.0	1.58496250072	0.0000000000	False
stack of integers	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
integers a stack	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stack of characters	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
characters a stack	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stack of reals	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
reals a stack	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
complicated data element	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
record of things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things or stacks	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stacks of arrays	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
arrays of things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
operation on stacks	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
pop push checking	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
checking for emptiness	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
repeat the code	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
piece of code	0.00093641929429	0.0	0.0	1.58496250072	0.0000000000	False
code carefully written	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
carefully written verified	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
tested and instantiate	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
instantiate the types	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of stacks	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of operations	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
important modern language	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
modern language design	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language design issue	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
verify your programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support for verification	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
provability of programs	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
necessarily machine based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
machine based provability	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
possibly hand based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
hand based provability	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
user interactive provability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
effort was expended	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
case of fortan	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fortan and cobol	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
compilers was portability	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
portability ok nowadays	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portability what means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
architecture or machine	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
independent or machine	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language other machines	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine independence means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
basic instruction set	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
users um convenience	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
convenience the abstractions	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
machine instructions sets	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
register based architectures	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
architectures or stack	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
stack based architectures	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
design the language	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
specific or machine	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
move the entire	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
amount of effort	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
archi certain machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine specific details	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
move an entire	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
entire language implementation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
alter of portability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portability um ease	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implementation the availability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
availability of ready	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms for implementing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
implementing the language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
low level primitives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
run very fast	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
common clear syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
clear syntax common	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
syntax common clear	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
common clear semantics	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
construct each construct	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
notion of semantics	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
run time efficient	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
efficient by run	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implementation which means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
compile time efficiency	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
efficiency how fast	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
compile programs written	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
excellent runtime support	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
program should run	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
run as fast	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language should run	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fast yeah ease	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
ease of maintenance	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
maintenance of programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
translation and support	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
support for extensibility	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language of pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
add new features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support for subsets	0.00661072018995	0.0	2.99706959707	6.33985000288	0.2983425414	False
programming languages books	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language should support	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of operations	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
operations or features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kernel and larger	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
larger large sort	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sort of extensions	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
language of ada	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
affects the portability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portability of programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language for embedded	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
real time things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things with systems	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
systems that control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
sensors various kinds	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds of hardware	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
hardware ballistic missiles	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
affect their portability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
move the program	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support that feature	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language gets affected	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
study of programming	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
theory of programming	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
languages is based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
highly simplified natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
simplified natural language	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
grammar certain things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things can occur	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
arbitrarily form sentences	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
languages all natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
languages one thing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
category called predicates	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
words a predicate	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sentence in natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
predicate no complete	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
subject well subject	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrases which means	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
qualified by object	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
object um adjectives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
grammatically correct sentence	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
firstly various clauses	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
clauses each clause	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
greatly simplified form	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
parts of speech	0.00495804014246	0.0	2.9978021978	3.16992500144	0.0000000000	False
specifies various parts	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language and parse	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
similarities with natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
inspired by natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
construction of artificial	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
lot of problems	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
study of pascal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
iso standard pascal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
standard pascal reference	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
pascal reference manual	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
manual by janson	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
manual really specifies	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
expected by executing	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
executing that syntactic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
notion of meanings	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
unlike natural language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine independent fashion	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language is implemented	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
implemented in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
talking about meanings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
restrictions on memory	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
restrictions on computational	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
number of operations	0.00403260999485	0.0	5.9978021978	1.58496250072	0.0000000000	False
assume a sort	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
semantic the programming	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
entity quite independent	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
ideal environment form	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
actual reference manual	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
manual of pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
manual is independent	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
specific machine paragraphs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implementation dependent features	0.00826340023744	0.0	3.99633699634	6.33985000288	0.2372583480	False
general the semantics	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
follow the syntax	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
syntax the syntax	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
compound forming operations	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
compound um connective	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
form um compound	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sentences from simpler	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
meanings in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
gave the meanings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
give the meanings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
connectives in terms	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
set of programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
express the effects	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
effects of connectives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
predict the behavior	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
follow this discipline	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kind of semantics	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
number of programs	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
programs which means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
derive the meaning	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
elements are formed	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
derivable in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
connectives which formed	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
formed a complex	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of allowable	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
set theory notation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
right the set	0.0	0.0	0.0	0.0	0.0000000000	False
set builder notation	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
give a finitary	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
structure in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
syntax the finitary	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
expressed in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
ideal environment don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about machine	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
machine constraints don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about architecture	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portable ok don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about word	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
word lengths don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about limits	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
worry about memory	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
memory constraints assume	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
constraints assume infinite	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
assume infinite amount	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
amount of memory	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
associate a disc	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
variable in side	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
side the program	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
operating system interface	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language all kinds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of machine	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
machine and architectural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
maxint the maximum	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
maximum integer allowable	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
typically implementation dependant	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
depends upon word	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
length or byte	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
bytes for representing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
representing a integers	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine to machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine the amount	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
program can vary	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stack based machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
register based machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things are implement	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
implementation in order	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
order to make	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
make the language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
out the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms of implementation	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
architectural specific nature	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine dependant features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features the actual	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
input and output	0.00116375602049	0.0	0.0	1.58496250072	0.0000000000	False
file based terminal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
based terminal based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
terminal based sensor	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
based sensor based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
interface also includes	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
includes the file	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
interact in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
written by errors	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
introduced by users	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
programs so errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
syntactic nature errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
recovering from errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
out the program	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
reduces the amount	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
amount of compilation	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
decent error reporting	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
error reporting mechanism	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
mechanism some error	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
error handling mechanism	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
thing but errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
attitudes different implementations	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
notion of syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
separately the semantic	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
semantic and pragmatic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
possibly an abstract	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
numbers um numbers	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
twentieth century attitude	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
attitude towards numbers	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
form of numerals	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
ways of representing	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
hundred and twenty	0.00537681332647	0.0	5.99706959707	6.33985000288	0.2983425414	False
twenty six written	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
written in hexadecimal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
roman representation differs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
representation of numbers	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
base the character	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
representations yeah positional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
representations i hope	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
hope everybody understands	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
units tens hundreds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
roman same number	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
thing fundamental difference	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
disregard the change	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
change in character	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set what makes	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
cases the grammar	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
identical the character	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
enlarge the grammar	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sense the form	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
form of representation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
represent compound forms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
forms from simpler	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
roman and arabic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
call a complete	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
dictionary of words	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language is formed	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fixed character set	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
identify certain strings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
strings of characters	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
characters as words	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
words as allowable	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
words as part	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
constitutes that states	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
languages like konkani	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
konkani or sindi	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
collection of words	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
words ok sindi	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
people some people	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
write in devanagri	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
devanagri some people	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
script the arabic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
devanagri can communicate	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
person who doesn	0.0	0.0	0.0	1.58496250072	0.0000000000	False
script by speech	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
communicate by letter	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
words whose actual	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
form might depend	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
ways of combining	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language to form	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of formation	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
set really depends	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kind of codes	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
frame the character	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds of differences	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
tuple of objects	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of non	0.0	0.0	3.9978021978	0.0	0.0000000000	False
terminals really specifies	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
specifies various kinds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of grammatical	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
speech noun phrase	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
noun phrase verb	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrase verb phrase	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
verb phrase adjectival	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrase adjectival phrase	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
adjectival phrase noun	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrase noun clause	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
noun clause subject	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
clause subject clauses	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
subject clauses subject	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
clauses subject phrases	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
subject phrases object	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrases object clauses	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
object clauses predicates	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set n consists	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
basic grammatical categories	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sets are finite	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
symbols or terminal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
collection of formation	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
represents a grammatical	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
constitutes a sentence	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
grammar specifying boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
categories the grammatical	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
add boolean expression	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
symbol any boolean	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
set of boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
languages are boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
fully parenthesized boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
parenthesized boolean expressions	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
two boolean expression	0.0	0.0	5.9978021978	1.58496250072	0.0000000000	False
form which consists	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
boolean expressions enclosed	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
enclosed in parenthesis	0.00268840666323	0.0	0.0	0.0	0.0000000000	False
parenthesis and separated	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
simple sentence generation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
generation you start	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
circled in orange	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
chosen to replace	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language which consists	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
symbol s important	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of terminal	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
symbols are disjoint	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
replacement it replaces	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
replaces a non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
consisting of terminals	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
terminals or non	0.0	0.0	0.0	0.0	0.0000000000	False
string of terminal	0.00116375602049	0.0	0.0	0.0	0.0000000000	False
terminal symbols generated	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
v.srinivasa rajkumar educational	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t.delhi	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
technology i.i.t.delhi presents	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
presents a video	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
comp.sc & engg	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
lecture so today	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
started on grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar on last	0.0	0.0	0.0	0.0	0.0000000000	False
set a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
four tuple consisting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
finite a set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set of non	0.0	0.0	2.9972299169	0.0	0.0000000000	False
non terminal symbols	0.0	0.0	11.9787626962	34.8691750159	0.4426946632	True
symbols or grammatical	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set of terminal	0.0135041351094	0.0	2.99261311173	0.0	0.3793103448	False
constitutes the vocabulary	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
vocabulary of programming	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
collection of formation	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
rules or productions	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
rules of replacement	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
signifies the grammatical	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
simple um grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generation of boolean	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammatical categories consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
stand for conditional	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
exp um complement	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbol the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
terminal set consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
consists of open	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
open and close	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
dealing with grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
black for terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
level of abstraction	0.00146141567327	0.0	0.0	1.58496250072	0.0000000000	False
green um light	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
things and dark	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string of terminal	0.00438424701981	0.0	4.9972299169	3.16992500144	0.0000000000	False
grammar by applying	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
applying the rules	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
circled in orange	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
orange the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choices for replacing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
choose different choices	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
generate a large	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
sentences in fact	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
absolutely no restriction	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generate an infinite	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
set of sentences	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set a large	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
part of computer	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
computer science mathematics	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
mathematics and logic	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
represent infintary object	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
warnings and cautions	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
relation from non	0.0	0.0	0.0	0.0	0.0000000000	False
symbols to strings	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
strings of non	0.0	0.0	4.9972299169	0.0	0.0000000000	False
terminal and terminal	0.00622618267517	0.0	4.9972299169	0.0	0.0000000000	False
terminal terminal symbols	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
choose any non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
symbol and replace	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
consisting of terminal	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
terminal and non	0.0	0.0	5.99630655586	0.0	0.4313725490	False
set n union	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
strings of finite	0.00415078845012	0.0	0.0	0.0	0.0000000000	False
greek letter epsilon	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
epsilon to denote	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
non empty strings	0.0	0.0	5.9972299169	3.16992500144	0.0000000000	False
empty strings generated	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
star with epsilon	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
kind of grammar	0.00830157690023	0.0	3.99630655586	4.75488750216	0.4313725490	False
context free grammar	0.0365353918317	1.0	16.9769159741	38.0391000173	0.3698722260	True
allowed to replace	0.00622618267517	0.0	5.9972299169	4.75488750216	0.0000000000	False
replace a single	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
single the rules	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
left hand side	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
single non terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
free as suppose	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context sensitive grammar	0.0269801249258	0.0	11.9879963066	19.0195500087	0.4022503516	True
right a context	0.0	0.0	0.0	0.0	0.0000000000	False
grammar has production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
replace the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
meaning of context	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
choosing this arbitrary	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
calling this grammar	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar context free	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
allowing this replacement	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rule the production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
contexts the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non terminal appears	0.0	0.0	0.0	1.58496250072	0.0000000000	False
kind of context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
define that context	0.0	0.0	0.0	1.58496250072	0.0000000000	False
general a context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
context a context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
free grammar production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context which consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
languages the language	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
start symbol located	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context and generate	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generate a string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string that string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
call a language	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
language on set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
possibly infinite set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set of strings	0.00622618267517	0.0	1.9972299169	3.16992500144	0.0000000000	False
set for strings	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
element the empty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
lots of subsets	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
languages the problem	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar can generate	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generate that language	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
defined um grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammars called regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar every production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
capital a denotes	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
denotes a non	0.0	0.0	0.0	3.16992500144	0.0000000000	False
symbol this capital	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
capital b denotes	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
small a denotes	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
denotes a terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbol in fact	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
made it black	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
right linear regular	0.0	0.0	4.9944598338	0.0	0.3666666667	False
linear regular grammar	0.0186785480255	0.0	8.99168975069	9.50977500433	0.3178170144	False
thing to realize	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
grammar allows productions	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
regular grammar means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right hand side	0.0	0.0	0.0	3.16992500144	0.0000000000	False
terminal symbol appearing	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
order the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
linear or regular	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
form the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
generate a full	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
define a left	0.0	0.0	0.0	0.0	0.0000000000	False
left linear regular	0.00830157690023	0.0	3.99630655586	1.58496250072	0.4313725490	False
terminal generation rule	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
out for completion	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
completion all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
left linear grammar	0.00622618267517	1.0	1.9972299169	3.16992500144	0.0000000000	True
designed some hard	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
ware using finite	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
finite state machines	0.00830157690023	0.0	7.99630655586	4.75488750216	0.3548387097	False
machines it turns	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right linear grammars	0.0	0.0	3.99630655586	6.33985000288	0.5500000000	True
grammars actually represents	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
represents finite state	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
machines without output	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
kinds of machines	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
state transition diagram	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
symbol the input	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
machine automatically defines	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
defines a right	0.0	0.0	0.0	0.0	0.0000000000	False
symbol the start	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
properties of grammars	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
firstly every regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar whether right	0.0	0.0	0.0	0.0	0.0000000000	False
linear or left	0.00415078845012	0.0	0.0	0.0	0.0000000000	False
linear every regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
free every context	0.00415078845012	0.0	0.0	0.0	0.0000000000	False
context of empty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
top most string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
empty string symbol	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context free production	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string implicitly appears	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbols between terminal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
reason every context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
interest in grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
ultimately in generating	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
supposing that language	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
linear grammar left	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar left linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
kind of production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set t star	0.00622618267517	0.0	3.9972299169	4.75488750216	0.0000000000	False
symbol ok obtained	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
star as consisting	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
strings of length	0.00622618267517	0.0	2.9972299169	4.75488750216	0.0000000000	False
union of cartesian	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
define a binary	0.0	0.0	0.0	0.0	0.0000000000	False
operation called catenation	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
effect of catenation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
strings and put	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set t consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
bab the operation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
operation of catenation	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
produce the string	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
catenation just juxtapose	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
operation on strings	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
string this string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set t cube	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set t raised	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
sets are subsets	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
cross t star	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
length and juxtapose	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
string and juxtapose	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
juxtapose an empty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
empty string satisfies	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
satisfies these conditions	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
star s concatenated	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
empty string equals	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
empty string concatenated	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
catenation is juxtaposition	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
fact the identity	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
element for catenation	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right secondly catenation	0.0	0.0	0.0	0.0	0.0000000000	False
catenation is associative	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
set the set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
star under catenation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
operation is associative	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
associative so catenation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
arbitrary context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
replace this non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
small b appearing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
sense this production	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
production is context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string and turns	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
minimal a minimal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context which means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
care what appears	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context really specifies	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
specifies the smallest	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
candidate for replacing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rule ok context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
enable a rule	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rule to applied	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar the minimal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
padding the minimal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
string which means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
means you don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
apply the production	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
sensitivity into account	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
simpler to deal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar as generated	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar and deal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context sensitive aspects	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
process of compilation	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
typical context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context sensitive feature	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
languages like pascal	0.00146141567327	0.0	0.0	1.58496250072	0.0000000000	False
grammar for pascal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
fail to check	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context sensitive issues	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
algorithms to recognize	0.00337603377736	0.0	0.0	0.0	0.0000000000	False
recognize or pause	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
pause context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context sensitive languages	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
sensitive languages represented	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
represented as context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
recognize and pause	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
pause context free	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
algorithms available linear	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
linear time algorithms	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
phrasing context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
aspects many people	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
people in fact	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
fact consider context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar is context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
sensitive every language	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
fact go supposing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
necessarily right linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
linear such grammars	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
purely right linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
purely left linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
machines for recognizing	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
theory of computation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
language is regular	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
exists a regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar which generates	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
similarly a language	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
language is context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
exists a context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
grammar that generates	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
written context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
remember one thing	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
thing to design	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
design a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
define a grammar	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of numerals	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar in natural	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
neat um rigorous	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rigorous um art	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
evolved such neat	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
notation for numbers	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
numerals the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
representation in decimal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
nice and simple	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
romans never considered	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
considered a things	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
tens of thousands	0.00146141567327	0.0	0.0	1.58496250072	0.0000000000	False
thousands the romans	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
ten fifty hundred	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
hundred five hundred	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
ten thousand fifty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
thousand fifty thousand	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
thousand um hundred	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
continue that pattern	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
require an infinite	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbols ok supposing	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbols which means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
means your condition	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
violated but supposing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
numerals are written	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
sense the roman	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
language it generates	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
easy to construct	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
construct a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammars are equivalent	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
non terminal set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language they generate	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context free language	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
equivalent context free	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
occurrence of left	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
writing this grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
produce this string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
make a grammar	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
smaller to reduce	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
reduce the number	0.00292283134654	0.0	0.0	3.16992500144	0.0000000000	False
number of non	0.0	0.0	5.9972299169	0.0	0.0000000000	False
thing to reduce	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
language really depends	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
variety of grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
matter of decision	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
making to choose	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
choose the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
grammar right correct	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right correct kind	0.0	0.0	0.0	0.0	0.0000000000	False
criteria for choosing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
choosing a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
firstly the grammar	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
impossible to parse	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
parse the language	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
non terminals low	0.0	0.0	0.0	1.58496250072	0.0000000000	False
facilitate an easy	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
language in fact	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
fact the arabic	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
equivalent in terms	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
terms of actual	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
thatn the right	0.0	0.0	0.0	0.0	0.0000000000	False
interest inherent constraint	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
finite recursion based	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
v.srinivasa rajkumar educational	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
technology i.i.t delhi	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi presents	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
presents a video	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.00119880376318	0.0	0.0	1.58496250072	0.0000000000	False
deptt of comp.sc	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
comp.sc & engg	0.00119880376318	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.00119880376318	0.0	0.0	1.58496250072	0.0000000000	False
talk about ambiguity	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
simple programming language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar our favorite	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
favorite context free	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
context free grammar	0.00538796657562	0.0	4.99660441426	4.75488750216	0.5454545455	False
generate this sentence	0.00765159079678	0.0	3.99660441426	6.33985000288	0.4285714286	False
applied the productions	0.00311170146237	0.0	0.0	3.16992500144	0.0000000000	False
productions or fired	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
fired the productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
four possible choices	0.0	0.0	0.0	1.58496250072	0.0000000000	False
chose the possibility	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
generate this ultimate	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
chosen to fire	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
chosen to apply	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
apply a production	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
keeping in mind	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
open bracket open	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
bracket open bracket	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
possibilities of replacement	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
intermediate sentence generation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence ok depending	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
chose to apply	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
fire a production	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
leftmost non terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
non terminal symbol	0.0	0.0	1.9974533107	3.16992500144	0.0000000000	False
chosen the left	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
replacement of non	0.0	0.0	0.0	0.0	0.0000000000	False
right hand sides	0.0	0.0	0.0	1.58496250072	0.0000000000	False
independent of context	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
matter which non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
terminal is chosen	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
first for replacement	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
provided you choose	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number these productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
write a justification	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
number you applied	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
permute the order	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
two possible choices	0.0	0.0	0.0	1.58496250072	0.0000000000	False
application of production	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
apply these productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentences your intermediate	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order of application	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
derivation of sentences	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose to replace	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
amount of order	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
applying this production	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
possibilities before applying	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
interested in generating	0.00573869309759	0.0	1.9974533107	4.75488750216	0.0000000000	False
derivation this independence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
partial ordering specifies	0.0019128976992	0.0	0.0	3.16992500144	0.0000000000	False
derivations and collapse	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
partial order colas	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
independence and dependence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
dependence in fact	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
draw a tree	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
tree of exact	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
sentence the first	0.00382579539839	0.0	0.0	1.58496250072	0.0000000000	False
symbol ok open	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
symbol um remember	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
remember our convention	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
convention that black	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
black denotes terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
denotes terminal symbols	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
symbols the eventual	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
strings in black	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
language the colors	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
denote um denote	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
denote certain abstractions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
production s yields	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
yields open parenthesis	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
generating the sentence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
expanded into open	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order you perform	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
productions the first	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
obtain a tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
call the parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
terminal symbols notice	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
read the tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
read the leaves	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
leaves from left	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
open parenthesis open	0.00382579539839	0.0	0.0	0.0	0.0000000000	False
parenthesis open parenthesis	0.00382579539839	0.0	0.0	0.0	0.0000000000	False
close parenthesis close	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
parenthesis close parenthesis	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
tree for generating	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
generating any sentence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
point of view	0.00455270068076	0.0	7.99575551783	7.92481250361	0.3858520900	False
view of compiling	0.00382579539839	0.0	0.0	1.58496250072	0.0000000000	False
compiling language implementation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
orders of derivation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
ways of traversing	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
traversing this parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
parse parse tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
tree as presenting	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
presenting the partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
firing of productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
unique parse tree	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
necessarily a unique	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
tree um depending	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
decide to traverse	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
traverse the tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
familiar topological sorting	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sort just takes	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
takes a partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order and linearizes	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
provide a linear	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order a total	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order are maintained	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
fact for partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
essentially a parsed	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
derivations or traverses	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
theory of partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
compiling or language	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
implementation it doesn	0.0	0.0	0.0	0.0	0.0000000000	False
stream of symbols	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
kind of language	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
implicit um type	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
type of terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
make we make	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
make a clear	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
call a concrete	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
concrete parse tree	0.00765159079678	1.0	4.99660441426	6.33985000288	0.5454545455	True
make no distinction	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
identifiers and operators	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
abstract parse tree	0.0019128976992	1.0	0.0	1.58496250072	0.0000000000	True
make a distinction	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
operators and operands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
define a language	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language of boolean	0.00573869309759	0.0	3.9974533107	0.0	0.0000000000	False
operands and operators	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
call abstract syntax	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
abstract syntax tree	0.0186702087742	1.0	13.9898132428	17.4345875079	0.2727272727	True
tree actually elevates	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
replaces non terminals	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
designed the language	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
elevate the operators	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
tree the operators	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
leaves the leaves	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
talk about distinction	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
distinction between operands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
kinds of terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
language the ultimate	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
ultimate programming language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
symbols the concrete	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
concrete syntax tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
apply the operators	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
operands in fact	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence the reason	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
application of operators	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
operators on operands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
uniform post fix	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
post fix notion	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
uniform prefix notion	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
fact every language	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
interested in giving	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
meanings to languages	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
calculations in school	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
ways of evaluating	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
evaluating that expression	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose to evaluate	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
evaluate one operand	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
first apply multiplication	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
keeping these things	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
things in mind	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
define a small	0.0	0.0	0.0	0.0	0.0000000000	False
small programming language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
variables and expressions	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
commands assignment sequencing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sequencing um conditional	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
simple looping command	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
syntactically valid programs	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
kinds of programs	0.00134699164391	0.0	0.0	1.58496250072	0.0000000000	False
question of formalizing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
giving rules production	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
rules production rules	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
build a compiler	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
start writing programs	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
purposes of translation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
translation and compilation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
compilation you require	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
summarize the construction	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
construction um summarize	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
summarize my coding	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
brown is part	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
free grammar notation	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
notation for productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
tree so branches	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
branches of parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
color the actual	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
actual terminal symbols	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
two different kinds	0.0	0.0	0.0	1.58496250072	0.0000000000	False
kinds of entities	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
commands and boolean	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
brown for boolean	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
commands the assignment	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
change um change	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
change my color	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
defined the grammar	0.0019128976992	0.0	0.0	3.16992500144	0.0000000000	False
top down fashion	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
interested in sentences	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
programs ok unlike	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
language like pascal	0.00269398328781	0.0	0.0	3.16992500144	0.0000000000	False
productions c arrow	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
arrow c semicolon	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
bar actually specifies	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
language in terms	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
level essentially tells	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
point it tells	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
form compound commands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
commands from simpler	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
two well simple	0.0	0.0	0.0	1.58496250072	0.0000000000	False
simple or compound	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
blue this semi	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
command this conditional	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
conditional compound command	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
compound commands inside	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
possibly a compound	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
grammar of commands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
commands is concerned	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
level of grammar	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
grammar atomic commands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar is sort	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
hatch patch grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
true and false	0.00382579539839	0.0	0.0	1.58496250072	0.0000000000	False
expression the terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
expression any boolean	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
make compound boolean	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
compound boolean expressions	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
expressions from simpler	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
simpler boolean expressions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
two boolean expressions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
changed the grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
fully parenthesized notion	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
boolean expression language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
defined this grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
rid of true	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar without parenthesis	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence this sentence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence is generated	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
easy to give	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
give a derivation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
two different ways	0.0	0.0	0.0	1.58496250072	0.0000000000	False
rule and derive	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose to expand	0.00956448849598	0.0	3.99575551783	7.92481250361	0.1726618705	False
expand this replace	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
decide to apply	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
chose to expand	0.00765159079678	0.0	3.99660441426	6.33985000288	0.2068965517	False
two different derivations	0.0	0.0	2.9974533107	4.75488750216	0.0000000000	False
two different syntax	0.0	0.0	0.0	0.0	0.0000000000	False
trees actually affect	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
tree would give	0.00382579539839	0.0	0.0	0.0	0.0000000000	False
give you value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of true	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of false	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sense this grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
unique expression language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
language with unique	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
specification of semantics	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar is ambiguous	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
exists a sentence	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
two different parse	0.0	0.0	0.0	0.0	0.0000000000	False
tree those parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
trees are important	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
view of translating	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
translating which means	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
means running programs	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
problem of compiling	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
problem of executing	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
programs in order	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
right so ambiguity	0.0	0.0	0.0	0.0	0.0000000000	False
meanings which means	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
means the execution	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
behavior of programs	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
specifies a language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
absolutely no ambiguity	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
normal mathematical notation	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
order of evaluation	0.00466755219356	0.0	5.9974533107	3.16992500144	0.0000000000	False
remove the parenthesis	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
absolutely no reason	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
reason except normal	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
normal mathematical convention	0.00311170146237	0.0	0.0	3.16992500144	0.0000000000	False
construct a syntax	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
syntax tree supposing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
supposing i removed	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
removed this parenthesis	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
precedence of operations	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
operations which ensures	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
ensures that multiplication	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
first and addition	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
multiplication should precede	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
addition other wise	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
wise the order	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
notation most programming	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
languages actually implement	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
dangling else problem	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
conditional the conditional	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
defined and pascal	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
possibility of ambiguity	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
ambiguity the sequencing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sequencing is ambiguous	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
v.srinivasa rajkumar educational	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
technology i.i.t delhi	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi presents	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
presents a video	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
deptt of comp.sc	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
comp.sc & engg	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
slightly more complicated	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
complicated programming language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
answer the question	0.000833878766623	0.0	0.0	1.58496250072	0.0000000000	False
programs and commands	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
commands and atomic	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
context free grammar	0.00680782123296	0.0	6.99572039943	6.33985000288	0.4719101124	False
free grammar notation	0.00262113817137	0.0	0.0	0.0	0.0000000000	False
notation will remain	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
last times grammar	0.0	0.0	0.0	1.58496250072	0.0000000000	False
firstly the grammar	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
grammar of programs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
sequence of commands	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
words in black	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
black are reserve	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
words so including	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
define the notion	0.0	0.0	0.0	1.58496250072	0.0000000000	False
notion of ambiguity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammar was ambiguous	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammar is ambiguous	0.00524227634274	0.0	2.99714693295	6.33985000288	0.2978723404	False
exists a sentence	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
abstract sentence tree	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
abstract syntax tree	0.00655284542843	0.0	4.99643366619	7.92481250361	0.5283018868	False
tree by elevating	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
elevating the operators	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
nodes and replacing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
replacing the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non terminal symbols	0.0	0.0	8.99215406562	15.8496250072	0.3706377858	False
class of parse	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two control structures	0.0	0.0	0.0	1.58496250072	0.0000000000	False
structures the conditional	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
eliminated the ambiguity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
ambiguity by introducing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
introducing two reserved	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two reserved words	0.0	0.0	0.0	0.0	0.0000000000	False
words the closing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
closing bracket words	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
operator on commands	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
atomic or compound	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
commands i don	0.0	0.0	0.0	0.0	0.0000000000	False
two different parse	0.0	0.0	0.0	0.0	0.0000000000	False
expand into trees	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
first this first	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
first semi colon	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
forms the root	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
left sub tree	0.000766992443296	0.0	0.0	1.58496250072	0.0000000000	False
trees really correspond	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two bracketed inside	0.0	0.0	0.0	1.58496250072	0.0000000000	False
bracketed outside right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
general um sequencing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
function composition operation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
language is concerned	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
concerned any implementation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
decision with regard	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
programs is concerned	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
things can change	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
expression of boolean	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
change the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of boolean	0.0	0.0	0.0	0.0	0.0000000000	False
boolean expression depending	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parse the boolean	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
language reference manual	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
languages since algol	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
backus naur form	0.0112792903386	0.0	5.99500713267	9.50977500433	0.2170542636	True
notation um created	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
created by john	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
backus and peter	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
definition algol sixty	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
sixty the algol	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
first um language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
rigorous syntactic form	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
syntactic form based	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
based on context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
context free languages	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
languages and context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammars to define	0.0	0.0	0.0	0.0	0.0000000000	False
define the language	0.0	0.0	0.0	0.0	0.0000000000	False
backus was involved	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
creation of fortan	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clear syntactic definition	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
language every fortan	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fortan compiler written	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
gave different interpretations	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
syntax of fortan	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
fortan comp fortan	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
comp fortan programs	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
compatible across machines	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
compiler and moving	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
team of programmers	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
rewrite that program	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
program to suit	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
required substantial rewriting	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
form of theoretical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
study and backus	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
define the algol	0.0	0.0	0.0	0.0	0.0000000000	False
algol sixty language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
symbol um single	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
single character non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
character non terminal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
statements within angle	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
double colon equal	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
form in full	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
full the non	0.0	0.0	0.0	0.0	0.0000000000	False
terminals being enclosed	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
enclosed in angle	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
arrow being replaced	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
replaced double colon	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
colon and equals	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extended backus naur	0.00483398157367	0.0	3.99786019971	0.0	0.0000000000	False
adds the power	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions within context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
firstly regular expressions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
symbols to aloow	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
kinds of iterations	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
naur form extended	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extended to include	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
iterations in choice	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
naur form production	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
beta and gamma	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
gamma are strings	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
strings of terminals	0.00113463687216	0.0	0.0	1.58496250072	0.0000000000	False
terminals or non	0.0	0.0	0.0	0.0	0.0000000000	False
light brown brackets	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
naur form notation	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
alpha b gamma	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
set of non	0.0	0.0	0.0	0.0	0.0000000000	False
notation this extended	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extended backus form	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
backus form notation	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
run the man	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
options given switches	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
enclosed in brackets	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
brackets to represent	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
separated by bars	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
separated by commas	0.00644530876489	0.0	2.99714693295	4.75488750216	0.4242424242	False
set of productions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
aide in writing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
out a grammar	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
significance you wouldn	0.0	0.0	0.0	0.0	0.0000000000	False
language like pascal	0.00113463687216	0.0	0.0	1.58496250072	0.0000000000	False
pascal you allowed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clause actually belongs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
normal one conditional	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
reduce the amount	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
number of non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
terminal symbols remember	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
language a real	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
real world programming	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
world programming language	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
piece of syntax	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
adding these extra	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extra non terminals	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
respect to ambiguity	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
alpha within braces	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
braces beta gamma	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
epsilon which denotes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
number of iterations	0.00113463687216	0.0	0.0	1.58496250072	0.0000000000	False
iterations um number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
number of repetitions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
extended bnf notation	0.00805663595611	0.0	9.99643366619	7.92481250361	0.3814713896	True
manual the syntax	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
diagrams of pascal	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
follow the arrow	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
ordinary context free	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
context free notation	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
manuals for learning	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
language the last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language which didn	0.0	0.0	0.0	0.0	0.0000000000	False
purposes of teaching	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
teaching programming languages	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
programming languages compilers	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
designer of pascal	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
written the compiler	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
smaller than pascal	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
single data type	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
type the main	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
assignment sequencing bracketing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequencing bracketing looping	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conditional that means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two one arm	0.0	0.0	0.0	0.0	0.0000000000	False
conditions in sequence	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
neglect the boolean	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
boolean data types	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
encode your booleans	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
control abstraction mechanism	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parameter list procedures	0.00483398157367	0.0	3.99786019971	4.75488750216	0.0000000000	False
step wise refinement	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
refinement of programs	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
abstraction complicated programs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
development of programs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
top down fashion	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
program my start	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
block which terminates	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
case of pascal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
programs you terminate	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
terminate the program	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
right a block	0.0	0.0	0.0	0.0	0.0000000000	False
brevity i don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
write full names	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
single um single	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
single letter non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
letter non terminal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sort of obvious	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clause is optional	0.00483398157367	0.0	2.99786019971	4.75488750216	0.0000000000	False
enclosed in light	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
declaration a constant	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
declaration which means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
means this word	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
stand for identifier	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifier and number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
set of identifiers	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
set of numbers	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
syntax the actual	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
value as identifiers	0.0	0.0	0.0	0.0	0.0000000000	False
identifiers um names	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
names and numbers	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
kinds of data	0.0020196219603	0.0	0.0	0.0	0.0000000000	False
number of constant	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
constant specified separated	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
commas are reserved	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
moment the word	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
word const occurs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clause i equals	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
const reserved word	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
define a sequence	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sequence of constants	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
declaration and terminate	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
terminate that sequence	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
terminate the entire	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
reserved word var	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
word var occurring	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
var the entire	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
entire variable declaration	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
procedure has procedure	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
entire the entire	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
optional you don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
block just consists	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
definition of statements	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	True
empty a declaration	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
empty which means	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
means an empty	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
assignment an assignment	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
identifier um colon	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
equals an expression	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
absolutely no relation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifiers are declared	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
syntax is context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
variable without declaring	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
context sensitive feature	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
procedure called statement	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
call an identifier	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifier and implicit	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequence of statements	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
statements by bracketing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
begin and end	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
end and call	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
produce a epsilon	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
pair of brackets	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
brackets begin end	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
repetition um occurrences	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
previous our previous	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expense of introducing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
introducing new non	0.0	0.0	0.0	0.0	0.0000000000	False
define so condition	0.0	0.0	0.0	1.58496250072	0.0000000000	False
modified the language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
language a bit	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
unary data type	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
data type applies	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
condition this unary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
unary predicate applies	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions and yields	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
yields the true	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
true or false	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
predicate some unary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
reason for choosing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
high level programs	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
programs a large	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
check for oddness	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
binary relational operators	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
simplified the original	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
single letter relational	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
letter relational symbols	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
odd looking symbols	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
original pascal compiler	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
equals the original	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
compiler has defined	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
defined by wirth	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
wirth actually assume	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
greater than equals	0.000833878766623	0.0	0.0	1.58496250072	0.0000000000	False
conditions really dependant	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
dependant upon expressions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
diff two extremes	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
addition subtraction multiplication	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
subtraction multiplication division	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
expressions a difference	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
expressions a product	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
ambiguous this grammar	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
order of evaluation	0.00393170725706	0.0	2.99786019971	3.16992500144	0.0000000000	False
define the expression	0.0	0.0	0.0	0.0	0.0000000000	False
expression every constant	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
constant an integer	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
bracket every expression	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
operator you put	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
pair of operands	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
enclosed in parenthesis	0.00786341451412	0.0	7.99572039943	7.92481250361	0.2641509434	False
parenthesis e minus	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
minus e enclosed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parenthesis e star	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
star e enclosed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
find it tedious	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
key in parenthesis	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
syntax in string	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
draw the trees	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
fully parenthesized notation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
tree which preserves	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
preserves the order	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions and vice	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fully bracketed string	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
string of symbols	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
point of view	0.000766992443296	0.0	0.0	1.58496250072	0.0000000000	False
programmer to write	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
write fully parenthesized	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fully parenthesized versions	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
parenthesized versions makes	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
makes it makes	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
strike a reasonable	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conventions of mathematical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
right in parsing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
overloaded unary operators	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
write positive numbers	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
non negative integer	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus are binary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
lot of overloading	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
multiplication division multilic	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
multilic and multiplication	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
real data types	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
integer data types	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
operators usually bind	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
bind the tightest	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
means a unary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
first available symbol	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
large expression enclosed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
normal mathematical convention	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
multiplication and division	0.00483398157367	0.0	5.99786019971	3.16992500144	0.0000000000	False
division bind tighter	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
division looses precedence	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
minus five star	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
expression this minus	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conventions into account	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
giving your friendly	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
friendly user interface	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
knowledge of mathematics	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
mathematics mathematic notation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
mathematic notation mathematical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
notation mathematical conventions	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conventions can write	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
programs can write	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
trained to write	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
convenience mean means	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
fairly large number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expect to define	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language of expression	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
deal with parsing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parsing or compiling	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
wont i wont	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
optionally an addition	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
right the addition	0.0	0.0	0.0	0.0	0.0000000000	False
term a signed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
signed or unsigned	0.00644530876489	0.0	3.99714693295	4.75488750216	0.4242424242	False
term a term	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
operator so star	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
star and division	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
division the multiplication	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
division are multiplicative	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
product or quotient	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
right a factor	0.0	0.0	0.0	0.0	0.0000000000	False
identifier which means	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
talking about variables	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
variables or constants	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
defined in terms	0.00302943294045	0.0	2.99786019971	4.75488750216	0.0000000000	False
circularly non recursive	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
account the fact	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
basically the sum	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expression whose root	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
operation that means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
left operand supposing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammar really takes	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
precedence of operators	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
operators into account	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
essential for writing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
writing the compiler	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
kind of syntactic	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
terms of abstract	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fully parenthesized expressions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions or abstract	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
identifier we follow	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
follow normal pascal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
normal pascal rules	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
rules an identifier	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
identifier should start	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
upper case letters	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
trivial to modify	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
include lower case	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
lower case letters	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
distinguishes a number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
integer and neglect	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
letters or digits	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
reason for removing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
part of parsing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
write such rules	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
word the word	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
scanning or lexical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
file of characters	0.00805663595611	0.0	7.99643366619	7.92481250361	0.2922755741	False
program into words	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
describe each entity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
file of words	0.00483398157367	0.0	3.99786019971	4.75488750216	0.0000000000	False
words and decide	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
out the entire	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
string of digits	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
representing an integer	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
scanner typically takes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
takes a file	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
file of lexemes	0.00483398157367	0.0	5.99786019971	4.75488750216	0.0000000000	False
file it means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
means any unbounded	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
unbounded sequence ordered	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequence ordered sequence	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequence of object	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
process of scanning	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
converts the file	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
process of parsing	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
parsing actually takes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
created a single	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
lose the status	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
string of characters	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
single entity unit	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
structured data type	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
create a huge	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
amount of information	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
process of compiling	0.00262113817137	0.0	0.0	3.16992500144	0.0000000000	False
type checking runtime	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
checking runtime type	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
runtime type checks	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
compile time type	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
checks to detect	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
detect un declared	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
detecting spelling mistakes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
table is resident	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
memory for reference	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
check various context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
sensitive um issues	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
issues like hasn	0.0	0.0	0.0	1.58496250072	0.0000000000	False
assigned the right	0.0	0.0	0.0	0.0	0.0000000000	False
require this table	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
table of information	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifier reserved word	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
future to defining	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
defining the semantics	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
notions of semantics	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
language new features	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
defined the syntactic	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
introducing without ambiguity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
meaning you give	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
jump into today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s material	0.0	0.0	0.0	0.0	0.0000000000	False
out the first	0.00198690377337	0.0	0.0	1.58496250072	0.0000000000	False
first homework assignment	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
mic a bit	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first problem sets	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
grade homework problems	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
combination of tas	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
tas and graders	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
members  students	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
email the class	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
class to solicit	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times this quarter	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
spend one evening	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
staying up late	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
late and grading	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taught a class	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
students that grade	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
first time sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
makes a difference	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
solution and amazing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write amazing solutions	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
graders are paid	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of hang	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
evening and grade	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll send email	0.0	0.0	0.0	3.16992500144	0.0000000000	False
started with today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is talk	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
talk about linear	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
out and work	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
homepage and download	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
download detailed lecture	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
detailed lecture notes	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
pretty much describe	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
amount of linear	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
refresher on linear	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
algebra i talk	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
talk about today	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
out in detail	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
start by showing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
fun video remember	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
talked about supervised	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
learning and supervised	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
close right answer	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number of examples	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
algorithm to replicate	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
problem of predicting	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
predicting housing prices	0.00172017965883	0.0	0.0	3.16992500144	0.0000000000	False
right " housing	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm to learn	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
learn the relationship	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
relationship between sizes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sizes of houses	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
right " answer	0.0	0.0	0.0	1.58496250072	0.0000000000	False
video now load	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
load the big	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
mellon on applied	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
applied supervised learning	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
car to drive	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
sorts of things	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
hear dean pomerleau	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pomerleau s voice	0.0	0.0	0.0	0.0	0.0000000000	False
mention and algorithm	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithm called neural	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
essential learning algorithm	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
watch the video	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
human driver shows	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
angle this segment	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
correct " steering	0.0	0.0	0.0	0.0	0.0000000000	False
learn to produce	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
pointer is moving	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
line actually shows	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
shows the human	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
human steering direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
right here shows	0.0	0.0	0.0	0.0	0.0000000000	False
shows the steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
steering direction chosen	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
moving the steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
wheel the human	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
human is steering	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
mamos is pointing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
algorithm currently thinks	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
right steering direction	0.0	0.0	0.0	1.58496250072	0.0000000000	False
beginning of training	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
range of steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
collects more examples	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
examples and learns	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
choose a steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
right ? switch	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ago and autonomous	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
darpa grand challenge	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
team s drive	0.0	0.0	0.0	0.0	0.0000000000	False
drive a car	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
absolutely amazing work	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
call the regression	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
predict a continuous	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
continuous value variables	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
continuous value steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
value steering directions	0.0	0.0	0.0	0.0	0.0000000000	False
first supervised learning	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
supervised learning algorithm	0.000993451886683	0.0	0.0	0.0	0.0000000000	True
prices in portland	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
number of houses	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
prices in thousands	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
thousands of dollars	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
data and plot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
call a training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
learn to predict	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
predict the relationship	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back and modify	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
modify this task	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
introduce some notation	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
piece of notation	0.00298035566005	0.0	1.99840764331	3.16992500144	0.0000000000	False
lower case alphabet	0.00366430748825	0.0	5.99840764331	3.16992500144	0.0000000000	False
alphabet m denote	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
denote the number	0.00298035566005	0.0	3.99840764331	3.16992500144	0.0000000000	False
number of training	0.00382733971974	0.0	3.99734607219	0.0	0.3738317757	False
means the number	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
number of rows	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
denote the input	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
call the features	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
denote the size	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
output " variable	0.0	0.0	0.0	1.58496250072	0.0000000000	False
comprises one training	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
table i drew	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
call one training	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
notation they re	0.0	0.0	0.0	0.0	0.0000000000	False
list of training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
feed our training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
denoted lower case	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
hypothesis s job	0.0	0.0	0.0	0.0	0.0000000000	False
takes this input	0.00298035566005	0.0	3.99787685775	6.33985000288	0.0000000000	False
area in square	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
estimates the price	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
hypothesis h maps	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
maps from inputs	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
order to design	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
design a learning	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
represent the hypothesis	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
first learning algorithm	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
represent my hypothesis	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
house we re	0.0	0.0	0.0	0.0	0.0000000000	False
knowing the size	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number of bedrooms	0.00397380754673	0.0	3.99787685775	6.33985000288	0.0000000000	False
size and square	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
script two denote	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
write the hypothesis	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rho plus theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
1x1 plus theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
make this dependent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta is explicit	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll sometimes write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
predicts a house	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
house with features	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
features x costs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
predicts this house	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
cost one final	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
convention of defining	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
equal to sum	0.00172017965883	0.0	0.0	3.16992500144	0.0000000000	False
two of theta	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of features	0.000632105886682	0.0	0.0	1.58496250072	0.0000000000	False
equal to two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
amount of notation	0.00198690377337	0.0	0.0	0.0	0.0000000000	False
day you re	0.0	0.0	0.0	0.0	0.0000000000	False
write a symbol	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
simple lower case	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll standardize notation	0.0	0.0	0.0	1.58496250072	0.0000000000	False
notation and make	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
make a lot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descriptions of learning	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithms a lot	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write some symbol	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
nt quite remember	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00043274096938	0.0	0.0	1.58496250072	0.0000000000	False
re ever wondering	0.0	0.0	0.0	1.58496250072	0.0000000000	False
means any questions	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters the thetas	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
algorithm and theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
set to choose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
learn appropriate parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta and theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta all great	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
questions the answer	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
answer is sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
linear hypothesis class	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
complicated hypothesis classes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll actually talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talk about higher	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
higher order functions	0.00122143582942	1.0	0.0	1.58496250072	0.0000000000	True
bit later today	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
chose the parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
make accurate predictions	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
houses all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis will make	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
make some prediction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
make the predictions	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
learning algorithm accurate	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
make that theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta square difference	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
choose parameters theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
training set mine	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
actual target variable	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
target variable mine	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
mine is actual	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minimizing this sum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
put a one-half	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus the actual	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters of theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of linear	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
linear algebra classes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
basic statistics classes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
regression or squares	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll actually show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
class of algorithms	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
algorithms for performing	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
performing that minimization	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minimization over theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta the first	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameter vector theta	0.0073286149765	0.0	5.99681528662	9.50977500433	0.3448275862	False
theta maybe initialize	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
initialize my parameter	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of write	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
arrow on top	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
top to denote	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
denote the vector	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
changing my parameter	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta to reduce	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minimum with respect	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
respect to theta	0.0137614372707	0.0	15.991507431	25.3594000115	0.3361344538	False
theta so switch	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
switch the laptops	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lower the big	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
algorithm for minimizing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithm called grading	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
grading and descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
display a plot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
axes are theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
represents the function	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
gradient descent algorithm	0.00496725943341	0.0	3.99734607219	7.92481250361	0.0000000000	True
choose some initial	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
randomly chosen point	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
display actually shows	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
park so imagine	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
re actually standing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
physically a hill	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
direction of steepest	0.0109929224648	0.0	5.99522292994	7.92481250361	0.3217158177	False
find the minimum	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
theta one property	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
property of gradient	0.00366430748825	0.0	2.99840764331	0.0	0.0000000000	False
lower left hand	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
left hand corner	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
running gradient descent	0.00344035931767	0.0	5.99734607219	7.92481250361	0.4166666667	False
started gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rerun gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
slightly different initial	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
initial starting point	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
steepest descent direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
completely different local	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
aware that gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
initialize your parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta one switch	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out the math	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
back and revisit	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
revisit this issue	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
issue of local	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithm we re	0.0	0.0	0.0	0.0	0.0000000000	False
update the parameters	0.00258026948825	0.0	3.99840764331	3.16992500144	0.0000000000	False
theta as theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta i minus	0.00366430748825	0.0	3.99840764331	3.16992500144	0.0000000000	False
minus the partial	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
derivative with respect	0.0146215271001	0.0	14.9909766454	23.7744375108	0.3974284044	False
iteration of gradient	0.00298035566005	0.0	4.99840764331	0.0	0.0000000000	False
point of notation	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
colon equals notation	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
notation to denote	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
setting a variable	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
left hand side	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
hand side equal	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
right hand side	0.0	0.0	0.0	3.16992500144	0.0000000000	False
side all right	0.0	0.0	0.0	0.0	0.0000000000	False
write a colon	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
overwrite the value	0.0	0.0	0.0	3.16992500144	0.0000000000	False
side in contrast	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write a equals	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
assertion of truth	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of makes	0.000765467943948	0.0	0.0	0.0	0.0000000000	False
work out gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out gradient descent	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first somewhat mathematical	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
step through derivations	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
gradient descent rule	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
one-half of script	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
training example comprising	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
comprising one pair	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
one-half something squared	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
times one-half times	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
one-half times theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inside the square	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inside this sum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking the partial	0.00122143582942	0.0	2.99840764331	4.75488750216	0.0000000000	False
sum with respect	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
depend on theta	0.00298035566005	0.0	1.99840764331	4.75488750216	0.0000000000	False
term that depends	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
updated as theta	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
minus alpha times	0.00298035566005	0.0	2.99840764331	3.16992500144	0.0000000000	False
greek alphabet alpha	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
parameter alpha controls	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
controls how large	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
large a step	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
hill you decided	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
decided what direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
controls how aggressive	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
set by hand	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
steepest descent algorithm	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
converge if alpha	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
end up overshooting	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
overshooting the minimum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking too aggressive	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
aggressive a step	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lots of errors	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
wrap this property	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
derived the algorithm	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
repeat until convergence	0.00172017965883	0.0	0.0	3.16992500144	0.0000000000	False
times the sum	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
bother to show	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
home and sort	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
sort of verify	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
show  switch	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
run the algorithm	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
problem of linear	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
ordinary release squares	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
re doing today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
multiple local optima	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out for ordinary	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
nice bow shape	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
bow shaped function	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
initialize the parameters	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
change the space	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
space of parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
step of gradient	0.00366430748825	0.0	1.99840764331	0.0	0.0000000000	False
property of regression	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
linear hypothesis cost	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
cost the function	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
value of alpha	0.0	0.0	0.0	0.0	0.0000000000	False
approach the local	0.00610717914709	0.0	9.99734607219	0.0	0.2877697842	False
smaller and smaller	0.00298035566005	0.0	5.99840764331	1.58496250072	0.0000000000	False
theta by subtracting	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
subtracting from alpha	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times the gradient	0.00198690377337	0.0	0.0	0.0	0.0000000000	False
minimum the gradient	0.00366430748825	0.0	0.0	0.0	0.0000000000	False
automatically take smaller	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
local minimum make	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minimum make sense	0.0	0.0	0.0	0.0	0.0000000000	False
housing prices data	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lets you initialize	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
shows the hypothesis	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters of initialization	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
prices are equal	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ve now found	0.0	0.0	0.0	1.58496250072	0.0000000000	False
run each sample	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
right and converged	0.0	0.0	0.0	0.0	0.0000000000	False
test the convergence	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ways of testing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
testing for convergence	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
two different iterations	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta has changed	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
changed a lot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
quantity you re	0.0	0.0	0.0	0.0	0.0000000000	False
changing much anymore	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of standard	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
rules of thumb	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
decide if gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
descent has converged	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
math at incline	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
choosing the direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
compute the gradient	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
compute the derivative	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
tas can talk	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
talk a bit	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
interest it turns	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of turns	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
give this algorithm	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
algorithm a specific	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
batch gradient descent	0.00244287165883	1.0	0.0	3.16992500144	0.0000000000	True
nt a great	0.0	0.0	0.0	0.0	0.0000000000	False
term batch refers	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descent you re	0.0	0.0	0.0	0.0	0.0000000000	False
entire training set	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
set you re	0.0	0.0	0.0	0.0	0.0000000000	False
perform a sum	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
examples so descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descent often works	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
large training set	0.00298035566005	0.0	2.99840764331	4.75488750216	0.0000000000	False
houses from portland	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
u.s census database	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
u.s census size	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
census size databases	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
hundreds of thousands	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
thousands or millions	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
millions of training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
re running batch	0.0	0.0	0.0	0.0	0.0000000000	False
running batch rate	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
rate and descent	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
perform every step	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lot of training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
ll also call	0.0	0.0	0.0	1.58496250072	0.0000000000	False
call it incremental	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
incremental gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
gradient descent updates	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
parameters data runs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
runs you perform	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
perform this update	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
order to start	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
modifying the parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first training examples	0.00122143582942	0.0	5.99628450106	11.094737505	0.0000000000	False
perform an update	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
error with respect	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
perform another update	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
adapting your parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
quickly without needing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
needing to scan	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
entire u.s census	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
start adapting parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
launch data sets	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
constantly gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
constant gradient descent	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
nt actually converge	0.0	0.0	0.0	0.0	0.0000000000	False
run the constant	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of tend	0.00122143582942	0.0	0.0	3.16992500144	0.0000000000	False
tend to wander	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
parameters will sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of tender	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
tender to wander	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
parameter that wanders	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
bit the global	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
works much faster	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
clean a couple	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
couple of boards	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
cleaning the boards	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of rearranging	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rearranging the order	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theory that sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of supports	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theory that supports	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
performing this minimization	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
minimization in terms	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ordinary least squares	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
squares it turns	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta in close	0.00366430748825	0.0	2.99840764331	0.0	0.0000000000	False
needing to run	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
run an iterative	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
undergraduate linear algebra	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
typically done requires	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
lots of derivatives	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
derivatives and writing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
lots of algebra	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
derive the closed	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
closed form solution	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
solution of theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
lines of algebra	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
notation for matrix	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
work has turned	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
respect to matrixes	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
writing out pages	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
pages and pages	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
pages of matrices	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrices and derivatives	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out the minimization	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector of parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
define the derivative	0.0	0.0	0.0	3.16992500144	0.0000000000	False
dimensional vector theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector with indices	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
define this derivative	0.0	0.0	0.0	1.58496250072	0.0000000000	False
rewrite the gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descent as updating	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta  notice	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
previous parameter minus	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameter minus alpha	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out of order	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
space of matrices	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
space of real	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function is matched	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matched from matrices	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrices to real	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function that takes	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
input to matrix	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking the gradient	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rows equals number	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number of columns	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
define the trace	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of operator	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
trace operator applied	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
means the sum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sum of diagonal	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
home and verify	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
verify the proofs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrix a times	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
home and prove	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
front so trace	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back and move	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
input of matrix	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
output a real	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function of trace	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back and referring	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
definitions of traces	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
work it out	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
lastly a couple	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
couple of easy	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
transpose the matrix	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
function of theta	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
algorithm so work	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
work this out	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
define the matrix	0.0	0.0	0.0	1.58496250072	0.0000000000	False
vector of inputs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector of features	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
defined as matrix	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta this derivation	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta  remember	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
remember how matrix	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
matrix vector multiplication	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus y contained	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
contained the math	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus y squared	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector and put	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
put a half	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
threw a lot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lot of notations	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
training examples runs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector that runs	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
vectors that index	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inside the parentheses	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta with respect	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
matrix vector notation	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
order to minimize	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
solve for theta	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
quickly without proof	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
derivative of half	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
exchanged the derivative	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
one-half in terms	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
notes and make	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
step is correct	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
slowly by referring	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of taking	0.000993451886683	0.0	0.0	3.16992500144	0.0000000000	False
taking a quadratic	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function and expanding	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out by multiplying	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
quantity in parentheses	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
operator without changing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
equal to one-half	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
property of trace	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
end and move	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
trace of theta	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
theta times theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times theta transposed	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
transpose x minus	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number without changing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
real number transposed	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus the trace	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking the transpose	0.00122143582942	0.0	5.99840764331	4.75488750216	0.0000000000	False
transpose x theta	0.00855005080592	0.0	11.9968152866	7.92481250361	0.3252032520	False
nt actually depend	0.0	0.0	0.0	0.0	0.0000000000	False
term with respect	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
drop that term	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
facts i wrote	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
wrote down earlier	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
earlier without proof	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
find in lecture	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times the identity	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
times b transposed	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrix x transpose	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
transpose is equal	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
plug this back	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
derivative  wow	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta is equal	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
one-half x transpose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minus x transpose	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
solve this equation	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
equation for theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
times x transpose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters in closed	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
writing out reams	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
reams of algebra	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first learning hour	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
nt you excited	0.0	0.0	0.0	0.0	0.0000000000	False
close for today	0.000993451886683	0.0	0.0	3.16992500144	0.0000000000	False
inverse ? pseudo	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pseudo inverse pseudo	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inverse pseudo inverse	0.0	0.0	0.0	0.0	0.0000000000	False
pseudo inverse minimized	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minimized to solve	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out x transpose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
means your features	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
features were dependent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out the minimum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minimum is obtained	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
re other questions	0.0	0.0	0.0	3.16992500144	0.0000000000	False
end of audio	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
topic to topic	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
outline for today	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
flow of ideas	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talked about linear	0.00248754233192	0.0	2.99848561333	0.0	0.0000000000	False
regression and today	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about sort	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
locally weighted regression	0.015308034098	1.0	13.9934376577	19.0195500087	0.3248811410	True
mentors probably favorite	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
favorite machine learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
machine learning algorithm	0.000737959318968	0.0	0.0	0.0	0.0000000000	True
ll then talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
probable second interpretation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
interpretation of linear	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
first classification algorithm	0.00287325060515	0.0	1.99848561333	4.75488750216	0.0000000000	False
allowing i hope	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm for fitting	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
fitting logistic regression	0.000667202458811	0.0	0.0	0.0	0.0000000000	False
logistic regression models	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
remember the notation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
notation i defined	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression or linear	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
linear least squares	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
denote the predicted	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
hypothesis was franchised	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
vector of grams	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
grams as theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
linear regression model	0.00191550040343	0.0	0.0	3.16992500144	0.0000000000	True
model and lowercase	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
number of features	0.00060938989456	0.0	0.0	1.58496250072	0.0000000000	False
predict housing prices	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
number of bedrooms	0.00287325060515	0.0	2.99848561333	4.75488750216	0.0000000000	False
equal to two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
recapping the previous	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
defined this quadratic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
quadratic cos function	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
minus yi squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set so lowercase	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
notation i ve	0.0	0.0	0.0	0.0	0.0000000000	False
denote the number	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
number of training	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
derive the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of theta	0.0	0.0	9.99444724886	15.8496250072	0.2816989382	False
theta that minimizes	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minimizes this enclosed	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
transpose x inverse	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
inverse x transpose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
amount of notation	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
lecture you forgot	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
re having trouble	0.0	0.0	0.0	0.0	0.0000000000	False
remembering what lowercase	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00125156866559	0.0	1.99848561333	3.16992500144	0.0000000000	False
linear regression last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
houses in square	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
house in general	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
apply a machine-learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choose your features	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
features to give	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
give the learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choice we made	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equal this size	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
leave this idea	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
nt have data	0.0	0.0	0.0	0.0	0.0000000000	False
data that tells	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
houses one thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
draw this out	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
define the set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of features	0.00224204027183	0.0	6.99798081777	6.33985000288	0.0000000000	False
square that number	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm will end	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
end up fitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fitting a quadratic	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
slightly better fit	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fill a model	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
model that fits	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fits your data	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
fit a line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
line that passes	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fits your training	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
training data perfectly	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
predictor of housing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
quadratic model fits	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fits the data	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
small a set	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
large a set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
problem of underfitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
failing to fit	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
algorithm is fitting	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
fitting the idiosyncrasies	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
specific data set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
houses we sampled	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
sampled in portland	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
bit more expensive	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
polynomial we re	0.0	0.0	0.0	0.0	0.0000000000	False
fitting the idiosyncratic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
true underlying trends	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
housing prices vary	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
size of house	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
issue of selecting	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about feature	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
feature selection algorithms	0.000829180777308	1.0	0.0	1.58496250072	0.0000000000	True
algorithms for choosing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choosing what features	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
today is talk	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
class of algorithms	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
algorithms called non-parametric	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
non-parametric learning algorithms	0.00588770542232	1.0	7.99747602221	6.33985000288	0.0000000000	True
features very carefully	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
define the term	0.0	0.0	0.0	1.58496250072	0.0000000000	False
parametric learning algorithm	0.00235508216893	0.0	11.9964664311	9.50977500433	0.0000000000	True
learning algorithm parametric	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algorithm parametric learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
number of parameters	0.0022138779569	0.0	5.99848561333	3.16992500144	0.0000000000	False
parameters that fit	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.00121877978912	0.0	0.0	1.58496250072	0.0000000000	False
data in contrast	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
first non-parametric learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algorithm the formal	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
slightly less formal	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
amount of stuff	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
entire training set	0.00147591863794	0.0	0.0	3.16992500144	0.0000000000	False
describe a specific	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
specific non-parametric learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
loess for self-hysterical	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
self-hysterical reasons loess	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
run linear regression	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
nt really quadratic	0.0	0.0	0.0	0.0	0.0000000000	False
function of sin	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fiddle with features	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
evaluate your hypothesis	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
query point low	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta to minimize	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
transpose xi squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
return theta transpose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression in contrast	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
locally weighted linear	0.00383100080686	0.0	5.99798081777	0.0	0.5256410256	False
weighted linear regression	0.00383100080686	0.0	5.99747602221	4.75488750216	0.5256410256	False
regression you re	0.0	0.0	0.0	0.0	0.0000000000	False
value my hypothesis	0.0	0.0	0.0	3.16992500144	0.0000000000	False
apply linear regression	0.00588770542232	0.0	4.99747602221	7.92481250361	0.4389721627	False
regression to fit	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fit a straight	0.00471016433786	0.0	3.99798081777	0.0	0.4162436548	False
value of straight	0.0	0.0	0.0	0.0	0.0000000000	False
value i return	0.0	0.0	0.0	1.58496250072	0.0000000000	False
terms w superscript	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choice for ways	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minus x squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
squared over two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus some large	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
give the points	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
weight and give	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
times this quadratic	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
term for points	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
points by points	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
term for faraway	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
linear regression fits	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fits a set	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
attention to fitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fitting the points	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
close by accurately	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
accurately whereas ignoring	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
ignoring the contribution	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
contribution from faraway	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
communities of researchers	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
researchers that tend	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
tend to choose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choose different choices	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
choices by default	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
literature on debating	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
debating what point	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
exponential decay function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
formula i ve	0.0	0.0	0.0	0.0	0.0000000000	False
remember the familiar	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
familiar bell-shaped gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
ways of associating	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
value your hypothesis	0.0	0.0	0.0	3.16992500144	0.0000000000	False
give a weight	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
gaussian  excuse	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
bell-shaped function evaluated	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
weight one last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
last small generalization	0.0	0.0	0.0	1.58496250072	0.0000000000	False
denote as tow	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
form or function	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
function this parameter	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
informally it controls	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
controls how fast	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fast the weights	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
copy my diagram	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
end up choosing	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
fairly narrow gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fairly narrow bell	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
narrow bell shape	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fall off rapidly	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
tow is large	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choosing a weighting	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
function that falls	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
slowly with distance	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
apply locally weighted	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
straight line making	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
making that prediction	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
kind of class	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
value you put	0.0	0.0	0.0	1.58496250072	0.0000000000	False
put a straight	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
predict that value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value it turns	0.0	0.0	0.0	1.58496250072	0.0000000000	False
vary your hypothesis	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to make	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.00243755957824	0.0	7.99798081777	6.33985000288	0.0000000000	False
evaluate this line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set we re	0.0	0.0	0.0	0.0	0.0000000000	False
check the questions	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression can run	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
problem of overfitting	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
overfitting or underfitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
re not building	0.0	0.0	0.0	1.58496250072	0.0000000000	False
building a model	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
entire data set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
write a code	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
implementing locally weighted	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
building your model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
successfully to model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choose this band	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
band with parameter	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll actually talk	0.0	0.0	0.0	3.16992500144	0.0000000000	False
talk about model	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
boy the weights	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choose to define	0.0	0.0	0.0	0.0	0.0000000000	False
things as gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
happened to choose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function to define	0.0	0.0	0.0	0.0	0.0000000000	False
define my weights	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose a function	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
nt even integrate	0.0	0.0	0.0	0.0	0.0000000000	False
integrates to infinity	0.00117754108446	0.0	0.0	3.16992500144	0.0000000000	False
re weighting function	0.0	0.0	0.0	1.58496250072	0.0000000000	False
functions that integrate	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
move on assume	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set of houses	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
predict the linear	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
re actually right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
large training set	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
huge data set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set again turns	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ways to make	0.00117754108446	0.0	0.0	3.16992500144	0.0000000000	False
efficient for large	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
large data sets	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
work of andrew	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
moore on kd-trees	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
figured out ways	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
ways to fit	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fit these models	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
weighted regression remember	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
remember the outline	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about logistic	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
ll just talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talk about ordinary	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ordinary unweighted linear	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
unweighted linear regression	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
criteria for minimizing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minimizing the square	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
values y predicted	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minimize the absolute	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
present one set	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
set of assumptions	0.00287325060515	0.0	2.99848561333	4.75488750216	0.0000000000	False
minimizing the sum	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
sum of square	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
sufficient to justify	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
squares regression make	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
regression make sense	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assumptions i describe	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
give one rationalization	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
model with probabilistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
term as capturing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
capturing unmodeled effects	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fail to capture	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
epsilon as random	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
random noise epsilon	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
term that captures	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
effects just things	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
things we forgot	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
forgot to model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
nt quite linear	0.0	0.0	0.0	0.0	0.0000000000	False
day the seller	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
variance sigma squared	0.00353262325339	0.0	2.99848561333	3.16992500144	0.0000000000	False
stands for normal	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
denote a normal	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
covariance sigma squared	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
density for gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
density for epsilon	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
epsilon i squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
erase the board	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sigma squared right	0.0	0.0	0.0	0.0	0.0000000000	False
prices are generated	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
house is equal	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equal to theta	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
random gaussian noise	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
noise with variance	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
sense ? raise	0.0	0.0	0.0	0.0	0.0000000000	False
point of notation	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
error as gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
mumble about justifications	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
central limit theorem	0.00287325060515	0.0	2.99848561333	4.75488750216	0.0000000000	False
theorem it turns	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
majority of problems	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
apply a linear	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
measure the distribution	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
error in regression	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
independent random variables	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
variables will tend	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
error is caused	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
effects are independent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
two real answers	0.0	0.0	0.0	1.58496250072	0.0000000000	False
assumption i guess	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assumptions we make	0.00353262325339	0.0	5.99848561333	4.75488750216	0.0000000000	False
prices are priced	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
priced to dollars	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
dollars and cents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
errors in prices	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
continued as value	0.0	0.0	0.0	0.0	0.0000000000	False
value random variables	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of dollars	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
number of cents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fractions of cents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
cents in housing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
gaussian random variable	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
accurate enough assumption	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
back to selected	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hurt our learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about generative	0.0022138779569	0.0	1.99848561333	4.75488750216	0.0000000000	False
generative and discriminative	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
discriminative learning algorithms	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
week or two	0.0	0.0	0.0	3.16992500144	0.0000000000	False
out one bit	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
bit of notation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
thinking of theta	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
frequentist s point	0.0	0.0	0.0	0.0	0.0000000000	False
point of view	0.000560510067958	0.0	0.0	1.58496250072	0.0000000000	False
generating the data	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
condition on random	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
re taking sort	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of frequentist	0.0	0.0	0.0	0.0	0.0000000000	False
frequentist s viewpoint	0.0	0.0	0.0	0.0	0.0000000000	False
part of class	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
class we re	0.0	0.0	0.0	0.0	0.0000000000	False
parameterized by theta	0.00580426544115	0.0	7.9964664311	11.094737505	0.0000000000	False
read the semicolon	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
semicolon as parameterized	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta is distributed	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
terms are iid	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
terms are independent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
identically distributed part	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
part just means	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assuming the outcome	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fit a model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
model the probability	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
likelihood of theta	0.00383100080686	0.0	5.99798081777	4.75488750216	0.0000000000	False
parts of notation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
define this term	0.0	0.0	0.0	1.58496250072	0.0000000000	False
prioritized by theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta to test	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
test the likelihood	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
likelihood and probability	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
taking this thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
thing and viewing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function of theta	0.00295183727587	0.0	3.99798081777	4.75488750216	0.0000000000	False
view this thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
data or probability	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
probability of parameters	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
estimate the parameters	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
principle of maximum	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
maximum likelihood estimation	0.00121877978912	0.0	0.0	3.16992500144	0.0000000000	False
choose the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta that makes	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
makes the data	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
data as probable	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
theta to maximize	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
maximize the likelihood	0.00331672310923	0.0	1.99798081777	6.33985000288	0.0000000000	False
choose the parameters	0.00133440491762	0.0	0.0	1.58496250072	0.0000000000	False
parameters that make	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
define lower case	0.0	0.0	0.0	1.58496250072	0.0000000000	False
log likelihood function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	True
log of capital	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
log over product	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
bother to write	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
previous board log	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
two pi sigma	0.0	0.0	0.0	0.0	0.0000000000	False
log of explanation	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
inside the exponent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
likelihood or maximizing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the log	0.00248754233192	0.0	1.99848561333	1.58496250072	0.0000000000	False
minimizing that term	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
sign so maximizing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ve just shown	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ordinary least squares	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
maximum likelihood assuming	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
assuming this probabilistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assuming iid gaussian	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
iid gaussian errors	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll actually leave	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of sigma	0.0	0.0	2.99848561333	0.0	0.0000000000	False
matter what sigma	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
number the value	0.0	0.0	0.0	0.0	0.0000000000	False
theta we end	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta no matter	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
model the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt really matter	0.0	0.0	0.0	0.0	0.0000000000	False
matter just remember	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
couple of boards	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
questions about learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
endows linear regression	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
interpretation in order	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
order to derive	0.00191550040343	0.0	0.0	1.58496250072	0.0000000000	False
predict is continuous	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
first classification problem	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
number of discrete	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about binding	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
build a spam	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
system will crash	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algorithm to predict	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
computing cluster crash	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
problem y takes	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
binding the classification	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set i ve	0.0	0.0	0.0	0.0	0.0000000000	False
amazingly easy classification	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
easy classification problem	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
linear regression hypothesis	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
line and threshold	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
answer you predict	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
regression to classification	0.00353262325339	0.0	3.99848561333	1.58496250072	0.0000000000	False
pretty bad idea	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
idea to apply	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
change my training	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
set by giving	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
right ? imagine	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value as greater	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt really convey	0.0	0.0	0.0	0.0	0.0000000000	False
fit linear regression	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set you end	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
hypothesis have changed	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
line that pulls	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
couple of problems	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
kind of fix	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fix this problem	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
start by changing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
changing the form	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis always lies	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis predict values	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
values much larger	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choosing a linear	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
choose this function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
crosses the vertical	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
generalized linear models	0.00191550040343	1.0	0.0	3.16992500144	0.0000000000	False
naturally as part	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
class of models	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choose logistic functions	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
endow the outputs	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis is outputting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
numbers that lie	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
estimate the probability	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
simply it turns	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
equations and write	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
times one minus	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
makes the variation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
variation much nicer	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equals zero equals	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equals this thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
times this thing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
equations to gather	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hope our parameter	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
model by data	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fit the parameters	0.00165836155462	0.0	0.0	0.0	0.0000000000	False
probability of theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
dropped this theta	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
find a maximum	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
setting the parameters	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
theta that maximizes	0.00165836155462	0.0	0.0	1.58496250072	0.0000000000	False
theta it turns	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
easier to maximize	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
find the value	0.0	0.0	0.0	0.0	0.0000000000	False
maximizes this log	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
maximized this function	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
gradient descent algorithm	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
minimize the quadratic	0.00248754233192	0.0	2.99848561333	3.16992500144	0.0000000000	False
quadratic error function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function was great	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
great in descent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to maximize	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
learning rate alpha	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
rate alpha times	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
times the gradient	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
function the log	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
likelihood will respect	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
respect the theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
quadratic error term	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
error term today	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
today we re	0.0	0.0	0.0	0.0	0.0000000000	False
great in ascents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
call this gradient	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
derive gradient descent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
compute the partial	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
function with respect	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
compute this partial	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
case l theta	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
derivative with respect	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
respect to theta	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
nt terribly complicated	0.0	0.0	0.0	0.0	0.0000000000	False
interest of saving	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
saving you watching	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
couple of blackboards	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
full of math	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta as function	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algebra it turns	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
updated as theta	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
lecture ? right	0.0	0.0	0.0	0.0	0.0000000000	False
worked up bastrian	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
learning rule last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea for classification	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
bunch of math	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
skipped some steps	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
end they re	0.0	0.0	0.0	0.0	0.0000000000	False
longer theta transpose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
linear function anymore	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
bastrian descent rule	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
rule i derived	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
totally different learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk a bit	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
elegant generalized learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
generalized learning models	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
cool one last	0.0	0.0	0.0	0.0	0.0000000000	False
comment as part	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
sort of learning	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
make you sit	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
long algebraic derivation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
out the entirety	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
derivation in full	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
follow every single	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
masking machine learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
machine learning material	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
notes and read	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
understand the material	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
material my concrete	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
check every line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
advice for studying	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
studying technical material	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
material like machine	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
understood every line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
rederive the entire	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
study various pieces	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
pieces of machine	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
machine learning theory	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
study because cover	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
derivation all right	0.0	0.0	0.0	0.0	0.0000000000	False
digression to talk	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
sort of alluding	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
talk about learning	0.00147591863794	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis output values	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
perceptron algorithm defines	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function it turns	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
perceptron learning rule	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	True
classic gradient ascent	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
ascent for logistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
gradient ascent rule	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
rule for logistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
flavor of algorithm	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression and logistic	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
outputs only values	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
difficult to endow	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
endow this algorithm	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm with probabilistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
excuse me right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
cosmetically very similar	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
type of learning	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
simple learning algorithm	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
computes theta transpose	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
algorithm than logistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll do today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is show	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
video series titled	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
titled the machine	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
machine that changed	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
changed the world	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
produced wgbh television	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
television in cooperation	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
british broadcasting corporation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
aired on pbs	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
ago this shows	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
clip on perceptron	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
explore the mysterious	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
learns this perceptron	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
trained to recognize	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
recognize the difference	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
difference between males	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
males and females	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
out many complex	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
rules about faces	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
faces and writing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
writing a computer	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
simply given lots	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
lots and lots	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
lots of examples	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
beetle the computer	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
features and hair	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
outline and takes	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
longer to learn	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
taylor andrew puts	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
searching after training	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
training on lots	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
successfully distinguish male	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
male from female	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
learned all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt that great	0.0	0.0	0.0	0.0	0.0000000000	False
jump into today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s technical	0.0	0.0	0.0	0.0	0.0000000000	False
website a handout	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
sort of guidelines	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
guidelines and suggestions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
suggestions for choosing	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choosing and proposing	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
proposing class projects	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
projects so project	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
due on friday	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
month at noon	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
nt yet formed	0.0	0.0	0.0	0.0	0.0000000000	False
teams or started	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
thinking about project	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ideas of projects	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hours on friday	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
list of project	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of collected	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
senior phd students	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phd students working	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
ideas in topics	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
control so ideas	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
variety of topics	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
re having trouble	0.0	0.0	0.0	0.0	0.0000000000	False
class i mentioned	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
fun and educational	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ll also email	0.0	0.0	0.0	1.58496250072	0.0000000000	False
email everyone registered	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
details about applying	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
submit problem set	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
days for problem	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
select is based	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
based on problem	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
set one solutions	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
today is talk	0.000764797142814	0.0	0.0	1.58496250072	0.0000000000	False
methods for fitting	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
models like logistic	0.00171867221692	0.0	0.0	0.0	0.0000000000	False
talk about exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
exponential family distributions	0.0168738820455	1.0	17.9909042269	25.3594000115	0.0000000000	True
distributions and generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
generalized linear models	0.0129035568583	1.0	7.9925093633	22.1894750101	0.3734610123	True
class of ideas	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ordinary v squares	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
increasingly large amounts	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
amounts of material	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
material on probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
refresher on sort	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
foundations of probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
class in terms	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
background in probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
probability and statistics	0.00198516259359	0.0	0.0	3.16992500144	0.0000000000	False
discussion section taught	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
taught this week	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
review a probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sort of octave	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
section all right	0.0	0.0	0.0	0.0	0.0000000000	False
lecture i talked	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
logistic regression model	0.00305918857126	0.0	2.99785981808	6.33985000288	0.0000000000	False
taking the riveters	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
gradient ascent interval	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
interval for finding	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
finding the maximum	0.00138293404816	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood estimate	0.00126310390896	0.0	0.0	3.16992500144	0.0000000000	False
wrote down gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
favor a logistic	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
find the value	0.0	0.0	4.99785981808	4.75488750216	0.4171122995	False
value of theta	0.0	0.0	10.9957196362	12.6797000058	0.4180704441	False
theta that maximizes	0.00171867221692	0.0	0.0	3.16992500144	0.0000000000	False
maximizes this log	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
ascent or gradient	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
perfectly fine algorithm	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for fitting	0.00297774389038	0.0	2.99839486356	3.16992500144	0.0000000000	False
run much faster	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
faster than gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
theta is equal	0.00343734443383	0.0	5.99785981808	6.33985000288	0.5270270270	False
mass and likelihood	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
guess that works	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
find this value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value for theta	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll call theta	0.0	0.0	0.0	0.0	0.0000000000	False
call theta superscript	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
evaluate the function	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
function  hope	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hope that makes	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sense  starting	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
starting the function	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
work out nicely	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of extend	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
extend this tangent	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
intercepts the horizontal	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
call this theta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
iteration of newton	0.0	0.0	7.99732477261	7.92481250361	0.5342465753	False
call that length	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
call that capital	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
delta so capital	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
remember the definition	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
evaluated at theta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
definition of gradient	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
length a gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
function is defined	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
width of triangle	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
divided by delta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
implies that delta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
delta is equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
prime of theta	0.00732219270464	0.0	11.9967897271	7.92481250361	0.2600000000	False
theta zero minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus capital delta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
theta t minus	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
theta t divided	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for finding	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
finding a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea to maximizing	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the log	0.00171867221692	0.0	0.0	0.0	0.0000000000	False
ant to maximize	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
maximize this function	0.00229439142844	0.0	5.99839486356	4.75488750216	0.0000000000	False
maximize the function	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set the derivative	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
find the place	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
function is equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
theta one equals	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus l prime	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sort of generalizing	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
generalizing any models	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
initialize the parameters	0.000764797142814	0.0	0.0	1.58496250072	0.0000000000	False
sort of answer	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
choose too large	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
large a linear	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
rate for gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
speeds of conversions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
out that newton	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm that enjoys	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
extremely fast conversions	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
conversions the technical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
enjoys a property	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
property called conversions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method will double	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
double the number	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number of significant	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
solution is accurate	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
lots of constant	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
constant factors suppose	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
iteration your solution	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
square the error	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
result that holds	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
slightly rosier picture	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method for logistic	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
reasonable size problems	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
problems of tens	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
tens of hundreds	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hundreds of features	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
case of theta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number the generalization	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
generalization to newton	0.0	0.0	0.0	1.58496250072	0.0000000000	False
first derivative divided	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
derivative where hij	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vector of first	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
first derivatives times	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
derivatives times sort	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
thing of multiple	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number of features	0.00252620781791	0.0	3.99785981808	4.75488750216	0.0000000000	False
features and training	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
run this algorithm	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
compare to gradient	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
means far fewer	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
iterations to converge	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
disadvantage of newton	0.0	0.0	0.0	1.58496250072	0.0000000000	False
invert the hessian	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
tens of thousands	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
thousands of features	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
slightly computationally expensive	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
computationally expensive step	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm to find	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
maximum likely estimate	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
parameters for logistic	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
regression i wrote	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
maximizing a function	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method to minimize	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
minimize the function	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
talk about generalized	0.00152959428563	0.0	0.0	1.58496250072	0.0000000000	False
give a recap	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
two different algorithms	0.0	0.0	0.0	1.58496250072	0.0000000000	False
algorithms for modeling	0.000764797142814	0.0	0.0	0.0	0.0000000000	False
parameterized by theta	0.0060153527592	0.0	2.99625468165	11.094737505	0.5342465753	False
distribution of zeros	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution models random	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
models random variables	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
natural default choice	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice that lead	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithms and show	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithms called generalized	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
function will fall	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
piece of chalk	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ideas in generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of point	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
out the key	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
ideas and give	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parameterized by phi	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
equals the phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
specifies the probability	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
vary the parameter	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
vary the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set to distributions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
cost of distributions	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
nt be true	0.0	0.0	0.0	0.0	0.0000000000	False
sort of fix	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
fix the forms	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
set of distributions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distributions it defines	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
write down specific	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
true specific choices	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
gaussians are special	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
cases of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
choose specific functions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ll get gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
statistic and statistics	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sense of sufficient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
product of raw	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
first two examples	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ll do today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian are examples	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
examples of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
guess i wrote	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.00229439142844	0.0	1.99839486356	4.75488750216	0.0000000000	False
parameter of phi	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
family becomes identical	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
phi is equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
similar exponential notation	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
talked about logistic	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
regression the probability	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
compactly as phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
times one minus	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
exponentiation in taking	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
taking log cancel	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
clean another board	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
things just copying	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to log	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
solve for phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
phi  excuse	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
solve for theta	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
function of phi	0.00297774389038	0.0	1.99839486356	4.75488750216	0.0000000000	False
phi just invert	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
invert this formula	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
formula you find	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
find that phi	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
function magically falls	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
right so depends	0.0	0.0	0.0	1.58496250072	0.0000000000	False
depends on phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
definition for phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
complete  excuse	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
complete the rest	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice of functions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
probability mass function	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
expand this term	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus y times	0.00366109635232	0.0	2.99839486356	0.0	0.0000000000	False
log y minus	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
term is minus	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
log is log	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
log one minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi becomes sort	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
real number times	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
times a real	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
one-dimensional vector transposed	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vector transposed times	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
times a one-dimensional	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number times real	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
times real number	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
end of today	0.0	0.0	3.99839486356	4.75488750216	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
restricting the domain	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
takes the distribution	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distribution and invites	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
basically just write	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
out the answers	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution with sequence	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
dividing the maximum	0.00198516259359	0.0	0.0	0.0	0.0000000000	False
likelihood  excuse	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parameters of ordinary	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
squares we showed	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parameter for squared	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
divide the model	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
model for square	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
matter what square	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
taking account squared	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
make in class	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
class a bit	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
easier and simpler	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
equals one square	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
couple of steps	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
steps of algebra	0.00488146180309	0.0	3.99785981808	6.33985000288	0.4171122995	False
root two pie	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
one-half y squared	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus one-half squared	0.00366109635232	0.0	2.99839486356	4.75488750216	0.0000000000	False
equal to minus	0.000691467024078	0.0	0.0	0.0	0.0000000000	False
expresses the gaussian	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
family distribution minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution minus half	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
undergrad statistics class	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distribution it turns	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
generalization of gaussian	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
gaussian random variables	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
dimension to vectors	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vectors the normal	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
family it turns	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
out the distribution	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
ll be coin	0.0	0.0	0.0	0.0	0.0000000000	False
outcomes the models	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
modeling counts things	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number of radioactive	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number of customers	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
numbers of visitors	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
store the parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distributions are distributions	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
bus to arrive	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of gamma	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution or exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distributions over fractions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distributions over probability	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution over covariance	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
form of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distributions and write	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
derive a generalized	0.00198516259359	0.0	0.0	0.0	0.0000000000	False
chosen and exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of turn	0.00198516259359	0.0	0.0	3.16992500144	0.0000000000	False
turn a crank	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
predict is distributed	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distributed exponential family	0.00366109635232	0.0	3.99839486356	4.75488750216	0.0000000000	False
families with parameter	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
customers have arrived	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choose to model	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
model the number	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number of people	0.00198516259359	0.0	0.0	1.58496250072	0.0000000000	False
number of hits	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
website by parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution since parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution is natural	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
natural for modeling	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
modeling com data	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choose the exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
output the effective	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
set of features	0.000580894484932	0.0	0.0	1.58496250072	0.0000000000	False
estimate the expected	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
meant to write	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
learning algorithms hypothesis	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis to output	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
output the expected	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
learning algorithms output	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
assumptions this last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
parameterizing my parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
make the assumption	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
assume the relationship	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to theta	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
reason i make	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
make this design	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
turn the crank	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
model of machinery	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
fitting say parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parson regression models	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
models or performed	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
gamma distribution outputs	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
outputs or exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
exponential distribution outputs	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equals theta transpose	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
transpose x works	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number all right	0.0	0.0	0.0	0.0	0.0000000000	False
family with natural	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
algorithm will make	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.000631551954478	0.0	0.0	1.58496250072	0.0000000000	False
sort of output	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
watch our learning	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm to output	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
out the relationship	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
made the design	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
logistic regression algorithm	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
model variable distribution	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sense ? raise	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.000864723492544	0.0	0.0	3.16992500144	0.0000000000	False
decision i made	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
predict the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
automatically having made	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
made the decision	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
decision to model	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
follow a similar	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm you re	0.0	0.0	0.0	0.0	0.0000000000	False
tiny little notation	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
relates the natural	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
canonical response function	0.00366109635232	1.0	2.99839486356	3.16992500144	0.0000000000	False
canonical link function	0.00366109635232	0.0	2.99839486356	4.75488750216	0.0000000000	True
nt a huge	0.0	0.0	0.0	0.0	0.0000000000	False
terminology a lot	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
case you hear	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
talk about canonical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions or canonical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithms in machine	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
terms canonical response	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions and canonical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions in lecture	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
lecture a lot	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
big on memorizing	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
lots of names	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
names of things	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distribution and end	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ordinary squares model	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
model the problem	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
problem with gaussian	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
complex example question	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose what theory	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
model that assumes	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
assumes the probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method or gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
examples of generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
quickly and give	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
steps i skip	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
skip or details	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
magically send emails	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
right email folder	0.0	0.0	0.0	1.58496250072	0.0000000000	False
dozen email folders	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to classify	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
learning algorithm figure	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
diseases your patient	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
lots of multi-cause	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
multi-cause classification problems	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	True
find a decision	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
boundary that separates	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
entertain the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of predicting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
taking on multiple	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm will learn	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi two phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ll actually change	0.0	0.0	0.0	1.58496250072	0.0000000000	False
derive the last	0.0	0.0	0.0	0.0	0.0000000000	False
phi k minus	0.00366109635232	0.0	3.99839486356	3.16992500144	0.0000000000	False
result is over-parameterized	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
treat my parameters	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
minus one parameters	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
minus the rest	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
minus one-dimensional vectors	0.00366109635232	0.0	1.99839486356	4.75488750216	0.0000000000	False
choosing to define	0.0	0.0	0.0	1.58496250072	0.0000000000	False
point to introduce	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
piece of notation	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
indicator function notation	0.00122036545077	1.0	0.0	1.58496250072	0.0000000000	False
write a true	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
true statement inside	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
write a false	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
false statement inside	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
indicator two equals	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
statement was equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
notation for indicating	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of truth	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
truth or falsehood	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
out a bit	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
bit of space	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
denote the element	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to indicator	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
clean a couple	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
couple more boards	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
true all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
equation makes sense	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
exponential family form	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
form so pfy	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
pfy is equal	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
phi one indicator	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
indicator y equals	0.00854255815542	0.0	10.9962546816	9.50977500433	0.2276897415	False
equals one times	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
times phi two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
phi two indicator	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi k times	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi one minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi two minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi one times	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
minus one times	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
show it turns	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
write out phi	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
distributions parameters phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
phi and invert	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
earlier design choice	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice from generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vector indicator function	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equals k minus	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
vector of indicator	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions the expected	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
value of indicator	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm will output	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
output the probability	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
give this algorithm	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
generalization of logistic	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
apply softmax regression	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
wan na model	0.0	0.0	0.0	1.58496250072	0.0000000000	False
made the choice	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
set we re	0.0	0.0	0.0	0.0	0.0000000000	False
find the parameters	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
model by maximum	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
maximize the likelihood	0.00171867221692	0.0	0.0	3.16992500144	0.0000000000	False
two of indicator	0.0	0.0	0.0	0.0	0.0000000000	False
indicator yi equals	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
phi one depends	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
depends on theta	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
similarly for phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
things all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
compute a derivative	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
apply say gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ascent to maximize	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
rows of theta	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta k minus	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ve been thinking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.000631551954478	0.0	0.0	0.0	0.0000000000	False
comprising k minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus one vectors	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hard to answer	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sort of similar	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
announcement and reminder	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
handout was posted	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
website last week	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt yet downloaded	0.0	0.0	0.0	0.0	0.0000000000	False
final project presentation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
today is talk	0.00147032391634	0.0	0.0	3.16992500144	0.0000000000	False
type of learning	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
start to talk	0.000516204230291	0.0	0.0	1.58496250072	0.0000000000	False
talk about generative	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
generative learning algorithms	0.0104953165466	1.0	6.99450823764	15.8496250072	0.4473988439	True
algorithm called gaussian	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
gaussian discriminant analysis	0.017346790146	1.0	12.9895157264	30.1142875137	0.4079696395	True
talk about gaussians	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
ll briefly discuss	0.0	0.0	0.0	1.58496250072	0.0000000000	False
briefly discuss generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discuss generative versus	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
generative versus discriminative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
versus discriminative learning	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discriminative learning algorithms	0.00477059843026	0.0	3.99750374438	6.33985000288	0.0000000000	True
wrap up today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
discussion of naive	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
motivate our discussion	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
discussion on generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
source of classification	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve been talking	0.0	0.0	0.0	3.16992500144	0.0000000000	False
run an algorithm	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
find a straight	0.00286235905816	0.0	2.99850224663	0.0	0.0000000000	False
line to divide	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
divide the crosses	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make the days	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
days a bit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
line that separates	0.00147032391634	0.0	0.0	1.58496250072	0.0000000000	False
out the positive	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
pass the law	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
set with logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
initialized the parameters	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
hypothesis that iteration	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
straight line shown	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
iteration and creating	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
logistic regression converges	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
found the straight	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
separates the positive	0.00121415979624	0.0	0.0	3.16992500144	0.0000000000	False
positive and negative	0.00103240846058	0.0	0.0	1.58496250072	0.0000000000	False
classify the team	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
team malignant cancer	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
cancer and benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
meaning a harmless	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
find the straight	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
line to separate	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
cases of malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
examples of malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
build a model	0.00413018812999	0.0	1.99750374438	3.16992500144	0.3726169844	False
examples of benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
malignant or benign	0.00381647874421	0.0	2.99800299551	4.75488750216	0.0000000000	False
model of malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model of benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model it matches	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
cancer is malignant	0.0019082393721	0.0	0.0	3.16992500144	0.0000000000	False
cross of methods	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
model for malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model for benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
learns a hypothesis	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that outputs	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
algorithm in contrast	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
algorithm of models	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
generative model builds	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
builds a probabilistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
models probability distribution	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
built this model	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
built a model	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
model for pfx	0.00703846448359	0.0	1.99700449326	9.50977500433	0.3957055215	False
pfx  pfx	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
calculate the denominator	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
back to pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
model  generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
learning algorithm starts	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
starts in modeling	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model a bit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discriminant analysis model	0.00572471811631	0.0	4.99700449326	0.0	0.5308641975	False
raise your hand	0.000831216253916	0.0	0.0	3.16992500144	0.0000000000	False
words about gaussians	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
normal with parameters	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
covariance sigma squared	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
dimension of gaussians	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
familiar bell-shape curve	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
high dimension vector	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
dimension vector value	0.0	0.0	0.0	0.0	0.0000000000	False
vector value random	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
value random variable	0.00117307741393	0.0	0.0	3.16992500144	0.0000000000	False
end up needing	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
two key quantities	0.0	0.0	0.0	1.58496250072	0.0000000000	False
matrix  covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
definition of covariance	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt look familiar	0.0	0.0	0.0	0.0	0.0000000000	False
re-watch the discussion	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
tas held last	0.0	0.0	0.0	0.0	0.0000000000	False
held last friday	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll be holding	0.0	0.0	0.0	1.58496250072	0.0000000000	False
recap of probability	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussians is parameterized	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
effects of varying	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
varying a gaussian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussian  varying	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
varying the parameters	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
gaussian with covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
covariance matrix equals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equals the identity	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
identity the covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
matrix is shown	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
upper right-hand corner	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
shrink the covariance	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
covariance your identity	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
widen the covariance	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
stand at normal	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
increase the diagonals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make the variables	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
gaussian becomes flattened	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
right  excuse	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll just show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
thing in contours	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
contours the standard	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
normal of distribution	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
distribution has contours	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
re actually circles	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian covariance matrix	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
density with negative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
strong of covariance	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussian with negative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
gaussian just moves	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
described the gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
discriminant analysis algorithm	0.0019082393721	0.0	0.0	0.0	0.0000000000	False
fit a gaussian	0.0035192322418	0.0	3.99850224663	3.16992500144	0.0000000000	False
two gaussian densities	0.0	0.0	0.0	3.16992500144	0.0000000000	False
densities will define	0.0	0.0	0.0	0.0	0.0000000000	False
define a separator	0.0	0.0	0.0	1.58496250072	0.0000000000	False
separator will turn	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
run logistic regression	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
back to chalkboard	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
put into model	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
bernoulli random variable	0.00286235905816	0.0	3.99850224663	4.75488750216	0.0000000000	False
variable as usual	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
variable and parameterized	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
parameterized by parameter	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
thought this looked	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
listing the sigma	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
determining the sigma	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
mew0 and covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model are phi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
probabilities of pfxi	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
equations on top	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
joint data likelihood	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	True
talking about logistic	0.000826037625999	0.0	0.0	0.0	0.0000000000	False
parameter s theater	0.0	0.0	0.0	0.0	0.0000000000	False
theater was log	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
re fitting logistic	0.0	0.0	0.0	0.0	0.0000000000	False
fitting logistic regression	0.000664673313974	0.0	0.0	0.0	0.0000000000	False
logistic regression models	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
models or generalized	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
generalized learning models	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
re always modeling	0.0	0.0	0.0	0.0	0.0000000000	False
re modeling pfyi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
regenerative learning algorithms	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	True
model to fit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
fit the parameters	0.002478112878	0.0	1.99850224663	3.16992500144	0.0000000000	False
ll do maximize	0.0	0.0	0.0	0.0	0.0000000000	False
maximize likelihood estimation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
estimation as usual	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
find the maximum	0.000664673313974	0.0	0.0	0.0	0.0000000000	False
maximum likelihood estimate	0.0145699175548	0.0	15.988017973	36.4541375166	0.2927066451	False
estimate of parameters	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
find that phi	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
practice for indicating	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
estimate for phi	0.00469230965573	0.0	3.99800299551	0.0	0.5243902439	False
alternatively as sum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
examples of indicator	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
newly parameter phi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
faction of training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
examples with label	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
estimate for mew0	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	3.16992500144	0.0000000000	False
denominator is sum	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
increment the count	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
number of examples	0.00220548587451	0.0	1.99850224663	3.16992500144	0.0000000000	False
indicator function means	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
negative fitting examples	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
examples and average	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
average the values	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
home and stare	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
divide the maximum	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
estimate for sigma	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
parameters find mew0	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make a prediction	0.000607079898118	0.0	0.0	1.58496250072	0.0000000000	False
benign your prediction	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
semicolon the parameters	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll just give	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pfy is uniform	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
give us arc	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
means the value	0.0	0.0	0.0	0.0	0.0000000000	False
choosing x equals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
squared is equal	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
makes this minimize	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
uniform i meant	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
meant if pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal to pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
turns out gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
out gaussian discriminant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
relationship to logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
draw 1d training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
kind of work	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
training set comprising	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
run gaussian discriminate	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll fit gaussians	0.0	0.0	0.0	1.58496250072	0.0000000000	False
negative training examples	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
overlay on top	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
variety of values	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
makes this part	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
formulas as usual	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.00147032391634	0.0	0.0	3.16992500144	0.0000000000	False
phi on pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
compute what pfy	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
increment the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
densities have equal	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
bunch more points	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
repeat this exercise	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
bunch of points	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
points all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
compute pfy equals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
takes a form	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
form of sigmoid	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
make the assumptions	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
back and compute	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
out the key	0.000826037625999	0.0	0.0	0.0	0.0000000000	False
analysis will end	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
end up choosing	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
gaussian of pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussian is pfx	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
draw each dot	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll also fit	0.0	0.0	0.0	1.58496250072	0.0000000000	False
fit a bernoulli	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
distribution to pfy	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll fit pfx	0.0	0.0	0.0	1.58496250072	0.0000000000	False
chosen my parameters	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
parameters of find	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
pick a point	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
advantages and disadvantages	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
case of gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
argument i showed	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
back and prove	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
write logistic posterior	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
home and prove	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
form of pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
out this implication	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
cool it turns	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
hessian with parameter	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
implies that pfy	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
lots of assumptions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lead to pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
logistic posterior holds	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
tradeoffs between gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
analysis and logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
right ? gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
discriminant analysis makes	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
assumption is true	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumption approximately holds	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
plot the data	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
make this assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
algorithm is making	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data the algorithm	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data is gaussian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data was gaussian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
out the data	0.00117307741393	0.0	2.99850224663	3.16992500144	0.0000000000	False
out the real	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
advantage of generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
requires less data	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
making stronger assumptions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data in order	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
order to fit	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
regression by making	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
making less assumption	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
making a weaker	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
slightly larger training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
larger training set	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
set to fit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
fit than gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discriminant analysis question	0.0	0.0	0.0	0.0	0.0000000000	False
order to meet	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
meet any assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assume that pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal two number	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
number of samples	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
samples is marginal	0.0	0.0	0.0	1.58496250072	0.0000000000	False
translate that differently	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumptions are made	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
random variables flowing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
giving a single	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
single training set	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
philosophy of mass	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
mass molecular estimation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pfy is equal	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
values of phi	0.00234615482786	0.0	9.99750374438	4.75488750216	0.3440000000	False
true underlying value	0.00117307741393	0.0	7.99800299551	6.33985000288	0.2935153584	False
phi that guards	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
generate the data	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
writing those formulas	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
formulas are writing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
writing for phi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
right so maximum	0.0	0.0	0.0	0.0	0.0000000000	False
attempt to estimate	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
estimate the true	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
notational and convention	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
bothering to distinguish	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hoping to estimate	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
sample of questions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
hope to tease	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
friday discussion section	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
family with parameter	0.0019082393721	0.0	0.0	0.0	0.0000000000	False
cool it means	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
ve seen gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
exponential they re	0.0	0.0	0.0	0.0	0.0000000000	False
list of exponential	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
exponential family extrusions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
exponential family distribution	0.0019082393721	0.0	0.0	1.58496250072	0.0000000000	False
shows the robustness	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
robustness of logistic	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
choice of modeling	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
regression to modeling	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
promised two justifications	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pulled the logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
exponential family derivation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumptions also lead	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
family distribution implies	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
rise to logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
first generative learning	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
naive bayes algorithm	0.0035192322418	1.0	1.99850224663	4.75488750216	0.0000000000	True
classification all right	0.0	0.0	0.0	0.0	0.0000000000	False
build a spam	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
stream of email	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
email and decide	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
piece of email	0.00858707717447	0.0	8.99550673989	14.2646625065	0.3900226757	False
represent a piece	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
piece of text	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
right ? email	0.0	0.0	0.0	1.58496250072	0.0000000000	False
list of words	0.00703846448359	0.0	8.99650524214	11.094737505	0.0000000000	False
list of ascii	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
feature of vector	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
ll use today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
construct the vector	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make a listing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
dictionary is aardvark	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
word  buy	0.0	0.0	0.0	1.58496250072	0.0000000000	False
spam email telling	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
collect your list	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt find cs229	0.0	0.0	0.0	0.0	0.0000000000	False
collect a list	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
emails you ve	0.0	0.0	0.0	0.0	0.0000000000	False
dictionary was zicmergue	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
chemistry that deals	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
process in brewing	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll then scan	0.0	0.0	0.0	1.58496250072	0.0000000000	False
word  aid	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ausworth or aardvark	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
creating a feature	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
vector to represent	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
throw the generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
binary value vectors	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
vectors they re	0.0	0.0	0.0	0.0	0.0000000000	False
re n dimensional	0.0	0.0	0.0	1.58496250072	0.0000000000	False
atypical so values	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
mid-thousands to tens	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
tens of thousands	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
typical for problems	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
50,000 possible values	0.0019082393721	0.0	0.0	3.16992500144	0.0000000000	False
50,000 possible bit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
vectors of length	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
parameters to model	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumption on pfx	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
rule of probability	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll just put	0.0	0.0	0.0	0.0	0.0000000000	False
holds i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve not made	0.0	0.0	0.0	1.58496250072	0.0000000000	False
made any assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
naive bayes assumption	0.0035192322418	0.0	2.99850224663	4.75488750216	0.0000000000	False
assume that pfx3	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal to pfx2	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
term s equal	0.0	0.0	0.0	0.0	0.0000000000	False
equal to pfx3	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assume that pfx1	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
50,000 or pfxi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
appears in email	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
affect the probability	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
word  ausworth	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ausworth  appears	0.0	0.0	0.0	1.58496250072	0.0000000000	False
email is spam	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
assumption is false	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
possibly be true	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
false under english	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
normal written english	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
extremely effective algorithm	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for classifying	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
classifying text documents	0.0019082393721	0.0	0.0	3.16992500144	0.0000000000	False
documents into spam	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
classifying your emails	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pages and classifying	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
talk a bit	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
ll make sense	0.0	0.0	0.0	1.58496250072	0.0000000000	False
familiar with bayesian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
bayesian x world	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
expect maximum likelihood	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
entire training set	0.000735161958171	0.0	0.0	1.58496250072	0.0000000000	False
number of times	0.000607079898118	0.0	0.0	1.58496250072	0.0000000000	False
word  jay	0.0	0.0	7.99800299551	6.33985000288	0.2935153584	False
emails and count	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
count the number	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
number of emails	0.00117307741393	0.0	0.0	3.16992500144	0.0000000000	False
jay  appeared	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of spam	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
spam the denominator	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
jay  conditions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
email being spam	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
number of inputs	0.00117307741393	0.0	0.0	3.16992500144	0.0000000000	False
number of features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of training	0.00220548587451	0.0	5.99850224663	1.58496250072	0.0000000000	False
compute the maximum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
estimates is training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
email i ve	0.0	0.0	0.0	0.0	0.0000000000	False
last two months	0.0	0.0	3.99850224663	3.16992500144	0.0000000000	False
months and label	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
hundred emails labeled	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
labeled as spam	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
comprise your training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
representing which words	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
re different things	0.0	0.0	0.0	1.58496250072	0.0000000000	False
making the naive	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
write the maximum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
count this list	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
count a list	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
set so words	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
tests i ve	0.0	0.0	0.0	0.0	0.0000000000	False
select these features	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
creating your feature	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
parameters ? correct	0.0	0.0	0.0	1.58496250072	0.0000000000	False
generous of learning	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
bullets my model	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
assume that pfx	0.00117307741393	0.0	1.99850224663	4.75488750216	0.0000000000	False
defined the feature	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
constructed my features	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
features for email	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
idea almost works	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
complete this class	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
submit your class	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
june every year	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
send your project	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
partners or senior	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
project and submit	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
word  nips	0.0	0.0	0.0	1.58496250072	0.0000000000	False
send a paper	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
compute this right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the denominator	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
statistically a bad	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
worth of email	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
statistically not sound	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nips in future	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
motivate the fix	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
stanford basketball team	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
tracking their wins	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
wins and losses	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
losses to gather	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
form a betting	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
win or lose	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
8th of february	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
february last season	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
season they played	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
played washington state	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
11th of february	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
22nd they played	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
lose against louisville	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
four guys last	0.0	0.0	0.0	0.0	0.0000000000	False
guys last year	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
idea behind laplace	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
number of zeros	0.0035192322418	0.0	5.99850224663	4.75488750216	0.0000000000	False
hope this informal	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
informal notation makes	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
notation makes sense	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
right ? knowing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
knowing the maximum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
win or loss	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
loss for bernoulli	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
smoothing we re	0.0	0.0	0.0	0.0	0.0000000000	False
zeros and add	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
estimating the probability	0.002478112878	0.0	7.99800299551	6.33985000288	0.4154589372	False
probability of winning	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
historical side note	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
sun will rise	0.0035192322418	0.0	5.99850224663	0.0	0.0000000000	False
lot of days	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
estimate the parameter	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
apply laplace smoothing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
numerator and adding	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
solves the problem	0.000735161958171	0.0	0.0	1.58496250072	0.0000000000	False
sends you email	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
make a meaningful	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
shoot any questions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt makes sense	0.0	0.0	0.0	0.0	0.0000000000	False
case the prediction	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lose five games	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lot of faith	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lose one game	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
chances of winning	0.00469230965573	0.0	7.99800299551	6.33985000288	0.2544378698	False
instance we re	0.0	0.0	0.0	0.0	0.0000000000	False
set of assumptions	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
set of bayesian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
prior and posterior	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pretty reasonable assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pretty good basketball	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
good basketball team	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
chose a losing	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
morning welcome back	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
announcement for today	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
tutorial on matlab	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
matlab and octaves	0.00198039004665	0.0	0.0	3.16992500144	0.0000000000	False
matlab or octave	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
terms and matlab	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
today is continue	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
continue our discussion	0.000762958487242	0.0	0.0	1.58496250072	0.0000000000	False
started to discuss	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
lecture and talk	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
digression to talk	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
talk about neural	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
spend a lot	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
start to talk	0.00107144390232	0.0	0.0	3.16992500144	0.0000000000	False
talk about support	0.00198039004665	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.00811297131912	1.0	12.9927045336	20.6045125094	0.4389721627	True
supervised learning algorithm	0.00198039004665	0.0	0.0	1.58496250072	0.0000000000	False
off-the-shelf supervised learning	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
algorithm that point	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
point of view	0.0017384938541	0.0	1.99843668577	4.75488750216	0.0000000000	False
view is debatable	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
people that hold	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hold that point	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ll start discussing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
discussing that today	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lectures to complete	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
bayes to recap	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
started off describing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
describing spam classification	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
create feature vectors	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
correspond to words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
piece of email	0.00594117013994	0.0	6.99687337155	9.50977500433	0.4572490706	False
email were represented	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
generative learning algorithm	0.00297058506997	1.0	3.99843668577	4.75488750216	0.0000000000	True
rule is rfx	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
number of words	0.00396078009329	0.0	4.99791558103	6.33985000288	0.5256410256	False
describe two variations	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
algorithm the first	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
bayes to problems	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
model where pfx	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
values it turns	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
choose to dispertise	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
continuous value feature	0.00365229467821	0.0	2.99843668577	4.75488750216	0.0000000000	False
feature and dispertise	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
first supervised learning	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
supervised learning problem	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
problem of predicting	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
predicting the price	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
price of houses	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
based on features	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
pretty common thing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
continuous value living	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
value living area	0.0	0.0	0.0	0.0	0.0000000000	False
2,000 square feet	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
choose the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
variation or generalization	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
bayes i wanted	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
wanted to talk	0.0012174315594	0.0	1.99843668577	4.75488750216	0.0000000000	False
buckets to dispertise	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
dispertise a continuous	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
feature i drew	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
save on writing	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
specific to classifying	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
classifying text documents	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
sequence of words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
describe to classifying	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
classifying other sequences	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
focus on text	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
binary vector value	0.0	0.0	0.0	0.0	0.0000000000	False
vector value representation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
number of times	0.0031501681742	0.0	3.99739447629	6.33985000288	0.3734061931	False
appears a lot	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lot of times	0.00160716585348	0.0	4.99843668577	4.75488750216	0.0000000000	False
word  viagra	0.0	0.0	0.0	1.58496250072	0.0000000000	False
viagra a ton	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ton of times	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
account the number	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
times a word	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
give this previous	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
model for text	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
multivariate bernoulli event	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
bernoulli event model	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
means it refers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
multiple bernoulli random	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
bernoulli random variables	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
means in contrast	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
representation for email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
email in terms	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
multinomial event model	0.00486972623762	0.0	5.99739447629	7.92481250361	0.3734061931	True
represent my email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
represent this email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
vector  lets	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
variable that takes	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
50,000 possible values	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
longer binary random	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
binary random variables	0.0	0.0	0.0	0.0	0.0000000000	False
re these indices	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of values	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
distribution over emails	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
distribution that generates	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
generates the emails	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
first the class	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
send you spam	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
emails is chosen	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
label of spam	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
spam is generated	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
distribution that depends	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
chose to send	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
send you words	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
tend to generate	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
previous event model	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
deciding to spend	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
spend you spam	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
word they choose	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
choose to email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the maximum	0.00198039004665	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood estimates	0.00693036998325	0.0	13.9937467431	19.0195500087	0.2979651163	True
big indicator function	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
indicator function things	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
training sets indicator	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
times the sum	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
words in email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times indicator xij	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
numerator says sum	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times you observed	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
observed the word	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
set and count	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
times the word	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
word k appeared	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
email the denominator	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
examples is spam	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
fraction of words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
piece of spam	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
spam mail generating	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
generating the word	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
talked about laplace	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
laplace smoothed estimate	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
out the estimates	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
essentially the identity	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
realized that overload	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
overload the notation	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
re absolutely right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
great i stole	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
translate it properly	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
properly so laplace	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.000862644603151	0.0	0.0	1.58496250072	0.0000000000	False
number of values	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
method to give	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
estimate the probability	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
multinomial random variable	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
number of observations	0.00365229467821	0.0	2.99843668577	3.16992500144	0.0000000000	False
observations the maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
equals k divided	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
add laplace smoothing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
examples make sense	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
definition of maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
definition for maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
talk about gaussian	0.00198039004665	0.0	0.0	0.0	0.0000000000	False
gaussian discriminant analysis	0.00257181051277	1.0	4.99843668577	3.16992500144	0.0000000000	True
board without proving	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
writing log likelihood	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ll just drop	0.0	0.0	0.0	1.58496250072	0.0000000000	False
drop the parameters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
parameters to write	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
fixed training set	0.00396078009329	0.0	5.99791558103	6.33985000288	0.5061728395	False
set of fixed	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ve been writing	0.0	0.0	0.0	0.0	0.0000000000	False
section of today	0.0	0.0	0.0	0.0	0.0000000000	False
lecture i wrote	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
out some maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
discriminant analysis model	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
maximize the likelihood	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
likelihood and maximize	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
maximize the log	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
cool all right	0.0	0.0	0.0	3.16992500144	0.0000000000	False
model i presented	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
model i talked	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
specific of text	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
reasons is hypothesized	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
takes into account	0.0012174315594	0.0	5.99687337155	9.50977500433	0.4572490706	False
model does nt	0.0	0.0	0.0	0.0	0.0000000000	False
text classification problem	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
straightforward to implement	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
positioning a variant	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
nt actually care	0.0	0.0	0.0	0.0	0.0000000000	False
natural language processing	0.00198039004665	0.0	0.0	3.16992500144	0.0000000000	False
unique grand model	0.0012174315594	1.0	0.0	1.58496250072	0.0000000000	False
model in natural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
higher order markup	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
order markup models	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
words it turns	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
models or trigram	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
discussion of non-linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
first classification algorithm	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
algorithm we talked	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
form for hypothesis	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
probability is greater	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
greater or equal	0.00171454034184	0.0	0.0	3.16992500144	0.0000000000	False
right ? logistic	0.0	0.0	0.0	0.0	0.0000000000	False
grade and descends	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
method to find	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
find a straight	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
separates the positive	0.000630033634841	0.0	0.0	1.58496250072	0.0000000000	False
positive and negative	0.000535721951161	0.0	0.0	0.0	0.0000000000	False
nt be separated	0.0	0.0	0.0	0.0	0.0000000000	False
start to learn	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
learn these sorts	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
sorts of non-linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
non-linear division boundaries	0.00486972623762	0.0	1.99739447629	6.33985000288	0.0000000000	True
talked about generative	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
build a generative	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
family with natural	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
model actually falls	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
taking a simpler	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
algorithm like logistic	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
complex non-linear classifiers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
motivate this discussion	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
follow our earlier	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
denote our logistic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
logistic regression unit	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
circle as denoting	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
denoting a computation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
note that takes	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
takes this input	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
outputs another number	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
output non-linear division	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
put a bunch	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
output my final	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
output h subscript	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
give these things	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
call the values	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
intermediate sigmoidal units	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.00189010090452	0.0	1.99843668577	4.75488750216	0.0000000000	False
write as theta	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hypothesis will output	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
equals one-half sum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
minus h subscript	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
familiar quadratic cost	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
quadratic cost function	0.00243486311881	0.0	0.0	1.58496250072	0.0000000000	False
learn the parameters	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
interscent to minimize	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
function of theta	0.000762958487242	0.0	0.0	1.58496250072	0.0000000000	False
phi gradient descent	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
descent to minimize	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
minimize this square	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
stated differently means	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
descent to make	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make the predictions	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
network as close	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
turns out green	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
out green descent	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
algorithm that implements	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
implements grand descent	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
means gradient interscent	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
advantages and disadvantages	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
notes are computing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
layers of computation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hidden unit computing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
computing the neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
sense of neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
show a video	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
video from yann	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
developed for hammerton	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hammerton digit recognition	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
convolutional neural network	0.0012174315594	1.0	0.0	1.58496250072	0.0000000000	False
display ? hum	0.0	0.0	0.0	0.0	0.0000000000	False
things about neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
write a quadratic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
out that unlike	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
unlike logistic regression	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
respond to non-convex	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
non-convex optimization problem	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
run gradient descent	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
descent or newton	0.0	0.0	0.0	0.0	0.0000000000	False
converse the global	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
true for neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
networks in general	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
lots of local	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
harder optimization problem	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
problem so neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
good at making	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
making design choices	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
majority of machine	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
machine learning researchers	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
learning researchers today	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
perceive support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
effective off-the-shelf learning	0.00365229467821	0.0	0.0	0.0	0.0000000000	False
off-the-shelf learning algorithm	0.00365229467821	0.0	1.99843668577	1.58496250072	0.0000000000	True
algorithm than neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
networks this point	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
view is contested	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
contested a bit	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hard optimization problem	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
sort of works	0.00198039004665	0.0	0.0	1.58496250072	0.0000000000	False
effective learning algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
algorithm before support	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
machines were invented	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lecun s video	0.0	0.0	0.0	0.0	0.0000000000	False
trained neural network	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
pointer is pointing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
showing the neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
network this image	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
final answer output	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
network correctly recognizes	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
recognizes this image	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
showing the intermediate	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
neural network computing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
edges into digits	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
re just computing	0.0	0.0	0.0	0.0	0.0000000000	False
play this video	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
inputs and outputs	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
robustness to noise	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
noise all right	0.0	0.0	0.0	0.0	0.0000000000	False
right multiple digits	0.0	0.0	0.0	1.58496250072	0.0000000000	False
machine that changed	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
changed the world	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
produced by wgbh	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
television in corporation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
corporation with british	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
british foreclass incorporation	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
aired on pbs	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
describing the nettalk	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
nettalk neural network	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
developed by terry	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
history of neural	0.00365229467821	0.0	3.99843668577	0.0	0.0000000000	False
network to read	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
show a piece	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
piece of english	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
verbally produce sounds	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
history of machine	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
created a lot	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lot of excitement	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
excitement about neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
machine learning part	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
foresight to choose	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
child-like voice talking	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
talking about visiting	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
visiting your grandmother	0.0	0.0	0.0	1.58496250072	0.0000000000	False
grandmother s house	0.0	0.0	0.0	0.0	0.0000000000	False
created the perception	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
created the impression	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
young child learning	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
generate a lot	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
excitement within academia	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
academia on neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
sound like words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
sound like attempts	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
computer s voice	0.0	0.0	0.0	0.0	0.0000000000	False
takes the letters	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
makes a random	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
attempt at pronouncing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
house the phonetic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
house by adjusting	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
adjusting the connection	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
net slowly improves	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
letting it train	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
morning it sounds	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
simply associating letters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
letters with sounds	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
piece of work	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
text to speech	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
systems that work	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
bit less impressive	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
impressive than talking	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
dow jones falling	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
wanted to show	0.0012174315594	0.0	0.0	3.16992500144	0.0000000000	False
discussion on neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
started off talking	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
networks by motivating	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
output non-linear classifiers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
nt really approve	0.0	0.0	0.0	0.0	0.0000000000	False
chalkboard earlier support	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
earlier support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
progression and development	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
class of linear	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
classifiers with linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
linear division boundaries	0.000990195023323	0.0	2.99687337155	9.50977500433	0.0000000000	False
vector machine idea	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make it work	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
generate non-linear division	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ll actually start	0.0	0.0	0.0	1.58496250072	0.0000000000	False
start by talking	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
talking about linear	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
convey two intuitions	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
intuitions about classification	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
outputting the probability	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
crosses this line	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
run logistic regression	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that computes	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
computes theta transpose	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
right ? iff	0.0	0.0	0.0	0.0	0.0000000000	False
case that theta	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
greater than sign	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
re very confident	0.0	0.0	0.0	3.16992500144	0.0000000000	False
fit logistic regression	0.000689804662093	0.0	0.0	1.58496250072	0.0000000000	False
find parameters theta	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
makes correct classifications	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
talk about functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
rest of today	0.0012174315594	0.0	3.99843668577	4.75488750216	0.0000000000	False
separate your training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
remove this assumption	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
develop the algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
linearly separable training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
separable training set	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lines that separate	0.000762958487242	0.0	0.0	1.58496250072	0.0000000000	False
separate the training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
separates the data	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
examples and division	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
line this notion	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
notion of distance	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
talk about geometric	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
order to describe	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
describe support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
pull a notation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
completely consistent notation	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
slightly for linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
easier later today	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
week s lectures	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis output values	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
previously i wrote	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
wrote g subscript	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
drop this convention	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
convention of letting	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
parameterize my linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
plays the role	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
role of theta	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
out the interceptor	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make it easier	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
develop support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
formalize the notion	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
notion of functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
margin and germesh	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make a definition	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
defined as gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hat i equals	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
equals yi times	0.00365229467821	0.0	2.99843668577	4.75488750216	0.0000000000	False
times w transpose	0.00365229467821	0.0	3.99843668577	4.75488750216	0.0000000000	False
defines a classifier	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
defines a linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
linear separating boundary	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hyper plane term	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
classifier with parameters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
large functional margin	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
margins to large	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
equal to minus	0.00137960932419	0.0	0.0	3.16992500144	0.0000000000	False
captures the intuition	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
earlier about functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
large and notice	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
means we classified	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
plane with respect	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
entire training set	0.00305183394897	0.0	3.99791558103	6.33985000288	0.0000000000	False
equal to min	0.000990195023323	0.0	5.99843668577	4.75488750216	0.0000000000	False
examples of gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
define the functional	0.0	0.0	0.0	0.0	0.0000000000	False
margin with respect	0.00365229467821	0.0	4.99843668577	3.16992500144	0.0000000000	False
worst-case functional margin	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
easy to make	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
make the functional	0.00365229467821	0.0	2.99843668577	0.0	0.0000000000	False
functional margin large	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
times w times	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
double my functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
goal of making	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
margin arbitrarily large	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
scaling other parameters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
add a normalization	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
plane w transpose	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
deliberately few training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
assuming we classified	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
define the geometric	0.000990195023323	0.0	5.99791558103	0.0	0.3445378151	False
separating hyper plane	0.0109568840346	0.0	11.9953100573	12.6797000058	0.2810357959	False
algebra fairly quickly	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
quickly in case	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
carefully for details	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
planes and high	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
high dimensions work	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
distance is gamma	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
put a hat	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hat on top	0.00198039004665	0.0	0.0	3.16992500144	0.0000000000	False
referring to functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
top for geometric	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
gamma i times	0.00486972623762	0.0	3.99791558103	4.75488750216	0.2939068100	False
length one vector	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times the unit	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
minus this vector	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
vector is gamma	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
point must satisfy	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
satisfy w transpose	0.00243486311881	0.0	0.0	1.58496250072	0.0000000000	False
times that point	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
hyper plane satisfy	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
satisfy the equation	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
equation w transpose	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
transpose this point	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
solve for gamma	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
solve this equation	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
equation for gamma	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
gamma or gamma	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
equation from gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
equal to gamma	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
times the norm	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
transpose x equals	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
calculation just showed	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hyper plane defined	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
account the sign	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ve been assuming	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ve been classifying	0.0	0.0	0.0	1.58496250072	0.0000000000	False
find the geometric	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
gamma i equals	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times that thing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
thing on top	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
couple of easy	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
margin is equal	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
functional margin divided	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
set as gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
gamma equals min	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
maximum margin classifier	0.00365229467821	0.0	5.99843668577	3.16992500144	0.0000000000	False
algorithm that chooses	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
chooses the parameters	0.000689804662093	0.0	0.0	1.58496250072	0.0000000000	False
maximize the geometric	0.00297058506997	0.0	5.99843668577	0.0	0.0000000000	False
margin classified poses	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ways to write	0.0012174315594	0.0	0.0	3.16992500144	0.0000000000	False
maximizing your classifier	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
problem over parameter	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
nt change depending	0.0	0.0	0.0	0.0	0.0000000000	False
set the norm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
change the geometric	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
impose any normalization	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
factor and replace	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
impose a constraint	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
ll say maximize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
geometric margins subject	0.00243486311881	0.0	0.0	1.58496250072	0.0000000000	False
maximize gamma subject	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
margin are identical	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
comparable to logistic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
develop this algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
change this algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
work in infinite	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.000689804662093	0.0	0.0	0.0	0.0000000000	False
dimensional feature spaces	0.000689804662093	0.0	0.0	0.0	0.0000000000	False
efficient non-linear classifiers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
right next week	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talk about authorization	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
octaves so show	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
taking the classes	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
process solutions due	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
due this wednesday	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
fax the solutions	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
fax number written	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
takes me longer	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
turn in hard	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
physical paper copies	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solutions from set	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
re an scpd	0.0	0.0	0.0	0.0	0.0000000000	False
proposals are due	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
due this friday	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
last few office	0.0	0.0	0.0	0.0	0.0000000000	False
discussions with people	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
people about ideas	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ideas this wednesday	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
immediately after class	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
right after class	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll be holding	0.0	0.0	0.0	1.58496250072	0.0000000000	False
holding extra office	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
extra office hours	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hours in case	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
discuss project ideas	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
due on friday	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
today is continue	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
continue our discussion	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
discussion on support	0.000861790545327	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.00640809000136	1.0	5.99413958444	15.8496250072	0.4401805869	True
wan na talk	0.0	0.0	0.0	3.16992500144	0.0000000000	False
optimal margin classifier	0.00995416308737	0.0	5.99467234949	14.2646625065	0.5492957746	True
digression and talk	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
talk about primal	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
primal and duo	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
duo optimization problems	0.0110146595409	0.0	5.99520511454	12.6797000058	0.3979591837	True
derive the duo	0.00367155318031	0.0	1.99840170485	3.16992500144	0.0000000000	False
discussion of kernels	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
part of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
talking about optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
justice i wan	0.0	0.0	0.0	0.0	0.0000000000	False
talk about convex	0.00199083261747	0.0	0.0	0.0	0.0000000000	False
week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
teach a discussion	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
session  focus	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
focus on convex	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
optimization  sort	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
friday s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
beginning on developing	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
developing on support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
development of support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
change the convention	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
convention of letting	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
note the class	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
labels so last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
large positive number	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
classifying a training	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
large negative number	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
increase functional margin	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
taking your parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
defined the geometric	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
functional margin divided	0.00497708154369	0.0	6.99733617475	7.92481250361	0.3255425710	False
examples the geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
reaching the point	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
reaching the training	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
re separating hyperplane	0.0	0.0	0.0	3.16992500144	0.0000000000	False
hyperplane is defined	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
equation w transpose	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
guess also defined	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
defined these things	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
respect to training	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
set i defined	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
minimum functional geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
functional geometric margin	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
algorithm would choose	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximize the geometric	0.00199083261747	0.0	0.0	0.0	0.0000000000	False
find the separating	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hyperplane that separates	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
separates the positive	0.00126671158792	0.0	0.0	3.16992500144	0.0000000000	False
positive and negative	0.00323128083604	0.0	3.9968034097	6.33985000288	0.3979591837	False
large a distance	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
multiply my parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
change my geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
line you re	0.0	0.0	0.0	0.0	0.0000000000	False
separating by positive	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
negative training examples	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
change the position	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
choose whatever scaling	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find a solution	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
rescaling the parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
meet this condition	0.00367155318031	0.0	5.99840170485	3.16992500144	0.0000000000	False
add the condition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
essentially not change	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
change the problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
add other conditions	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
add a condition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find the absolute	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
ensure you meet	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ability to choose	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
choose any scaling	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
attempt at writing	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem actually wrote	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
previous lecture begin	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
begin to solve	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solve the parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
choose to add	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
add this normalization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
makes the geometric	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find a value	0.0	0.0	0.0	3.16992500144	0.0000000000	False
value for gamma	0.0012238510601	0.0	3.99840170485	4.75488750216	0.0000000000	False
gamma as big	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
examples have functional	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
functional margin greater	0.00298624892621	0.0	3.99840170485	4.75488750216	0.0000000000	False
constraint that normal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
normal w equals	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
margin and geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
find the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
margins are greater	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
greater or equal	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
equal to gamma	0.00298624892621	0.0	1.99840170485	1.58496250072	0.0000000000	False
solve this optimization	0.00344716218131	0.0	1.9978689398	0.0	0.5270270270	False
derived the optimal	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
nice optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solve for parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization problem	0.00344716218131	0.0	4.9978689398	4.75488750216	0.0000000000	False
change the optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
slightly different optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximize the functional	0.00489540424041	0.0	3.9978689398	0.0	0.3451327434	False
normal w subject	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
find a number	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
examples has functional	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
gamma hat divided	0.00367155318031	0.0	2.99840170485	1.58496250072	0.0000000000	False
wan na maximize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
previously the function	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
optimization problem confused	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
margin y divided	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin is divided	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
end up dividing	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
stage the functional	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem where gamma	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
convex optimization software	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
optimization software solves	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solves this problem	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.00126671158792	0.0	0.0	1.58496250072	0.0000000000	False
imposing the constraint	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
greater than gamma	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
greater than equal	0.00126671158792	0.0	0.0	3.16992500144	0.0000000000	False
gamma or gamma	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
respect to gamma	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
problem in order	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
order to solve	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
hat the function	0.0012238510601	0.0	5.99733617475	6.33985000288	0.0000000000	False
previous mathematical definition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization solvers	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
software for solving	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solving convex optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
software to find	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
find me values	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
make this value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value as big	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose for gamma	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
maximize gamma hat	0.00367155318031	0.0	1.99840170485	1.58496250072	0.0000000000	False
choose to make	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hat as big	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
smallest functional margin	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
value of gamma	0.0	0.0	0.0	1.58496250072	0.0000000000	False
class of data	0.00367155318031	0.0	2.99840170485	0.0	0.0000000000	False
maximize the distance	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find separate hyperplane	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find a line	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
repeating the questions	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
questions in case	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
line that separates	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the worst-case	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
formulate this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.0013007899753	0.0	2.99840170485	4.75488750216	0.0000000000	False
formulation makes sense	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ve now added	0.0	0.0	0.0	1.58496250072	0.0000000000	False
added a nasty	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
function in parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
fairly bizarre scaling	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
bizarre scaling constraints	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
purposes of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
impose a constraint	0.00298624892621	0.0	5.99840170485	4.75488750216	0.0000000000	False
margin is equal	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
constraint that min	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
worst-case function margin	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
constraint would imply	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin be equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
previous optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem and add	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
add the scaling	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximization over gamma	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
minimizing the normal	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
normal w squared	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
great maximum normal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
added the constraint	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin classifier problem	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
pictures can draw	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
minimize the quadratic	0.000861790545327	0.0	0.0	0.0	0.0000000000	False
number of linear	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
constraints that eliminates	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
space or linear	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
linear constraint eliminates	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
out various half	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
guess kinda draw	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
set of points	0.000633355793961	0.0	0.0	1.58496250072	0.0000000000	False
margin classifier algorithm	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem and throw	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
quadratic program software	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
software this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
quadratic convex objective	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
convex objective function	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
function and constraints	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
software to solve	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solve these optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
digression to talk	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
back and derive	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
out this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
properties that make	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
make it amenable	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ll be deriving	0.0	0.0	0.0	1.58496250072	0.0000000000	False
apply the optimal	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
high-dimensional feature spaces	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.000693441993058	0.0	0.0	0.0	0.0000000000	False
dimensional feature spaces	0.000693441993058	0.0	0.0	1.58496250072	0.0000000000	False
remember the method	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
method of lagrange	0.00734310636061	0.0	7.9968034097	0.0	0.2600000000	False
multipliers for solving	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solving an optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem like minimum	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
minimum  minimization	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
maximization problem subject	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
set of constraints	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
vector value function	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
arrow on top	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
denote the vector	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
construct this lagrange	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
original optimization objective	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
multipliers the highest	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
call the lagrange	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solve the optimization	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
parameters and set	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
derivative with respect	0.00517074327196	0.0	3.9968034097	4.75488750216	0.3979591837	False
value w star	0.0	0.0	0.0	1.58496250072	0.0000000000	False
star ? right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
right the backwards	0.0	0.0	0.0	1.58496250072	0.0000000000	False
exists beta star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
derivatives are equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
construct a lagrange	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lagrange multipliers beta	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
multipliers beta set	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
set the partial	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
partial derivatives equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
great so great	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
slightly more difficult	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
type of constraint	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
constraint optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
inequality for constraint	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
optimization for parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
sets of lagrange	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
alpha and beta	0.00734310636061	0.0	8.9968034097	9.50977500433	0.4171122995	False
define theta subscript	0.0	0.0	0.0	1.58496250072	0.0000000000	False
equal to max	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
max of alpha	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
alpha beta subject	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
optimization problem min	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
max over alpha	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
equal to min	0.00199083261747	0.0	2.99733617475	7.92481250361	0.0000000000	False
sense of primal	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
thing this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem that written	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem this means	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
original optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
pick the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
primal problems constraints	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
suppose i pick	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
pick a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
maximize this function	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
function of alpha	0.00398166523495	0.0	2.9978689398	6.33985000288	0.0000000000	False
make this arbitrarily	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem s constraints	0.0	0.0	0.0	0.0	0.0000000000	False
minus infinity depending	0.0	0.0	0.0	1.58496250072	0.0000000000	False
maximize in terms	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
terms of alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lagrange multiply theorems	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
obtained by setting	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
constraints are satisfied	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
problem i wrote	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
minimizes the function	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
original primal problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
choose a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
violates the constraints	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
satisfy the constraints	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
minimizing the state	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
right i hope	0.0	0.0	0.0	1.58496250072	0.0000000000	False
thing we started	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem to find	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
problem to maximize	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximize over alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
previous prime optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
prime optimization problem	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
max and min	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
switched the order	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
defined p star	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
previously p star	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
inequality actually holds	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
exchange the order	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
order to min	0.0012238510601	0.0	0.0	3.16992500144	0.0000000000	False
min and max	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
two optimization problems	0.0	0.0	0.0	1.58496250072	0.0000000000	False
solve the duo	0.00489540424041	0.0	3.9978689398	3.16992500144	0.4171122995	False
vector machine problem	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
duo problem turns	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
make user compared	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problems are equivalent	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
strategy for working	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
vector machine algorithm	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
primal optimization problem	0.00298624892621	0.0	1.99840170485	4.75488750216	0.0000000000	False
derive this support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
sake of completeness	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
optimization problems give	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
discussion session taught	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
tas then suppose	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha i transpose	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
thing as linear	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
writing these things	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
details strictly feasible	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
satisfy were stricter	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
exists w star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solves the primal	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem and alpha	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
star and beta	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
multiplier  excuse	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
parameters will satisfy	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
satisfy these conditions	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
conditions partial derivative	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
partial derivative perspective	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
derivative perspective parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
equation in mind	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
derive our duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
ll actually perform	0.0	0.0	0.0	1.58496250072	0.0000000000	False
perform this step	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
beta is equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
kkt complementary condition	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
complementary condition kkt	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
condition kkt stands	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
stands for karush-kuhn-tucker	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
optimal margin optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin optimization problem	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
ktt complementary condition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
star i times	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
numbers is equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
wan na show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
names so kkt	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
complementary condition implies	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
star is equal	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
kkt condition guarantees	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha i star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
call a constraint	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
extend this idea	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
bit more board	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
back and work	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
point of notation	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
ve been writing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
deriving the kkt	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
multipliers were alpha	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
lagrange multipliers alpha	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
out the kkt	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
denote the parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem i wanted	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
wanted to minimize	0.0012238510601	0.0	3.99733617475	7.92481250361	0.4171122995	False
first optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
optimization problem finding	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
finding the parameters	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
sort of slight	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
slight notation change	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
change in mind	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
mind so problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem we worked	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
add a half	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
makes other work	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
work  math	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
nicer and subject	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
kkt duo complementary	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
duo complementary condition	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
functional margin equal	0.0110146595409	0.0	17.9952051145	14.2646625065	0.2146788991	False
equality that means	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
examples with functional	0.00298624892621	0.0	5.99840170485	0.0	0.0000000000	False
alpha i equal	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
examples of functional	0.00199083261747	0.0	0.0	0.0	0.0000000000	False
true in general	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
picture i ve	0.0	0.0	0.0	0.0	0.0000000000	False
minimum possible distance	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
call the support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
machine there ll	0.0	0.0	0.0	0.0	0.0000000000	False
points with functional	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
re calling support	0.0	0.0	0.0	0.0	0.0000000000	False
calling support vectors	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
vectors also means	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
out the actual	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
actual optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
multipliers of type	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
one-half w squared	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
out what theta	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
alpha is min	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
min with respect	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lagrange and minimize	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
order to minimize	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
minimize the lagrange	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
lagrange with respect	0.00489540424041	0.0	5.9978689398	6.33985000288	0.4171122995	False
wan na minimize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minimize this function	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
derivative and set	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
input feature vectors	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
derivative of lagrange	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
equal to minus	0.00208032597918	0.0	1.99840170485	3.16992500144	0.0000000000	False
ll just set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minimize with respect	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
transpose w minus	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
sum y equals	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
worked out previously	0.00258537163598	0.0	1.99840170485	4.75488750216	0.0000000000	False
brackets to denote	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
denote end product	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
means the end	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
minus one half	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha my duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
realize the notation	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha to denote	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
denote that formula	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
formula i wrote	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
wrote down earlier	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
primal problem lowercase	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lowercase w transpose	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
uppercase and lowercase	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
totally different things	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
notation is standard	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
constraint that sum	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
alpha is equal	0.00734310636061	0.0	5.9968034097	9.50977500433	0.2392638037	False
infinity for minimizing	0.0	0.0	0.0	0.0	0.0000000000	False
out my lagrange	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
constraint we worked	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
values of alpha	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
ended up deciding	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
deciding to maximize	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
bit of extra	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
derived a duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
out this constraint	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
out the duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
approach to finding	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
classifier or support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
parameters alpha star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solve for alpha	0.00367155318031	0.0	2.99840170485	4.75488750216	0.0000000000	False
easy to solve	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
interpretation of training	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
found the direction	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
hyperplane s direction	0.0	0.0	0.0	0.0	0.0000000000	False
orientation and separating	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
place this hyperplane	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem and solve	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
find the worst	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
set the threshold	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
place the separating	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hope the process	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
process is clear	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem we re	0.0	0.0	0.0	0.0	0.0000000000	False
thing i wan	0.0	0.0	0.0	1.58496250072	0.0000000000	False
wan na point	0.0	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
express the entire	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
algorithm in terms	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.000633355793961	0.0	0.0	1.58496250072	0.0000000000	False
function that outputs	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
compute w transpose	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
equal to alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
idea of kernels	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
source of feature	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
inner-dimensional feature vectors	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
compute inner products	0.00398166523495	0.0	7.9978689398	6.33985000288	0.3451327434	False
nt hold true	0.0	0.0	0.0	0.0	0.0000000000	False
true for arbitrary	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
sets of features	0.000582553636488	0.0	0.0	0.0	0.0000000000	False
ll see examples	0.0	0.0	0.0	1.58496250072	0.0000000000	False
extremely high-dimensional feature	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
high-dimensional feature vectors	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
store in computer	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
vectors very efficiently	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
predictions by making	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
reason we derive	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
written in terms	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
problem and step	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
learn the parameters	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
parameters of alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
needing to represent	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
represent xi directly	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
represent this compute	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
vectors that function	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
fairly small fraction	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
fraction of training	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
nice because alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
talk about kernels	0.00199083261747	0.0	0.0	1.58496250072	0.0000000000	False
kernels quick questions	0.0012238510601	1.0	0.0	1.58496250072	0.0000000000	False
points are kinda	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
nt we assume	0.0	0.0	0.0	0.0	0.0000000000	False
assume that point	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ways to generalize	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
close for today	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
morning welcome back	0.000797923784772	0.0	0.0	0.0	0.0000000000	False
end of class	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
project proposals start	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
start to trickle	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
proposals are due	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
due this friday	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
meet and chat	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
immediately after lecture	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
today ? great	0.0	0.0	0.0	0.0	0.0000000000	False
today is wrap	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
discussion on support	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.0115150547778	1.0	17.989432703	28.529325013	0.4135855546	True
ll also talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea of kernels	0.00517787123339	0.0	2.99721913237	7.92481250361	0.4180790960	False
algorithm for solving	0.00207114849336	0.0	0.0	1.58496250072	0.0000000000	False
solving the optimization	0.00310672274003	0.0	1.99833147942	0.0	0.0000000000	False
context optimization problem	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
find the optimal	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
optimal margin classifier	0.00207114849336	0.0	0.0	3.16992500144	0.0000000000	False
set that maximizes	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
maximizes this geometric	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
derived the dual	0.00509289883434	0.0	5.9977753059	6.33985000288	0.4180790960	False
primal optimization problem	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
brackets to denote	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
denote inner product	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out the ways	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.00131781435256	0.0	0.0	3.16992500144	0.0000000000	False
prediction of classification	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
compute the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
function that outputs	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
written in terms	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
products between input	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
products in fact	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
write the entire	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
vector between input	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
input feature vectors	0.00310672274003	0.0	2.99833147942	3.16992500144	0.0000000000	False
set of features	0.00121211102925	0.0	0.0	1.58496250072	0.0000000000	False
four polynomial features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
call this mapping	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
ll let phi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
denote the mapping	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
higher dimensional set	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
product between phi	0.00636612354292	0.0	6.99721913237	7.92481250361	0.4415274463	False
corresponds to running	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
running a support	0.00381967412575	0.0	3.99833147942	0.0	0.0000000000	False
original one-dimensional input	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
one-dimensional input feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
fact sometimes phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
high degree polynomial	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
degree polynomial features	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
features sometimes phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
infinite dimensional vector	0.00268967291455	0.0	2.99833147942	3.16992500144	0.0000000000	False
vector of features	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
extremely high dimensional	0.00310672274003	0.0	3.99833147942	3.16992500144	0.0000000000	False
nt actually compute	0.0	0.0	0.0	0.0	0.0000000000	False
high dimensional feature	0.00724901972675	0.0	5.99610678532	7.92481250361	0.4769797422	False
dimensional feature vector	0.00828459397342	0.0	5.99555061179	11.094737505	0.5362318841	False
inefficient it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
important special cases	0.00381967412575	0.0	2.99833147942	4.75488750216	0.0000000000	False
call the kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vectors it turns	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
cases where computing	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
computationally very expensive	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
nt compute infinite	0.0	0.0	0.0	0.0	0.0000000000	False
compute infinite dimensional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
cases where phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
expensive to represent	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
compute a kernel	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vectors very inexpensively	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
lets you work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
work in feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
feature spaces phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
bit later today	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
examples of phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
constructing kernels explicitly	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
save on writing	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
equals x transpose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
transpose z squared	0.00381967412575	0.0	5.99833147942	4.75488750216	0.0000000000	False
mapping where phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
definition of phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
elements of phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
order to compute	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
length of phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
order n squared	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
compute the kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
function is defined	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
computed this kernel	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
kernel you find	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
raise your hand	0.000902178372964	0.0	0.0	3.16992500144	0.0000000000	False
describe a couple	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
couple of quick	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
kernel in order	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out to correspond	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
creating a feature	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
meaning the first	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
first order terms	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
control the relative	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
product between vectors	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vectors of length	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
length and square	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
square in order	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
examples of kernels	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
construct the feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
re implicitly working	0.0	0.0	0.0	1.58496250072	0.0000000000	False
high dimensional computing	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
dimensional computing space	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
set of attributes	0.00207114849336	0.0	0.0	3.16992500144	0.0000000000	False
vector of phi	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
feature vector phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
kernel is computing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt as rigorous	0.0	0.0	0.0	0.0	0.0000000000	False
pointing different directions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
small that intuition	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
thing to classify	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
learn the algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
similar and small	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt always true	0.0	0.0	0.0	0.0	0.0000000000	False
classify some brand	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
brand new thing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
classify or dna	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
answers the question	0.000658907176278	0.0	0.0	1.58496250072	0.0000000000	False
similar or dissimilar	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
exist some phi	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
kxz is equal	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kernel it turns	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
result that characterizes	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
result now suppose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
exist some function	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
set of points	0.000658907176278	0.0	0.0	1.58496250072	0.0000000000	False
define a matrix	0.0	0.0	0.0	1.58496250072	0.0000000000	False
apologize for overloading	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
nt enough alphabets	0.0	0.0	0.0	0.0	0.0000000000	False
find the kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
kernel function applied	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
definition of matrix	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
valid kernel function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
value for phi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two feature vectors	0.0	0.0	0.0	1.58496250072	0.0000000000	False
product the explicit	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
phi xi subscript	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vector just rearrange	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
sum of squares	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
transpose b equals	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
makes sense questions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
posisemidefinite it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
due to mercer	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
kernels it means	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
exists a phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kxz equals phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
necessarily a training	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
choose it holds	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
result i proved	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
show it turns	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
kernel a concrete	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
find an input	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
possibly be equal	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
examples of functions	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
fail to meet	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
meet the conditions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
tie this back	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose some function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out that function	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
function i wrote	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
similarity to galceans	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose some kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
choose x transpose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vector to apply	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
apply a support	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
vector machine kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
problem it depends	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
two examples similar	0.0	0.0	0.0	1.58496250072	0.0000000000	False
formulation of support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vector machine algorithm	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
galcean kernel corresponds	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional nonetheless	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
working with infinite	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.00288566969728	0.0	5.9977753059	3.16992500144	0.4180790960	False
compute these things	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
represent these infinite	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
feature vectors explicitly	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
started off talking	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
talking about support	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
machines i started	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
wanted to start	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
start to develop	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
develop non-linear learning	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
non-linear learning algorithms	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
draw that slanted	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
one-dimensional input data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
takes your original	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
original input data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
data and maps	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
dimensional feature space	0.00360708712161	0.0	5.99721913237	4.75488750216	0.0000000000	False
case of galcean	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
draw two dimensions	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
infinite dimensional space	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
exponentially high dimensional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
high dimensional space	0.00310672274003	0.0	3.99833147942	3.16992500144	0.0000000000	False
classifier that separates	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
separates your data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
largest possible geometric	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
originally one dimensional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
higher dimensional space	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
vector machines output	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
machines output nonlinear	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
output nonlinear decision	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
nonlinear decision boundaries	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
solve complex optimization	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
complex optimization problems	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
optimization problems questions	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
sigmer is save	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
values of sigmer	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
sigmer and train	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
train an svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
hold out cross	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
out cross validation	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
cross validation set	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
algorithms we talked	0.00179311527637	0.0	0.0	1.58496250072	0.0000000000	False
locally linear aggressions	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
linear aggressions bandwidth	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
aggressions bandwidth parameter	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
number of parameters	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
ids by saving	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
data to test	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
model selection explicitly	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kind of separation	0.0	0.0	0.0	1.58496250072	0.0000000000	False
separation ? good	0.0	0.0	0.0	0.0	0.0000000000	False
svms that work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
tend linearly separated	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
separated by mapping	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
mapping a higher	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
address that work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
discussion of soft	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
soft margin svms	0.00509289883434	0.0	4.9977753059	3.16992500144	0.0000000000	False
run an svm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
algorithm that assumes	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
assumes the data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
separable on data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
separable it turns	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
out this algorithm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
make it work	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
word about kernels	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
talked about kernels	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
context of support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
made support vector	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
powerful learning algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
end of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
ll actually give	0.0	0.0	0.0	1.58496250072	0.0000000000	False
give a couple	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
couple more examples	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
general than support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
derived a dual	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm in terms	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
algorithms and rewrite	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
rewrite in terms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
map the features	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
algorithm still work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
work the idea	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
talk about non-linear	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
non-linear decision boundaries	0.00127322470858	1.0	0.0	1.58496250072	0.0000000000	False
norm soft margin	0.00381967412575	0.0	3.99833147942	0.0	0.0000000000	False
margin svm machine	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
machine only people	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
great at coming	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
linearly separable data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
separable data set	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
makes the data	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
data non-linearly separable	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nice data set	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
great decision boundary	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
boundary that separates	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
separate this data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
suspicious example skew	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
skew my entire	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
entire decision boundary	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
slightly modified formulation	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
svm optimization problem	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
prefer to choose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose that original	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
original decision boundary	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
formulation our svm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
svm primal problem	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
one-half w squared	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
add these penalty	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
examples is separated	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
separated with functional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
functional margin greater	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
margin is greater	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
implies you classified	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
classified it correctly	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
examples with functional	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
functional margin negative	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
allowing my algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to misclassify	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
encourage the algorithm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
sort of penalty	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
term that penalizes	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
penalizes setting cis	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization problem	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
problem it turns	0.00159584756954	0.0	0.0	0.0	0.0000000000	False
out that similar	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out the dual	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
denote the multipliers	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
set of constraints	0.00207114849336	0.0	0.0	3.16992500144	0.0000000000	False
optimization objective minus	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
objective minus sum	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
greater or equal	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
redivide the entire	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
dual changes compared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha are greater	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt very hard	0.0	0.0	0.0	0.0	0.0000000000	False
solution to constrain	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
constrain optimization problems	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
derive conversions conditions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
solve this optimization	0.00358623055274	0.0	7.9977753059	0.0	0.4180790960	False
alphas have converged	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem in terms	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
change the algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that lets	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
lets us handle	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
handle non-linearly separable	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
non-linearly separable data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
stuff makes sense	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem we wrote	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
dual optimization problem	0.00381967412575	0.0	2.99833147942	3.16992500144	0.0000000000	False
problem with convergence	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
partly to give	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
excuse to talk	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm called coordinate	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
apply an algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
talk about coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
algorithm to describe	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
describe coordinate assent	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
maximize some function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
function of alpha	0.00621344548007	0.0	7.99666295884	7.92481250361	0.4605809129	False
coordinate assent algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
repeat until convergence	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
assent essentially holds	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
parameters except alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha i fixed	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
maximizes this function	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
function with respect	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
alpha i hat	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha one alpha	0.00509289883434	0.0	0.0	3.16992500144	0.0000000000	False
alpha i minus	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
fixed just optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
objective with respect	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
assent one picture	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
optimize a quadratic	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
call this alpha	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
alpha two axis	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
begin by minimizing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
respect to alpha	0.0127322470858	0.0	11.9944382647	15.8496250072	0.3195164076	False
minimize with respect	0.00207114849336	0.0	0.0	0.0	0.0000000000	False
back to alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
re always taking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
taking these axis-aligned	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
minimum it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
describe the algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
optimize with respect	0.00381967412575	0.0	2.99833147942	4.75488750216	0.0000000000	False
lot of parameters	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose which alphas	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
update next depending	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
sense to alternate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
higher dimensional parameters	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose to update	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
make faster progress	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
maximum it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out that coordinate	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
coordinate assent compared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
previously  compared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
lot more steps	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
advantage of coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
inexpensive to optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
method in order	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
order to converge	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
converge it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
easy to fix	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
parameters and optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
group of coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
assent with optimizing	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
modify this algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to solve	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
solve the svm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vector machine dual	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
machine dual optimization	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
reason the reason	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
change one alpha	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
alpha without violating	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
violating the constraint	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
due to john	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
colleague at microsoft	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
microsoft the smo	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
change two alphas	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sense the sequential	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sequential minimal optimization	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
term minimal refers	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choosing the smallest	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
number of alpha	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
outline the algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
select two alphas	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas to change	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
means a rule	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
rule of thumb	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
alpha ks fixed	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
fixed except alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
optimize w alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha with respect	0.00381967412575	0.0	3.99833147942	4.75488750216	0.0000000000	False
alpha j subject	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
constraints it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out the key	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
chose to update	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
update and subject	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
running this algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
satisfied these convergence	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
smo algorithm works	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
number of iterations	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
iterations to converge	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
order to derive	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
derive that step	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
update in respect	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
two in general	0.0	0.0	0.0	1.58496250072	0.0000000000	False
make my notation	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
derive the derivation	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
derivation for alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
general completely analogous	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm with respect	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
respect to constraint	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem this means	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
means that alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
denote by zeta	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
values of alpha	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
two must lie	0.0	0.0	0.0	0.0	0.0000000000	False
box that ranges	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
constraint that alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
equal to zeta	0.00381967412575	0.0	5.99833147942	1.58496250072	0.0000000000	False
implies that alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
zeta minus alpha	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
optimize the objective	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
definition for alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
dimensional quadratic function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
form a alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha two squared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
standard quadratic function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
easy to optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
school or undergrad	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
optimize quadratic functions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
value for alpha	0.0	0.0	0.0	0.0	0.0000000000	False
two the last	0.0	0.0	0.0	0.0	0.0000000000	False
solution must lie	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sort of quadratic	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
minimize the quadratic	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
value that lies	0.0	0.0	0.0	1.58496250072	0.0000000000	False
optimize your quadratic	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
clip your solution	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
inside the box	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
box that ll	0.0	0.0	0.0	0.0	0.0000000000	False
quadratic optimization problem	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
optimization problem subject	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
satisfying this box	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
constraint and lying	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
box having solved	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
solved the alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm very efficient	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
efficient you mentioned	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
understand that right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
run optimization algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
respect the constraint	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
constraint that sum	0.00207114849336	0.0	0.0	1.58496250072	0.0000000000	False
talking about ascent	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
change just alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
four through alpha	0.0	0.0	0.0	0.0	0.0000000000	False
alpha m fixed	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt change alpha	0.0	0.0	0.0	0.0	0.0000000000	False
choose to change	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
two must satisfy	0.0	0.0	0.0	0.0	0.0000000000	False
satisfy that linear	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
satisfies the constraint	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
zeta was defined	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
validated the constraint	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
equal to sum	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
pair of alphas	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas to update	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
couple more words	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
select some alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
procedure to optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt actually talk	0.0	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
alpha ? exchanging	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas  optimizing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
translate it differently	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
metric of progress	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
true for coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
nt get worse	0.0	0.0	0.0	0.0	0.0000000000	False
alphas will converge	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas may move	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
words on smo	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
platt s original	0.0	0.0	0.0	0.0	0.0000000000	False
original algorithm talked	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choosing which values	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
values or pairs	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
complicated to explain	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
explain in words	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
platt s paper	0.0	0.0	0.0	0.0	0.0000000000	False
easy to read	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
ll also posting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
posting a handout	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
update the parameter	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
compute the parameter	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problems to wrap	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
wrap up today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
couple of examples	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
examples of applications	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
applications of svms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	True
problem of handler	0.0	0.0	0.0	1.58496250072	0.0000000000	False
handler s integer	0.0	0.0	0.0	0.0	0.0000000000	False
recognition in handler	0.0	0.0	0.0	0.0	0.0000000000	False
array of pixels	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
combination of pixels	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
represents the character	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
pixels by ten	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
hundred dimensional feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
features of xb01	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
gray scale values	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for handler	0.0	0.0	0.0	0.0	0.0000000000	False
apply an svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
galcean kernel works	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kernel and throwing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
throwing an svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
svm gave performance	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
gave performance comparable	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
surprising because support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
account any knowledge	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
representing the pixel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
pixel intensity value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
means the performance	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
performance of svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
fairly esoteric objects	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
classify protein sequences	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
classes of proteins	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
suspect that biologists	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
bodies are made	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sequences of amino	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
denote amino acids	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
amino acid sequence	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
acid sequence represented	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
series of alphabets	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
assign this protein	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
type of protein	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
construct my feature	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
long protein sequences	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
write down aaaa	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
acids and count	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
representation for protein	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
protein this representation	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
applies no matter	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
matter how long	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
long my protein	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
160,000 dimensional feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
modern computer standards	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
represent these high	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
feature vectors imagine	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
modern day computers	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
big it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
efficient dynamic programming	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
dynamic programming algorithm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
compute inner products	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
apply this feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
ridiculously high feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
high feature vector	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vector to classify	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
algorithm for finding	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
kind of reminiscent	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose a standard	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
research papers written	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem two last	0.0	0.0	0.0	0.0	0.0000000000	False
two last sentences	0.0	0.0	0.0	0.0	0.0000000000	False
wraps up svms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
shelf learning algorithms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
lot of learning	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
close this class	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
congrats you re	0.0	0.0	0.0	0.0	0.0000000000	False
apply learning algorithms	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
lot of problems	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
problems we re	0.0	0.0	0.0	0.0	0.0000000000	False
understand the learning	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
email back comments	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
slightly questionable aspects	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
today is start	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
talk about learning	0.00156245566001	0.0	0.0	1.58496250072	0.0000000000	False
guess eight lectures	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
lot of learning	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
tools of machine	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
powerful learning algorithms	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
sorts of problems	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hope you start	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
made an analogy	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
school to learn	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
acquire a set	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set of tools	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
cut a piece	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
piece of wood	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
mastering the tools	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
machine learning tools	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
machine learning algorithms	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
scenarios in machine	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
learning is someday	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms you learned	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
apply logistic regression	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
support vector machines	0.00356024555418	0.0	4.9967514889	7.92481250361	0.4408352668	True
separates the people	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
compared to people	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
read the textbook	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
apply a support	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
modify the algorithm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
separates the great	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
people in machine	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
machine learning versus	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
versus the people	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
read the text	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
ll the math	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today  today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
start to talk	0.000548550025184	0.0	0.0	0.0	0.0000000000	False
results of machine	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms for sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
theory will point	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
apply learning algorithms	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
thing we re	0.0	0.0	0.0	0.0	0.0000000000	False
bias variance trade-off	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ordinary least squares	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
first learning algorithm	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
algorithm we learned	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
good model right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
underfit the data	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
failing to fit	0.00175559568851	0.0	0.0	3.16992500144	0.0000000000	False
fit the evident	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
evident quadratic structure	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
algorithm as representing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
representing the fact	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
amount of training	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
tons of training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fit the quadratic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithm with high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fit a fourth	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
problem  excuse	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
overfitting the data	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
algorithm has high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
intuition behind overfitting	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
overfitting a high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithm is fitting	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
fitting serious patterns	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fitting idiosyncratic properties	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
dataset of housing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
medium of fitting	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fitting a quadratic	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
interpolate your data	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
picture of classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
positive and negative	0.00109710005037	0.0	0.0	1.58496250072	0.0000000000	False
fit logistic regression	0.00141264461515	0.0	0.0	3.16992500144	0.0000000000	False
high order polynomial	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
equals the sigmoid	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sigmoid function applied	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
separate the positive	0.000645120039435	0.0	0.0	1.58496250072	0.0000000000	False
contrast you fit	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
understand this problem	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
problem of overfitting	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
overfitting versus underfitting	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bias versus high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
versus high variance	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
model of machine	0.00498633375858	0.0	7.99783432593	3.16992500144	0.4175824176	False
two twin problems	0.0	0.0	0.0	1.58496250072	0.0000000000	False
foray into learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
indicator z grading	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
apologies in advance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
advance for changing	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
changing the notation	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
vector machine lectures	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
learning theory lectures	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
forum as logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
similar to logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
force the logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
logistic regression algorithm	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
opt for labels	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
classifier to opt	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
notation for writing	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
writing a set	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
xiyi i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve drawn iid	0.0	0.0	0.0	3.16992500144	0.0000000000	False
running a classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problem on houses	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
distribution over features	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
features of houses	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ll be sold	0.0	0.0	0.0	3.16992500144	0.0000000000	False
assume that training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
thing for spam	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
build a spam	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
understand or simplify	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
understand the phenomena	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
phenomena of bias	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
logistic regression fits	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fits this parameters	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
parameters the model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the law	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
law of likelihood	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
order to understand	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
understand learning algorithms	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
assume a simplified	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
define training error	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis x subscript	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
subscript data write	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
write this epsilon	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hat of subscript	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
make the dependence	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
training set explicit	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hope the notation	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
notation is clear	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sum of indicator	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis correctly classifies	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fraction of training	0.00202781126965	0.0	0.0	0.0	0.0000000000	False
examples your hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
classifies so defined	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error and training	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
risk the simplified	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
empirical risk minimization	0.0192642070617	1.0	7.98971304819	28.529325013	0.3653846154	True
learning algorithm works	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
choose parameters data	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
minimize my training	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
ll prove properties	0.0	0.0	0.0	1.58496250072	0.0000000000	False
basic learning algorithm	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that minimizes	0.00202781126965	0.0	0.0	1.58496250072	0.0000000000	False
minimizes your training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error it turns	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
out that logistic	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
regression and support	0.00175559568851	0.0	0.0	0.0	0.0000000000	False
viewed as approximation	0.00202781126965	0.0	0.0	1.58496250072	0.0000000000	False
nonconvex optimization problem	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
hard to solve	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
solve this optimization	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
problem and logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problem by finding	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
finding the convex	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms like logistic	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
definition of empirical	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
choosing a set	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
set of parameters	0.00129024007887	0.0	0.0	3.16992500144	0.0000000000	False
choosing a function	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
define the hypothesis	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm is choosing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
specific linear classifier	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
vary the parameter	0.0	0.0	0.0	1.58496250072	0.0000000000	False
parameter s data	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis class script	0.00506952817413	0.0	2.99783432593	6.33985000288	0.5277777778	False
regression can choose	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
redefine empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
writing this choosing	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
function into hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class of script	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00220825242347	0.0	3.99729290742	6.33985000288	0.4408352668	False
algorithms as choosing	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
choosing from function	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
case this set	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class of functions	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
represented by viewer	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
functions the learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
definition for empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
understand whether empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
reasonable algorithm alex	0.0	0.0	0.0	1.58496250072	0.0000000000	False
data still defined	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
framework is general	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
mind a model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
algorithm or logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
set of functions	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
center of class	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
perform empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
purpose of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talking about binary	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
generalizes to regression	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
answer your question	0.0	0.0	0.0	1.58496250072	0.0000000000	False
cool all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
wan na understand	0.0	0.0	0.0	1.58496250072	0.0000000000	False
understand if empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt actually care	0.0	0.0	0.0	0.0	0.0000000000	False
care about training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt really care	0.0	0.0	0.0	0.0	0.0000000000	False
care about making	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
making accurate predictions	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
goal the ultimate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
makes  generalization	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
predictions on examples	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prices or sale	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
outcomes of houses	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
write as epsilon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
terms of notational	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
place a hat	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hat on top	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
attempt to estimate	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
epsilon hat training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hat training error	0.00124658343965	0.0	4.99783432593	4.75488750216	0.0000000000	False
attempt to approximate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
approximate generalization error	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
top are things	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
estimate other quantities	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
output by learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prove some things	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sense of giving	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
giving us low	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
low generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
order to prove	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
prove our first	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
first learning theory	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
learning theory result	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
state two lemmas	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
two or dot	0.0	0.0	0.0	1.58496250072	0.0000000000	False
means this sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
notation for probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
probability just means	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
two plus dot	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ve seen venn	0.0	0.0	0.0	0.0	0.0000000000	False
venn diagrams depictions	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
depictions of probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
surprising it turns	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
out that depending	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
define your axioms	0.0	0.0	0.0	1.58496250072	0.0000000000	False
axioms of probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
axiom so sigmas	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sigmas of avitivity	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
nt actually prove	0.0	0.0	0.0	0.0	0.0000000000	False
ll just state	0.0	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
observe m iid	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
newly random variables	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
phi hat means	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
semper my equals	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
benuve random variables	0.00997266751716	0.0	7.99566865187	11.094737505	0.0000000000	False
variables by sort	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of taking	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
taking its average	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gamma be fixed	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
probability your estimate	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
estimate of phi	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
value of phi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two gamma squared	0.0	0.0	10.9962100704	1.58496250072	0.4408352668	False
statement of fact	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
draw a cartoon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
cartoon to describe	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
guess so lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
real number line	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
probability or statistics	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
central limit theorem	0.00608343380895	0.0	4.9967514889	7.92481250361	0.2342786683	True
toss m coins	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
coins with bias	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
distribution of phi	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
cumulative distribution function	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
function of phi	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
hat will converse	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gaussian technically phi	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set of values	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
pick a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of gamma	0.00124658343965	0.0	4.99621007038	9.50977500433	0.2883156297	False
words the probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
total probability mass	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
negative two gamma	0.00997266751716	0.0	10.9967514889	0.0	0.3986013986	False
right hand side	0.0	0.0	6.99783432593	6.33985000288	0.0000000000	False
squared so balance	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
balance the probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
make a mistake	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
mistake in estimating	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
increase the size	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
toss a coin	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gaussian will shrink	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
shrink the worth	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
probability mass left	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
tails to decrease	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
familiar with tend	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of asymptotic	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
limit theorem approximation	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
explain the intuition	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
theorem just holds	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
reference to central	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
theorem all right	0.0	0.0	0.0	0.0	0.0000000000	False
right so lets	0.0	0.0	0.0	0.0	0.0000000000	False
start to understand	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
understand empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
begin with studying	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
studying empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
start with studying	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
studying the case	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
case of finite	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
finite hypothesis classes	0.00304171690448	0.0	5.99566865187	12.6797000058	0.0000000000	False
mapping from inputs	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
inputs to outputs	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
lowest training error	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
continuous infinitely large	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
infinitely large class	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class of hypotheses	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
prove the first	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
describe our first	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
first learning theorem	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ll later generalize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
classes so empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
risk minimization takes	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
takes the hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prove a bound	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
hat all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minimizing training error	0.00608343380895	0.0	3.9967514889	7.92481250361	0.3986013986	False
show that training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
approximation to generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
implies a bound	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis of empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class i guess	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
slightly notation heavy	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
notation heavy class	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
heavy class round	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt quite remember	0.0	0.0	0.0	0.0	0.0000000000	False
empirical risk strategy	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
show training errors	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
errors that give	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
give approximation generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
imply that minimizing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
terms of minimizing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
minimizing generalization error	0.00498633375858	0.0	3.99783432593	6.33985000288	0.0000000000	False
output by empirical	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
idea so lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
pick any hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis so pick	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
misclassifies the ife	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis was classified	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set is drawn	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
randomly from sum	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sum distribution scripts	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
examples i ve	0.0	0.0	0.0	0.0	0.0000000000	False
sample my training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
training set iid	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
iid from distribution	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis will misclassify	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
drawn are iid	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
iid random variables	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
examples were drawn	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
definition of training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
average of miid	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
drawn from benuve	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
miid benuve random	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
add the probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
difference between training	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
training and generalization	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
greater than gamma	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
set is large	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
probability my training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
approve this bound	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
estimate for generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
order to show	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
define a random	0.0	0.0	0.0	0.0	0.0000000000	False
exists some hypothesis	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
make a large	0.00623291719823	0.0	7.99729290742	0.0	0.3259005146	False
estimate of generalization	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
exists a hypothesis	0.00373975031894	0.0	5.99837574445	4.75488750216	0.0000000000	False
holds the chance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
chance there exists	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
error in estimating	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
estimating the generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
two and make	0.0	0.0	0.0	0.0	0.0000000000	False
estimating generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
minus both sides	0.00373975031894	0.0	5.99837574445	4.75488750216	0.0000000000	False
exist for hypothesis	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
make a small	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
error in taking	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
taking one minus	0.00124658343965	0.0	5.99837574445	4.75488750216	0.0000000000	False
sides the minus	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
minus sign flips	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
flips the sign	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
probability one minus	0.00373975031894	0.0	2.99837574445	1.58496250072	0.0000000000	False
gamma of epsilon	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
give this result	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
uniform conversions result	0.00498633375858	1.0	2.99783432593	6.33985000288	0.0000000000	False
term uniform conversions	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of alludes	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
converge to epsilon	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
close to generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
term uniform refers	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
clean a couple	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
couple more boards	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
computed ? right	0.0	0.0	0.0	0.0	0.0000000000	False
imagine a gamma	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
chose in advance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound that holds	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
sort of develop	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
develop this result	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ll choose specific	0.0	0.0	0.0	0.0	0.0000000000	False
choose specific values	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll just imagine	0.0	0.0	0.0	1.58496250072	0.0000000000	False
proved this holds	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gamma any questions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
phase is infinite	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
lecture to infinite	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
infinite hypothesis classes	0.00506952817413	1.0	4.99729290742	7.92481250361	0.0000000000	False
concretely about algorithms	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
things i ve	0.0	0.0	0.0	0.0	0.0000000000	False
uniform conversions bound	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
bound and rewrite	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound on probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
suppose i fix	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fix my training	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
set  fix	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fix my threshold	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
error threshold gamma	0.00124658343965	0.0	0.0	3.16992500144	0.0000000000	False
probability that uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
uniform conversions holds	0.00498633375858	0.0	2.99783432593	6.33985000288	0.0000000000	False
parameters of interest	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
training set size	0.00438898922128	0.0	3.99729290742	6.33985000288	0.3259005146	False
two other equivalent	0.0	0.0	0.0	0.0	0.0000000000	False
probability of uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
delta of making	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
large a training	0.00747950063787	0.0	5.9967514889	1.58496250072	0.2602739726	False
order to give	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
give a bound	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
give a uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
bound with parameters	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gamma and delta	0.0	0.0	0.0	0.0	0.0000000000	False
training set assigns	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
greater than equal	0.000645120039435	0.0	0.0	1.58496250072	0.0000000000	False
gamma of generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sample complexity bound	0.00498633375858	0.0	3.99783432593	6.33985000288	0.0000000000	False
undergrad computer science	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
computer science classes	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
heard of computational	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
complexity just means	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
means how large	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
large a sample	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sample of examples	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
order to achieve	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound and error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
theorems we write	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
form of probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
personally often find	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
find the sample	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
easy to interpret	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bounds often sort	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
machine learning problem	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
slowest growing functions	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
true so log	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sample complexity grows	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
increase this number	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
number of hypotheses	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
talk about infinite	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
classes the final	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fixed and solved	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
solved for gamma	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
training generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gamma and plugging	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
plugging the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
essentially that uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
conversions will hold	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
true with high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
assume that uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
suppose this holds	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
selected by empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
define h star	0.0	0.0	0.0	1.58496250072	0.0000000000	False
smallest generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sense of minimizing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of makes	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
sense to compare	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
compare the performance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
linear decision boundaries	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
nt be separated	0.0	0.0	0.0	0.0	0.0000000000	False
prove this result	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis i chose	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
number these equations	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hat and epsilon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hat was chosen	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
chosen to minimize	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis with lower	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
lower training error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that minimizes	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error h hat	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
apply this uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
error with estimate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
examples it misclassifies	0.0	0.0	0.0	0.0	0.0000000000	False
chosen by empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
talk about empirical	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
hat is defined	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
training error epsilon	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
member of typical	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
delta be fixed	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
error bound form	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypotheses in set	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set h epsilon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gamma to equal	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
times the square	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
square root term	0.00373975031894	0.0	2.99837574445	4.75488750216	0.0000000000	False
term to prove	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prove this theorem	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
theorem we set	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
great so set	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
previous board holds	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
holds with probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
minus delta right	0.0	0.0	0.0	0.0	0.0000000000	False
delta right equation	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
set gamma equal	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
delta this uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
call this equation	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
equation  star	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two  generalization	0.0	0.0	0.0	0.0	0.0000000000	False
two times gamma	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of helps	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bit that bias	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
bias variance tradeoff	0.00304171690448	0.0	3.99837574445	4.75488750216	0.0000000000	True
functions and linear	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class h prime	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
features so lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
linear hypothesis class	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
quadratic hypothesis class	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
larger hypothesis class	0.00373975031894	0.0	2.99837574445	4.75488750216	0.0000000000	False
holds for infinite	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
switch from linear	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
linear to quadratic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
functions then epsilon	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sense of generalization	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
lowest generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
lower generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
complex hypothesis class	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
increase by switching	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
term will increase	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hope for finding	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
risk of sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fitting my model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
accurately also increases	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fit a hypothesis	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fit this hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
note of warning	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
class you ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve seen definitions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
definitions of bias	0.00373975031894	0.0	4.99837574445	3.16992500144	0.0000000000	False
bias and variance	0.00351119137702	0.0	6.99783432593	6.33985000288	0.0000000000	False
defined in terms	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
terms of squared	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
universally accepted formal	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
accepted formal definition	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
variance for classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problems for regression	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
square error definition	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
definition for classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problems it turns	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
out there ve	0.0	0.0	0.0	0.0	0.0000000000	False
proposals for definitions	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fixed training set	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
size m vertical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll plot model	0.0	0.0	0.0	0.0	0.0000000000	False
plot model complexity	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of degree	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
degree of polynomial	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
remember the bandwidth	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
locally weighted linear	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
weighted linear regression	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
effect in controlling	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
controlling how complex	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
complex your model	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
model is model	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
model complexity polynomial	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
polynomial i guess	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error will tend	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
increase the complexity	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
complete your model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fit your training	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
find that generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
model of sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of intermediate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll actually talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of algorithms	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
automatically select model	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
select model complexities	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
area of minimized	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error the last	0.0	0.0	0.0	0.0	0.0000000000	False
theorem i wrote	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
error bound theorem	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
delta where probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound on gamma	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
thing i wan	0.0	0.0	5.99783432593	3.16992500144	0.0000000000	False
theorem and write	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
out a corollary	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fix my error	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
delta and solve	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
delta and gamma	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
order to guarantee	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis i choose	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
choose with empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
times gamma worse	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis class lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
true with probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of solving	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set that term	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gamma and solve	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
home and sort	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
sort of convince	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
result really holds	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
theorem we ve	0.0	0.0	0.0	0.0	0.0000000000	False
formula we wrote	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
wrote and solve	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
back and convince	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
prove these bounds	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
bounds in learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
theory it turns	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
constants are sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of loose	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
class is logarithmic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll actually start	0.0	0.0	0.0	1.58496250072	0.0000000000	False
result again remember	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
talk about practical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms for model	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
couple of quick	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
submissions they ve	0.0	0.0	0.0	0.0	0.0000000000	False
end of lecture	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
re an sepd	0.0	0.0	2.9985	0.0	0.0000000000	False
submitted your problem	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hand in box	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
picked up today	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
access after hours	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
end of class	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
homework by fax	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
posted online last	0.0	0.0	0.0	0.0	0.0000000000	False
online last week	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
guys actually understood	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class for working	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
working as graders	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
late on monday	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class is scheduled	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
8th of november	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
laptops and computers	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
computers sepd students	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
person to stanford	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
midterm in person	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
drive to stanford	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
usual class mailing	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class mailing address	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
cs229qa @ cs.stanford.edu	0.0	0.0	0.0	1.58496250072	0.0000000000	False
attend the midterm	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
make alternate arrangements	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
regular stanford students	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
event of sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
equal or greater	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class that conflicts	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
usual staff mailing	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
staff mailing address	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
ll be showing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lecture s technical	0.0	0.0	0.0	0.0	0.0000000000	False
week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
talking about convex	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
section they discussed	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
discussed total convex	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
total convex optimization	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
present on convex	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
lecture is talk	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension and building	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
issues of bias	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bias variance tradeoffs	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
talk about model	0.00284796479574	0.0	3.9985	0.0	0.0000000000	False
model selection algorithms	0.0023343564589	1.0	0.0	1.58496250072	0.0000000000	False
automatically making decisions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
started to talk	0.000513608336833	0.0	0.0	1.58496250072	0.0000000000	False
lecture and depending	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
week s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
lecture to recap	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
result we proved	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
finite hypothesis class	0.000949321598579	0.0	4.998	6.33985000288	0.0000000000	False
gamma and delta	0.00466871291781	0.0	5.998	4.75488750216	0.2937062937	False
order to guarantee	0.00474660799289	0.0	3.9975	7.92481250361	0.5316455696	False
delta it suffices	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
greater and equal	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
learning dropped constants	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
talked about empirical	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
empirical risk minimization	0.00949321598579	1.0	6.9945	15.8496250072	0.5316455696	True
simplified modern machine	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
modern machine learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class of script	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
empirical risk minimization-learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
risk minimization-learning algorithm	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
chooses the hypothesis	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that attains	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
attains the smallest	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
denoted generalization error	0.0	0.0	0.0	1.58496250072	0.0000000000	False
error ; right	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis h misclassifying	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis h output	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
output by empirical	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
two times gamma	0.0	0.0	0.0	3.16992500144	0.0000000000	False
gamma two times	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times this error	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
holds a probability	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
delta we show	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
training set size	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
greater than equal	0.000604027008112	0.0	0.0	1.58496250072	0.0000000000	False
two gamma square	0.0	0.0	0.0	0.0	0.0000000000	False
gamma square log	0.00189864319716	0.0	0.0	1.58496250072	0.0000000000	False
number of training	0.00877757961247	0.0	9.994	0.0	0.3925233645	False
order to give	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
give a guarantee	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sample complexity result	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
case of infinite	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
infinite hypothesis classes	0.00284796479574	0.0	3.9985	4.75488750216	0.0000000000	False
model like logistic	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
parameterized by real	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
give an argument	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
broken just sort	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
technically somewhat broken	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
conveys useful intuition	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
apply this result	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
result analyzing logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
analyzing logistic regression	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
linear division boundaries	0.000949321598579	0.0	0.0	3.16992500144	0.0000000000	False
re applying logistic	0.0	0.0	0.0	0.0	0.0000000000	False
applying logistic regression	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
regression to find	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
find the linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
linear position boundary	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
parameterized by endless	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
endless one real	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bits to represent	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
represent real numbers	0.00350153468835	0.0	5.9985	4.75488750216	0.0000000000	False
normal standard computer	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
double position floating	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
position floating point	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
floating point numbers	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
number is represented	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
representation ; right	0.0	0.0	0.0	0.0	0.0000000000	False
64-bit floating point	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
times d bits	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
nt represent real	0.0	0.0	0.0	0.0	0.0000000000	False
number of ways	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of guarantee	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
great and equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
returned by empirical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
give that sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of error	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
error bound guarantee	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
number of parameters	0.00585171974165	0.0	7.9955	14.2646625065	0.3500000000	False
representation of 14-point	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
outline the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the right	0.0	0.0	0.0	0.0	0.0000000000	False
state the result	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
prove it farther	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
source of learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
learning theory balance	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
classes this definition	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class h shatters	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shatters the set	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
realize any labeling	0.00350153468835	0.0	3.9985	4.75488750216	0.0000000000	False
class has shattered	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set of labels	0.00350153468835	0.0	3.9985	3.16992500144	0.0000000000	False
choose any set	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis class shatters	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that labels	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
comprising two points	0.0	0.0	0.0	1.58496250072	0.0000000000	False
four possible labelings	0.0	0.0	0.0	1.58496250072	0.0000000000	False
labelings that computes	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose to label	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
label both positive	0.0	0.0	0.0	1.58496250072	0.0000000000	False
class h classed	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classed all linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of find	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
find a linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classifier that attains	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
attains zero training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hypothesis class script	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
script h shatters	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shatters this set	0.00700306937671	0.0	5.997	9.50977500433	0.3730017762	False
larger example suppose	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
suppose my set	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
points ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
find the hypothesis	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
class that labels	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
labels these examples	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class also shatters	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set s right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
find a hypothesis	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
separates the positive	0.000604027008112	0.0	0.0	1.58496250072	0.0000000000	False
positive and negative	0.000513608336833	0.0	0.0	0.0	0.0000000000	False
set ? suppose	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lots of labels	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
realize some labelings	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
realize this labeling	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
classifiers can shatter	0.0	0.0	0.0	0.0	0.0000000000	False
vapnik and chervonenkis	0.00350153468835	0.0	2.9985	3.16992500144	0.0000000000	False
class can shatter	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shatter arbitrarily large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
arbitrarily large sets	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
dimension is infinite	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
kind of good	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
set is equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
nt really prove	0.0	0.0	0.0	0.0	0.0000000000	False
sets of size	0.00583589114726	0.0	4.9975	7.92481250361	0.2335928810	False
choose a set	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
definition no right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose my set	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
lapping three points	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out this result	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
result holds true	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class of linear	0.00379728639431	0.0	2.998	3.16992500144	0.5250000000	False
dimensions is equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimensional feature space	0.00198399239271	0.0	2.9985	3.16992500144	0.0000000000	False
arguably the best-known	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re in probability	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the essential	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
delta you enjoy	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
enjoy this sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of uniform	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
uniform conversions results	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
things is bounded	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
step ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lecture we proved	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
error and training	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
hypotheses you pick	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
two gamma times	0.0	0.0	0.0	1.58496250072	0.0000000000	False
constants in front	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
slightly more complicated	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
delta we re	0.0	0.0	0.0	0.0	0.0000000000	False
write m equals	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
error to denote	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
delta as constants	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
turns that depend	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
depend on gamma	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
guarantee this holds	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension and hypotheses	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
risk minimization algorithms	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
minimize training error	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
error the intuition	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shows that sample	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
complexity is upper	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
reasonable hypothesis classes	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
dimension is sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
parameters you model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model and logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
logistic regression linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
regression linear classification	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
dimensions logistic regression	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimensions is endless	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
endless one parameters	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sense of low	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
low other polynomial	0.0	0.0	0.0	1.58496250072	0.0000000000	False
dimension is enormous	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
strange and degenerate	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
things it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
shows the sample	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
find it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
case some complexity	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
perfectly nasty learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
nasty learning problem	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
prove this bound	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bounded and lower	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
assume any sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of finites	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ve actually stated	0.0	0.0	0.0	1.58496250072	0.0000000000	False
stated the entirety	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
true it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
someway that sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of proof	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
clever to prove	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
reading the book	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
book that led	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
understand this proof	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
tie a couple	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
couple of loose	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
bit like random	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bound was proved	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that minimizes	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
minimizes 0-1 training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
0-1 training error	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.00333346406681	0.0	7.9965	9.50977500433	0.3500000000	True
nt over fit	0.0	0.0	0.0	0.0	0.0000000000	False
sequel of remember	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
remember our discussion	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
discussion on support	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
map the features	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
features in infinite	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
separators with large	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
low vc dimension	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension i wan	0.0	0.0	0.0	1.58496250072	0.0000000000	False
understand the details	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
informally it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
set of points	0.000604027008112	0.0	0.0	1.58496250072	0.0000000000	False
lines that separate	0.00146292993541	0.0	0.0	3.16992500144	0.0000000000	False
separate these points	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class will comprise	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
boundaries that separate	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
separate the points	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
points it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
points all lie	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sphere of radius	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
separators is separate	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
separate to data	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
four gamma squared	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out you prove	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classifiers with large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bounded the surprising	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
points x combine	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
combine an infinite	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional space	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
dimension is bounded	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
find a large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
large margin separator	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
find the line	0.00116717822945	0.0	0.0	3.16992500144	0.0000000000	False
separates your positive	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
examples with large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class with small	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
small vc dimension	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
finite dimensional spaces	0.000949321598579	0.0	0.0	3.16992500144	0.0000000000	False
constantly infinite dimensional	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
infinite dimensional vectors	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
squared is equal	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
insures that conversions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
tie empirical risk	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
source of algorithms	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
draw a function	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
equals data transpose	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
positive or negative	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
negative and depending	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
right or wrong	0.0	0.0	0.0	1.58496250072	0.0000000000	False
part of indicator	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
indicator h subscript	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose parameters data	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
minimize this step	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
function ; right	0.0	0.0	0.0	0.0	0.0000000000	False
classification on setting	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
setting your training	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out this step	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
linear classifiers minimizing	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
minimizing the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
empty heart problem	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
problem it turns	0.000731464967706	0.0	0.0	0.0	0.0000000000	False
out that logistic	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
tying to minimize	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
minimize the minus	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
plot the minus	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
approximate empirical risk	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
hard optimization problem	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization problem	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
find the maximum	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
parameters for logistic	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
viewed as approximated	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
vector machine turns	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
approximate this step	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of linear	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
theory we developed	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
nt exactly due	0.0	0.0	0.0	0.0	0.0000000000	False
due to empirical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
completely appropriate intuitions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
intuitions for svm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
regression are reasonable	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
check for questions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
started to develop	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
sort of wrapped	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
trade-off between bias	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bias and variance	0.000821883638985	0.0	0.0	3.16992500144	0.0000000000	False
choose a hypothesis	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
data has sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose a linear	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
hypothesis with high	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
ll also fail	0.0	0.0	0.0	1.58496250072	0.0000000000	False
fail to fit	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
fit the data	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
fail to generalize	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
selection algorithms provide	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
provide a class	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class of methods	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
automatically trade make	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
make these tradeoffs	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
tradeoffs between bias	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
variance ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
remember the cartoon	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
cartoon i drew	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
drew this last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
x-axis was model	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
meaning the number	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
simple a model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
high generalization error	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
complex a model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
re over fitting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
examples of model	0.00189864319716	0.0	0.0	1.58496250072	0.0000000000	False
model selection problems	0.00466871291781	0.0	7.998	6.33985000288	0.0000000000	False
problems will include	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
choose the degree	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose the parameter	0.00132266159514	0.0	0.0	3.16992500144	0.0000000000	False
locally awaited linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
awaited linear regression	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of local	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
objective ; right	0.0	0.0	0.0	0.0	0.0000000000	False
parameter c controls	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
controls the tradeoff	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
large margin versus	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
set of models	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
parameter and discretize	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
range of values	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
re training set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lowest training error	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
fit ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea to choose	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
choose a model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
end up choosing	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
model ; right	0.0	0.0	0.0	0.0	0.0000000000	False
choose a 10th	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
10th degree polynomial	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fits the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set several standard	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hold out cross	0.0123411807815	0.0	9.9935	15.8496250072	0.2956145100	False
out cross validation	0.0151891455773	0.0	9.992	19.0195500087	0.3903345725	False
teach a training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
split the training	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
subsets we call	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
call it subset	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
cross validation subset	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
train each model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
cross validation set	0.00189864319716	0.0	0.0	0.0	0.0000000000	False
pick the model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
data then test	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
cross validation error	0.00466871291781	0.0	2.998	3.16992500144	0.0000000000	False
output the hypothesis	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
chosen the degree	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
back and retrain	0.00350153468835	0.0	0.0	3.16992500144	0.0000000000	False
retrain the model	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
validation does sort	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of work	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
company or application	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
acquired at great	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
cost ; right	0.0	0.0	0.0	0.0	0.0000000000	False
data is acquired	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
acquired by medical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
training example represents	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
represents a sick	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
man in amounts	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
amounts of physical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
physical human pain	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
select my model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model if people	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
variations on hold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validation that makes	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
slightly more efficient	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
k-fold cross validation	0.00700306937671	1.0	4.997	9.50977500433	0.0000000000	True
draw this box	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
note the entirety	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ll then divide	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus one pieces	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
remaining one test	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
guess ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll just hold	0.0	0.0	0.0	1.58496250072	0.0000000000	False
remaining pieces test	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model you selected	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
drew five pieces	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fairly common choice	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fold cross validation	0.00116717822945	0.0	5.9965	11.094737505	0.0000000000	False
out cross option	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
switch the data	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
data into ten	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re only holding	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out in simple	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
commonly k equals	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choice the disadvantage	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
disadvantage of k-fold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validate your model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
train your model	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
model ten times	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
times per model	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
computationally more expensive	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
equals ten works	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
ten works great	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set k equals	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out the first	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
data than k-fold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
computationally very expensive	0.00284796479574	0.0	1.9985	3.16992500144	0.0000000000	False
run your learning	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
minus one training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
lot of times	0.000513608336833	0.0	0.0	1.58496250072	0.0000000000	False
re extremely data	0.0	0.0	0.0	0.0	0.0000000000	False
extremely data scarce	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
generalized by number	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
number of examples	0.00146292993541	0.0	0.0	3.16992500144	0.0000000000	False
compute the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
people in structure	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
structure risk minimization	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
minimization that propose	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
questions for cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
marginal ? right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
re proving learning	0.0	0.0	0.0	0.0	0.0000000000	False
proving learning theory	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
learning theory bounds	0.00583589114726	0.0	9.9975	6.33985000288	0.0000000000	False
sort of proving	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
proving the worse	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
worse case upper	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
case upper bound	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bound that holds	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
absolutely any probability	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
distribution over training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
examples ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
assume the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
bounds i proved	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
proved hold true	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
distribution over script	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
real life distribution	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
constants of learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
extremely large numbers	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
numbers take logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
logistic regression logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
regression logistic regression	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
plug in actual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
text for learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
extremely pessimistic estimates	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ridiculously large numbers	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
10,000 training examples	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
examples to fit	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
fit ten parameters	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
papers on learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
absolutely just ignore	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ignore the constant	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bounds to give	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
model to choose	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
gross x dimension	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension in number	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bounds the fact	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
examples the fact	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
complexity is linear	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bound will tend	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
answer your question	0.0	0.0	0.0	1.58496250072	0.0000000000	False
question ? uh-huh	0.0	0.0	0.0	1.58496250072	0.0000000000	False
rule of thumb	0.00164376727797	0.0	0.0	3.16992500144	0.0000000000	False
fit a logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
logistic regression model	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
examples is ten	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times your number	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times the number	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
perfectly fine fitting	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fitting that model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sorts of intuitions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bounds in cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
assume these examples	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
train testers randomly	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
case of model	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
feature selection problem	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
high dimensional feature	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
wan na talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
spam versus non-spam	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
reduce the number	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
number of features	0.00181208102434	0.0	3.9985	3.16992500144	0.0000000000	False
reduce the variance	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
reduce the risk	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
case of text	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
number of relevant	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
email is spam	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
spam or non-spam	0.00350153468835	0.0	5.9985	4.75488750216	0.0000000000	False
english function words	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
non-spam so words	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
words in contrast	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
buy or viagra	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
spam and non-spam	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
stanford or machine-learning	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
select a subset	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
specific learning problem	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
learning a simpler	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
simpler hypothesis class	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class to choose	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
50,000 features originally	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
included or excluded	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of simple	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
simple search algorithms	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
subsets of features	0.00466871291781	0.0	7.997	7.92481250361	0.0000000000	False
find a good	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
large a number	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
number to enumerate	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
forward search algorithm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
forward selection algorithm	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	True
ll just write	0.0	0.0	0.0	3.16992500144	0.0000000000	False
write it out	0.00164376727797	0.0	0.0	3.16992500144	0.0000000000	False
out my writing	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out will make	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
starts with initialize	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
initialize the sets	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
evaluate the model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model using cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validation or k-fold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validation or leave	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set of features	0.00111115468894	0.0	10.9955	12.6797000058	0.0000000000	False
adding that feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
feature to add	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
add that feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
single feature addition	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
addition that results	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
lowest cross validation	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
adding one feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
exceeded some threshold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re fitting logistic	0.0	0.0	0.0	0.0	0.0000000000	False
fitting logistic regression	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
added to set	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
learning this algorithm	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
lots of hypothesis	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
output best hypothesis	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hypothesis you ve	0.0	0.0	0.0	0.0	0.0000000000	False
wrapper feature selection	0.0023343564589	1.0	0.0	3.16992500144	0.0000000000	True
feature selection algorithm	0.00246565091695	0.0	2.9985	3.16992500144	0.0000000000	True
piece of software	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
write that wraps	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
perform forward selection	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to train	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
wrapper model feature	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
model feature selection	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
performing the search	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re repeatedly training	0.0	0.0	0.0	1.58496250072	0.0000000000	False
training your learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
search or backward	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
equals the entire	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
nt even make	0.0	0.0	0.0	0.0	0.0000000000	False
sense to initialize	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
training 10,000 features	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
features in email	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
examples then depending	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
algorithm you re	0.0	0.0	0.0	0.0	0.0000000000	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
selection algorithms tend	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
tend to work	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
class of algorithms	0.00164376727797	0.0	0.0	3.16992500144	0.0000000000	False
re actually right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
search and backward	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
forward selection backward	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
selection backward selection	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
backward selection work	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
envision other search	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
methods to search	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
end possible feature	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classification it turns	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
out for text	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
50,000 features forward	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
features forward selection	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sense of generalization	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
tend to learn	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
learn the hypothesis	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that works	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
filter feature selection	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
feature selection methods	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
compute some measure	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
compute some rough	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
estimate or compute	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
compute the correlation	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
pick the top	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
features i guess	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ideas in problem	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
information between feature	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
out the definition	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times the distribution	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
standard information theoretic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
information theoretic measure	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class in information	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
concepts of mutual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
two probability distributions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll have large	0.0	0.0	0.0	1.58496250072	0.0000000000	False
large mutual information	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
measure of information	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
chosen some measure	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
measure like correlation	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
correlation or major	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
top k features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features ; meaning	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features of mutual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
largest mutual information	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
mutual information label	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
order of mutual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
top one feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
top two features	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
top three features	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
includes using cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bayesian model selection	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
morning welcome back	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
discussion on learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theory and sort	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
start by talking	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
talking about bayesian	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
statistics and regularization	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
applying machine learning	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
machine learning algorithms	0.00480916103251	0.0	6.99672369858	12.6797000058	0.4321907601	True
algorithms to problems	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
start the talk	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remember from last	0.0	0.0	0.0	0.0	0.0000000000	False
started to talk	0.000375202171673	0.0	0.0	1.58496250072	0.0000000000	False
talk about learning	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
learned about bias	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
bias and variance	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
previous lecture talking	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
talking about algorithms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithms for model	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
selection we talked	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
talked about cross-validation	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
methods we talked	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lecture were ways	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
simply the model	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
feature selection algorithms	0.00120080810257	0.0	0.0	1.58496250072	0.0000000000	False
algorithms we talked	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
eliminate a number	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
number of features	0.000441254997125	0.0	0.0	1.58496250072	0.0000000000	False
reduce the number	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
number of parameters	0.00106870245167	0.0	0.0	1.58496250072	0.0000000000	False
reduce overfitting right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
selection algorithms choose	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose a subset	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
method called regularization	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
linear regression model	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
model we learned	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose the parameters	0.00096623334805	0.0	0.0	1.58496250072	0.0000000000	False
parameters via maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta that maximized	0.00120080810257	0.0	0.0	0.0	0.0000000000	False
maximized the probability	0.00138700055999	0.0	0.0	3.16992500144	0.0000000000	False
data we observe	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
give this sort	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
sort of procedure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
common frequencies procedure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
school of statistics	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
view behind writing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
true parameter theta	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
theta that govern	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
govern housing prices	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
value of theta	0.0	0.0	7.99672369858	12.6797000058	0.3493975904	False
procedure for estimating	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
estimating the value	0.0	0.0	0.0	3.16992500144	0.0000000000	False
estimating the unknown	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
value for theta	0.0	0.0	2.99854386604	4.75488750216	0.0000000000	False
random variable right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
procedure called maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
likelihood for estimating	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
procedure the alternative	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
put a prior	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
prior on theta	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
bayesian school students	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
represent our uncertainty	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
uncertainty over theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
denote my training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
represents my beliefs	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
sort of bayesian	0.00341059733663	0.0	6.99854386604	3.16992500144	0.4113475177	False
calculate the probability	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
probability by parameters	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bayes  rule	0.0	0.0	0.0	0.0	0.0000000000	False
call it posterior	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
distribution now represents	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
estimate the price	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
theta and times	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
times the posterior	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
distribution of theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
started to write	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
longer writing semicolon	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing semicolon theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing comma theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
concrete it turns	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
computation are difficult	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
one-dimensional parameter vector	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
difficult to compute	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
high dimensional spaces	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
hard to compute	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
compute the posterior	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
posterior in theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
compute this integral	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
integral if theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
bayesian logistic regression	0.0170529866832	0.0	28.9927193302	30.1142875137	0.3036649215	False
computing a full	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
full posterior distribution	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
chi of theta	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
maximize this quantity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
computing the full	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum a posteriori	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
estimate of theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
ont max chi	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
make a prediction	0.00220627498562	0.0	4.99817983254	7.92481250361	0.3411764706	False
theta in place	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
standard maximum likelihood	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood estimation	0.00132376499137	0.0	3.99890789953	3.16992500144	0.0000000000	True
choosing the maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
re instead maximizing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
prior is theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
theta being gaussian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
mass is close	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
remember our discussion	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
discussion on feature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
eliminate a feature	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
feature from consideration	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
setting the source	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
source and value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
prior that drives	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
reminiscent of feature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
guess in pictures	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit a fourth-order	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit very high	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
estimation all right	0.0	0.0	0.0	0.0	0.0000000000	False
apply this sort	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
fit a higher-order	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
smoother and smoother	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
driving the parameters	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
closer and closer	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of hard	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
tau becomes smaller	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
smaller and smaller	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
curves you tend	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
tend to fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit your data	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
fitting a large	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
piece of intuition	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
set of ideas	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ll post online	0.0	0.0	0.0	1.58496250072	0.0000000000	False
week i guess	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
linear regression turns	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
add this prior	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
objective you end	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
end up optimizing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
add an extra	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
penalizes your parameter	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
similar to maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
kind of hard	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
strengthening the parameters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
effect of keeping	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
keeping the functions	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
functions you fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
make more sense	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
ideas a bit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
common for models	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
models like logistic	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
regression and linear	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sorts of smoothing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
effects all right	0.0	0.0	0.0	0.0	0.0000000000	False
problems like text	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm like logistic	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
prone to overfitting	0.00255794800248	0.0	3.99890789953	4.75488750216	0.0000000000	False
build a spam	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
effective text classification	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
text classification algorithm	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bayesian regularization alex	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pick either tau	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
squared or lambda	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
relation is lambda	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
methods for preventing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
talking about online	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
designing the syllabus	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
place to fit	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
batch learning algorithms	0.000852649334158	1.0	0.0	1.58496250072	0.0000000000	False
run your learning	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
setting called online	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
process of learning	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sees all right	0.0	0.0	0.0	0.0	0.0000000000	False
make a guess	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
call your guess	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
made your prediction	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
first one right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
slightly more educated	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
guess and call	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
made your guess	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reveal the true	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
make your guess	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lot of machine	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
learning and batch	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
re making predictions	0.0	0.0	0.0	3.16992500144	0.0000000000	False
setting your website	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
start making predictions	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
likes or dislikes	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
total online error	0.00255794800248	0.0	3.99890789953	4.75488750216	0.0000000000	True
number of mistakes	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
mistakes you make	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sequence of examples	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
setting one thing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
asked to make	0.00138700055999	0.0	0.0	1.58496250072	0.0000000000	False
algorithm and run	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
run the learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
examples you ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve seen previous	0.0	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to make	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
stochastic gradient descent	0.00255794800248	0.0	2.99890789953	3.16992500144	0.0000000000	False
remember the perceptron	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
initial the parameter	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
update the parameters	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
reel a lot	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lot of times	0.00187601085836	0.0	2.99817983254	6.33985000288	0.4113475177	False
standard perceptron learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
perceptron learning rule	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
run one-step stochastic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
one-step stochastic gradient	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reason i ve	0.0	0.0	0.0	0.0	0.0000000000	False
sort of learning	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
prove fairly amazing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fairly amazing results	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error using algorithms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lecture to prove	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
infinite dimensional feature	0.00096623334805	0.0	0.0	1.58496250072	0.0000000000	False
dimensional feature vectors	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
simple vector machines	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
infinite feature dimensional	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
feature dimensional vectors	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
extremely high dimensional	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
positive and negative	0.00150080868669	0.0	3.99854386604	0.0	0.2027972028	False
examples are separated	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
infinite dimensional space	0.0016030536775	0.0	2.99890789953	4.75488750216	0.0000000000	False
separating the positive	0.00132376499137	0.0	2.99890789953	4.75488750216	0.0000000000	False
prove that perceptron	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm will converge	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
number of examples	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
converge to digital	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
class  syllabus	0.0	0.0	0.0	0.0	0.0000000000	False
nt be asked	0.0	0.0	0.0	0.0	0.0000000000	False
bounded vc dimension	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
prove learning theory	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
learning theory results	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
dimensional feature spaces	0.000483116674025	0.0	0.0	0.0	0.0000000000	False
sort of read	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
half an hour	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hour and understand	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lecture notes online	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
online learning setting	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
based on stochastic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
majority of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
switch to powerpoint	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sort of talking	0.00138700055999	0.0	0.0	1.58496250072	0.0000000000	False
talking about advice	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
advice for applying	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
applying different machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
humankind in machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine learning right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is give	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
tool it turns	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
machine learning tool	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
two different people	0.0	0.0	0.0	1.58496250072	0.0000000000	False
people to apply	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
person will sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithms to work	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
rest of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
conceptually most difficult	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
class to understand	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
understand all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll say today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is debatable	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
good machine learning	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
machine learning people	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
people will agree	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
focusing on today	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
today is advice	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
stuff to work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
deliver a product	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
building a system	0.00138700055999	0.0	0.0	3.16992500144	0.0000000000	False
machine learning system	0.00511589600495	0.0	3.99781579905	7.92481250361	0.0000000000	True
system to work	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
nt great advice	0.0	0.0	0.0	0.0	0.0000000000	False
make machine learning	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
learning algorithm work	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
deploy a working	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
diagnostics for debugging	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
debugging learning algorithms	0.00170529866832	1.0	0.0	3.16992500144	0.0000000000	False
briefly about error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
analyses and ablative	0.00255794800248	0.0	2.99890789953	1.58496250072	0.0000000000	False
out you ve	0.0	0.0	0.0	0.0	0.0000000000	False
heard about premature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
piece of code	0.00144935002207	0.0	2.99890789953	3.16992500144	0.0000000000	False
choose a subroutine	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
subroutine to optimize	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
write the subroutine	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
guilty of premature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
code to run	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
run really quickly	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt the bottleneck	0.0	0.0	0.0	0.0	0.0000000000	False
call that premature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
undergraduate programming classes	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimization and people	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
building machine-learning systems	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
premature statistical optimization	0.00255794800248	1.0	3.99890789953	4.75488750216	0.0000000000	True
heavily optimize part	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
talk about debugging	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
build an anti-spam	0.00255794800248	0.0	1.99890789953	0.0	0.0000000000	False
ve carefully chosen	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
chosen a small	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implement bayesian logistic	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
implement gradient descent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
percent test error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
additional lambda squared	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lambda squared term	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
minus lambda theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lambda theta square	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
implemented your bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
logistic regression algorithm	0.00180121215386	0.0	1.99890789953	3.16992500144	0.0000000000	False
unacceptably high error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improve this algorithm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improve the algorithm.well	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
set of features	0.00121758436085	0.0	1.99890789953	3.16992500144	0.0000000000	False
suspect your features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out better features	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
finding spam emails	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
suspect that gradient	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt quite converged	0.0	0.0	0.0	0.0	0.0000000000	False
running gradient descent	0.00180121215386	0.0	3.99890789953	3.16992500144	0.0000000000	False
descent a bit	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
gradient descent longer	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
hearing from class	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
tune the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value for lambda	0.0	0.0	3.99890789953	4.75488750216	0.0000000000	False
svm might work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
listed eight things	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hundreds of ways	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ways to improve	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
improve a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
improve the learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm and picking	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
largely a matter	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
matter of luck	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
end up fixing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improvements all fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
people in industry	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
change a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
learning algorithm randomly	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lots of things	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
improve your learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
run various diagnostics	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostics to figure	0.00426324667079	0.0	1.99817983254	7.92481250361	0.4321907601	False
out the problem	0.000852649334158	0.0	2.99817983254	4.75488750216	0.0000000000	False
logistic regression test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
regression test error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
suppose you suspected	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
suspected the problem	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
two few features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features that classify	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
classify as spam	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
wrote that wrong	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
forget the tables	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bias or high	0.00341059733663	0.0	5.99854386604	0.0	0.2914572864	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
variance ? right	0.0	0.0	0.0	0.0	0.0000000000	False
problem is high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
remember the cartoon	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
previously for high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
high variance problems	0.00426324667079	0.0	5.99817983254	7.92481250361	0.5178571429	False
variance the training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error all right	0.0	0.0	0.0	0.0	0.0000000000	False
fitting your training	0.00120080810257	0.0	0.0	1.58496250072	0.0000000000	False
tenth order polynomial	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
points all right	0.0	0.0	0.0	0.0	0.0000000000	False
re just fitting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
fitting the data	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
data is quadratic	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fitting a linear	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt even fitting	0.0	0.0	0.0	0.0	0.0000000000	False
typical learning curve	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
curve for high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
plotting the training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training set size	0.00360242430772	0.0	9.99781579905	9.50977500433	0.2914572864	False
plotting the error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
test set error	0.00255794800248	0.0	3.99890789953	3.16992500144	0.0000000000	False
sort of suggests	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
increase the training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
extrapolate the green	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error will decrease	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
red horizontal line	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
performance you re	0.0	0.0	0.0	0.0	0.0000000000	False
thing to plot	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
training error right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
larger your training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training set perfectly	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
set perfectly right	0.0	0.0	0.0	0.0	0.0000000000	False
size because smart	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
smart training sets	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
easy to fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
10,000 data points	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
harder to fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit that perfectly	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
perfectly all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
diagnostic for high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training versus test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
versus test error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
close that gap	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
case of high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
curve for test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error has flattened	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
extrapolate this curve	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
property of high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
plot training errors	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hold out test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out test set	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error is high	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
training error grows	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
level of desired	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
reduce your training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
level of performance	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training error sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
curve on test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
tend to find	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
diagnostic i tend	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
training and test	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
re very close	0.0	0.0	0.0	1.58496250072	0.0000000000	False
list of fixes	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fix high variance	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
variance all right	0.0	0.0	0.0	0.0	0.0000000000	False
features or adding	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
adding email features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
solutions that fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fix high bias	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
working on machine	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
machine learning problems	0.00277400111999	0.0	3.99854386604	4.75488750216	0.0000000000	False
training examples helps	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
build a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
money and effort	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
collecting more training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
high bias problem	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
spend three months	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
valley and companies	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
building various machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
spending six months	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
working on fixing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fixing a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
possibly have helped	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
invent new features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
solutions and save	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
months of fruitless	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
great so bias	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bias versus variance	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
ingenuity to figure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
wrong all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ingenuity to construct	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
slightly more contrived	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
illustrate another common	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
applying learning algorithms	0.000534351225834	0.0	0.0	1.58496250072	0.0000000000	False
error on spam	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
percent error non-spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error non-spam mail	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
non-spam mail right	0.0	0.0	0.0	0.0	0.0000000000	False
error on non-spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
deploy logistic regression	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
overnight every day	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
regression just runs	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
problem with logistic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
optimizing your objective	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
number of iterations	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
out all right	0.0	0.0	0.0	0.0	0.0000000000	False
curves a lot	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run this ten	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
regression is converged	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
optimizing the right	0.0	0.0	0.0	0.0	0.0000000000	False
weighted accuracy function	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
higher for non-spam	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correct for spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
optimizes a quantity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood thing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
right optimization function	0.0	0.0	0.0	1.58496250072	0.0000000000	False
change the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lambda to change	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
change this parameter	0.0	0.0	0.0	1.58496250072	0.0000000000	False
switching to support	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
support vector machine	0.00121758436085	0.0	5.99890789953	3.16992500144	0.0000000000	True
vector machine optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine optimization objective	0.0	0.0	0.0	0.0	0.0000000000	False
optimization algorithm converging	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
objective i chose	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reiterate the story	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
svm outperforms bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
outperforms bayesian logistic	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
deploy bayesian logistic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theta subscript svm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ll let theta	0.0	0.0	0.0	0.0	0.0000000000	False
theta subscript blr	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
learned by bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
objective you care	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
weighted accuracy criteria	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
vector machine outperforms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine outperforms bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
accuracy for bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimize an optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
denoted j theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostic i choose	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
svm is bigger-than	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
bigger-than or less-than	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
accuracy of support	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
accuracy of bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out whether bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimizing the wrong	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
wrong objective function	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
two equations copied	0.0	0.0	0.0	1.58496250072	0.0000000000	False
svm is greater	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
definition of bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means that theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
theta the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
output that bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
regression actually fails	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fails to maximize	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
back to machine	0.00255794800248	0.0	5.99890789953	0.0	0.0000000000	False
machine actually returned	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
returned the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt actually maximize	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm the optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
means that bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
regression actually attains	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
attains the higher	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine the support	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
weighted accuracy measure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
weighted accuracy objective	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means that maximizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt really correspond	0.0	0.0	0.0	0.0	0.0000000000	False
maximizing your weighted	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
wrong optimization objective	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt a good	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.000302084064114	0.0	0.0	1.58496250072	0.0000000000	False
sense ? cool	0.0	0.0	0.0	0.0	0.0000000000	False
iterations that fixes	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fixes the optimization	0.00511589600495	0.0	11.9978157991	6.33985000288	0.1912087912	False
lambda times norm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
norm of data	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
objective and changing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
harder and harder	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
harder to fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
iterations of gradient	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
crazy optimization algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fix the problem	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
sorts of diagnostics	0.00426324667079	0.0	2.99817983254	6.33985000288	0.5178571429	False
fixing your optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm or fixing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
work on flying	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
draws on reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
diagnostic we re	0.0	0.0	0.0	0.0	0.0000000000	False
talked about reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
back and redo	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
redo this exact	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fly autonomous helicopters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to design	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
design the controller	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
controller for helicopter	0.0	0.0	0.0	1.58496250072	0.0000000000	False
build a simulator	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fly a helicopter	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
helicopter in simulation	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
choose a cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
call it cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
expected squared error	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
helicopter s position	0.0	0.0	0.0	0.0	0.0000000000	False
run a reinforcement-learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
weeks you run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run reinforcement learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reinforcement learning algorithm	0.00554800223997	0.0	7.99708773207	11.094737505	0.4113475177	False
minimize this cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
minimize the squared	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
controlling your helicopter	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm will output	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
output some parameters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
denoting theta subscript	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fly your helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
suppose you run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run this learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out a set	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
set of controller	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
improve the simulator	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt that accurate	0.0	0.0	0.0	0.0	0.0000000000	False
capture the aerodynamic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
effects more accurately	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
capture the airflow	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
helicopter more accurately	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
modify the cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt just optimizing	0.0	0.0	0.0	0.0	0.0000000000	False
optimizing square area	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
wanted to experiment	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm does poorly	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
poorly well suppose	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things hold true	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
hold true suppose	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
suppose the contrary	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
simulator is accurate	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
controls the helicopter	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
tend to run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm in simulation	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm can crash	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
crash a helicopter	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
assume our reinforcement-learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm correctly controls	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
minimize the cost	0.00341059733663	0.0	3.99854386604	3.16992500144	0.2914572864	False
suppose that minimizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correspond to accurate	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correct autonomous flight	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things held true	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
real helicopter right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
learning control parameters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of means	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
assumptions is wrong	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
learning algorithm flies	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
predicts the helicopter	0.0	0.0	0.0	0.0	0.0000000000	False
helicopter s controller	0.0	0.0	0.0	0.0	0.0000000000	False
spend out efforts	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out efforts improving	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
improving the accuracy	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
write theta subscript	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theta subscript human	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human control policy	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
policy all right	0.0	0.0	0.0	0.0	0.0000000000	False
fly the helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means squared error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
pilot s flight	0.0	0.0	0.0	0.0	0.0000000000	False
terms of optimizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimizing this objective	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human does worse	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
good human pilot	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human pilot attains	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
attains a worse	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human actually attains	0.00255794800248	0.0	2.99890789953	4.75488750216	0.0000000000	False
attains a lower	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
managing to minimize	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
attains a larger	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
larger mean squared	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
function but flies	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
means the problem	0.0	0.0	0.0	1.58496250072	0.0000000000	False
function it means	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
means oh excuse	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means that minimizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
function my learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
correspond to good	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
good autonomous flight	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
reinforcement learning problems	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
work often reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithms just work	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
changing the cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
changing the reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
spend two years	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out that modeling	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
modeling helicopter aerodynamics	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
area of research	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing entire phd	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
entire phd theses	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out and spend	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
spend six years	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
years and write	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
write a phd	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
thesis and build	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fixing the wrong	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
described are sort	0.0	0.0	0.0	0.0	0.0000000000	False
specific learning problem	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
algorithm is working	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
idea to run	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
couple of reasons	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
understand your application	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
graduate from stanford	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
amazingly high-paying job	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
job to apply	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
apply machine-learning algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
significant economic interest	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
specific important machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
important machine learning	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
machine learning application	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
work your problem	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of right	0.0	0.0	0.0	0.0	0.0000000000	False
companies with important	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
years on end	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
problem using learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
personal intuitive understanding	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort i talked	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
problems it turns	0.000534351225834	0.0	0.0	1.58496250072	0.0000000000	False
silicon valley companies	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
companies that outsource	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
outsource their machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
re a company	0.0	0.0	0.0	1.58496250072	0.0000000000	False
company in silicon	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
hire a firm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
york to run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
maintain that expertise	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
knowledge is outsourced	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
reason for running	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing research papers	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostics and error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
justify your research	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing a research	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
algorithm that works	0.00138700055999	0.0	0.0	3.16992500144	0.0000000000	False
works i built	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
built this helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
justification that shows	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
thing that fixed	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fixed this problem,and	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
made it work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
discussion on error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine learning practice	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sources of errors	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
call error analyses	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
times the thing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
difficult a helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
building an accurate	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
two specific examples	0.0	0.0	0.0	1.58496250072	0.0000000000	False
actual machine learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
people from images	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
input in camera	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
preprocess the image	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
image and remove	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove the background	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
run a face	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
face detection algorithm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to detect	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
people s faces	0.0	0.0	0.0	0.0	0.0000000000	False
recognize the identity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
detect the mouth	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
regression or soft	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
soft match regression	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
long complicated pipeline	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
complicated pipeline combining	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
combining many machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine learning components	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
typical error analysis	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error analysis procedure	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
ll repeatedly plug	0.0	0.0	0.0	1.58496250072	0.0000000000	False
bottom left bottom	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
percent of error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ll actually code	0.0	0.0	0.0	1.58496250072	0.0000000000	False
implement my correct	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
correct background removal	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
give my algorithm	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
correct background versus	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
background versus foreground	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
color that blue	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
blue to denote	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
giving that ground-truth	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
assume our accuracy	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm the ground-truth	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
face detection output	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm s accuracy	0.0	0.0	0.0	0.0	0.0000000000	False
nose segmentation algorithm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
figure that out	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
end up giving	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correct output label	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
label and end	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
giving the ground-truth	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
boost your final	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
added the face	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
face detection ground-truth	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
percent accuracy right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
boost my accuracy	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostic also tells	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improve the system	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
improve your background	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
potential for gains	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose to spend	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
months on right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choosing the right	0.0	0.0	0.0	0.0	0.0000000000	False
piece is critical	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
type of analyses	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
explain the difference	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
performance and perfect	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sort of ablative	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
suppose you ve	0.0	0.0	0.0	0.0	0.0000000000	False
good anti-spam classifier	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
classifier for adding	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lots of clever	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
regression algorithm right	0.0	0.0	0.0	0.0	0.0000000000	False
features for spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sender host features	0.00341059733663	0.0	3.99854386604	6.33985000288	0.0000000000	False
email header features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
email text parser	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
text parser features	0.00255794800248	0.0	2.99890789953	3.16992500144	0.0000000000	False
javascript parser features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
features for embedded	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
preview the system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
components actually contribute	0.0	0.0	0.0	1.58496250072	0.0000000000	False
paper and claim	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
piece that made	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
made the big	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
document that claim	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
claim and justify	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
simple logistic regression	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out what accounts	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
ll instead remove	0.0	0.0	0.0	0.0	0.0000000000	False
rates so start	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove spelling correction	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove the sender	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
biggest drop occurred	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove the text	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
make a credible	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
made the biggest	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
features to speed	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
speed up computational	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
candidate for elimination	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
drop those features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
address the question	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
natural of ordering	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fairly natural ordering	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things or remove	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose one ordering	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
analyses as sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of formulas	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
free to invent	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
started on learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
problem the first	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
design your system	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
spend a long	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
long time designing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
collecting the right	0.0	0.0	0.0	0.0	0.0000000000	False
right data set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
designing the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
right algorithmic structure	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hope it works	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
works all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of approach	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
elegant learning algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
contribute to basic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
research in machine	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
invent new machine	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
process of slowing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
problem and invent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
invent new solutions	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
solutions second sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
input something quick	0.000852649334158	0.0	0.0	3.16992500144	0.0000000000	False
quick and dirty	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run error analyses	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
analyses and diagnostics	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fix those errors	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
errors the benefit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
type of approach	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
end up working	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
product that wins	0.0	0.0	0.0	1.58496250072	0.0000000000	False
product to market	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
market that wins	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
approach of building	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
building a quick-and-dirty	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
system that works	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
clear what parts	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
system are easier	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
big complicated learning	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
complicated learning system	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
big complicated pipeline	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
working on right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt the right	0.0	0.0	0.0	0.0	0.0000000000	False
easily have spent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
spent three months	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
works was inputting	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out what parts	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
parts and find	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
parts to implement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
make a difference	0.000534351225834	0.0	0.0	1.58496250072	0.0000000000	False
difference in performance	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
performance in fact	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
build a people	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
people recognition system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
converged a system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
system you re	0.0	0.0	0.0	0.0	0.0000000000	False
piece of advice	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
build a working	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
design a system	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
plot your data	0.00341059733663	0.0	4.99854386604	6.33985000288	0.0000000000	False
data you re	0.0	0.0	0.0	0.0	0.0000000000	False
numbers are negative	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out be implementing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implementing these big	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
complicated learning algorithms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
plotting the data	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
sounds so simple	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
advice that lots	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithms all right	0.0	0.0	0.0	0.0	0.0000000000	False
complicated than logistic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
simple and figure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
focus your efforts	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
add another hack	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hack to fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
machine learning research	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
follow this specifically	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
two more slides	0.0	0.0	0.0	3.16992500144	0.0000000000	False
optimization of code	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
optimize one component	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
big complicated machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
complicated machine learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sort of cartoon	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
written by christos	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
progress of research	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
build a mail	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
mail delivery robot	0.00426324667079	0.0	9.99817983254	7.92481250361	0.0000000000	False
drawn a circle	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
free up people	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
robot to wander	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
wander around indoor	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
robot to manipulate	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
objects and pickup	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
components in order	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
arrows to denote	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
avoidance is needed	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
build your mail	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
obstacle for avoidance	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
avoid the obstacles	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
vision to detect	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
detect the objects	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
morning or noontime	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
noontime or evening	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
color of things	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things to change	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
object detection system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
represented by three-dimensional	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out and study	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
study differential geometry	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
build a sound	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
similarity learning algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
understand the fundamental	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
study the complexity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
complexity of non-riemannian	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
eventually you re	0.0	0.0	0.0	0.0	0.0000000000	False
re proving convergence	0.0	0.0	0.0	0.0	0.0000000000	False
proving convergence bounds	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bounds for sampled	0.00255794800248	0.0	5.99890789953	0.0	0.0000000000	False
sampled of non-monotonic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt real color	0.0	0.0	0.0	0.0	0.0000000000	False
real color variance	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
barely helped object	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
helped object recognition	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
circles can represent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
represent a person	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
written on differential	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
guy once told	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
friend of mine	0.00138700055999	0.0	0.0	1.58496250072	0.0000000000	False
working on color	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
working on convergence	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sampled non-monotonic logic	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
light of day	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
criticizing the role	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
role of theory	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
dramatically advanced data	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
advanced data machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
data machine learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theory of np-hardness	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
highly theoretical things	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
re only hoping	0.0	0.0	0.0	1.58496250072	0.0000000000	False
tend to work	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
tend to trust	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
choose to work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
work on theory	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt necessarily trust	0.0	0.0	0.0	0.0	0.0000000000	False
summarize one lesson	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostics for learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implementing learning algorithms	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
algorithms and making	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implementing those tests	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
talked about error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
risks of premature	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
announcement of sorts	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
ago that stanford	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
submitted an entry	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
darpa grand challenge	0.00264177103744	0.0	0.0	1.58496250072	0.0000000000	False
competition to build	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
build a car	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
car to drive	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
grand challenge phase	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
stanford the team	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
colleagues sebastian thrun	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
ll be racing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
racing another autonomous	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
car that incorporates	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
incorporates many tools	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
midst of traffic	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
traffic and avoid	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
avoid other cars	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
cars and carry	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
out the sort	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
sort of mission	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
free this weekend	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
free on saturday	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
online for urban	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
thing to watch	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
demo or instance	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
machines in action	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
seconds before class	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
start to talk	0.00071463434039	0.0	0.0	1.58496250072	0.0000000000	False
talk about clustering	0.0	0.0	0.0	0.0	0.0000000000	False
mixture of model	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
model to describe	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
jensen and equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
derive a general	0.00132088551872	0.0	0.0	0.0	0.0000000000	False
expectation maximization algorithm	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	True
algorithm we sort	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
draw for supervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
positive and negative	0.00071463434039	0.0	0.0	0.0	0.0000000000	False
sort of told	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
right cross label	0.0	0.0	0.0	1.58496250072	0.0000000000	False
supervision in unsupervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
problem you re	0.0	0.0	0.0	0.0	0.0000000000	False
comprises a set	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
set of points	0.00252132848065	0.0	4.99789621318	4.75488750216	0.0000000000	False
points you re	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm to discover	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
couple of weeks	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
variety of unsupervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
unsupervised learning algorithms	0.00264177103744	0.0	0.0	1.58496250072	0.0000000000	False
types of structure	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
two different crosses	0.0	0.0	0.0	1.58496250072	0.0000000000	False
first unsupervised learning	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
breaks the data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
variety of applications	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guess in biology	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
order to examine	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
understand the biological	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
application of clustering	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
clustering is market	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
research so imagine	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
practice to apply	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
apply clustering algorithms	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
algorithms to break	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
break your database	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
database of customers	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
target your products	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
segments and target	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
target your sales	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm to everyday	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
everyday group related	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
group related news	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
related news articles	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
thousand news articles	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
news articles today	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
story of today	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
solid actually talks	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
talks about image	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
picture and group	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
picture into coherent	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
pieces of pixels	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
group the data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
sets into coherent	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
start to write	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
out the specific	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
specific clustering algorithm	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
k-means clustering algorithm	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for finding	0.00114356841605	0.0	0.0	0.0	0.0000000000	False
inset the input	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
unlabeled data set	0.00487203332366	0.0	1.99789621318	4.75488750216	0.0000000000	False
re now talking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talking about unsupervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
make a bit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
bit more sense	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
laptop to initialize	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
initialize a set	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
re of training	0.0	0.0	0.0	0.0	0.0000000000	False
repeat until convergence	0.0022871368321	0.0	0.0	3.16992500144	0.0000000000	False
assigning your point	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
point and picking	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
picking the cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
update the cluster	0.00487203332366	0.0	3.99789621318	0.0	0.0000000000	False
laptop ? excuse	0.0	0.0	0.0	1.58496250072	0.0000000000	False
algorithm and hope	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
hope the animation	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
animation will make	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
make more sense	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
jordan in berkley	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
points in green	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
initialize a pair	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
pair of cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
crosses to note	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
note the positions	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
positions of new1	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
new1 and new2	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
sets of k-means	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
algorithms as follow	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
two cluster centroids	0.0	0.0	0.0	1.58496250072	0.0000000000	False
dots either blue	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
blue or red	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
closer cluster centroid	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
blue cross points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
points are painted	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
step is updating	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ve painted blue	0.0	0.0	0.0	1.58496250072	0.0000000000	False
blue and compute	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
compute the average	0.00649604443155	0.0	3.99719495091	6.33985000288	0.2056737589	False
dots and compute	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
move the cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
points and assign	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
assignments of points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll again compute	0.0	0.0	0.0	1.58496250072	0.0000000000	False
points and compute	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
points and update	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm i wrote	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
steps this step	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
assigning the points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
shifting the cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
k-means is guaranteed	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guaranteed to converge	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
define the distortion	0.0	0.0	0.0	0.0	0.0000000000	False
centroids and square	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
nt really prove	0.0	0.0	0.0	0.0	0.0000000000	False
show that k-means	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
repeatedly with respect	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
steps of k-means	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimizing this function	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
function with respect	0.00114356841605	0.0	0.0	1.58496250072	0.0000000000	False
extremely unlikely case	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
objective function k-means	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
converge another question	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
choose the number	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
number of clusters	0.0113680777552	0.0	7.99438990182	11.094737505	0.2423398329	False
people apply k-means	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
pick a number	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
clusters and pick	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
hard to choose	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
ways of choosing	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
problems the true	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
clusters is sort	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
sort of ambiguous	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
data point points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
k-means is susceptible	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
susceptible to local	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
multiple random initializations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
clustering a bunch	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
bunch of times	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
times and pick	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
pick the solution	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
solution that ended	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
majority of applications	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
applications i ve	0.0	0.0	0.0	0.0	0.0000000000	False
longer to describe	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
closely related problem	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
talk about density	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
guys that worked	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
aircraft engine building	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
re building aircraft	0.0	0.0	0.0	0.0	0.0000000000	False
building aircraft engines	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
aircraft engines roll	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
test these aircraft	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
engines and measure	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
write these properties	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
properties as heat	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
heat and vibrations	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
right in reality	0.0	0.0	0.0	0.0	0.0000000000	False
measure different vibrations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
write the amount	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
amount of heat	0.00324802221578	0.0	0.0	0.0	0.0000000000	False
produced and vibrations	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
estimate the density	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
amount of vibrations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
undergo further inspections	0.0	0.0	0.0	1.58496250072	0.0000000000	False
distribution of features	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
build a model	0.0022871368321	0.0	0.0	3.16992500144	0.0000000000	False
raise a red	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
anomaly aircraft engine	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
data you re	0.0	0.0	0.0	0.0	0.0000000000	False
transactions to start	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
stolen my credit	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
talk about specific	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm for density	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
works with data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
nt really fall	0.0	0.0	0.0	0.0	0.0000000000	False
standard text book	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
text book distributions	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
model to estimate	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
describe the algorithm	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
algorithm a bit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
represent the positions	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
two gaussian distributions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
mixture of gaussian	0.0	0.0	3.99649368864	7.92481250361	0.4233576642	False
gaussian s model	0.0	0.0	0.0	0.0	0.0000000000	False
two separate gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
generated this data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
put a gaussian	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
algorithm to fit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
fit this mixture	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
latent random variable	0.00649604443155	0.0	2.99719495091	6.33985000288	0.0000000000	False
synonymous with hidden	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
hidden or unobserved	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
chamber of probability	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
multinomial with parameters	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
gaussian discriminant analysis	0.00571784208025	0.0	5.99649368864	6.33985000288	0.2974358974	True
discriminant analysis algorithm	0.00132088551872	0.0	0.0	0.0	0.0000000000	False
guess supervised learning	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ve now replaced	0.0	0.0	0.0	1.58496250072	0.0000000000	False
unobserved random variables	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
make the link	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
sake of argument	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
likelihood the parameters	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
knew the value	0.00324802221578	0.0	3.99789621318	4.75488750216	0.0000000000	False
law of likelihood	0.0145297407059	0.0	12.992286115	14.2646625065	0.3251783894	True
sense ? raise	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00230147544123	0.0	3.99719495091	6.33985000288	0.0000000000	False
makes sense cool	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
playing a similar	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
labels in gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian s discriminant	0.0	0.0	0.0	0.0	0.0000000000	False
maximum likeliness estimation	0.014616099971	0.0	6.99368863955	12.6797000058	0.2556317336	True
likeliness estimation parameters	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
specific bootstrap procedure	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guessed to fit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
fit the parameters	0.00114356841605	0.0	0.0	1.58496250072	0.0000000000	False
ll actually iterate	0.0	0.0	0.0	1.58496250072	0.0000000000	False
estimation to set	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
set even parameters	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guess the values	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
compute the probability	0.00487203332366	0.0	3.99789621318	4.75488750216	0.0000000000	False
probability that point	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
sort of concrete	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
step is sort	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
gaussian density right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
divided by sum	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
update your estimates	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll just lay	0.0	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood estimation	0.00168088565377	0.0	0.0	3.16992500144	0.0000000000	False
formulas on top	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
computed that point	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
call it cluster	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
covariant matrix sigma	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
lot of equations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
give you labeled	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
labeled data sets	0.00162401110789	0.0	2.99719495091	6.33985000288	0.0000000000	False
analysis we figured	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
out the maximum	0.00132088551872	0.0	0.0	0.0	0.0000000000	False
parameters of gda	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
parameters for gda	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
indicator zi equals	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
re deriving gda	0.0	0.0	0.0	1.58496250072	0.0000000000	False
knew the cross	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
versus the negative	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
fraction of examples	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
examples your maximum	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
estimate for probability	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
examples from cross	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
estimation for gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of dots	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
observe the xis	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
zis are unknown	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
label is unknown	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm we re	0.0	0.0	0.0	0.0	0.0000000000	False
step we computed	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
current best guess	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
formula of estimating	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
sum of wij	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
wij so wij	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
wij is right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
right the probability	0.0	0.0	0.0	1.58496250072	0.0000000000	False
point i belongs	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
belongs to gaussian	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
gaussian or belongs	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
belongs to cross	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
replaces the wijs	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
convey an intuitive	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm s make	0.0	0.0	0.0	0.0	0.0000000000	False
present a broader	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
specially to make	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
remaining half hour	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
describe a general	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
written f prime	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
drop the square	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
ll often drop	0.0	0.0	0.0	1.58496250072	0.0000000000	False
draw a picture	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
remember the sign	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
probability of one-half	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
illustrate this inequality	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
axis we re	0.0	0.0	0.0	0.0	0.0000000000	False
holds an equality	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
constant with probability	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
strictly convex function	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
inequality to hold	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
hold its equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
convexed just means	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
straight line portion	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
nt any straight	0.0	0.0	0.0	0.0	0.0000000000	False
problem was face	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
maximize the law	0.00264177103744	0.0	0.0	3.16992500144	0.0000000000	False
parameters of model	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
find the maximum	0.000920175286124	0.0	0.0	0.0	0.0000000000	False
likelihood is defined	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
data as usual	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
parameterized by data	0.00487203332366	0.0	5.99789621318	4.75488750216	0.0000000000	False
taking our model	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
performing this maximum	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
likeliness estimation problem	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
likelihood of theta	0.00396265655617	0.0	2.99789621318	4.75488750216	0.0000000000	False
maximizing our derivatives	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
initializes some value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of theta	0.0	0.0	3.99789621318	1.58496250072	0.0000000000	False
algorithm will end	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
construct a lower	0.00649604443155	0.0	5.99719495091	0.0	0.2974358974	False
tight of equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
equality after current	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
guessing the parameters	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
maximize this lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
boundary with respect	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
respect to theta	0.0022871368321	0.0	0.0	1.58496250072	0.0000000000	False
bound of theta	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
converge to local	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimum on theta	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
cartoon that displays	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
make that formal	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
maximize with respect	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
multiply and divide	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
construct the probability	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
describe the specific	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
value of log	0.0	0.0	0.0	0.0	0.0000000000	False
concave function form	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
form of jensen	0.0	0.0	0.0	0.0	0.0000000000	False
out this formula	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
equal to sum	0.00114356841605	0.0	0.0	1.58496250072	0.0000000000	False
denote the distribution	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
value with respect	0.0	0.0	0.0	0.0	0.0000000000	False
variable z joined	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
re doing maximum	0.0	0.0	0.0	0.0	0.0000000000	False
choose the parameters	0.000920175286124	0.0	0.0	1.58496250072	0.0000000000	False
parameters that maximizes	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
maximizes the probability	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
likelihood of parameters	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
wanted to maximize	0.00162401110789	0.0	0.0	3.16992500144	0.0000000000	False
ve know constructed	0.0	0.0	0.0	1.58496250072	0.0000000000	False
likelihood of data	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
function of theta	0.00305327978867	0.0	6.99719495091	3.16992500144	0.0000000000	False
ve just shown	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta is lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
thing okay remember	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
remember that cartoon	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
bound and optimizing	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimizing the lower	0.00324802221578	0.0	0.0	0.0	0.0000000000	False
likelihood for theta	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
hold with equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
value for theta	0.0	0.0	0.0	0.0	0.0000000000	False
construct some lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimize my lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
true objective function	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
function is concave	0.0	0.0	0.0	1.58496250072	0.0000000000	False
models we work	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
law of bound	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
right in general	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
back to jensen	0.0	0.0	0.0	1.58496250072	0.0000000000	False
random variable inside	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
taking an expectation	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
expectation with respect	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
respect to constant	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
constant valued variables	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
zis must sum	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
parameterized by theta	0.0022871368321	0.0	0.0	3.16992500144	0.0000000000	False
normalize the sum	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
definition of conditional	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
summarize the algorithm	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
choose the distributions	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
step we ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve now created	0.0	0.0	0.0	1.58496250072	0.0000000000	False
created a lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimize that lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
bound with respect	0.00324802221578	0.0	0.0	0.0	0.0000000000	False
ll probably show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian s algorithm	0.0	0.0	0.0	0.0	0.0000000000	False
constructs this lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
bound and makes	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
respect to data	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll continue talking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
embedded systems today	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
discuss what embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
covering in forty	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cover the processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors a bus	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bus structures interfacing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
structures interfacing issues	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
program also real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
occasion to examine	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examine different aspects	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
aspects of network	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
network embedded systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sets of books	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
books which action	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
action primarily follow	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded system micro	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
micro any device	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
device that includes	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
includes a computer	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
general purpose computer	0.0176830004486	0.0	11.9903647626	20.6045125094	0.4338498212	True
expected to function	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
function without human	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
intervention an embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system is expect	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
expect to expect	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expect to respond	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control external environment	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
environment using sensors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sensors and actuators	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
embedding a computer	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
simplest possible model	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded system lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examples are personal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
personal digital assistance	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital assistance printers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computers cell phone	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
automobiles in fact	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
number of microcontrollers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded networks computing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
networks computing system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computing system television	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
television in television	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
household appliances lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microcontrollers sitting inside	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
managing these microcontrollers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designing there hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designing the software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software for managing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing a general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computer so lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system in fact	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
fact surveillance system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
surveillance system oblate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
smart cards etcetera	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
part of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
types of microcontroller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
users are thirty	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
thirty two bit	0.00656109227832	0.0	3.99587061253	7.92481250361	0.3589743590	False
two bit microcontroller	0.0	0.0	3.99793530626	1.58496250072	0.0000000000	False
planes example front	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
panel of microwave	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
size much smaller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
camera in fact	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
two bit processor	0.0	0.0	0.0	0.0	0.0000000000	False
handles complex functions	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
primarily the problem	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
problem of tuning	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tuning and channel	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital tv decompression	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
decompression disk family	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
set of box	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
box your microcontroller	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
handles a number	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
number of complex	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
complex functions lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
automobile system today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
four bit microcontroller	0.0	0.0	0.0	1.58496250072	0.0000000000	False
microcontroller can check	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
check the tension	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
seat belt microcontrollers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microcontrollers can run	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
run the display	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control the engine	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
engine and sees	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sees the engine	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sixteen or thirty	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
bit microcontroller lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system of breaking	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sensors this sensors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensors actually sensors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensors the speed	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control by hydraulic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
automated breaking system	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
system which receives	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
breaking system actuate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
actuate the hydraulic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
pump to control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control the break	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control system begin	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system begin implemented	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
characteristics of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems first thing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implement sophisticated functionality	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
functionality the degree	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
degree of sophistication	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sophistication can vary	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
plans by plans	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
plans this satisfy	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real time operation	0.00631535730306	0.0	9.99655884377	6.33985000288	0.2922755741	False
cases low manufacturing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
low manufacturing cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost but cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue which request	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
request further closer	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
application dependent processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
general purpose processors	0.00252614292122	0.0	0.0	3.16992500144	0.0000000000	False
find in computers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
work with restricted	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
battery operator devices	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
val mounter devices	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
mounter devices powered	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
powered from direct	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
direct power supply	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
supply then power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
heat management heat	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
management heat dissipation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
heat dissipation design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system so lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue of manufacturing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aspects first aspect	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
call non recurring	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
non recurring engineering	0.0	0.0	0.0	0.0	0.0000000000	False
recurring engineering cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost is production	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
production and marketing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
marketing each unit	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
targeting um mass	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
production marketing cost	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
invest into enary	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
set for high	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
high production cost	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
highly sophisticated recruitments	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing as cell	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
phone or low	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
low cost cell	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost cell phone	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cell phone aiming	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aiming to serve	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
serve a mass	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
based technology choice	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of units	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
units with plans	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
plans to produce	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
produce now lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
issue of real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
operation the basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
completed by deadlines	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deadline so real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
completed within headline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kinds of real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
real time headlines	0.00465878848625	0.0	5.99793530626	3.16992500144	0.0000000000	False
headlines hard real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
headlines and soft	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
headlines and occluding	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
real time systems	0.0108705064679	0.0	5.99518238128	9.50977500433	0.3835616438	True
miss a deadline	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
automatic reactor control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
times miss deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
playing a video	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
decode a frame	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
distance you viewing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
experience many systems	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
multi-rate that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
means this embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems are receiving	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
application dependent requirements	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
monitoring accritical person	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tolerance and reliability	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
systems um avoid	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
physical or economic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
damage to person	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system that means	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
means nonce programmed	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
programmed this systems	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems um expected	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expected to execute	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
programmed or design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design for specific	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
call dedicated systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deliver the goals	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
goals and accept	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
accept the cache	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
machine which users	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users eight bit	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bit motorola microcontroller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
thousand four introduction	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
four introduction product	0.0	0.0	0.0	0.0	0.0000000000	False
web enabled cashless	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
enabled cashless vending	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cashless vending machine	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
task of delivering	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
delivering a good	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
good in response	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
web enabled device	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
enabling the stock	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cards or smart	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
brought in sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sophisticated processors sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors sophisticated functionalities	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bit intel microprocessor	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microprocessor in fact	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
robot which move	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
move down mars	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
gps receiver global	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
receiver global positioning	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
global positioning system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
vehicle to deprovement	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deprovement its location	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
automated navigational tool	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tool this gps	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
two receive input	0.0	0.0	0.0	1.58496250072	0.0000000000	False
display because display	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
player various versions	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
versions of mp3	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
form of audio	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
audio to play	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computational task apprentic	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
task apprentic sophisticated	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
apprentic sophisticated computational	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sophisticated computational task	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
two bit risk	0.0	0.0	0.0	0.0	0.0000000000	False
bit risk microprocessor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue is applicable	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
decompression and decompression	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
decompression what rate	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
video rate video	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
rate video rate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
video rate means	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
means what twenty	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
twenty five hertz	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
milliseconds to decompress	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
decompress of video	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
case aprentic sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aprentic sophisticated microprocessor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
microprocessor to work	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
two bit risc	0.0	0.0	0.0	0.0	0.0000000000	False
bit risc microprocessor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sony aibo robotic	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
aibo robotic dog	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
pet in japan	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users just note	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sixty four bit	0.00465878848625	0.0	3.99793530626	3.16992500144	0.0000000000	False
four bit neat	0.0	0.0	0.0	0.0	0.0000000000	False
bit neat processor	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
handle and number	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
coordinate its emotions	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
emotions that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control the manipulator	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computational robo football	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
teams in fact	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fact this sony	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
detect the ball	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
request pretty sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
pretty sophisticated processors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors to handle	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
handle it tasks	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
four bit mips	0.0	0.0	0.0	0.0	0.0000000000	False
bit mips risc	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
variety of examples	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examples now lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
classify the examples	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
similar to general	0.00465878848625	0.0	5.99793530626	0.0	0.0000000000	False
computing like pda	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
pda video games	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
video games set	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
boxes automatic teller	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
automatic teller machines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computing the similar	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
pda the maturity	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computer similar thing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
provide the input	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
input the user	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expect some output	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
output they note	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
note really sensing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensing external environment	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
activating any actuator	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
influence or change	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
change the external	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
purpose computing machines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
machines they respond	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
respond to users	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system whose basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sensing and actuating	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
actuating the feedback	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control of real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system various real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
feedback control depending	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examples of user	0.0	0.0	0.0	1.58496250072	0.0000000000	False
vehicles engine foal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
engine foal injection	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control flight control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
flight control nuclear	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control nuclear reactors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
examples of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems which belongs	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
category of control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
job or basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
focus is signal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processing your mp3	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
players your dvd	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
dvd players radar	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
players radar control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
radar control system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system the basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
similarly a sonar	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
signal processing systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
systems and communication	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
communication and networking	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of internet	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
internet a planes	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
planes in fact	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
fact the web	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
web enable vending	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
enable vending machine	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kind of functions	0.00109351537972	0.0	0.0	1.58496250072	0.0000000000	False
expected to implement	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensing an actuation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
realize some control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
realize a control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control second important	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logic this sequencing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose sequencing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
purpose sequencing logic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
task specific sequencing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
specific sequencing logic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sequencing logic implemented	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interfacing and embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system with external	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
signal processing ability	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
ability to deal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deal with sense	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sense your inputs	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inputs next thing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
thing is application	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
application specific interfacing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
interfacing because application	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kind of senses	0.00155292949542	0.0	0.0	3.16992500144	0.0000000000	False
kind of actuated	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
interface this interfacing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implies both hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software next thing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing fault response	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
occurs the basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue or basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
basic design philosophy	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
philosophy for fault	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
call graceful depredation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
graceful depredation cattest	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
depredation cattest traffic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cattest traffic failure	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
happening the system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
users that things	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
things are failing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
failing and graceful	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
battery is low	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
low so user	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
stop its activity	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sun so graceful	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implement so lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expanded the basic	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
block have expanded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
shown the cpu	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cpu the alum	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
alum its cpu	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
obvious the memory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
memory because memory	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software to control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control the system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
analog to digital	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
converters and digital	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
digital to analog	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
environment is expected	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expected to receive	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
receive sensor inputs	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inputs and actuate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
actuate the actuators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
actuators to change	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
essential and integral	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
component in majority	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
shown an fpga	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
fpga or acid	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cases my cpu	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
ability to execute	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
execute my software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software satisfying real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
real time circumstance	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fpga and acid	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
cpu now lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cpu the human	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kind of reading	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
systems any control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
lcd display panel	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simple um simple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
simple led based	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
led based informative	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
informative um color	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
color color codes	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tools why diagnostic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems are expected	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
expected to work	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
trace that failure	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
out and thrown	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tools to interface	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interface and check	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
working second important	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing why diagnostic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tools are important	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system is starting	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system is working	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
check at regular	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
basics so diagnostics	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
diagnostics tools form	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dealt with power	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
powered to dissipation	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dissipation when cooling	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design the cooling	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
extra heat dissipations	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design becomes important	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
casing the casing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system is exceptive	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
good well design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system can fail	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
packaging the system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
electronics then heat	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
heat can effective	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design becomes extrument	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
discuss those mechanical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
embedded system design	0.00465878848625	0.0	2.99793530626	4.75488750216	0.0000000000	True
kind an appliances	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design and implementation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implement an embedded	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
elements the processing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
basically your microprocessors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microprocessors and microcontrollers	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
devices because input	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
input an output	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kinds of interfacing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computer we tend	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tend to talk	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
talk about standard	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
standard input output	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
input output devices	0.00378921438184	0.0	5.99793530626	1.58496250072	0.0000000000	True
day by day	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
set of input	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
devices a large	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kind of sensors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
targeted for embedded	0.00465878848625	0.0	1.99793530626	3.16992500144	0.0000000000	False
cases even simpler	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
mechanism to interface	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interface with external	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
devices and external	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
external io devices	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
talked about system	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
software and application	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
components one aspects	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
aspects of vsd	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
typically we talk	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
talk about assemblers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
clause of system	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
software or operating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems now majority	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cases embedded systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
specialized operating systems	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
general purpose operating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
purpose operating system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
window units order	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
units order variance	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
satisfy certain caricaturists	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
encounter in general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
purpose computing system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designed to satisfy	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
satisfy the general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
case this embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems are dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real time scheduling	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
cases we require	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
require real tome	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real tome scheduling	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
compilers your compilers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compilers which compile	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compile your high	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
high level language	0.00194642685162	0.0	0.0	1.58496250072	0.0000000000	False
level language code	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
target machine code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system but incase	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
call cross assemblers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
assemblers and cross	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
entire development process	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
level language program	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
compilers and cross	0.00465878848625	0.0	3.99793530626	0.0	0.0000000000	False
compiler would run	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compiler to compile	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
generate the code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
code for big	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
compiler is running	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
find this compilers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compilers and assemblers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
family of processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
targeting one processor	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of registers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
part of system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
emulators this instruction	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
instruction set emulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
emulators actually emulates	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
emulates your processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simple bevorial emulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
implement the instruction	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
complete simulation environment	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tools system software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system software tools	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
embedded system development	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tool that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software to execute	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
execute your code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
connector that code	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
talk about emulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
emulators and simulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
talk about debugging	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
system software set	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expect for general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
targeted for dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software obviously software	0.0	0.0	0.0	0.0	0.0000000000	False
flavors different kinds	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kinds of flavors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
operating system weak	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system weak works	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
weak works running	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
plants but application	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
printer is targeted	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
targeted for printing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
supported on top	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
present in multiple	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software would things	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
history of hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
status of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose microprocessor	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
fact this arrow	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
arrow actually tells	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
faster clock rate	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
faster execution speed	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
degree of integration	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
integration that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
devices and peripherals	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
purpose microprocessor microcontroller	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
develop a system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system so unary	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost towards development	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors and microcontrollers	0.00155292949542	0.0	1.99793530626	3.16992500144	0.0000000000	False
microcontrollers for implementing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded system dsp	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dsp that digital	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital signal processor	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	True
talking about digital	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital signal processing	0.00155292949542	1.0	2.99793530626	4.75488750216	0.0000000000	False
variety of signal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose microcontroller	0.00465878848625	0.0	2.99793530626	4.75488750216	0.0000000000	True
application specific processor	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing a processor	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
suit you application	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
application is search	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
permit this additional	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
additional unary cost	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
cost the kind	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system on chip	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
soc and soc	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
single processor code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
code but multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
multiple processor codes	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processor codes alu	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
codes alu peripherals	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
textes instrument omap	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
instrument omap processor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
dsp sitting inside	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inside the chip	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
peripheral also integrated	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
variety of issues	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system it means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of peripherals	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
special purpose coprocessors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors being integrated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
piece of silicon	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
functionality being implemented	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system as single	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
associate a design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
canjancem of power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems that supports	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
supports that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
correct logically correct	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logically correct means	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing is temporal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real time consideration	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
correct at wrong	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deal with inherent	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inherent physical concurrency	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computer we talk	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
talk about concurrency	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multiple users multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users multiple processors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
multiple processors running	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
world is concurrent	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
reliability and fault	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tolerance obviously critical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
specific and single	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
single purpose lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multitasking and concurrency	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multitasking is important	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
important for embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
inputs and outputs	0.00109351537972	0.0	0.0	1.58496250072	0.0000000000	False
outputs and multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
events can occur	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cases as exceptive	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multitasking and separating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue is separating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
separating task simplifies	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simplifies your programming	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tasks and concurrency	0.00155292949542	0.0	0.0	3.16992500144	0.0000000000	False
appearance of simultaneous	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
execution of multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tasks so lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
concurrency in temperature	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
simple temperature controller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control the temperature	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
request to handle	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
temperature and depending	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors or task	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
handled in dependent	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simple embedded system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system also request	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
external world interact	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors from multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users being run	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
challenges in designing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing an embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
size of memory	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
meet our deadlines	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deadline on project	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deadlines but deadlines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system okay faster	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
hardware or cleverer	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
write a clever	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
meet my deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
cpu as incase	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
require a first	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fpga at dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
low cost cpu	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
meat the deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software i design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design at dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fpga or make	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
acid and include	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dealing with real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
systems next issue	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
minimize power turn	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
turn of unnecessary	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
unnecessary logic reduce	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logic reduce memory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
reduce memory access	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
memory access reducing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
access reducing memory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption of power	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
discuss is power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
power management issue	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
point to deal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designing a system	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
objectives dependability affordability	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
dependability affordability safety	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
affordability safety security	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
safety security scalability	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
security scalability timeliness	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
discussed the timeliness	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kind of fault	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tolerance and graceful	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
safe and secure	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
depending on market	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
objectives in order	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
order to multi	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multi the objectives	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
objectives we require	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
require a kind	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multi disciplinary approach	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
aspect is electronic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aspect is mechanical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing is humans	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
humans on society	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
society or institutions	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
institutions the sociological	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aspect about accepting	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
accepting a product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
make a product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
product but people	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sociologically acceptable depending	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
depending on norms	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
perspective for introducing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
life cycle events	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system gets developed	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logistics of maintaining	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
maintaining the system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
draw the product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
introducing a product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
support the product	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
important design goal	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
goal in terms	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
terms of performance	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
speed and deadlines	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deadlines then functionality	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
functionality and user	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
user interface manufacturing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interface manufacturing cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
manufacturing cost power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost power consumption	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
power consumption physical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption physical size	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption although related	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
product is non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non be acceptability	0.0	0.0	0.0	1.58496250072	0.0000000000	False
functional and non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non functional requirements	0.0	0.0	0.0	1.58496250072	0.0000000000	False
function of input	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
non-functional requirements non-functional	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
requirements non-functional requirements	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
size power consumption	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
power consumption reliability	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption reliability etcetera	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
goal and design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
requirement at times	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
important for acceptance	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design development process	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
start with requirements	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design an architecture	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
block level architecture	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
component level design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
basically testing face	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
face because testing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
find a bug	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
download a patch	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system that flexibility	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
giving that product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
user and user	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
user is expect	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
internet and download	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
download the patch	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
bug for hardware	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
faults the design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
top down design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design you start	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
description and work	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
level the bottom	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bottom up design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
common in terms	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
terms of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design um strategies	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
strategies you work	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
work from small	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
component to big	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
developing a product	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
component from previous	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bottom up process	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
fact any real	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design actually involves	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
step wise requirement	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
talking about software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
hardware and software	0.00109351537972	0.0	0.0	0.0	0.0000000000	False
system go handing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
meet at deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design a special	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
special purpose hardware	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing software hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software hardware partitioning	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
show for covered	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
overview um introductory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fact some body	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
made this statement	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
statement that today	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microcontrollers and microprocessors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microprocessors at home	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
home then computers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microwave your cell	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
phone a viewer	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
microcontroller setting inside	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computers and embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design challenges design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design time deadlines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deadlines and power	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
realize that embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
form a general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
characteristics of components	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
mange the design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design process perfect	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
end this lecture	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
start our discussion	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
discussion on embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
