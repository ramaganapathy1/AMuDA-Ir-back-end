basically talking about clipping	0.0	0.0	0.0	2.0	0.0000000000	False
right so we covered	0.0	0.0	0.0	2.0	0.0000000000	False
covered polygon point clipping	0.0	0.0	0.0	2.0	0.0000000000	False
talked about line clipping	0.0	0.0	0.0	2.0	0.0000000000	False
clipping right so today	0.0	0.0	0.0	2.0	0.0000000000	False
talk about polygon clipping	0.0	0.0	0.0	2.0	0.0000000000	False
give you the kinds	0.0	0.0	0.0	2.0	0.0000000000	False
basically a planner set	0.0	0.0	0.0	2.0	0.0000000000	False
set of a ordered	0.0	0.0	0.0	2.0	0.0000000000	False
grasp for the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
right so the restriction	0.0	0.0	0.0	2.0	0.0000000000	False
restriction we are passing	0.0	0.0	0.0	2.0	0.0000000000	False
right just the weight	0.0	0.0	0.0	2.0	0.0000000000	False
crossing of the line	0.0	0.0	0.0	2.0	0.0000000000	False
polygon and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
interested in a polygon	0.0	0.0	0.0	2.0	0.0000000000	False
define primitives filling area	0.0	0.0	0.0	2.0	0.0000000000	False
right and one thing	0.0	0.0	0.0	2.0	0.0000000000	False
clipping for the line	0.0	0.0	0.0	2.0	0.0000000000	False
right to the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon to be defined	0.0	0.0	0.0	2.0	0.0000000000	False
line of the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
line clipping right lets	0.0	0.0	0.0	2.0	0.0000000000	False
convex and non convex	0.0	0.0	0.0	2.0	0.0000000000	False
region right the line	0.0	0.0	0.0	2.0	0.0000000000	False
non convex or concave	0.0	0.0	0.0	2.0	0.0000000000	False
polygon right the line	0.0	0.0	0.0	2.0	0.0000000000	False
right the line joining	0.0	0.0	0.0	2.0	0.0000000000	False
joining these two points	0.0	0.0	0.0	2.0	0.0000000000	False
right this is non	0.0	0.0	0.0	2.0	0.0000000000	False
convex so now lets	0.0	0.0	0.0	2.0	0.0000000000	False
interested in to clip	0.0	0.0	0.0	2.0	0.0000000000	False
right and the window	0.0	0.0	0.0	2.0	0.0000000000	False
concerned we are taking	0.0	0.0	0.0	2.0	0.0000000000	False
taking a simple polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon convex or non	0.0	0.0	0.0	4.0	0.0000000000	False
convex or non convex	0.0	0.0	0.997530864198	6.0	0.0000000000	False
restriction to the window	0.0	0.0	0.0	2.0	0.0000000000	False
work on a window	0.0	0.0	0.0	2.0	0.0000000000	False
window which is convex	0.0	0.0	0.0	2.0	0.0000000000	False
restriction and the window	0.0	0.0	0.0	2.0	0.0000000000	False
window must be convex	0.0	0.0	0.0	2.0	0.0000000000	False
convex but the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon could be convex	0.0	0.0	0.0	2.0	0.0000000000	False
right which is convex	0.0	0.0	0.0	2.0	0.0000000000	False
polygon which is non	0.0	0.0	0.0	2.0	0.0000000000	False
triangle its a convex	0.0	0.0	0.0	2.0	0.0000000000	False
portion of the polygon	0.0	0.0	0.0	4.0	0.0000000000	False
polygon and this portion	0.0	0.0	0.0	2.0	0.0000000000	False
polygon inside the window	0.0	0.0	0.0	2.0	0.0000000000	False
right similarly iam interested	0.0	0.0	0.0	2.0	0.0000000000	False
part of the polygon	0.0	0.0	5.9975308642	6.0	0.0000000000	False
polygon to be declared	0.0	0.0	0.0	2.0	0.0000000000	False
declared inside the window	0.0	0.0	0.0	2.0	0.0000000000	False
chop of the rest	0.0	0.0	0.0	2.0	0.0000000000	False
basically what is shown	0.0	0.0	0.0	2.0	0.0000000000	False
result for this polygon	0.0	0.0	0.0	2.0	0.0000000000	False
triangle to be clipped	0.0	0.0	0.0	2.0	0.0000000000	False
result is this right	0.0	0.0	0.0	2.0	0.0000000000	False
case of line clipping	0.0	0.0	0.0	4.0	0.0000000000	False
clipping can you suggest	0.0	0.0	0.0	2.0	0.0000000000	False
right what is happening	0.0	0.0	0.0	2.0	0.0000000000	False
suggestion towards an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
thing that for instance	0.0	0.0	0.0	2.0	0.0000000000	False
instance sires back algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
back algorithm or lanbask	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm or lanbask algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
basically got an exception	0.0	0.0	0.0	2.0	0.0000000000	False
window right the non	0.0	0.0	0.0	2.0	0.0000000000	False
right the non convexity	0.0	0.0	0.0	2.0	0.0000000000	False
convexity of the window	0.0	0.0	0.0	2.0	0.0000000000	False
clipping against the convex	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a notion	0.0	0.0	0.0	2.0	0.0000000000	False
notion of each edge	0.0	0.0	0.0	2.0	0.0000000000	False
edge of the convex	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a clipper	0.0	0.0	0.0	2.0	0.0000000000	False
inside or one side	0.0	0.0	0.0	2.0	0.0000000000	False
side of that edge	0.0	0.0	0.0	2.0	0.0000000000	False
apply a similar concept	0.0	0.0	0.0	2.0	0.0000000000	False
concept where the edge	0.0	0.0	0.0	2.0	0.0000000000	False
edge of the window	0.0	0.0	7.99588477366	10.0	0.3342618384	False
acts like a clipper	0.0	0.0	0.0	2.0	0.0000000000	False
right considering each edge	0.0	0.0	0.0	2.0	0.0000000000	False
acts as a clipper	0.0	0.0	0.0	2.0	0.0000000000	False
clipped against this rectangular	0.0	0.0	0.0	2.0	0.0000000000	False
clipping against that edge	0.0	0.0	0.0	2.0	0.0000000000	False
defined to the edge	0.0	0.0	0.0	2.0	0.0000000000	False
edge may be left	0.0	0.0	0.0	2.0	0.0000000000	False
basically take this polygon	0.0	0.0	0.0	2.0	0.0000000000	False
right so this portion	0.0	0.0	0.0	2.0	0.0000000000	False
potion of this clipper	0.0	0.0	0.0	2.0	0.0000000000	False
clipper and this portion	0.0	0.0	0.0	2.0	0.0000000000	False
portion is the inside	0.0	0.0	0.0	2.0	0.0000000000	False
portion of the clipper	0.0	0.0	0.0	2.0	0.0000000000	False
polygon after having clipped	0.0	0.0	0.0	2.0	0.0000000000	False
clipped against the edge	0.0	0.0	0.0	2.0	0.0000000000	False
succession for all edges	0.0	0.0	0.0	2.0	0.0000000000	False
edges from the window	0.0	0.0	0.0	2.0	0.0000000000	False
apply again this edge	0.0	0.0	0.0	2.0	0.0000000000	False
chops of this part	0.0	0.0	0.0	2.0	0.0000000000	False
chops of the left	0.0	0.0	0.0	2.0	0.0000000000	False
window as a clipper	0.0	0.0	0.0	2.0	0.0000000000	False
clipper at the end	0.0	0.0	0.0	2.0	0.0000000000	False
right so now lets	0.0	0.0	0.0	4.0	0.0000000000	False
diagram as an approach	0.0	0.0	0.0	2.0	0.0000000000	False
polygon to be clipped	0.0	0.0	0.0	2.0	0.0000000000	False
clipped given as series	0.0	0.0	0.0	2.0	0.0000000000	False
points right ordered points	0.0	0.0	0.0	2.0	0.0000000000	False
right and a polygon	0.0	0.0	0.0	2.0	0.0000000000	False
basically a pair define	0.0	0.0	0.0	2.0	0.0000000000	False
right and since polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon is the close	0.0	0.0	0.0	2.0	0.0000000000	False
right from the sequence	0.0	0.0	0.0	2.0	0.0000000000	False
process all the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
edges right in succession	0.0	0.0	0.0	2.0	0.0000000000	False
succession against the window	0.0	0.0	0.0	2.0	0.0000000000	False
polygon the input polygon	0.0	0.0	0.0	2.0	0.0000000000	False
pairs of this vis	0.0	0.0	0.0	2.0	0.0000000000	False
vis defining the edges	0.0	0.0	0.0	2.0	0.0000000000	False
set of points define	0.0	0.0	0.0	2.0	0.0000000000	False
exhausted all the window	0.0	0.0	0.0	2.0	0.0000000000	False
right as a process	0.0	0.0	0.0	2.0	0.0000000000	False
edge of the polygon	0.0	0.0	0.0	4.0	0.0000000000	False
polygon against a window	0.0	0.0	0.0	2.0	0.0000000000	False
right so in fact	0.0	0.0	0.0	2.0	0.0000000000	False
create a new set	0.0	0.0	0.0	2.0	0.0000000000	False
points which are referred	0.0	0.0	0.0	2.0	0.0000000000	False
point or two point	0.0	0.0	0.0	2.0	0.0000000000	False
point right after performing	0.0	0.0	0.0	2.0	0.0000000000	False
clipping of an edge	0.0	0.0	0.0	2.0	0.0000000000	False
polygon against the window	0.0	0.0	0.0	2.0	0.0000000000	False
edge right actually happen	0.0	0.0	0.0	2.0	0.0000000000	False
recovered by four cases	0.0	0.0	0.0	2.0	0.0000000000	False
included in my series	0.0	0.0	0.0	2.0	0.0000000000	False
define a new polygon	0.0	0.0	0.0	2.0	0.0000000000	False
vertex of the polygon	0.0	0.0	0.0	4.0	0.0000000000	False
point for the edge	0.0	0.0	0.0	2.0	0.0000000000	False
ending point or ending	0.0	0.0	0.0	2.0	0.0000000000	False
point or ending vertex	0.0	0.0	0.0	2.0	0.0000000000	False
vertex of the intersection	0.0	0.0	0.0	2.0	0.0000000000	False
intersection now i define	0.0	0.0	0.0	2.0	0.0000000000	False
result from the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon edge and window	0.0	0.0	0.0	2.0	0.0000000000	False
edge and window edge	0.0	0.0	0.0	2.0	0.0000000000	False
intersection of this polygon	0.0	0.0	0.0	2.0	0.0000000000	False
edge with the window	0.0	0.0	0.0	4.0	0.0000000000	False
intersection which i define	0.0	0.0	0.0	2.0	0.0000000000	False
confuse with the subscript	0.0	0.0	0.0	2.0	0.0000000000	False
declare as the output	0.0	0.0	0.0	2.0	0.0000000000	False
output from the case	0.0	0.0	0.0	2.0	0.0000000000	False
polygon of my interest	0.0	0.0	0.0	2.0	0.0000000000	False
interest right now lets	0.0	0.0	0.0	2.0	0.0000000000	False
right which would intend	0.0	0.0	0.0	2.0	0.0000000000	False
output right zero point	0.0	0.0	0.0	2.0	0.0000000000	False
point or one output	0.0	0.0	0.0	2.0	0.0000000000	False
output or two output	0.0	0.0	0.0	2.0	0.0000000000	False
output right two points	0.0	0.0	0.0	2.0	0.0000000000	False
points for the output	0.0	0.0	0.0	2.0	0.0000000000	False
case one so case	0.0	0.0	0.0	2.0	0.0000000000	False
case one i define	0.0	0.0	0.0	2.0	0.0000000000	False
define it as remember	0.0	0.0	0.0	2.0	0.0000000000	False
kind of a shape	0.0	0.0	0.0	2.0	0.0000000000	False
case where the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
inside the window edge	0.0	0.0	5.99670781893	8.0	0.5454545455	False
drawn in blue right	0.0	0.0	0.0	2.0	0.0000000000	False
respect to this window	0.0	0.0	0.0	4.0	0.0000000000	False
polygon edge in question	0.0	0.0	0.0	2.0	0.0000000000	False
right and this edge	0.0	0.0	0.0	2.0	0.0000000000	False
related to the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon in some fashion	0.0	0.0	0.0	2.0	0.0000000000	False
analyze these two end	0.0	0.0	0.0	2.0	0.0000000000	False
observe that the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
side of the window	0.0	0.0	0.0	2.0	0.0000000000	False
window edge that means	0.0	0.0	0.0	2.0	0.0000000000	False
right then i output	0.0	0.0	0.0	4.0	0.0000000000	False
test of the resulting	0.0	0.0	0.0	2.0	0.0000000000	False
polygon meaning i assign	0.0	0.0	0.0	2.0	0.0000000000	False
right and iam increment	0.0	0.0	0.0	2.0	0.0000000000	False
series of the points	0.0	0.0	0.0	2.0	0.0000000000	False
defining why output polygon	0.0	0.0	0.0	2.0	0.0000000000	False
edge the next case	0.0	0.0	0.0	2.0	0.0000000000	False
polygon edge crosses window	0.0	0.0	0.0	4.0	0.0000000000	False
edge crosses window edge	0.0	0.0	0.0	4.0	0.0000000000	False
right going out means	0.0	0.0	0.0	2.0	0.0000000000	False
cross the window edge	0.0	0.0	0.0	2.0	0.0000000000	False
intersection with the window	0.0	0.0	0.0	2.0	0.0000000000	False
right so i find	0.0	0.0	0.0	2.0	0.0000000000	False
find out this point	0.0	0.0	0.0	2.0	0.0000000000	False
output for the point	0.0	0.0	0.0	2.0	0.0000000000	False
edge then i give	0.0	0.0	0.0	2.0	0.0000000000	False
output for the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
case which is left	0.0	0.0	0.0	2.0	0.0000000000	False
intersection of this edge	0.0	0.0	0.0	2.0	0.0000000000	False
case i would output	0.0	0.0	0.0	2.0	0.0000000000	False
vertices of the polygon	0.0	0.0	0.0	4.0	0.0000000000	False
basically means that assign	0.0	0.0	0.0	2.0	0.0000000000	False
polygon as a collection	0.0	0.0	0.0	2.0	0.0000000000	False
collection of my vertices	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of this points	0.0	0.0	0.0	2.0	0.0000000000	False
definition of my polygon	0.0	0.0	0.0	4.0	0.0000000000	False
collection of a sorted	0.0	0.0	0.0	2.0	0.0000000000	False
order of this points	0.0	0.0	0.0	2.0	0.0000000000	False
window to be convex	0.0	0.0	0.0	2.0	0.0000000000	False
polygon any simple polygon	0.0	0.0	0.0	2.0	0.0000000000	False
region to be convex	0.0	0.0	0.0	2.0	0.0000000000	False
right and we analyze	0.0	0.0	0.0	2.0	0.0000000000	False
output appropriately the points	0.0	0.0	0.0	2.0	0.0000000000	False
points to be considered	0.0	0.0	0.0	2.0	0.0000000000	False
considered as the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
clipper the top edge	0.0	0.0	0.0	2.0	0.0000000000	False
inside right totally inside	0.0	0.0	0.0	2.0	0.0000000000	False
respect to the window	0.0	0.0	0.0	4.0	0.0000000000	False
basically considering with respect	0.0	0.0	0.0	2.0	0.0000000000	False
respect to the edge	0.0	0.0	0.0	2.0	0.0000000000	False
edge so this remember	0.0	0.0	0.0	2.0	0.0000000000	False
remember this outside inside	0.0	0.0	0.0	2.0	0.0000000000	False
operation is with respect	0.0	0.0	0.0	2.0	0.0000000000	False
respect to that window	0.0	0.0	0.0	2.0	0.0000000000	False
right so i output	0.0	0.0	0.0	4.0	0.0000000000	False
window edge i output	0.0	0.0	0.0	2.0	0.0000000000	False
basically change the suffixes	0.0	0.0	0.0	2.0	0.0000000000	False
four t five right	0.0	0.0	0.0	2.0	0.0000000000	False
edge all the points	0.0	0.0	0.0	2.0	0.0000000000	False
points are inside right	0.0	0.0	0.0	2.0	0.0000000000	False
two i will output	0.0	0.0	0.0	2.0	0.0000000000	False
change the respective suffixes	0.0	0.0	0.0	2.0	0.0000000000	False
edge right all points	0.0	0.0	0.0	2.0	0.0000000000	False
respect to this vertices	0.0	0.0	0.0	2.0	0.0000000000	False
numbering changes the enumeration	0.0	0.0	0.0	2.0	0.0000000000	False
four v five right	0.0	0.0	0.0	2.0	0.0000000000	False
interesting things are happening	0.0	0.0	0.0	2.0	0.0000000000	False
happening so i start	0.0	0.0	0.0	2.0	0.0000000000	False
inside right i find	0.0	0.0	0.0	2.0	0.0000000000	False
right and i output	0.0	0.0	0.0	2.0	0.0000000000	False
inside find the point	0.0	0.0	0.0	2.0	0.0000000000	False
right and the idea	0.0	0.0	0.0	2.0	0.0000000000	False
case of the line	0.0	0.0	0.0	2.0	0.0000000000	False
clipping is being reused	0.0	0.0	0.0	2.0	0.0000000000	False
right so this inside	0.0	0.0	0.0	2.0	0.0000000000	False
polygon for various reasons	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a degeneration	0.0	0.0	0.0	2.0	0.0000000000	False
shading of the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
modification to this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of w points	0.0	0.0	0.0	2.0	0.0000000000	False
fragmentation but that fragmentation	0.0	0.0	0.0	2.0	0.0000000000	False
fragmentation is actually requires	0.0	0.0	0.0	2.0	0.0000000000	False
requires much more book	0.0	0.0	0.0	2.0	0.0000000000	False
keeping right in order	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm when we talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about hidden surface	0.0	0.0	0.0	2.0	0.0000000000	False
inconjection with hidden surface	0.0	0.0	0.0	2.0	0.0000000000	False
elimination and the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
modify this southern sutherland	0.0	0.0	0.0	2.0	0.0000000000	False
southern sutherland hodgman algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
basically looked at drawing	0.0	0.0	0.0	2.0	0.0000000000	False
looked at drawing algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
drawing algorithms for lines	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms for lines drawing	0.0	0.0	0.0	2.0	0.0000000000	False
drawing algorithm for circle	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for circle ellipse	0.0	0.0	0.0	2.0	0.0000000000	False
right but we havent	0.0	0.0	0.0	2.0	0.0000000000	False
drawing of a polygon	0.0	0.0	0.0	2.0	0.0000000000	False
drawing basically a line	0.0	0.0	0.0	2.0	0.0000000000	False
basically a line drawing	0.0	0.0	0.0	2.0	0.0000000000	False
sustains set of connected	0.0	0.0	0.0	2.0	0.0000000000	False
set of connected points	0.0	0.0	0.0	2.0	0.0000000000	False
points through this edges	0.0	0.0	0.0	2.0	0.0000000000	False
plot of each edge	0.0	0.0	0.0	2.0	0.0000000000	False
edge right using line	0.0	0.0	0.0	2.0	0.0000000000	False
right using line drawing	0.0	0.0	0.0	2.0	0.0000000000	False
feeling of that polygon	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a drawing	0.0	0.0	0.0	2.0	0.0000000000	False
polygon with some color	0.0	0.0	0.0	2.0	0.0000000000	False
collection of line drawing	0.0	0.0	0.0	2.0	0.0000000000	False
drawing doing the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon edges for drawing	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a wire	0.0	0.0	0.0	2.0	0.0000000000	False
display of the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
address the polygon display	0.0	0.0	0.0	2.0	0.0000000000	False
polygon display using filling	0.0	0.0	0.0	2.0	0.0000000000	False
conversion of the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
pixels of the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
converted into some value	0.0	0.0	0.0	2.0	0.0000000000	False
basically for drawing polygons	0.0	0.0	0.0	2.0	0.0000000000	False
drawing polygons using filling	0.0	0.0	0.0	2.0	0.0000000000	False
examples of filled polygons	0.0	0.0	0.0	2.0	0.0000000000	False
irrespective whether a polygon	0.0	0.0	0.0	2.0	0.0000000000	False
replicate my triangle filling	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm right so lets	0.0	0.0	0.0	2.0	0.0000000000	False
pixel which is inside	0.0	0.0	0.0	2.0	0.0000000000	False
out that this pixel	0.0	0.0	0.0	2.0	0.0000000000	False
assign the desired attributes	0.0	0.0	0.0	2.0	0.0000000000	False
desired attributes of color	0.0	0.0	0.0	2.0	0.0000000000	False
attribute to this pixel	0.0	0.0	0.0	2.0	0.0000000000	False
right so the question	0.0	0.0	0.0	2.0	0.0000000000	False
right in other words	0.0	0.0	0.0	2.0	0.0000000000	False
words is a matter	0.0	0.0	0.0	2.0	0.0000000000	False
containment test of points	0.0	0.0	0.0	2.0	0.0000000000	False
points or the pixels	0.0	0.0	0.0	2.0	0.0000000000	False
triangle i just give	0.0	0.0	0.0	2.0	0.0000000000	False
give the necessary attributes	0.0	0.0	0.0	2.0	0.0000000000	False
attributes of this plane	0.0	0.0	0.0	2.0	0.0000000000	False
right if i define	0.0	0.0	0.0	2.0	0.0000000000	False
answer that with respect	0.0	0.0	0.0	2.0	0.0000000000	False
color to that pixel	0.0	0.0	0.0	2.0	0.0000000000	False
triangle i just discard	0.0	0.0	0.0	2.0	0.0000000000	False
start with all pixels	0.0	0.0	0.0	2.0	0.0000000000	False
pixels in this screen	0.0	0.0	0.0	2.0	0.0000000000	False
basically bound your area	0.0	0.0	0.0	2.0	0.0000000000	False
minmax of the points	0.0	0.0	0.0	2.0	0.0000000000	False
create a virtual window	0.0	0.0	0.0	2.0	0.0000000000	False
conversion of that window	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a extend	0.0	0.0	0.0	2.0	0.0000000000	False
right which is defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined around that triangle	0.0	0.0	0.0	2.0	0.0000000000	False
right and this sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of also explode	0.0	0.0	0.0	2.0	0.0000000000	False
fact that this scans	0.0	0.0	0.0	2.0	0.0000000000	False
scans are horizontal right	0.0	0.0	0.0	2.0	0.0000000000	False
coherence along the scan	0.0	0.0	0.0	2.0	0.0000000000	False
extremes of that scan	0.0	0.0	0.0	2.0	0.0000000000	False
point which are spanned	0.0	0.0	0.0	2.0	0.0000000000	False
line can be colored	0.0	0.0	0.0	2.0	0.0000000000	False
right what it turn	0.0	0.0	0.0	2.0	0.0000000000	False
turn what in turn	0.0	0.0	0.0	2.0	0.0000000000	False
find out an extend	0.0	0.0	0.0	2.0	0.0000000000	False
referred to scan line	0.0	0.0	0.0	2.0	0.0000000000	False
basically a horizontal line	0.0	0.0	0.0	2.0	0.0000000000	False
horizontal line with respect	0.0	0.0	0.0	2.0	0.0000000000	False
convert around this triangle	0.0	0.0	0.0	2.0	0.0000000000	False
scan line i find	0.0	0.0	0.0	2.0	0.0000000000	False
intersection of this scan	0.0	0.0	0.0	2.0	0.0000000000	False
scan line with respect	0.0	0.0	0.0	2.0	0.0000000000	False
respect to this edge	0.0	0.0	0.0	4.0	0.0000000000	False
edge and this edge	0.0	0.0	3.9975308642	6.0	0.0000000000	False
assign a one color	0.0	0.0	0.0	2.0	0.0000000000	False
line i can cover	0.0	0.0	0.0	2.0	0.0000000000	False
cover like this right	0.0	0.0	0.0	2.0	0.0000000000	False
find out the point	0.0	0.0	0.0	2.0	0.0000000000	False
intersection explicitly with respect	0.0	0.0	0.0	2.0	0.0000000000	False
thing that could turn	0.0	0.0	0.0	2.0	0.0000000000	False
knowledge of the edge	0.0	0.0	0.0	2.0	0.0000000000	False
slope right the edge	0.0	0.0	0.0	2.0	0.0000000000	False
right the edge slope	0.0	0.0	0.0	2.0	0.0000000000	False
slope can actually give	0.0	0.0	0.0	2.0	0.0000000000	False
knowledge while doing line	0.0	0.0	0.0	2.0	0.0000000000	False
drawing bresenharms or midpoing	0.0	0.0	0.0	2.0	0.0000000000	False
bresenharms or midpoing algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
right using the slope	0.0	0.0	0.0	2.0	0.0000000000	False
slope of this edge	0.0	0.0	0.0	4.0	0.0000000000	False
point using the slope	0.0	0.0	0.0	2.0	0.0000000000	False
two extremes the rest	0.0	0.0	0.0	2.0	0.0000000000	False
right the only thing	0.0	0.0	0.0	2.0	0.0000000000	False
basically between this edge	0.0	0.0	0.0	2.0	0.0000000000	False
scan by scan finding	0.0	0.0	0.0	2.0	0.0000000000	False
out the two extremes	0.0	0.0	0.0	2.0	0.0000000000	False
information from edge slopes	0.0	0.0	0.0	2.0	0.0000000000	False
first scan line yah	0.0	0.0	0.0	2.0	0.0000000000	False
window around this right	0.0	0.0	0.0	2.0	0.0000000000	False
finding out the minmax	0.0	0.0	0.0	2.0	0.0000000000	False
minmax of this area	0.0	0.0	0.0	2.0	0.0000000000	False
top of the window	0.0	0.0	0.0	2.0	0.0000000000	False
right now the question	0.0	0.0	0.0	2.0	0.0000000000	False
filling algorithm by decomposing	0.0	0.0	0.0	2.0	0.0000000000	False
general polygon simple polygon	0.0	0.0	0.0	2.0	0.0000000000	False
polygon simple polygon general	0.0	0.0	0.0	2.0	0.0000000000	False
simple polygon general simple	0.0	0.0	0.0	2.0	0.0000000000	False
polygon general simple polygon	0.0	0.0	0.0	2.0	0.0000000000	False
general simple polygon convex	0.0	0.0	0.0	2.0	0.0000000000	False
right which is non	0.0	0.0	0.0	2.0	0.0000000000	False
scan line in question	0.0	0.0	0.0	2.0	0.0000000000	False
intercepted by this pixels	0.0	0.0	0.0	2.0	0.0000000000	False
pixels by this scan	0.0	0.0	0.0	2.0	0.0000000000	False
scan line or inside	0.0	0.0	0.0	2.0	0.0000000000	False
sinerio can i device	0.0	0.0	0.0	2.0	0.0000000000	False
point outside the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
basically do all checks	0.0	0.0	0.0	2.0	0.0000000000	False
intersections right this point	0.0	0.0	0.0	2.0	0.0000000000	False
line with the edges	0.0	0.0	0.0	2.0	0.0000000000	False
right in some sense	0.0	0.0	0.0	2.0	0.0000000000	False
find out the segments	0.0	0.0	0.0	2.0	0.0000000000	False
segment is odd fill	0.0	0.0	0.0	2.0	0.0000000000	False
fill it the segment	0.0	0.0	0.0	2.0	0.0000000000	False
dont fill it simple	0.0	0.0	0.0	2.0	0.0000000000	False
apply the same parity	0.0	0.0	0.0	2.0	0.0000000000	False
display only this part	0.0	0.0	0.0	2.0	0.0000000000	False
give you a modification	0.0	0.0	0.0	2.0	0.0000000000	False
modification to the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
right duplicate this point	0.0	0.0	0.0	2.0	0.0000000000	False
duplicate this point means	0.0	0.0	0.0	2.0	0.0000000000	False
virtually added a segment	0.0	0.0	0.0	2.0	0.0000000000	False
right there i dont	0.0	0.0	0.0	2.0	0.0000000000	False
intersection with a vertex	0.0	0.0	0.0	2.0	0.0000000000	False
vertex for the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
duplicated i dont plot	0.0	0.0	0.0	2.0	0.0000000000	False
plot at this point	0.0	0.0	0.0	2.0	0.0000000000	False
point but i plot	0.0	0.0	0.0	2.0	0.0000000000	False
minimum or a maximum	0.0	0.0	0.0	2.0	0.0000000000	False
vertex of the incident	0.0	0.0	0.0	2.0	0.0000000000	False
edges on that point	0.0	0.0	0.0	2.0	0.0000000000	False
point then i duplicate	0.0	0.0	0.0	2.0	0.0000000000	False
right and if yah	0.0	0.0	0.0	2.0	0.0000000000	False
back to this case	0.0	0.0	0.0	2.0	0.0000000000	False
right minimum in terms	0.0	0.0	0.0	2.0	0.0000000000	False
edges at this point	0.0	0.0	0.0	2.0	0.0000000000	False
right for this case	0.0	0.0	0.0	2.0	0.0000000000	False
minimum for this case	0.0	0.0	0.0	2.0	0.0000000000	False
intersects to a vertex	0.0	0.0	0.0	2.0	0.0000000000	False
right but the rest	0.0	0.0	0.0	2.0	0.0000000000	False
right i just label	0.0	0.0	0.0	2.0	0.0000000000	False
segments to be drawn	0.0	0.0	0.0	2.0	0.0000000000	False
basically when we fill	0.0	0.0	0.0	2.0	0.0000000000	False
percents some way grow	0.0	0.0	0.0	2.0	0.0000000000	False
point using the neighborhood	0.0	0.0	0.0	2.0	0.0000000000	False
information around that point	0.0	0.0	0.0	2.0	0.0000000000	False
question to the neighbors	0.0	0.0	0.0	2.0	0.0000000000	False
neighbors right and propagate	0.0	0.0	0.0	2.0	0.0000000000	False
right and the propagation	0.0	0.0	0.0	2.0	0.0000000000	False
boundary line boundary edges	0.0	0.0	0.0	2.0	0.0000000000	False
edges of the region	0.0	0.0	0.0	2.0	0.0000000000	False
black points are showing	0.0	0.0	0.0	2.0	0.0000000000	False
boundary of the polygon	0.0	0.0	0.0	2.0	0.0000000000	False
seat which is plotted	0.0	0.0	0.0	2.0	0.0000000000	False
establish at this point	0.0	0.0	0.0	2.0	0.0000000000	False
neighborhood of this point	0.0	0.0	0.0	2.0	0.0000000000	False
point right so neighborhood	0.0	0.0	0.0	2.0	0.0000000000	False
ways here iam talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking about the left	0.0	0.0	0.0	2.0	0.0000000000	False
left and the right	0.0	0.0	0.0	2.0	0.0000000000	False
right neighbor the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
sort of we call	0.0	0.0	0.0	2.0	0.0000000000	False
neighbors of the point	0.0	0.0	0.0	2.0	0.0000000000	False
tern get the neighbors	0.0	0.0	0.0	2.0	0.0000000000	False
neighbors for these points	0.0	0.0	0.0	2.0	0.0000000000	False
right its a pixel	0.0	0.0	0.0	2.0	0.0000000000	False
aggregation or a region	0.0	0.0	0.0	2.0	0.0000000000	False
futures of the image	0.0	0.0	0.0	2.0	0.0000000000	False
image or the segment	0.0	0.0	0.0	2.0	0.0000000000	False
right so those pixel	0.0	0.0	0.0	2.0	0.0000000000	False
attributes within that segment	0.0	0.0	0.0	2.0	0.0000000000	False
find out the connected	0.0	0.0	0.0	2.0	0.0000000000	False
out the connected pixel	0.0	0.0	0.0	2.0	0.0000000000	False
pixel to the seat	0.0	0.0	0.0	2.0	0.0000000000	False
right and keep growing	0.0	0.0	0.0	2.0	0.0000000000	False
region till i hit	0.0	0.0	0.0	2.0	0.0000000000	False
information from the pixel	0.0	0.0	0.0	2.0	0.0000000000	False
pixel itself for instance	0.0	0.0	0.0	2.0	0.0000000000	False
instance if i found	0.0	0.0	0.0	2.0	0.0000000000	False
found out this pixel	0.0	0.0	0.0	2.0	0.0000000000	False
pixel is inside right	0.0	0.0	0.0	2.0	0.0000000000	False
restrict to only part	0.0	0.0	0.0	2.0	0.0000000000	False
part of the boundaries	0.0	0.0	0.0	2.0	0.0000000000	False
information to the point	0.0	0.0	0.0	2.0	0.0000000000	False
earlier but this shows	0.0	0.0	0.0	2.0	0.0000000000	False
thought right okay lets	0.0	0.0	0.0	2.0	0.0000000000	False
right okay lets stop	0.0	0.0	0.0	2.0	0.0000000000	False
basically the extreme end	0.0	0.0	0.0	2.0	0.0000000000	False
end of the rendering	0.0	0.0	0.0	2.0	0.0000000000	False
graphics and the clipping	0.0	0.0	0.0	2.0	0.0000000000	False
steps in the pipeline	0.0	0.0	0.0	2.0	0.0000000000	False
pipeline which are transformations	0.0	0.0	0.0	2.0	0.0000000000	False
right thank you transcriptor	0.0	0.0	0.0	2.0	0.0000000000	False
last class we looked	0.0	0.0	0.0	2.0	0.0000000000	False
tree what the height	0.0	0.0	0.0	2.0	0.0000000000	False
height of these things	0.0	0.0	0.0	2.0	0.0000000000	False
continue with our discussion	0.0	0.0	0.0	2.0	0.0000000000	False
tree walk or tree	0.0	0.0	0.0	2.0	0.0000000000	False
walk or tree traversals	0.0	0.0	0.0	2.0	0.0000000000	False
traversals so a tree	0.0	0.0	0.0	2.0	0.0000000000	False
nodes of a tree	0.0	0.0	0.0	2.0	0.0000000000	False
visit process each node	0.0	0.0	0.0	2.0	0.0000000000	False
children okay ill show	0.0	0.0	0.0	2.0	0.0000000000	False
show you soon examples	0.0	0.0	0.0	2.0	0.0000000000	False
clearer in a post	0.0	0.0	0.0	2.0	0.0000000000	False
process all the children	0.0	0.0	0.0	2.0	0.0000000000	False
children s or visit	0.0	0.0	0.0	0.0	0.0000000000	False
visit all the children	0.0	0.0	0.0	2.0	0.0000000000	False
node okay so lets	0.0	0.0	0.0	4.0	0.0000000000	False
examples preorder tree walks	0.0	0.0	0.0	2.0	0.0000000000	False
book or a paper	0.0	0.0	0.0	2.0	0.0000000000	False
construct a tree out	0.0	0.0	0.0	2.0	0.0000000000	False
out of it tree	0.0	0.0	0.0	2.0	0.0000000000	False
organization of a book	0.0	0.0	0.0	2.0	0.0000000000	False
book as a tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree so or lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets says the title	0.0	0.0	0.0	2.0	0.0000000000	False
section is the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
two such sub sections	0.0	0.0	0.0	2.0	0.0000000000	False
section “ one point	0.0	0.0	2.99814126394	6.0	0.0000000000	False
two has three sub	0.0	0.0	0.0	2.0	0.0000000000	False
section three two sub	0.0	0.0	0.0	2.0	0.0000000000	False
start reading the paper	0.0	0.0	0.0	2.0	0.0000000000	False
paper when you read	0.0	0.0	0.0	2.0	0.0000000000	False
right suppose your reading	0.0	0.0	0.0	2.0	0.0000000000	False
reading the paper end	0.0	0.0	0.0	2.0	0.0000000000	False
paper end to end	0.0	0.0	0.0	2.0	0.0000000000	False
title read the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
section one section sub	0.0	0.0	0.0	2.0	0.0000000000	False
listing as the table	0.0	0.0	0.0	2.0	0.0000000000	False
contents of the book	0.0	0.0	0.0	2.0	0.0000000000	False
listed the um sections	0.0	0.0	0.0	2.0	0.0000000000	False
sections within the chapter	0.0	0.0	0.0	4.0	0.0000000000	False
chapter then the sub	0.0	0.0	0.0	2.0	0.0000000000	False
referring to our accessing	0.0	0.0	0.0	2.0	0.0000000000	False
accessing is this node	0.0	0.0	0.0	2.0	0.0000000000	False
ten then eleven twelve	0.0	0.0	0.0	2.0	0.0000000000	False
twelve thirteen then fourteen	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of a tree	0.0	0.0	0.0	4.0	0.0000000000	False
tree right and pseudo	0.0	0.0	0.0	2.0	0.0000000000	False
right and pseudo code	0.0	0.0	0.0	2.0	0.0000000000	False
pseudo code for pre	0.0	0.0	0.0	2.0	0.0000000000	False
code for pre order	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of an node	0.0	0.0	0.0	2.0	0.0000000000	False
tree so to begin	0.0	0.0	0.0	2.0	0.0000000000	False
traversal at the root	0.0	0.0	0.0	2.0	0.0000000000	False
first visit the node	0.0	0.0	3.99628252788	12.0	0.3555555556	False
out the the book	0.0	0.0	0.0	2.0	0.0000000000	False
print the title print	0.0	0.0	0.0	2.0	0.0000000000	False
title print the heading	0.0	0.0	0.0	2.0	0.0000000000	False
print the heading print	0.0	0.0	0.0	2.0	0.0000000000	False
heading print the title	0.0	0.0	0.0	2.0	0.0000000000	False
title of that node	0.0	0.0	0.0	2.0	0.0000000000	False
right so for instance	0.0	0.0	0.0	2.0	0.0000000000	False
instance each node corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to a section	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to same print	0.0	0.0	0.0	2.0	0.0000000000	False
children nodes and repeat	0.0	0.0	0.0	2.0	0.0000000000	False
repeat this same process	0.0	0.0	0.0	2.0	0.0000000000	False
right because this tree	0.0	0.0	0.0	2.0	0.0000000000	False
subsection “ one point	0.0	0.0	0.0	2.0	0.0000000000	False
point two “ right	0.0	0.0	0.0	2.0	0.0000000000	False
visit all its children	0.0	0.0	0.0	2.0	0.0000000000	False
children of that node	0.0	0.0	0.0	2.0	0.0000000000	False
means visit this node	0.0	0.0	0.0	2.0	0.0000000000	False
node this corresponds visit	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds visit this node	0.0	0.0	0.0	2.0	0.0000000000	False
node and then visit	0.0	0.0	0.0	2.0	0.0000000000	False
whats called a post	0.0	0.0	0.0	2.0	0.0000000000	False
traversal in a post	0.0	0.0	0.0	2.0	0.0000000000	False
post order traversal recall	0.0	0.0	0.0	2.0	0.0000000000	False
first visit its children	0.0	0.0	0.0	2.0	0.0000000000	False
grades within this sub	0.0	0.0	0.0	2.0	0.0000000000	False
files within this sub	0.0	0.0	0.0	2.0	0.0000000000	False
structure okay now suppose	0.0	0.0	0.0	2.0	0.0000000000	False
compute the total space	0.0	0.0	15.9944237918	18.0	0.3054082715	False
occupied by this file	0.0	0.0	0.0	2.0	0.0000000000	False
occupied by this subdirectory	0.0	0.0	0.0	2.0	0.0000000000	False
obtain the total spaces	0.0	0.0	0.0	2.0	0.0000000000	False
computation on this node	0.0	0.0	0.0	2.0	0.0000000000	False
computation at two children	0.0	0.0	0.0	2.0	0.0000000000	False
nodes after having computed	0.0	0.0	0.0	2.0	0.0000000000	False
required by the sub	0.0	0.0	0.0	2.0	0.0000000000	False
computed total spaces required	0.0	0.0	0.0	2.0	0.0000000000	False
right in a post	0.0	0.0	0.0	4.0	0.0000000000	False
child of the node	0.0	0.0	0.0	4.0	0.0000000000	False
traversal of a node	0.0	0.0	0.0	2.0	0.0000000000	False
first going to perform	0.0	0.0	0.0	2.0	0.0000000000	False
perform a post order	0.0	0.0	0.0	2.0	0.0000000000	False
post order here corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
finding the total spaces	0.0	0.0	0.0	2.0	0.0000000000	False
occupied by that sub	0.0	0.0	0.0	2.0	0.0000000000	False
directory so to compute	0.0	0.0	0.0	2.0	0.0000000000	False
total space is occupied	0.0	0.0	0.0	2.0	0.0000000000	False
occupied by this directory	0.0	0.0	0.0	4.0	0.0000000000	False
first going to compute	0.0	0.0	0.0	4.0	0.0000000000	False
occupied by this sub	0.0	0.0	0.0	4.0	0.0000000000	False
directory and having computed	0.0	0.0	0.0	2.0	0.0000000000	False
required by this directory	0.0	0.0	0.0	4.0	0.0000000000	False
order in which computation	0.0	0.0	0.0	2.0	0.0000000000	False
right and in fact	0.0	0.0	0.0	2.0	0.0000000000	False
disk usage command unix	0.0	0.0	0.0	2.0	0.0000000000	False
command in a directory	0.0	0.0	0.0	2.0	0.0000000000	False
type the disk usage	0.0	0.0	0.0	2.0	0.0000000000	False
command in the sub	0.0	0.0	0.0	2.0	0.0000000000	False
first going to list	0.0	0.0	0.0	2.0	0.0000000000	False
out the total spaces	0.0	0.0	0.0	4.0	0.0000000000	False
occupied in this directory	0.0	0.0	0.0	4.0	0.0000000000	False
directory then the total	0.0	0.0	0.0	2.0	0.0000000000	False
eventually at the end	0.0	0.0	0.0	2.0	0.0000000000	False
question is which child	0.0	0.0	0.0	2.0	0.0000000000	False
hood would we visited	0.0	0.0	0.0	2.0	0.0000000000	False
first child second child	0.0	0.0	0.0	2.0	0.0000000000	False
first child is visited	0.0	0.0	0.0	2.0	0.0000000000	False
drawn the the trees	0.0	0.0	0.0	2.0	0.0000000000	False
leftmost child is visited	0.0	0.0	0.0	2.0	0.0000000000	False
visit the childrens nodes	0.0	0.0	0.0	4.0	0.0000000000	False
childrens nodes in postorder	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in postorder visit	0.0	0.0	0.0	2.0	0.0000000000	False
postorder visit the children	0.0	0.0	0.0	2.0	0.0000000000	False
children node then visits	0.0	0.0	0.0	2.0	0.0000000000	False
visits the nodes lets	0.0	0.0	0.0	2.0	0.0000000000	False
case of binary tree	0.0	0.0	0.0	2.0	0.0000000000	False
visit to be visit	0.0	0.0	0.0	2.0	0.0000000000	False
traversal on the left	0.0	0.0	2.99814126394	6.0	0.0000000000	False
traversal on the right	0.0	0.0	0.0	4.0	0.0000000000	False
right child so note	0.0	0.0	0.0	2.0	0.0000000000	False
right we are calling	0.0	0.0	0.0	2.0	0.0000000000	False
order within the procedure	0.0	0.0	0.0	2.0	0.0000000000	False
child and another right	0.0	0.0	0.0	2.0	0.0000000000	False
right child the difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference between pre order	0.0	0.0	0.0	2.0	0.0000000000	False
pre order and post	0.0	0.0	4.99690210657	10.0	0.4210526316	False
order and post order	0.0	0.0	4.99690210657	10.0	0.4210526316	False
order traversal on left	0.0	0.0	0.0	2.0	0.0000000000	False
traversal on left child	0.0	0.0	0.0	2.0	0.0000000000	False
eventually you do visit	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of this tree	0.0	0.0	1.99752168525	8.0	0.5333333333	False
printing out the contents	0.0	0.0	0.0	4.0	0.0000000000	False
contents of the node	0.0	0.0	2.99814126394	6.0	0.0000000000	False
node right so lets	0.0	0.0	0.0	2.0	0.0000000000	False
first look at pre	0.0	0.0	0.0	2.0	0.0000000000	False
first thing get printed	0.0	0.0	0.0	2.0	0.0000000000	False
pre order traversal left	0.0	0.0	0.0	4.0	0.0000000000	False
order traversal left sub	0.0	0.0	0.0	4.0	0.0000000000	False
traversal left sub tree	0.0	0.0	0.0	4.0	0.0000000000	False
traversal of the left	0.0	0.0	5.99318463445	22.0	0.4195470799	False
root of the left	0.0	0.0	0.0	4.0	0.0000000000	False
tree and first print	0.0	0.0	0.0	2.0	0.0000000000	False
first print the node	0.0	0.0	0.0	2.0	0.0000000000	False
visit the node visit	0.0	0.0	0.0	4.0	0.0000000000	False
visit corresponds to printing	0.0	0.0	0.0	2.0	0.0000000000	False
left sub tree left	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree left sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree left sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
root node first visit	0.0	0.0	0.0	2.0	0.0000000000	False
node visit the node	0.0	0.0	0.0	2.0	0.0000000000	False
node here means printing	0.0	0.0	0.0	2.0	0.0000000000	False
contents we will print	0.0	0.0	0.0	2.0	0.0000000000	False
tree but its left	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of this guy	0.0	0.0	0.0	4.0	0.0000000000	False
order traversal of right	0.0	0.0	0.0	4.0	0.0000000000	False
traversal of right sub	0.0	0.0	0.998141263941	6.0	0.0000000000	False
sub tree which means	0.0	0.0	0.0	4.0	0.0000000000	False
means that first visit	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of this sub	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of the right	0.0	0.0	5.99504337051	16.0	0.4444444444	False
sub tree right sub	0.0	0.0	0.0	4.0	0.0000000000	False
tree right sub tree	0.0	0.0	0.0	4.0	0.0000000000	False
lets do a post	0.0	0.0	0.0	2.0	0.0000000000	False
first do a post	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of its left	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of its right	0.0	0.0	0.0	2.0	0.0000000000	False
first do the post	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of this left	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree then post	0.0	0.0	0.0	2.0	0.0000000000	False
tree then post order	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of this right	0.0	0.0	0.0	4.0	0.0000000000	False
tree and then print	0.0	0.0	0.0	2.0	0.0000000000	False
content so post order	0.0	0.0	0.0	2.0	0.0000000000	False
tree do the post	0.0	0.0	0.0	2.0	0.0000000000	False
traversal here which means	0.0	0.0	0.0	2.0	0.0000000000	False
minus so in essence	0.0	0.0	0.0	2.0	0.0000000000	False
compute what the value	0.0	0.0	0.0	4.0	0.0000000000	False
value of this quantity	0.0	0.0	0.0	2.0	0.0000000000	False
value of this expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression this sub expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression yeah this corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to sub expression	0.0	0.0	0.0	2.0	0.0000000000	False
value of this sub	0.0	0.0	0.0	4.0	0.0000000000	False
expression right whatever values	0.0	0.0	0.0	2.0	0.0000000000	False
value the entire thing	0.0	0.0	0.0	2.0	0.0000000000	False
sitting in this node	0.0	0.0	0.0	2.0	0.0000000000	False
value of this left	0.0	0.0	0.0	2.0	0.0000000000	False
value of this right	0.0	0.0	0.0	2.0	0.0000000000	False
return the variable stored	0.0	0.0	0.0	2.0	0.0000000000	False
value the leaf corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
leaf corresponds to numbers	0.0	0.0	0.0	2.0	0.0000000000	False
numbers in this expression	0.0	0.0	0.0	2.0	0.0000000000	False
leaf then that means	0.0	0.0	0.0	2.0	0.0000000000	False
first evaluate the left	0.0	0.0	0.0	2.0	0.0000000000	False
evaluate v dot left	0.0	0.0	0.0	2.0	0.0000000000	False
left child this arrow	0.0	0.0	0.0	2.0	0.0000000000	False
direction so x lets	0.0	0.0	0.0	2.0	0.0000000000	False
value of right child	0.0	0.0	0.0	2.0	0.0000000000	False
right when i evaluate	0.0	0.0	0.0	2.0	0.0000000000	False
evaluate on the right	0.0	0.0	0.0	2.0	0.0000000000	False
order traversal small modification	0.0	0.0	0.0	2.0	0.0000000000	False
traversal small modification question	0.0	0.0	0.0	2.0	0.0000000000	False
problem so the problem	0.0	0.0	0.0	2.0	0.0000000000	False
incorporate the priority rules	0.0	0.0	0.0	2.0	0.0000000000	False
rules to be generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated such a tree	0.0	0.0	0.0	2.0	0.0000000000	False
evaluate the tree expression	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to this tree	0.0	0.0	0.0	2.0	0.0000000000	False
traversal we seen inorder	0.0	0.0	0.0	2.0	0.0000000000	False
inorder traversal pre order	0.0	0.0	0.0	2.0	0.0000000000	False
traversal pre order traversal	0.0	0.0	0.0	2.0	0.0000000000	False
order traversal and post	0.0	0.0	0.0	2.0	0.0000000000	False
traversal and post order	0.0	0.0	0.0	2.0	0.0000000000	False
order kind of traversal	0.0	0.0	0.0	2.0	0.0000000000	False
recall that pre order	0.0	0.0	0.0	2.0	0.0000000000	False
order traversal we visited	0.0	0.0	0.0	2.0	0.0000000000	False
right then we visited	0.0	0.0	0.0	2.0	0.0000000000	False
possibilities we just visit	0.0	0.0	0.0	2.0	0.0000000000	False
node between the visits	0.0	0.0	0.0	2.0	0.0000000000	False
visits to the left	0.0	0.0	2.99814126394	6.0	0.0000000000	False
left and the right	0.0	0.0	2.99814126394	6.0	0.0000000000	False
left and right sub	0.0	0.0	2.99814126394	6.0	0.0000000000	False
sub tree so pseudo	0.0	0.0	0.0	2.0	0.0000000000	False
tree so pseudo code	0.0	0.0	0.0	2.0	0.0000000000	False
pseudo code for inorder	0.0	0.0	0.0	2.0	0.0000000000	False
code for inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
first do an inorder	0.0	0.0	2.99814126394	6.0	0.0000000000	False
inorder on the left	0.0	0.0	0.0	2.0	0.0000000000	False
child then we visit	0.0	0.0	0.0	2.0	0.0000000000	False
inorder traversal right child	0.0	0.0	0.0	2.0	0.0000000000	False
possibilities these are threes	0.0	0.0	0.0	2.0	0.0000000000	False
node either you visit	0.0	0.0	0.0	2.0	0.0000000000	False
visit both the left	0.0	0.0	0.0	4.0	0.0000000000	False
right or you visit	0.0	0.0	0.0	4.0	0.0000000000	False
guy of this left	0.0	0.0	0.0	2.0	0.0000000000	False
left then the right	0.0	0.0	0.0	2.0	0.0000000000	False
node so it corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
thing we ill print	0.0	0.0	0.0	2.0	0.0000000000	False
right sub tree inorder	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
inorder traversal of right	0.0	0.0	0.0	2.0	0.0000000000	False
eventually we will print	0.0	0.0	0.0	2.0	0.0000000000	False
expression and this tours	0.0	0.0	0.0	2.0	0.0000000000	False
right so we start	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of binary tree	0.0	0.0	1.99814126394	6.0	0.0000000000	False
pre post that inorder	0.0	0.0	0.0	2.0	0.0000000000	False
post that inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
special cases of eulers	0.0	0.0	0.0	2.0	0.0000000000	False
cases of eulers rule	0.0	0.0	0.0	2.0	0.0000000000	False
right so each node	0.0	0.0	0.0	2.0	0.0000000000	False
basically getting visited thrice	0.0	0.0	0.0	2.0	0.0000000000	False
touching this node lets	0.0	0.0	0.0	2.0	0.0000000000	False
right so three times	0.0	0.0	0.0	2.0	0.0000000000	False
qualify every internal node	0.0	0.0	0.0	2.0	0.0000000000	False
internal node of degree	0.0	0.0	0.0	2.0	0.0000000000	False
children if the node	0.0	0.0	0.0	2.0	0.0000000000	False
expression this is tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree corresponding to set	0.0	0.0	0.0	2.0	0.0000000000	False
set an arithmetic expression	0.0	0.0	0.0	2.0	0.0000000000	False
print this arithmetic expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression out with parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
draw the parenthesis print	0.0	0.0	0.0	2.0	0.0000000000	False
out in this manner	0.0	0.0	0.0	2.0	0.0000000000	False
euler walk this thing	0.0	0.0	0.0	2.0	0.0000000000	False
start on the left	0.0	0.0	0.0	4.0	0.0000000000	False
sub tree ill print	0.0	0.0	0.0	2.0	0.0000000000	False
print an left bracket	0.0	0.0	0.0	2.0	0.0000000000	False
tree when i finish	0.0	0.0	0.0	2.0	0.0000000000	False
finish with the right	0.0	0.0	0.0	2.0	0.0000000000	False
tree and ill print	0.0	0.0	0.0	2.0	0.0000000000	False
print the right bracket	0.0	0.0	0.0	4.0	0.0000000000	False
bracket right this corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
node ill just print	0.0	0.0	0.0	2.0	0.0000000000	False
recall that every node	0.0	0.0	0.0	2.0	0.0000000000	False
node was visited thrice	0.0	0.0	0.0	2.0	0.0000000000	False
essentially print the right	0.0	0.0	0.0	2.0	0.0000000000	False
content of this node	0.0	0.0	0.0	2.0	0.0000000000	False
left so ill print	0.0	0.0	0.0	2.0	0.0000000000	False
node on the left	0.0	0.0	5.99814126394	6.0	0.0000000000	False
print other left bracket	0.0	0.0	0.0	2.0	0.0000000000	False
left bracket i touch	0.0	0.0	0.0	4.0	0.0000000000	False
print another left bracket	0.0	0.0	0.0	2.0	0.0000000000	False
four bracket to begin	0.0	0.0	0.0	2.0	0.0000000000	False
leaf ill just print	0.0	0.0	0.0	2.0	0.0000000000	False
content of the leaf	0.0	0.0	0.0	2.0	0.0000000000	False
star or a multiplication	0.0	0.0	0.0	2.0	0.0000000000	False
left print a left	0.0	0.0	0.0	2.0	0.0000000000	False
print a left bracket	0.0	0.0	0.0	2.0	0.0000000000	False
out the arithmetic expression	0.0	0.0	0.0	4.0	0.0000000000	False
arithmetic expression some kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of euler walk	0.0	0.0	0.0	2.0	0.0000000000	False
walk on this tree	0.0	0.0	0.0	2.0	0.0000000000	False
right a generic method	0.0	0.0	0.0	2.0	0.0000000000	False
generic method for tree	0.0	0.0	0.0	2.0	0.0000000000	False
method for tree traversal	0.0	0.0	0.0	2.0	0.0000000000	False
traversal and then specialized	0.0	0.0	0.0	2.0	0.0000000000	False
pre order or post	0.0	0.0	0.0	2.0	0.0000000000	False
order or post order	0.0	0.0	0.0	2.0	0.0000000000	False
post order inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
method called external right	0.0	0.0	0.0	2.0	0.0000000000	False
external is a method	0.0	0.0	0.0	2.0	0.0000000000	False
invoke if the node	0.0	0.0	0.0	2.0	0.0000000000	False
invoke when you visit	0.0	0.0	0.0	2.0	0.0000000000	False
node from the left	0.0	0.0	0.0	2.0	0.0000000000	False
method here you continue	0.0	0.0	0.0	2.0	0.0000000000	False
continue with the left	0.0	0.0	0.0	2.0	0.0000000000	False
child when you touch	0.0	0.0	0.0	2.0	0.0000000000	False
method then you continue	0.0	0.0	0.0	2.0	0.0000000000	False
continue with right child	0.0	0.0	0.0	2.0	0.0000000000	False
right you will invoke	0.0	0.0	0.0	2.0	0.0000000000	False
methods you can create	0.0	0.0	0.0	2.0	0.0000000000	False
create you can create	0.0	0.0	0.0	2.0	0.0000000000	False
choice you can specialize	0.0	0.0	0.0	2.0	0.0000000000	False
specialize this binary tree	0.0	0.0	0.0	2.0	0.0000000000	False
traversal the generic tree	0.0	0.0	0.0	2.0	0.0000000000	False
abstract class which means	0.0	0.0	0.0	2.0	0.0000000000	False
means that these methods	0.0	0.0	0.0	2.0	0.0000000000	False
external left below right	0.0	0.0	0.0	2.0	0.0000000000	False
right these are left	0.0	0.0	0.0	2.0	0.0000000000	False
leave certain methods unspecified	0.0	0.0	0.0	2.0	0.0000000000	False
object of that class	0.0	0.0	0.0	2.0	0.0000000000	False
point specify those methods	0.0	0.0	0.0	2.0	0.0000000000	False
manner create a sub	0.0	0.0	0.0	2.0	0.0000000000	False
create a sub class	0.0	0.0	0.0	2.0	0.0000000000	False
sub class sub class	0.0	0.0	0.0	2.0	0.0000000000	False
class of this class	0.0	0.0	0.0	2.0	0.0000000000	False
specializes this generic tree	0.0	0.0	0.0	2.0	0.0000000000	False
generic tree traversal procedure	0.0	0.0	0.0	4.0	0.0000000000	True
left below and right	0.0	0.0	0.0	2.0	0.0000000000	False
class for printing out	0.0	0.0	0.0	2.0	0.0000000000	False
printing out arithmetic expressions	0.0	0.0	0.0	2.0	0.0000000000	False
back from the left	0.0	0.0	0.0	2.0	0.0000000000	False
compute a certain result	0.0	0.0	0.0	2.0	0.0000000000	False
utilize used for instance	0.0	0.0	0.0	2.0	0.0000000000	False
occupied by that directory	0.0	0.0	0.0	2.0	0.0000000000	False
right so we compute	0.0	0.0	0.0	2.0	0.0000000000	False
compute the space required	0.0	0.0	0.0	4.0	0.0000000000	False
left the left child	0.0	0.0	0.0	2.0	0.0000000000	False
directory in the left	0.0	0.0	0.0	2.0	0.0000000000	False
child compute the space	0.0	0.0	0.0	2.0	0.0000000000	False
required by the directory	0.0	0.0	0.0	2.0	0.0000000000	False
stored in r dot	0.0	0.0	0.0	2.0	0.0000000000	False
left result r dot	0.0	0.0	0.0	2.0	0.0000000000	False
specialize this our printing	0.0	0.0	0.0	2.0	0.0000000000	False
expression example so recall	0.0	0.0	0.0	2.0	0.0000000000	False
node is a leaf	0.0	0.0	0.0	2.0	0.0000000000	False
content of that node	0.0	0.0	0.0	2.0	0.0000000000	False
print out the element	0.0	0.0	0.0	4.0	0.0000000000	False
element in that node	0.0	0.0	0.0	2.0	0.0000000000	False
node from a left	0.0	0.0	0.0	2.0	0.0000000000	False
print out a left	0.0	0.0	0.0	2.0	0.0000000000	False
out a left bracket	0.0	0.0	0.0	2.0	0.0000000000	False
print out the left	0.0	0.0	0.0	2.0	0.0000000000	False
left then we touch	0.0	0.0	0.0	2.0	0.0000000000	False
print out the right	0.0	0.0	0.0	2.0	0.0000000000	False
out the right bracket	0.0	0.0	0.0	2.0	0.0000000000	False
methods in this manner	0.0	0.0	0.0	2.0	0.0000000000	False
manner this becomes print	0.0	0.0	0.0	2.0	0.0000000000	False
class which is extending	0.0	0.0	0.0	2.0	0.0000000000	False
extending binary tree traversal	0.0	0.0	0.0	2.0	0.0000000000	False
invoke the traversal method	0.0	0.0	0.0	2.0	0.0000000000	False
expressions with the tree	0.0	0.0	0.0	2.0	0.0000000000	False
expression it will print	0.0	0.0	0.0	2.0	0.0000000000	False
expression in the parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
specialized the same class	0.0	0.0	0.0	2.0	0.0000000000	False
class binary tree traversal	0.0	0.0	0.0	2.0	0.0000000000	False
occupied by the files	0.0	0.0	0.0	2.0	0.0000000000	False
files by certain directories	0.0	0.0	0.0	2.0	0.0000000000	False
structure right by specializing	0.0	0.0	0.0	2.0	0.0000000000	False
lets continue our discussion	0.0	0.0	0.0	2.0	0.0000000000	False
pre and in order	0.0	0.0	0.0	4.0	0.0000000000	False
pre pre order inorder	0.0	0.0	0.0	2.0	0.0000000000	False
pre order inorder traversal	0.0	0.0	0.0	4.0	0.0000000000	False
right i have mention	0.0	0.0	0.0	2.0	0.0000000000	False
figure out the trees	0.0	0.0	0.0	2.0	0.0000000000	False
traversal this was inorder	0.0	0.0	0.0	2.0	0.0000000000	False
node for the root	0.0	0.0	0.0	2.0	0.0000000000	False
tree of a right	0.0	0.0	0.0	2.0	0.0000000000	False
order of the left	0.0	0.0	0.0	2.0	0.0000000000	False
note that the left	0.0	0.0	0.0	2.0	0.0000000000	False
tree has five elements	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to the pre	0.0	0.0	0.0	2.0	0.0000000000	False
pre order pre order	0.0	0.0	0.0	4.0	0.0000000000	False
order pre order traversal	0.0	0.0	0.0	2.0	0.0000000000	False
tree so in essence	0.0	0.0	0.0	2.0	0.0000000000	False
essence what have manage	0.0	0.0	0.0	2.0	0.0000000000	False
identify what the left	0.0	0.0	0.0	2.0	0.0000000000	False
pre order and inorder	0.0	0.0	0.0	4.0	0.0000000000	False
order and inorder traversal	0.0	0.0	0.0	4.0	0.0000000000	False
tree so my problem	0.0	0.0	0.0	2.0	0.0000000000	False
work on this problem	0.0	0.0	0.0	2.0	0.0000000000	False
tree the rep order	0.0	0.0	0.0	2.0	0.0000000000	False
rep order inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
out what the tree	0.0	0.0	7.99690210657	10.0	0.4210526316	False
root of this left	0.0	0.0	0.0	2.0	0.0000000000	False
order traversal and inorder	0.0	0.0	0.0	2.0	0.0000000000	False
traversal and inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
nodes the right sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree is three nodes	0.0	0.0	0.0	2.0	0.0000000000	False
nodes so the problem	0.0	0.0	0.0	2.0	0.0000000000	False
reduce to this problem	0.0	0.0	0.0	2.0	0.0000000000	False
out about the trees	0.0	0.0	0.0	2.0	0.0000000000	False
user yeah the pre	0.0	0.0	0.0	2.0	0.0000000000	False
compute not the tree	0.0	0.0	0.0	2.0	0.0000000000	False
compute the post order	0.0	0.0	0.0	2.0	0.0000000000	False
simple if you compute	0.0	0.0	0.0	2.0	0.0000000000	False
order traversal this tree	0.0	0.0	0.0	2.0	0.0000000000	False
flag out an error	0.0	0.0	0.0	2.0	0.0000000000	False
error if the sequences	0.0	0.0	0.0	2.0	0.0000000000	False
possibly d the rep	0.0	0.0	0.0	2.0	0.0000000000	False
rep and inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
right suppose i gave	0.0	0.0	0.0	2.0	0.0000000000	False
gave you the post	0.0	0.0	0.0	2.0	0.0000000000	False
post order in order	0.0	0.0	0.0	2.0	0.0000000000	False
out where the root	0.0	0.0	0.0	2.0	0.0000000000	False
right in the pre	0.0	0.0	0.0	2.0	0.0000000000	False
order very first element	0.0	0.0	0.0	2.0	0.0000000000	False
element is the root	0.0	0.0	0.0	4.0	0.0000000000	False
root in a post	0.0	0.0	0.0	2.0	0.0000000000	False
order the last element	0.0	0.0	0.0	2.0	0.0000000000	False
search for the root	0.0	0.0	0.0	2.0	0.0000000000	False
root in your inorder	0.0	0.0	0.0	2.0	0.0000000000	False
traversal and wherever find	0.0	0.0	0.0	2.0	0.0000000000	False
root that neatly divides	0.0	0.0	0.0	2.0	0.0000000000	False
neatly divides the thing	0.0	0.0	0.0	2.0	0.0000000000	False
tree and right sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree what the number	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the left	0.0	0.0	0.0	4.0	0.0000000000	False
tree you can figure	0.0	0.0	0.0	2.0	0.0000000000	False
out what the post	0.0	0.0	0.0	2.0	0.0000000000	False
nodes of your post	0.0	0.0	0.0	2.0	0.0000000000	False
recursive we ill figure	0.0	0.0	0.0	2.0	0.0000000000	False
figure what the left	0.0	0.0	0.0	2.0	0.0000000000	False
trees and then plugged	0.0	0.0	0.0	2.0	0.0000000000	False
post and in order	0.0	0.0	0.0	2.0	0.0000000000	False
whats the third question	0.0	0.0	0.0	2.0	0.0000000000	False
pre and post order	0.0	0.0	9.99628252788	12.0	0.2622950820	False
uniquely determine the tree	0.0	0.0	0.0	4.0	0.0000000000	False
tree and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
traversal and this post	0.0	0.0	0.0	2.0	0.0000000000	False
traversal right three nodes	0.0	0.0	0.0	2.0	0.0000000000	False
tree this pre order	0.0	0.0	0.0	2.0	0.0000000000	False
tree also has pre	0.0	0.0	0.0	2.0	0.0000000000	False
pre order traversal post	0.0	0.0	0.0	2.0	0.0000000000	False
order traversal post order	0.0	0.0	0.0	2.0	0.0000000000	False
traversal post order traversal	0.0	0.0	0.0	2.0	0.0000000000	False
trees that you concerned	0.0	0.0	0.0	2.0	0.0000000000	False
problem given a pre	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the tress	0.0	0.0	0.0	2.0	0.0000000000	False
child suppose i gave	0.0	0.0	0.0	2.0	0.0000000000	False
gave you this information	0.0	0.0	0.0	4.0	0.0000000000	False
internal node the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree has two children	0.0	0.0	0.0	2.0	0.0000000000	False
complete every internal node	0.0	0.0	0.0	2.0	0.0000000000	False
node of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
node has two children	0.0	0.0	3.99814126394	6.0	0.0000000000	False
tree every internal node	0.0	0.0	0.0	4.0	0.0000000000	False
node having two children	0.0	0.0	0.0	2.0	0.0000000000	False
node has binary tree	0.0	0.0	0.0	2.0	0.0000000000	False
post order to determine	0.0	0.0	0.0	2.0	0.0000000000	False
uniquely again and lets	0.0	0.0	0.0	2.0	0.0000000000	False
right so i gave	0.0	0.0	0.0	2.0	0.0000000000	False
gave you the pre	0.0	0.0	0.0	2.0	0.0000000000	False
whats the first thing	0.0	0.0	0.0	2.0	0.0000000000	False
quickly draw the root	0.0	0.0	0.0	2.0	0.0000000000	False
child because every node	0.0	0.0	0.0	2.0	0.0000000000	False
node ahs two children	0.0	0.0	0.0	2.0	0.0000000000	False
basically the it means	0.0	0.0	0.0	2.0	0.0000000000	False
means that the left	0.0	0.0	0.0	2.0	0.0000000000	False
child and the left	0.0	0.0	0.0	2.0	0.0000000000	False
visits post order traversal	0.0	0.0	0.0	2.0	0.0000000000	False
left has the pre	0.0	0.0	0.0	2.0	0.0000000000	False
right no right child	0.0	0.0	0.0	2.0	0.0000000000	False
child is d draw	0.0	0.0	0.0	2.0	0.0000000000	False
child so every thing	0.0	0.0	0.0	2.0	0.0000000000	False
visited the other elements	0.0	0.0	0.0	2.0	0.0000000000	False
tree so the left	0.0	0.0	0.0	2.0	0.0000000000	False
tree only one elements	0.0	0.0	0.0	2.0	0.0000000000	False
figure out the left	0.0	0.0	0.0	2.0	0.0000000000	False
out the left sub	0.0	0.0	0.0	2.0	0.0000000000	False
means is the left	0.0	0.0	0.0	2.0	0.0000000000	False
tree only one node	0.0	0.0	0.0	2.0	0.0000000000	False
node it is left	0.0	0.0	0.0	2.0	0.0000000000	False
high level in fact	0.0	0.0	0.0	2.0	0.0000000000	False
class right the code	0.0	0.0	0.0	2.0	0.0000000000	False
translate in to code	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms you should learn	0.0	0.0	0.0	2.0	0.0000000000	False
questions till this point	0.0	0.0	0.0	2.0	0.0000000000	False
write down the code	0.0	0.0	0.0	2.0	0.0000000000	False
traversal can i figure	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in one line	0.0	0.0	0.0	2.0	0.0000000000	False
number of different combinations	0.0	0.0	0.0	2.0	0.0000000000	False
knowledge of one traversal	0.0	0.0	0.0	2.0	0.0000000000	False
similarly for post order	0.0	0.0	0.0	2.0	0.0000000000	False
similarly for in order	0.0	0.0	0.0	2.0	0.0000000000	False
give the inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
trees same inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
suffices for most purposes	0.0	0.0	0.0	2.0	0.0000000000	False
two does nt suffices	0.0	0.0	0.0	0.0	0.0000000000	False
order and the post	0.0	0.0	0.0	2.0	0.0000000000	False
traversal in which case	0.0	0.0	0.0	2.0	0.0000000000	False
tree some internal nodes	0.0	0.0	0.0	2.0	0.0000000000	False
sufficient right more questions	0.0	0.0	0.0	2.0	0.0000000000	False
find how many tree	0.0	0.0	0.0	2.0	0.0000000000	False
number of binary trees	0.0	0.0	0.0	2.0	0.0000000000	False
lets say pre order	0.0	0.0	0.0	2.0	0.0000000000	False
two to the power	0.0	0.0	7.99752168525	8.0	0.2051282051	False
binary tree right wee	0.0	0.0	0.0	2.0	0.0000000000	False
right of its parent	0.0	0.0	0.0	2.0	0.0000000000	False
child of its parent	0.0	0.0	0.0	2.0	0.0000000000	False
finitely many different trees	0.0	0.0	0.0	2.0	0.0000000000	False
trees with six nodes	0.0	0.0	0.0	2.0	0.0000000000	False
compute the close form	0.0	0.0	0.0	2.0	0.0000000000	False
stop today s class	0.0	0.0	0.0	0.0	0.0000000000	False
traversals how to traverse	0.0	0.0	0.0	2.0	0.0000000000	False
ways of traversing trees	0.0	0.0	0.0	2.0	0.0000000000	False
trees um in order	0.0	0.0	0.0	2.0	0.0000000000	False
traversal for binary trees	0.0	0.0	0.0	2.0	0.0000000000	False
trees there is notion	0.0	0.0	0.0	2.0	0.0000000000	False
notion of inorder traversal	0.0	0.0	0.0	4.0	0.0000000000	False
right as perhaps understand	0.0	0.0	0.0	2.0	0.0000000000	False
traversal for general trees	0.0	0.0	0.0	2.0	0.0000000000	False
node has three children	0.0	0.0	0.0	2.0	0.0000000000	False
visiting the first child	0.0	0.0	0.0	2.0	0.0000000000	False
child or after visiting	0.0	0.0	0.0	2.0	0.0000000000	False
visiting the second child	0.0	0.0	0.0	2.0	0.0000000000	False
left in a right	0.0	0.0	0.0	2.0	0.0000000000	False
left then you visit	0.0	0.0	0.0	2.0	0.0000000000	False
node then you visit	0.0	0.0	0.0	2.0	0.0000000000	False
notion of n order	0.0	0.0	0.0	2.0	0.0000000000	False
order pre order post	0.0	0.0	0.0	2.0	0.0000000000	False
pre order post order	0.0	0.0	0.0	2.0	0.0000000000	False
order post order traversal	0.0	0.0	0.0	2.0	0.0000000000	False
two of these traversals	0.0	0.0	0.0	2.0	0.0000000000	False
traversals you can figure	0.0	0.0	0.0	2.0	0.0000000000	False
tree was which gave	0.0	0.0	0.0	2.0	0.0000000000	False
raise to those traversals	0.0	0.0	0.0	2.0	0.0000000000	False
talking about ordered dictionaries	0.0	0.0	0.0	2.0	0.0000000000	False
ways way of implementing	0.0	0.0	0.0	2.0	0.0000000000	False
right so recall dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
search for an element	0.0	0.0	0.0	2.0	0.0000000000	False
element or to delete	0.0	0.0	0.0	2.0	0.0000000000	False
key element with maximum	0.0	0.0	0.0	2.0	0.0000000000	False
key and the notion	0.0	0.0	0.0	2.0	0.0000000000	False
notion of predecessor successor	0.0	0.0	0.0	2.0	0.0000000000	False
order of a keys	0.0	0.0	0.0	2.0	0.0000000000	False
hashing when we talked	0.0	0.0	0.0	2.0	0.0000000000	False
dictionary if we recall	0.0	0.0	0.0	2.0	0.0000000000	False
keys is to compare	0.0	0.0	0.0	2.0	0.0000000000	False
equality given two keys	0.0	0.0	0.0	2.0	0.0000000000	False
out of our keys	0.0	0.0	0.0	2.0	0.0000000000	False
kind of a ordering	0.0	0.0	0.0	2.0	0.0000000000	False
relation of the keys	0.0	0.0	0.0	2.0	0.0000000000	False
function predecessor and successor	0.0	0.0	0.0	2.0	0.0000000000	False
taking only one parameter	0.0	0.0	0.0	2.0	0.0000000000	False
keys are the elements	0.0	0.0	0.0	2.0	0.0000000000	False
field all the part	0.0	0.0	0.0	2.0	0.0000000000	False
ordered on the keys	0.0	0.0	0.0	2.0	0.0000000000	False
keys so similarly successor	0.0	0.0	0.0	2.0	0.0000000000	False
implement such a ordered	0.0	0.0	0.0	2.0	0.0000000000	False
dictionary so two trivals	0.0	0.0	0.0	2.0	0.0000000000	False
trivals doing both cases	0.0	0.0	0.0	2.0	0.0000000000	False
list kind of data	0.0	0.0	0.0	2.0	0.0000000000	False
kind of data structure	0.0	0.0	0.0	2.0	0.0000000000	False
structure so in unordered	0.0	0.0	0.0	2.0	0.0000000000	False
taking only constant amount	0.0	0.0	0.0	2.0	0.0000000000	False
amount of time searching	0.0	0.0	0.0	2.0	0.0000000000	False
searching will take ordered	0.0	0.0	0.0	2.0	0.0000000000	False
list before i found	0.0	0.0	0.0	2.0	0.0000000000	False
out the entire elements	0.0	0.0	0.0	2.0	0.0000000000	False
entire elements and deletion	0.0	0.0	0.0	2.0	0.0000000000	False
order n not order	0.0	0.0	0.0	2.0	0.0000000000	False
dictionary successor of twelve	0.0	0.0	0.0	2.0	0.0000000000	False
twelve is not twenty	0.0	0.0	0.0	2.0	0.0000000000	False
two it is fourteen	0.0	0.0	0.0	2.0	0.0000000000	False
twelve in the ordered	0.0	0.0	0.0	2.0	0.0000000000	False
relation so the ordered	0.0	0.0	0.0	2.0	0.0000000000	False
order on the integers	0.0	0.0	0.0	2.0	0.0000000000	False
integers yeah so twelve	0.0	0.0	0.0	2.0	0.0000000000	False
larger than that eighteen	0.0	0.0	0.0	2.0	0.0000000000	False
eighteen twenty two thirty	0.0	0.0	0.0	2.0	0.0000000000	False
entire thing to find	0.0	0.0	0.0	2.0	0.0000000000	False
key larger than twelve	0.0	0.0	0.0	2.0	0.0000000000	False
twelve yeah both successor	0.0	0.0	0.0	2.0	0.0000000000	False
inefficient implementation an ordered	0.0	0.0	0.0	2.0	0.0000000000	False
implementation an ordered list	0.0	0.0	0.0	2.0	0.0000000000	False
lets say we ordered	0.0	0.0	0.0	2.0	0.0000000000	False
total order of keys	0.0	0.0	0.0	2.0	0.0000000000	True
reference to the end	0.0	0.0	0.0	2.0	0.0000000000	False
end in this list	0.0	0.0	0.0	2.0	0.0000000000	False
give me the successor	0.0	0.0	0.0	2.0	0.0000000000	False
successor say predecessor takes	0.0	0.0	0.0	2.0	0.0000000000	False
node when i asked	0.0	0.0	0.0	2.0	0.0000000000	False
search for the node	0.0	0.0	0.0	2.0	0.0000000000	False
throw this entire list	0.0	0.0	0.0	2.0	0.0000000000	False
entire list to reach	0.0	0.0	0.0	2.0	0.0000000000	False
node in this list	0.0	0.0	0.0	2.0	0.0000000000	False
constant time right inserting	0.0	0.0	0.0	2.0	0.0000000000	False
right inserting also takes	0.0	0.0	0.0	2.0	0.0000000000	False
out way to insert	0.0	0.0	0.0	2.0	0.0000000000	False
find out the correction	0.0	0.0	0.0	2.0	0.0000000000	False
out the correction position	0.0	0.0	0.0	2.0	0.0000000000	False
correction position for insertion	0.0	0.0	0.0	2.0	0.0000000000	False
insertion okay searching takes	0.0	0.0	0.0	2.0	0.0000000000	False
searching takes n order	0.0	0.0	0.0	2.0	0.0000000000	False
array searching can improve	0.0	0.0	0.0	2.0	0.0000000000	False
right if you put	0.0	0.0	0.0	2.0	0.0000000000	False
elements they are ordered	0.0	0.0	0.0	2.0	0.0000000000	False
binary search to find	0.0	0.0	0.0	2.0	0.0000000000	False
find out the element	0.0	0.0	0.0	2.0	0.0000000000	False
element logarithmic time log	0.0	0.0	0.0	2.0	0.0000000000	False
right but binary search	0.0	0.0	0.0	2.0	0.0000000000	False
search then now insertion	0.0	0.0	0.0	2.0	0.0000000000	False
deletion still take order	0.0	0.0	0.0	2.0	0.0000000000	False
right place to insert	0.0	0.0	0.0	2.0	0.0000000000	False
shift all the elements	0.0	0.0	0.0	2.0	0.0000000000	False
elements to the right	0.0	0.0	0.0	2.0	0.0000000000	False
insertion similarly for deletion	0.0	0.0	0.0	2.0	0.0000000000	False
recap what binary search	0.0	0.0	0.0	2.0	0.0000000000	False
binary search to search	0.0	0.0	0.0	2.0	0.0000000000	False
larger the right twenty	0.0	0.0	0.0	2.0	0.0000000000	False
location which has twenty	0.0	0.0	0.0	2.0	0.0000000000	False
two or an array	0.0	0.0	0.0	2.0	0.0000000000	False
two inch away case	0.0	0.0	0.0	2.0	0.0000000000	False
make a comparison size	0.0	0.0	0.0	2.0	0.0000000000	False
size of the array	0.0	0.0	0.0	2.0	0.0000000000	False
array which you making	0.0	0.0	0.0	2.0	0.0000000000	False
making the search halves	0.0	0.0	0.0	2.0	0.0000000000	False
searching as to recall	0.0	0.0	0.0	2.0	0.0000000000	False
recall insertion and deletion	0.0	0.0	0.0	2.0	0.0000000000	False
questions still this point	0.0	0.0	0.0	2.0	0.0000000000	False
binary search binary search	0.0	0.0	0.0	2.0	0.0000000000	False
search binary search tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree which has search	0.0	0.0	0.0	2.0	0.0000000000	False
binary tree binary tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree is a tree	0.0	0.0	0.0	2.0	0.0000000000	False
children right a node	0.0	0.0	0.0	2.0	0.0000000000	False
child or no children	0.0	0.0	0.0	2.0	0.0000000000	False
children no children means	0.0	0.0	0.0	2.0	0.0000000000	False
out so each node	0.0	0.0	0.0	2.0	0.0000000000	False
talking about the element	0.0	0.0	0.0	2.0	0.0000000000	False
interested in the keys	0.0	0.0	0.0	2.0	0.0000000000	False
written on the nodes	0.0	0.0	0.0	2.0	0.0000000000	False
nodes are the keys	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree all keys	0.0	0.0	0.0	2.0	0.0000000000	False
tree and this property	0.0	0.0	0.0	2.0	0.0000000000	False
holds at every node	0.0	0.0	0.0	2.0	0.0000000000	False
tree which have keys	0.0	0.0	0.0	2.0	0.0000000000	False
tree all the keys	0.0	0.0	0.0	4.0	0.0000000000	False
keys in the left	0.0	0.0	2.9941089838	8.0	0.4561403509	False
node all the keys	0.0	0.0	0.0	2.0	0.0000000000	False
keys in the right	0.0	0.0	2.99558173785	6.0	0.0000000000	False
larger than this node	0.0	0.0	0.0	2.0	0.0000000000	False
similarly for this tree	0.0	0.0	0.0	2.0	0.0000000000	False
larger than this key	0.0	0.0	0.0	2.0	0.0000000000	False
value all the keys	0.0	0.0	0.0	2.0	0.0000000000	False
tree nothing to talk	0.0	0.0	0.0	2.0	0.0000000000	False
right sub tree larger	0.0	0.0	0.0	2.0	0.0000000000	False
larger than seven right	0.0	0.0	0.0	2.0	0.0000000000	False
keys which satisfies property	0.0	0.0	0.0	2.0	0.0000000000	False
property so the search	0.0	0.0	0.0	2.0	0.0000000000	False
search properties is satisfied	0.0	0.0	0.0	2.0	0.0000000000	False
clear so binary tree	0.0	0.0	0.0	2.0	0.0000000000	False
binary tree plus search	0.0	0.0	0.0	2.0	0.0000000000	False
tree plus search property	0.0	0.0	0.0	2.0	0.0000000000	False
property equals binary search	0.0	0.0	0.0	2.0	0.0000000000	False
equals binary search tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree with this keys	0.0	0.0	0.0	2.0	0.0000000000	False
binary satisfy the search	0.0	0.0	0.0	2.0	0.0000000000	False
satisfy the search property	0.0	0.0	0.0	2.0	0.0000000000	False
right so keys stored	0.0	0.0	0.0	2.0	0.0000000000	False
keys stored left sub	0.0	0.0	0.0	2.0	0.0000000000	False
stored left sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
keys which two keys	0.0	0.0	0.0	2.0	0.0000000000	False
dictionaries only in settings	0.0	0.0	0.0	2.0	0.0000000000	False
settings were the keys	0.0	0.0	0.0	2.0	0.0000000000	False
keys are unique right	0.0	0.0	0.0	4.0	0.0000000000	False
unique right an element	0.0	0.0	0.0	2.0	0.0000000000	False
key no two keys	0.0	0.0	0.0	2.0	0.0000000000	False
setting were two keys	0.0	0.0	0.0	2.0	0.0000000000	False
right you can define	0.0	0.0	0.0	2.0	0.0000000000	False
define total order names	0.0	0.0	0.0	2.0	0.0000000000	False
geographic order alphabetic order	0.0	0.0	0.0	2.0	0.0000000000	False
settings in which keys	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the discussion	0.0	0.0	0.0	2.0	0.0000000000	False
dictionary we are implementing	0.0	0.0	0.0	2.0	0.0000000000	False
out where the element	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree we compare	0.0	0.0	0.0	2.0	0.0000000000	False
tree we compare eleven	0.0	0.0	0.0	2.0	0.0000000000	False
find an element key	0.0	0.0	0.0	2.0	0.0000000000	False
key k ill compare	0.0	0.0	0.0	2.0	0.0000000000	False
key in the root	0.0	0.0	4.9941089838	8.0	0.4561403509	False
root then you search	0.0	0.0	0.0	2.0	0.0000000000	False
right okay then wee	0.0	0.0	0.0	2.0	0.0000000000	False
left then we compare	0.0	0.0	0.0	2.0	0.0000000000	False
left but the left	0.0	0.0	0.0	2.0	0.0000000000	False
tree of this guy	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree this guy	0.0	0.0	0.0	2.0	0.0000000000	False
write the binary search	0.0	0.0	0.0	2.0	0.0000000000	False
binary search this search	0.0	0.0	0.0	2.0	0.0000000000	False
search this search procedure	0.0	0.0	0.0	2.0	0.0000000000	False
search procedure binary search	0.0	0.0	0.0	2.0	0.0000000000	False
procedure binary search tree	0.0	0.0	0.0	2.0	0.0000000000	False
root of t lets	0.0	0.0	0.0	2.0	0.0000000000	False
equals nil which means	0.0	0.0	0.0	2.0	0.0000000000	False
key in this node	0.0	0.0	0.0	2.0	0.0000000000	False
return the root node	0.0	0.0	0.0	2.0	0.0000000000	False
search in the left	0.0	0.0	0.0	4.0	0.0000000000	False
right so x begin	0.0	0.0	0.0	2.0	0.0000000000	False
refers to the root	0.0	0.0	0.0	4.0	0.0000000000	False
root of the tree	0.0	0.0	0.0	4.0	0.0000000000	False
tree and then left	0.0	0.0	0.0	2.0	0.0000000000	False
reference to a left	0.0	0.0	0.0	2.0	0.0000000000	False
root of the left	0.0	0.0	0.0	2.0	0.0000000000	False
right so its referring	0.0	0.0	0.0	2.0	0.0000000000	False
key in the node	0.0	0.0	0.0	2.0	0.0000000000	False
version the iterative version	0.0	0.0	0.0	2.0	0.0000000000	False
calls to the search	0.0	0.0	0.0	2.0	0.0000000000	False
tree right we start	0.0	0.0	0.0	2.0	0.0000000000	False
value of the left	0.0	0.0	0.0	2.0	0.0000000000	False
referring to this guy	0.0	0.0	0.0	2.0	0.0000000000	False
right or actually code	0.0	0.0	0.0	2.0	0.0000000000	False
left x right pseudo	0.0	0.0	0.0	2.0	0.0000000000	False
first it will pointing	0.0	0.0	0.0	2.0	0.0000000000	False
pointing to this node	0.0	0.0	3.9941089838	8.0	0.2131147541	False
node then its pointing	0.0	0.0	0.0	2.0	0.0000000000	False
node and eventually pointing	0.0	0.0	0.0	2.0	0.0000000000	False
right keep getting modified	0.0	0.0	0.0	2.0	0.0000000000	False
level in the tree	0.0	0.0	0.0	4.0	0.0000000000	False
children node child nodes	0.0	0.0	0.0	2.0	0.0000000000	False
nodes either the left	0.0	0.0	0.0	2.0	0.0000000000	False
child of the node	0.0	0.0	0.0	4.0	0.0000000000	False
node or the right	0.0	0.0	0.0	2.0	0.0000000000	False
run of while loop	0.0	0.0	0.0	2.0	0.0000000000	False
times this while loop	0.0	0.0	0.0	2.0	0.0000000000	False
loop executed the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
executed the maximum number	0.0	0.0	0.0	2.0	0.0000000000	False
maximum number of levels	0.0	0.0	0.0	4.0	0.0000000000	False
levels in a tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree so the height	0.0	0.0	0.0	2.0	0.0000000000	False
height of the tree	0.0	0.0	11.9911634757	12.0	0.3513513514	True
right so the height	0.0	0.0	0.0	2.0	0.0000000000	False
height if the height	0.0	0.0	0.0	2.0	0.0000000000	False
running time of procedure	0.0	0.0	0.0	4.0	0.0000000000	True
tree on n nodes	0.0	0.0	0.0	2.0	0.0000000000	False
situations happens but note	0.0	0.0	0.0	2.0	0.0000000000	False
note that the height	0.0	0.0	0.0	2.0	0.0000000000	False
order h the height	0.0	0.0	0.0	2.0	0.0000000000	False
tree order the height	0.0	0.0	0.0	2.0	0.0000000000	False
tree but the height	0.0	0.0	0.0	2.0	0.0000000000	False
large has the number	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the tree	0.0	0.0	0.0	2.0	0.0000000000	False
procedure that of finding	0.0	0.0	0.0	2.0	0.0000000000	False
finding the minimum element	0.0	0.0	0.0	2.0	0.0000000000	False
element in the tree	0.0	0.0	0.0	2.0	0.0000000000	False
left most tree left	0.0	0.0	0.0	2.0	0.0000000000	False
tree left most leaf	0.0	0.0	0.0	2.0	0.0000000000	False
left most leaf left	0.0	0.0	0.0	2.0	0.0000000000	False
leaf left most leaf	0.0	0.0	0.0	2.0	0.0000000000	False
search tree so lets	0.0	0.0	0.0	2.0	0.0000000000	False
tree so lets put	0.0	0.0	0.0	2.0	0.0000000000	False
talking about quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm we are discussing	0.0	0.0	0.0	2.0	0.0000000000	False
discussing in the series	0.0	0.0	0.0	2.0	0.0000000000	False
first one was insertion	0.0	0.0	0.0	2.0	0.0000000000	False
argued a worst case	0.0	0.0	0.0	2.0	0.0000000000	False
running time of order	0.0	0.0	0.0	4.0	0.0000000000	False
today the quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
quick algorithm in practice	0.0	0.0	0.0	2.0	0.0000000000	False
constants the another property	0.0	0.0	0.0	2.0	0.0000000000	False
property of this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
sorting algorithm an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
place sort in place	0.0	0.0	0.0	2.0	0.0000000000	False
require any additional memory	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the numbers	0.0	0.0	0.0	2.0	0.0000000000	False
array the n numbers	0.0	0.0	0.0	2.0	0.0000000000	False
sort a large collection	0.0	0.0	0.0	2.0	0.0000000000	False
large collection of numbers	0.0	0.0	0.0	2.0	0.0000000000	False
divide and conquer algorithms	0.0	0.0	0.0	4.0	0.0000000000	True
high level the idea	0.0	0.0	0.0	2.0	0.0000000000	False
two or more pieces	0.0	0.0	0.0	2.0	0.0000000000	False
case of quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
chose the n numbers	0.0	0.0	0.0	2.0	0.0000000000	False
call the lower part	0.0	0.0	0.0	2.0	0.0000000000	False
call the higher part	0.0	0.0	0.0	2.0	0.0000000000	False
higher part the property	0.0	0.0	0.0	2.0	0.0000000000	False
lower part every number	0.0	0.0	0.0	2.0	0.0000000000	False
sort the lower part	0.0	0.0	1.99847638395	6.0	0.0000000000	False
sort the higher part	0.0	0.0	0.0	4.0	0.0000000000	False
part and i put	0.0	0.0	0.0	2.0	0.0000000000	False
entire thing is sorted	0.0	0.0	0.0	4.0	0.0000000000	False
sorted rite i sorted	0.0	0.0	0.0	2.0	0.0000000000	False
lower part is sorted	0.0	0.0	0.0	2.0	0.0000000000	False
higher part every elements	0.0	0.0	0.0	2.0	0.0000000000	False
first how this partition	0.0	0.0	0.0	2.0	0.0000000000	False
procedure so the partitioning	0.0	0.0	0.0	2.0	0.0000000000	False
elements as a pivot	0.0	0.0	0.0	2.0	0.0000000000	False
smaller than the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
lower half lower part	0.0	0.0	0.0	4.0	0.0000000000	False
part of the array	0.0	0.0	0.0	4.0	0.0000000000	False
larger than the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
procedure to the partitioning	0.0	0.0	0.0	2.0	0.0000000000	False
limits of the array	0.0	0.0	0.0	2.0	0.0000000000	False
refers to this location	0.0	0.0	0.0	4.0	0.0000000000	False
location and r refers	0.0	0.0	0.0	2.0	0.0000000000	False
partitions the sub array	0.0	0.0	0.0	2.0	0.0000000000	False
end of the procedure	0.0	0.0	0.0	2.0	0.0000000000	False
start in the end	0.0	0.0	0.0	2.0	0.0000000000	False
end of the array	0.0	0.0	0.0	2.0	0.0000000000	False
array the sub array	0.0	0.0	0.0	2.0	0.0000000000	False
means we just continue	0.0	0.0	0.0	2.0	0.0000000000	False
loop till you break	0.0	0.0	0.0	2.0	0.0000000000	False
out to the loop	0.0	0.0	0.0	2.0	0.0000000000	False
ten so keep decrementing	0.0	0.0	0.0	2.0	0.0000000000	False
locations which has counting	0.0	0.0	0.0	2.0	0.0000000000	False
reached such a location	0.0	0.0	0.0	2.0	0.0000000000	False
location so i stopped	0.0	0.0	0.0	2.0	0.0000000000	False
loop where am incrementing	0.0	0.0	0.0	2.0	0.0000000000	False
exchange ai aj means	0.0	0.0	0.0	2.0	0.0000000000	False
contents rite is ort	0.0	0.0	0.0	2.0	0.0000000000	False
blue i will denote	0.0	0.0	0.0	2.0	0.0000000000	False
part of the left	0.0	0.0	0.0	2.0	0.0000000000	False
left part and orange	0.0	0.0	0.0	2.0	0.0000000000	False
part of the right	0.0	0.0	0.0	2.0	0.0000000000	False
ten so i found	0.0	0.0	0.0	2.0	0.0000000000	False
found find an element	0.0	0.0	0.0	2.0	0.0000000000	False
things ya i stopped	0.0	0.0	0.0	2.0	0.0000000000	False
moving till i find	0.0	0.0	0.0	4.0	0.0000000000	False
ten at this location	0.0	0.0	0.0	2.0	0.0000000000	False
nineteen ya i swap	0.0	0.0	0.0	2.0	0.0000000000	False
decrementing till i find	0.0	0.0	0.0	2.0	0.0000000000	False
ten j is searching	0.0	0.0	0.0	2.0	0.0000000000	False
incrementing till i find	0.0	0.0	0.0	2.0	0.0000000000	False
exit return the procedure	0.0	0.0	0.0	2.0	0.0000000000	False
returning we are returning	0.0	0.0	0.0	2.0	0.0000000000	False
left half my left	0.0	0.0	0.0	2.0	0.0000000000	False
half my left half	0.0	0.0	0.0	2.0	0.0000000000	False
dos this procedure takes	0.0	0.0	0.0	2.0	0.0000000000	False
clear that its taking	0.0	0.0	0.0	2.0	0.0000000000	False
step we are decrementing	0.0	0.0	0.0	2.0	0.0000000000	False
decremented utmost ten times	0.0	0.0	0.0	2.0	0.0000000000	False
ten times the size	0.0	0.0	0.0	2.0	0.0000000000	False
size of the array	0.0	0.0	0.0	4.0	0.0000000000	False
array so this loop	0.0	0.0	0.0	2.0	0.0000000000	False
loop is done utmost	0.0	0.0	0.0	4.0	0.0000000000	False
pivot and saying compare	0.0	0.0	0.0	2.0	0.0000000000	False
element with the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
back into this place	0.0	0.0	0.0	2.0	0.0000000000	False
elements in this array	0.0	0.0	0.0	2.0	0.0000000000	False
partitioning in in place	0.0	0.0	0.0	2.0	0.0000000000	False
memory and in linear	0.0	0.0	0.0	2.0	0.0000000000	False
group inside by taking	0.0	0.0	0.0	2.0	0.0000000000	False
inside by taking order	0.0	0.0	0.0	2.0	0.0000000000	False
order n and wait	0.0	0.0	0.0	2.0	0.0000000000	False
total number of times	0.0	0.0	4.99796851193	8.0	0.4166666667	False
times is this statement	0.0	0.0	0.0	2.0	0.0000000000	False
executed utmost n times	0.0	0.0	0.0	2.0	0.0000000000	False
loop i might decrement	0.0	0.0	0.0	2.0	0.0000000000	False
executed and this step	0.0	0.0	0.0	2.0	0.0000000000	False
complete quick sort algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort on lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets say this array	0.0	0.0	0.0	2.0	0.0000000000	False
array a between limits	0.0	0.0	0.0	2.0	0.0000000000	False
initial call for quick	0.0	0.0	0.0	2.0	0.0000000000	False
call for quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
nt make any sense	0.0	0.0	0.0	0.0	0.0000000000	False
first find the partition	0.0	0.0	0.0	2.0	0.0000000000	False
partition of this part	0.0	0.0	0.0	2.0	0.0000000000	False
invoke the previous procedure	0.0	0.0	0.0	2.0	0.0000000000	False
part of the sub	0.0	0.0	0.0	4.0	0.0000000000	False
returns the demarcating lines	0.0	0.0	0.0	2.0	0.0000000000	False
sort the lower half	0.0	0.0	0.0	2.0	0.0000000000	False
recursively invoke quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
stops when you return	0.0	0.0	0.0	2.0	0.0000000000	False
loop like a break	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to copy	0.0	0.0	0.0	0.0	0.0000000000	False
copies of the variables	0.0	0.0	0.0	2.0	0.0000000000	False
space that is created	0.0	0.0	0.0	2.0	0.0000000000	False
created on this track	0.0	0.0	0.0	2.0	0.0000000000	False
taking any additional memory	0.0	0.0	0.0	4.0	0.0000000000	False
memory for the variab	0.0	0.0	0.0	2.0	0.0000000000	False
variab for the elements	0.0	0.0	0.0	2.0	0.0000000000	False
sir in quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
number than a fixed	0.0	0.0	0.0	2.0	0.0000000000	False
element should be partitioned	0.0	0.0	0.0	2.0	0.0000000000	False
pivot element you partitioned	0.0	0.0	0.0	2.0	0.0000000000	False
array around the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
sort this left half	0.0	0.0	0.0	2.0	0.0000000000	False
half let me sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort this right half	0.0	0.0	0.0	2.0	0.0000000000	False
notion of a left	0.0	0.0	0.0	2.0	0.0000000000	False
half and a right	0.0	0.0	0.0	2.0	0.0000000000	False
write a quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
procedure in this manner	0.0	0.0	0.0	2.0	0.0000000000	False
limits of the sub	0.0	0.0	0.0	2.0	0.0000000000	False
partition procedure takes order	0.0	0.0	0.0	2.0	0.0000000000	False
takes order n times	0.0	0.0	2.99847638395	6.0	0.0000000000	False
order n times linear	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort will depend	0.0	0.0	0.0	2.0	0.0000000000	False
left half but left	0.0	0.0	0.0	2.0	0.0000000000	False
half but left part	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort is taking	0.0	0.0	0.0	2.0	0.0000000000	False
sort is taking lets	0.0	0.0	0.0	2.0	0.0000000000	False
halves ya which means	0.0	0.0	0.0	2.0	0.0000000000	False
means that i started	0.0	0.0	0.0	2.0	0.0000000000	False
lets say which means	0.0	0.0	0.0	2.0	0.0000000000	False
elements were less half	0.0	0.0	0.0	2.0	0.0000000000	False
half and half elements	0.0	0.0	0.0	2.0	0.0000000000	False
lucky again i picked	0.0	0.0	0.0	2.0	0.0000000000	False
divided up the thing	0.0	0.0	0.0	2.0	0.0000000000	False
lucky i it happened	0.0	0.0	0.0	2.0	0.0000000000	False
two parts equal parts	0.0	0.0	0.0	2.0	0.0000000000	False
lucky at every step	0.0	0.0	0.0	2.0	0.0000000000	False
size of this array	0.0	0.0	0.0	2.0	0.0000000000	False
two into two parts	0.0	0.0	0.0	2.0	0.0000000000	False
sort into two parts	0.0	0.0	0.0	2.0	0.0000000000	False
effect in each level	0.0	0.0	0.0	2.0	0.0000000000	False
level of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
drawn in this manner	0.0	0.0	0.0	2.0	0.0000000000	False
manner am taking order	0.0	0.0	0.0	2.0	0.0000000000	False
eventually you will end	0.0	0.0	0.0	2.0	0.0000000000	False
log n such levels	0.0	0.0	0.0	2.0	0.0000000000	False
lucky i am naveen	0.0	0.0	0.0	2.0	0.0000000000	False
naveen rite which means	0.0	0.0	0.0	2.0	0.0000000000	False
sir in this sort	0.0	0.0	0.0	2.0	0.0000000000	False
times i will increase	0.0	0.0	5.99847638395	6.0	0.0000000000	False
increase i or decrease	0.0	0.0	0.0	2.0	0.0000000000	False
ten rite total number	0.0	0.0	0.0	2.0	0.0000000000	False
times so the sum	0.0	0.0	0.0	2.0	0.0000000000	False
times so which means	0.0	0.0	0.0	2.0	0.0000000000	False
constant time some theta	0.0	0.0	0.0	2.0	0.0000000000	False
send the quality good	0.0	0.0	0.0	2.0	0.0000000000	False
element the other side	0.0	0.0	0.0	2.0	0.0000000000	False
side gets n minus	0.0	0.0	0.0	2.0	0.0000000000	False
writing the recurrence relation	0.0	0.0	0.0	2.0	0.0000000000	False
relation time to quick	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort n elements	0.0	0.0	0.0	2.0	0.0000000000	False
sort n elements equals	0.0	0.0	0.0	2.0	0.0000000000	False
procedure was quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort the left	0.0	0.0	0.0	2.0	0.0000000000	False
sort the left part	0.0	0.0	0.0	2.0	0.0000000000	False
lets say the left	0.0	0.0	0.0	2.0	0.0000000000	False
part has one element	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort the right	0.0	0.0	0.0	2.0	0.0000000000	False
sort the right part	0.0	0.0	0.0	2.0	0.0000000000	False
part which was lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets say n minus	0.0	0.0	0.0	4.0	0.0000000000	False
recurrence and lets solve	0.0	0.0	0.0	2.0	0.0000000000	False
lets solve this recurrence	0.0	0.0	0.0	2.0	0.0000000000	False
minus one plus theta	0.0	0.0	5.99847638395	6.0	0.0000000000	False
theta of n wait	0.0	0.0	0.0	2.0	0.0000000000	False
minus two plus theta	0.0	0.0	5.99847638395	6.0	0.0000000000	False
theta of n minus	0.0	0.0	11.9969527679	12.0	0.1459854015	False
minus three plus theta	0.0	0.0	0.0	4.0	0.0000000000	False
two plus this term	0.0	0.0	0.0	2.0	0.0000000000	False
minus four plus theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta of n squared	0.0	0.0	0.0	4.0	0.0000000000	False
squared ya n squared	0.0	0.0	0.0	2.0	0.0000000000	False
bothering you just replace	0.0	0.0	0.0	2.0	0.0000000000	False
half and half split	0.0	0.0	0.0	4.0	0.0000000000	False
simple skewed split split	0.0	0.0	0.0	2.0	0.0000000000	False
minus one n minus	0.0	0.0	0.0	4.0	0.0000000000	False
minus two n minus	0.0	0.0	0.0	2.0	0.0000000000	False
height of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
makes it n squared	0.0	0.0	0.0	2.0	0.0000000000	False
element as the pivot	0.0	0.0	5.99339766379	26.0	0.3111909037	False
lets say in increasing	0.0	0.0	0.0	2.0	0.0000000000	False
element in my upper	0.0	0.0	0.0	2.0	0.0000000000	False
divided in this manner	0.0	0.0	0.0	2.0	0.0000000000	False
worst case would happen	0.0	0.0	0.0	4.0	0.0000000000	False
happen when the input	0.0	0.0	0.0	2.0	0.0000000000	False
input is already sorted	0.0	0.0	0.0	2.0	0.0000000000	False
sorted in ascending order	0.0	0.0	0.0	2.0	0.0000000000	False
order or in descending	0.0	0.0	0.0	2.0	0.0000000000	False
order even in descending	0.0	0.0	0.0	2.0	0.0000000000	False
element in right half	0.0	0.0	0.0	2.0	0.0000000000	False
happen rite similar kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of a thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing happened in insertion	0.0	0.0	0.0	2.0	0.0000000000	False
happened in insertion sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort if you remember	0.0	0.0	0.0	2.0	0.0000000000	False
recall in insertion sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort we were taking	0.0	0.0	0.0	2.0	0.0000000000	False
out the best place	0.0	0.0	0.0	2.0	0.0000000000	False
find the best place	0.0	0.0	0.0	2.0	0.0000000000	False
sorted in decreasing order	0.0	0.0	0.0	2.0	0.0000000000	False
front of the array	0.0	0.0	0.0	4.0	0.0000000000	False
array at every step	0.0	0.0	0.0	2.0	0.0000000000	False
squared but in insertion	0.0	0.0	0.0	2.0	0.0000000000	False
sort if the array	0.0	0.0	0.0	2.0	0.0000000000	False
sorted in increasing order	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to move	0.0	0.0	0.0	0.0	0.0000000000	False
comparison with insertion sort	0.0	0.0	0.0	2.0	0.0000000000	False
sorted increasing sorted decreasing	0.0	0.0	0.0	2.0	0.0000000000	False
decreasing you might end	0.0	0.0	0.0	2.0	0.0000000000	False
case seems to app	0.0	0.0	0.0	2.0	0.0000000000	False
half at every step	0.0	0.0	0.0	4.0	0.0000000000	False
tenth that is ten	0.0	0.0	0.0	2.0	0.0000000000	False
percent of the elements	0.0	0.0	0.0	4.0	0.0000000000	False
side and ninety percent	0.0	0.0	0.0	2.0	0.0000000000	False
suppose this was happening	0.0	0.0	0.0	2.0	0.0000000000	False
happening at every stage	0.0	0.0	0.0	2.0	0.0000000000	False
elements on one side	0.0	0.0	0.0	2.0	0.0000000000	False
tenth on one side	0.0	0.0	0.0	2.0	0.0000000000	False
side and nine tenth	0.0	0.0	2.99847638395	6.0	0.0000000000	False
side one tenth means	0.0	0.0	0.0	2.0	0.0000000000	False
means n by hundred	0.0	0.0	0.0	2.0	0.0000000000	False
hundred on one side	0.0	0.0	0.0	2.0	0.0000000000	False
ten on one side	0.0	0.0	0.0	2.0	0.0000000000	False
tenths of this guy	0.0	0.0	4.99847638395	6.0	0.0000000000	False
ten number of elements	0.0	0.0	0.0	2.0	0.0000000000	False
out what the right	0.0	0.0	0.0	2.0	0.0000000000	False
number at this step	0.0	0.0	0.0	4.0	0.0000000000	False
guy at this step	0.0	0.0	0.0	2.0	0.0000000000	False
number at every level	0.0	0.0	0.0	2.0	0.0000000000	False
decreasing by a factor	0.0	0.0	0.0	2.0	0.0000000000	False
ten how many times	0.0	0.0	0.0	2.0	0.0000000000	False
times can i decrease	0.0	0.0	0.0	2.0	0.0000000000	False
utmost to the log	0.0	0.0	0.0	2.0	0.0000000000	False
decrementing by a factor	0.0	0.0	0.0	2.0	0.0000000000	False
factor of nine tens	0.0	0.0	0.0	2.0	0.0000000000	False
tens at every step	0.0	0.0	0.0	2.0	0.0000000000	False
decreasing decrementing by half	0.0	0.0	0.0	2.0	0.0000000000	False
work out the map	0.0	0.0	0.0	2.0	0.0000000000	False
constant its different constant	0.0	0.0	0.0	2.0	0.0000000000	False
height is order log	0.0	0.0	0.0	2.0	0.0000000000	False
level we are taking	0.0	0.0	0.0	2.0	0.0000000000	False
sir moving the left	0.0	0.0	0.0	2.0	0.0000000000	False
providing an upper bound	0.0	0.0	0.0	2.0	0.0000000000	False
strange manner one tenth	0.0	0.0	0.0	2.0	0.0000000000	False
tenth and nine tenth	0.0	0.0	0.0	2.0	0.0000000000	False
thirty six by thirty	0.0	0.0	0.0	2.0	0.0000000000	False
constant fraction of numbers	0.0	0.0	0.0	4.0	0.0000000000	False
side a constant fraction	0.0	0.0	0.0	2.0	0.0000000000	False
side we cant afford	0.0	0.0	0.0	2.0	0.0000000000	False
constant fraction one tenth	0.0	0.0	0.0	2.0	0.0000000000	False
tenth or one hundredth	0.0	0.0	0.0	2.0	0.0000000000	False
hundredth or one thousandth	0.0	0.0	0.0	2.0	0.0000000000	False
formal analysis from starting	0.0	0.0	0.0	2.0	0.0000000000	False
lucky and unlucky cases	0.0	0.0	0.0	2.0	0.0000000000	False
lucky case n minus	0.0	0.0	0.0	2.0	0.0000000000	False
two and n minus	0.0	0.0	0.0	4.0	0.0000000000	False
two on one side	0.0	0.0	0.0	2.0	0.0000000000	False
side actually i managed	0.0	0.0	0.0	2.0	0.0000000000	False
two n times log	0.0	0.0	0.0	2.0	0.0000000000	False
log n such thing	0.0	0.0	0.0	2.0	0.0000000000	False
lets try and prove	0.0	0.0	0.0	2.0	0.0000000000	False
case that we expect	0.0	0.0	0.0	2.0	0.0000000000	False
word expected time expected	0.0	0.0	0.0	2.0	0.0000000000	False
find a median element	0.0	0.0	0.0	4.0	0.0000000000	False
median as the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
break up my array	0.0	0.0	0.0	2.0	0.0000000000	False
numbers and then find	0.0	0.0	0.0	2.0	0.0000000000	False
find the median element	0.0	0.0	1.99847638395	6.0	0.0000000000	False
strategy except the sorting	0.0	0.0	0.0	2.0	0.0000000000	False
place ya so finding	0.0	0.0	0.0	2.0	0.0000000000	False
number of small array	0.0	0.0	0.0	2.0	0.0000000000	False
small array then find	0.0	0.0	0.0	2.0	0.0000000000	False
find the then sorting	0.0	0.0	0.0	2.0	0.0000000000	False
compute a median element	0.0	0.0	0.0	2.0	0.0000000000	False
median element in linear	0.0	0.0	0.0	2.0	0.0000000000	False
fairly a involved procedure	0.0	0.0	0.0	2.0	0.0000000000	False
pick a random element	0.0	0.0	5.9969527679	12.0	0.2597402597	False
random element and declare	0.0	0.0	0.0	2.0	0.0000000000	False
element as our pivot	0.0	0.0	0.0	2.0	0.0000000000	False
nt want top pick	0.0	0.0	0.0	0.0	0.0000000000	False
pick a specific element	0.0	0.0	0.0	2.0	0.0000000000	False
pick the last element	0.0	0.0	0.0	2.0	0.0000000000	False
lets say in decreasing	0.0	0.0	0.0	2.0	0.0000000000	False
decreasing order or increasing	0.0	0.0	0.0	2.0	0.0000000000	False
order or increasing order	0.0	0.0	0.0	2.0	0.0000000000	False
order then am struck	0.0	0.0	0.0	2.0	0.0000000000	False
struck i will struck	0.0	0.0	0.0	2.0	0.0000000000	False
call a randomized algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
randomized algorithm an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
basically making some kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of random choices	0.0	0.0	0.0	2.0	0.0000000000	False
analyze what this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm in a minute	0.0	0.0	0.0	2.0	0.0000000000	False
partition around a random	0.0	0.0	0.0	2.0	0.0000000000	False
random element a pivot	0.0	0.0	0.0	2.0	0.0000000000	False
pivot is a random	0.0	0.0	0.0	2.0	0.0000000000	False
element we just pick	0.0	0.0	0.0	2.0	0.0000000000	False
probability so what kind	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of different splits	0.0	0.0	0.0	2.0	0.0000000000	False
two n n minus	0.0	0.0	0.0	2.0	0.0000000000	False
probability of these splits	0.0	0.0	0.0	2.0	0.0000000000	False
random element each element	0.0	0.0	0.0	2.0	0.0000000000	False
element can be picked	0.0	0.0	0.0	2.0	0.0000000000	False
picked with equal probability	0.0	0.0	0.0	2.0	0.0000000000	False
elements and i pick	0.0	0.0	0.0	2.0	0.0000000000	False
versus n minus ten	0.0	0.0	0.0	4.0	0.0000000000	False
split or a ten	0.0	0.0	0.0	2.0	0.0000000000	False
ten versus n minus	0.0	0.0	0.0	2.0	0.0000000000	False
element rite the probability	0.0	0.0	0.0	2.0	0.0000000000	False
tool for designing algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
randomize the partition procedure	0.0	0.0	0.0	2.0	0.0000000000	False
partition procedure and call	0.0	0.0	0.0	2.0	0.0000000000	False
call it randomized partition	0.0	0.0	0.0	2.0	0.0000000000	False
partition the a array	0.0	0.0	0.0	2.0	0.0000000000	False
sub array between locations	0.0	0.0	0.0	2.0	0.0000000000	False
generates a random number	0.0	0.0	0.0	2.0	0.0000000000	False
lets say that number	0.0	0.0	0.0	4.0	0.0000000000	False
procedure if you recall	0.0	0.0	0.0	2.0	0.0000000000	False
taking the last element	0.0	0.0	1.99847638395	6.0	0.0000000000	False
exchange the pivot element	0.0	0.0	0.0	2.0	0.0000000000	False
call my partition procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedure the same partition	0.0	0.0	0.0	2.0	0.0000000000	False
sort do now randomized	0.0	0.0	0.0	2.0	0.0000000000	False
calling partition it calls	0.0	0.0	0.0	2.0	0.0000000000	False
partition it calls randomized	0.0	0.0	0.0	2.0	0.0000000000	False
randomized partition the rest	0.0	0.0	0.0	2.0	0.0000000000	False
pivot we just pick	0.0	0.0	0.0	2.0	0.0000000000	False
difference between a random	0.0	0.0	0.0	2.0	0.0000000000	False
input which is lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets say increasing order	0.0	0.0	0.0	2.0	0.0000000000	False
element we are picking	0.0	0.0	0.0	2.0	0.0000000000	False
random element to partition	0.0	0.0	0.0	4.0	0.0000000000	False
partition when i pick	0.0	0.0	0.0	2.0	0.0000000000	False
sorted sequence as input	0.0	0.0	0.0	2.0	0.0000000000	False
squared time in fact	0.0	0.0	0.0	2.0	0.0000000000	False
run the same algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm and it takes	0.0	0.0	0.0	4.0	0.0000000000	False
depends upon what random	0.0	0.0	0.0	2.0	0.0000000000	False
random numbers are selected	0.0	0.0	0.0	2.0	0.0000000000	False
selected and those random	0.0	0.0	0.0	2.0	0.0000000000	False
random numbers selected decide	0.0	0.0	0.0	2.0	0.0000000000	False
selected decide the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
pivot and the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
bad ones fairly skewed	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of random numbers	0.0	0.0	0.0	2.0	0.0000000000	False
random numbers is generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated in some sense	0.0	0.0	0.0	2.0	0.0000000000	False
input we will run	0.0	0.0	0.0	2.0	0.0000000000	False
run the algorithm today	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm today and tomorrow	0.0	0.0	0.0	2.0	0.0000000000	False
expected time for sorting	0.0	0.0	0.0	2.0	0.0000000000	False
sorting that specific input	0.0	0.0	0.0	2.0	0.0000000000	False
denote the expected number	0.0	0.0	0.0	2.0	0.0000000000	False
expected number of comparisons	0.0	0.0	2.99796851193	8.0	0.4166666667	False
number of comparisons required	0.0	0.0	3.99746063992	10.0	0.3738317757	False
required by quick sort	0.0	0.0	0.0	4.0	0.0000000000	False
comparisons required to sort	0.0	0.0	0.0	2.0	0.0000000000	False
depend upon the depend	0.0	0.0	0.0	2.0	0.0000000000	False
numbers you have depend	0.0	0.0	0.0	2.0	0.0000000000	False
sort does quick sort	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort first partitions	0.0	0.0	0.0	2.0	0.0000000000	False
matter what the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
require the same number	0.0	0.0	0.0	2.0	0.0000000000	False
process as every number	0.0	0.0	0.0	2.0	0.0000000000	False
compared against the pivot	0.0	0.0	0.0	4.0	0.0000000000	False
pivot yes every number	0.0	0.0	0.0	2.0	0.0000000000	False
put on one side	0.0	0.0	0.0	2.0	0.0000000000	False
side how many elements	0.0	0.0	0.0	2.0	0.0000000000	False
side and n minus	0.0	0.0	0.0	2.0	0.0000000000	False
element is already lets	0.0	0.0	0.0	2.0	0.0000000000	False
sort those i minus	0.0	0.0	0.0	4.0	0.0000000000	False
sort those n minus	0.0	0.0	0.0	2.0	0.0000000000	False
elements how much expected	0.0	0.0	0.0	2.0	0.0000000000	False
taking to quick sort	0.0	0.0	5.99847638395	6.0	0.0000000000	False
minus n one elements	0.0	0.0	0.0	2.0	0.0000000000	False
sort the n minus	0.0	0.0	0.0	2.0	0.0000000000	False
fact that the pivot	0.0	0.0	0.0	2.0	0.0000000000	False
thirteen plus n minus	0.0	0.0	0.0	2.0	0.0000000000	False
basically then the sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum rite this quantity	0.0	0.0	0.0	2.0	0.0000000000	False
summed over all choices	0.0	0.0	0.0	2.0	0.0000000000	False
picked with the probability	0.0	0.0	0.0	2.0	0.0000000000	False
instance just to give	0.0	0.0	0.0	2.0	0.0000000000	False
give you an examples	0.0	0.0	0.0	2.0	0.0000000000	False
equally likely each occurs	0.0	0.0	0.0	2.0	0.0000000000	False
occurs with the probability	0.0	0.0	0.0	2.0	0.0000000000	False
two with the probability	0.0	0.0	0.0	2.0	0.0000000000	False
dice so each appears	0.0	0.0	0.0	2.0	0.0000000000	False
expected value so expectation	0.0	0.0	0.0	2.0	0.0000000000	False
variable is the number	0.0	0.0	0.0	4.0	0.0000000000	False
number on the dice	0.0	0.0	0.0	2.0	0.0000000000	False
dice rite this random	0.0	0.0	0.0	2.0	0.0000000000	False
random variable lets call	0.0	0.0	0.0	2.0	0.0000000000	False
takes six different values	0.0	0.0	0.0	2.0	0.0000000000	False
value take the probability	0.0	0.0	0.0	2.0	0.0000000000	False
dice and keep recording	0.0	0.0	0.0	2.0	0.0000000000	False
dice one billion times	0.0	0.0	0.0	2.0	0.0000000000	False
billion by six times	0.0	0.0	0.0	2.0	0.0000000000	False
probability means the probability	0.0	0.0	0.0	2.0	0.0000000000	False
experiment sufficiently many times	0.0	0.0	0.0	2.0	0.0000000000	False
times the this fraction	0.0	0.0	0.0	2.0	0.0000000000	False
fraction of the times	0.0	0.0	0.0	2.0	0.0000000000	False
sum of the outcomes	0.0	0.0	0.0	2.0	0.0000000000	False
sum how many times	0.0	0.0	0.0	2.0	0.0000000000	False
probability of the event	0.0	0.0	0.0	2.0	0.0000000000	False
written it as probability	0.0	0.0	0.0	2.0	0.0000000000	False
variable takes the value	0.0	0.0	0.0	2.0	0.0000000000	False
value of the random	0.0	0.0	0.0	2.0	0.0000000000	False
variable plus the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability that it takes	0.0	0.0	0.0	4.0	0.0000000000	False
value two so probability	0.0	0.0	0.0	2.0	0.0000000000	False
random variable is taking	0.0	0.0	0.0	2.0	0.0000000000	False
set of discrete values	0.0	0.0	0.0	2.0	0.0000000000	False
takes the value times	0.0	0.0	0.0	2.0	0.0000000000	False
value times the value	0.0	0.0	0.0	2.0	0.0000000000	False
times the value summed	0.0	0.0	0.0	4.0	0.0000000000	False
choices is the expectation	0.0	0.0	0.0	2.0	0.0000000000	False
expectation of the random	0.0	0.0	0.0	2.0	0.0000000000	False
revert to our slides	0.0	0.0	0.0	2.0	0.0000000000	False
value with the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability times the value	0.0	0.0	0.0	2.0	0.0000000000	False
part of the sum	0.0	0.0	0.0	2.0	0.0000000000	False
summing it n times	0.0	0.0	0.0	2.0	0.0000000000	False
times and then dividing	0.0	0.0	0.0	2.0	0.0000000000	False
recurrence for the expected	0.0	0.0	0.0	2.0	0.0000000000	False
comparisons required to insert	0.0	0.0	0.0	2.0	0.0000000000	False
insert a randomly chosen	0.0	0.0	0.0	2.0	0.0000000000	False
permutation of n elements	0.0	0.0	0.0	2.0	0.0000000000	False
last class we solved	0.0	0.0	0.0	2.0	0.0000000000	False
recurrence and we showed	0.0	0.0	0.0	2.0	0.0000000000	False
solution is n log	0.0	0.0	0.0	2.0	0.0000000000	False
log n hence expected	0.0	0.0	0.0	2.0	0.0000000000	False
comparisons required by randomized	0.0	0.0	0.0	2.0	0.0000000000	False
sort is n log	0.0	0.0	0.0	2.0	0.0000000000	False
recurrence ya we solved	0.0	0.0	0.0	2.0	0.0000000000	False
questions till this point	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort so lets	0.0	0.0	0.0	2.0	0.0000000000	False
quick sort worst case	0.0	0.0	0.0	2.0	0.0000000000	False
log n we dint	0.0	0.0	0.0	2.0	0.0000000000	False
intuitively you can understand	0.0	0.0	0.0	2.0	0.0000000000	False
case time n log	0.0	0.0	0.0	2.0	0.0000000000	False
element i was inserting	0.0	0.0	0.0	4.0	0.0000000000	False
depends upon the numbers	0.0	0.0	0.0	2.0	0.0000000000	False
random numbers were generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated rite the running	0.0	0.0	0.0	2.0	0.0000000000	False
give you i fix	0.0	0.0	0.0	2.0	0.0000000000	False
tomorrow because the random	0.0	0.0	0.0	2.0	0.0000000000	False
today we will compute	0.0	0.0	0.0	2.0	0.0000000000	False
compute what the value	0.0	0.0	0.0	4.0	0.0000000000	False
tomorrow we will compute	0.0	0.0	0.0	2.0	0.0000000000	False
input and i compute	0.0	0.0	0.0	2.0	0.0000000000	False
matter what the input	0.0	0.0	0.0	2.0	0.0000000000	False
input is your expected	0.0	0.0	0.0	2.0	0.0000000000	False
expected time is turning	0.0	0.0	0.0	2.0	0.0000000000	False
running time would depend	0.0	0.0	0.0	4.0	0.0000000000	False
depend upon what input	0.0	0.0	0.0	2.0	0.0000000000	False
randomly pick my pivot	0.0	0.0	0.0	2.0	0.0000000000	False
pick my pivot element	0.0	0.0	0.0	2.0	0.0000000000	False
depend upon my input	0.0	0.0	0.0	2.0	0.0000000000	False
input is it depends	0.0	0.0	0.0	2.0	0.0000000000	False
expectation is will give	0.0	0.0	0.0	2.0	0.0000000000	False
give me a running	0.0	0.0	0.0	2.0	0.0000000000	False
nt make any fix	0.0	0.0	0.0	0.0	0.0000000000	False
make any fix element	0.0	0.0	0.0	2.0	0.0000000000	False
independent upon the input	0.0	0.0	0.0	4.0	0.0000000000	False
sequence rite no matter	0.0	0.0	0.0	2.0	0.0000000000	False
expectation is n log	0.0	0.0	0.0	2.0	0.0000000000	False
log n which quit	0.0	0.0	0.0	2.0	0.0000000000	False
quit often will turn	0.0	0.0	0.0	2.0	0.0000000000	False
independent of the input	0.0	0.0	0.0	2.0	0.0000000000	False
input then this kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind we are making	0.0	0.0	0.0	2.0	0.0000000000	False
makes sense to design	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for those kind	0.0	0.0	0.0	2.0	0.0000000000	False
sequence or specific times	0.0	0.0	0.0	2.0	0.0000000000	False
specific times of input	0.0	0.0	0.0	2.0	0.0000000000	False
class for binary search	0.0	0.0	0.0	2.0	0.0000000000	False
today or you run	0.0	0.0	0.0	2.0	0.0000000000	False
random choices being made	0.0	0.0	0.0	2.0	0.0000000000	False
matter when you run	0.0	0.0	0.0	2.0	0.0000000000	False
average over all input	0.0	0.0	0.0	2.0	0.0000000000	False
call an average case	0.0	0.0	0.0	2.0	0.0000000000	False
analysis rite we looked	0.0	0.0	0.0	2.0	0.0000000000	False
inputs possible we looked	0.0	0.0	0.0	2.0	0.0000000000	False
randomized algorithm our algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
taking different times depending	0.0	0.0	0.0	2.0	0.0000000000	False
numbers were and today	0.0	0.0	0.0	2.0	0.0000000000	False
today we were taking	0.0	0.0	0.0	2.0	0.0000000000	False
average over the random	0.0	0.0	0.0	2.0	0.0000000000	False
end today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
analyze the the expected	0.0	0.0	0.0	2.0	0.0000000000	False
analysis for randomized quick	0.0	0.0	0.0	2.0	0.0000000000	False
data structures and algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms dr naveen garg	0.0	0.0	0.0	2.0	0.0000000000	False
garg dept of computer	0.0	0.0	0.0	2.0	0.0000000000	False
dept of computer science	0.0	0.0	0.0	2.0	0.0000000000	False
computer science and engineering	0.0	0.0	0.0	2.0	0.0000000000	False
science and engineering iit	0.0	0.0	0.0	2.0	0.0000000000	False
engineering iit delhi lecture	0.0	0.0	0.0	2.0	0.0000000000	False
talking about avl trees	0.0	0.0	0.0	2.0	0.0000000000	False
binary search trees data	0.0	0.0	0.0	2.0	0.0000000000	False
search trees data structure	0.0	0.0	0.0	2.0	0.0000000000	False
structure now one problem	0.0	0.0	0.0	2.0	0.0000000000	False
tree if you recall	0.0	0.0	0.0	2.0	0.0000000000	False
operations of insertion deletion	0.0	0.0	0.0	2.0	0.0000000000	False
proportional to the height	0.0	0.0	0.0	4.0	0.0000000000	False
height of the tree	0.0	0.0	8.98934169279	34.0	0.3809523810	True
bad as order end	0.0	0.0	0.0	2.0	0.0000000000	False
end or n minus	0.0	0.0	0.0	2.0	0.0000000000	False
data structure call avl	0.0	0.0	0.0	2.0	0.0000000000	False
structure call avl trees	0.0	0.0	0.0	2.0	0.0000000000	False
ignore this white spots	0.0	0.0	0.0	2.0	0.0000000000	False
spots that are showing	0.0	0.0	0.0	2.0	0.0000000000	False
keys inside the nodes	0.0	0.0	0.0	2.0	0.0000000000	False
nodes of the keys	0.0	0.0	0.0	2.0	0.0000000000	False
left of the root	0.0	0.0	0.0	4.0	0.0000000000	False
node is the height	0.0	0.0	0.0	4.0	0.0000000000	False
height of a node	0.0	0.0	2.99811912226	6.0	0.0000000000	False
define this turn end	0.0	0.0	0.0	2.0	0.0000000000	False
height of the sub	0.0	0.0	0.0	4.0	0.0000000000	False
rooted at that node	0.0	0.0	2.99811912226	6.0	0.0000000000	False
rooted at this node	0.0	0.0	0.0	2.0	0.0000000000	False
classes we have define	0.0	0.0	0.0	2.0	0.0000000000	False
call this is height	0.0	0.0	0.0	2.0	0.0000000000	False
node just one node	0.0	0.0	0.0	2.0	0.0000000000	False
calling it this sub	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree has height	0.0	0.0	7.99435736677	18.0	0.3834886818	False
height two so level	0.0	0.0	0.0	2.0	0.0000000000	False
two so level numbers	0.0	0.0	0.0	2.0	0.0000000000	False
numbers are not beginning	0.0	0.0	0.0	2.0	0.0000000000	False
two this has height	0.0	0.0	0.0	2.0	0.0000000000	False
height this sub tree	0.0	0.0	0.0	4.0	0.0000000000	False
entire tree has height	0.0	0.0	0.0	2.0	0.0000000000	False
call this as height	0.0	0.0	0.0	2.0	0.0000000000	False
purpose of the avl	0.0	0.0	0.0	2.0	0.0000000000	False
height of that node	0.0	0.0	0.0	2.0	0.0000000000	False
height of the node	0.0	0.0	0.0	2.0	0.0000000000	True
leaves will have height	0.0	0.0	0.0	4.0	0.0000000000	False
height one the parents	0.0	0.0	0.0	2.0	0.0000000000	False
parents of the leaves	0.0	0.0	0.0	2.0	0.0000000000	False
trees called avl tree	0.0	0.0	0.0	2.0	0.0000000000	False
balanced what is height	0.0	0.0	0.0	2.0	0.0000000000	False
children than the difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference in their height	0.0	0.0	0.0	4.0	0.0000000000	False
case with this node	0.0	0.0	0.0	2.0	0.0000000000	False
node its two children	0.0	0.0	0.0	2.0	0.0000000000	False
node has the difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference the left subtree	0.0	0.0	0.0	2.0	0.0000000000	False
height than the right	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree the left	0.0	0.0	0.0	2.0	0.0000000000	False
tree the left sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree has the height	0.0	0.0	0.0	2.0	0.0000000000	False
two and the right	0.0	0.0	0.0	2.0	0.0000000000	False
definition of an avl	0.0	0.0	0.0	2.0	0.0000000000	False
true for every node	0.0	0.0	0.0	2.0	0.0000000000	False
node of the tree	0.0	0.0	0.0	4.0	0.0000000000	False
heights of the children	0.0	0.0	0.0	2.0	0.0000000000	False
nt make any incidence	0.0	0.0	0.0	0.0	0.0000000000	False
talk up the height	0.0	0.0	0.0	2.0	0.0000000000	False
node the right sub	0.0	0.0	0.0	2.0	0.0000000000	False
height one and sis	0.0	0.0	0.0	2.0	0.0000000000	False
sis the left sub	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree is missing	0.0	0.0	0.0	2.0	0.0000000000	False
made this change today	0.0	0.0	0.0	2.0	0.0000000000	False
change today right absence	0.0	0.0	0.0	2.0	0.0000000000	False
absence of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree i will note	0.0	0.0	0.0	2.0	0.0000000000	False
note i will call	0.0	0.0	0.0	2.0	0.0000000000	False
height was the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree i kept put	0.0	0.0	0.0	2.0	0.0000000000	False
equal to n minus	0.0	0.0	0.0	2.0	0.0000000000	False
write is this node	0.0	0.0	0.0	2.0	0.0000000000	False
balanced is this node	0.0	0.0	0.0	2.0	0.0000000000	False
right subtree has height	0.0	0.0	0.0	2.0	0.0000000000	False
two and the left	0.0	0.0	0.0	2.0	0.0000000000	False
height balanced properties violated	0.0	0.0	0.0	4.0	0.0000000000	False
trees as avl trees	0.0	0.0	0.0	4.0	0.0000000000	False
lets trying figure outs	0.0	0.0	0.0	2.0	0.0000000000	False
lets trying the figure	0.0	0.0	0.0	2.0	0.0000000000	False
height of an avl	0.0	0.0	3.99686520376	10.0	0.5333333333	False
tree of n nodes	0.0	0.0	0.0	2.0	0.0000000000	False
bad as n minus	0.0	0.0	0.0	2.0	0.0000000000	False
height of the avl	0.0	0.0	0.0	2.0	0.0000000000	False
small slightly different argument	0.0	0.0	0.0	2.0	0.0000000000	False
avl tree of height	0.0	0.0	19.989968652	32.0	0.2162162162	False
smallest number of nodes	0.0	0.0	0.0	4.0	0.0000000000	False
minimum number of nodes	0.0	0.0	5.99561128527	14.0	0.4838012959	False
nodes in an avl	0.0	0.0	3.99811912226	6.0	0.0000000000	False
height h and lets	0.0	0.0	0.0	4.0	0.0000000000	False
avl tree of heritage	0.0	0.0	0.0	2.0	0.0000000000	False
right if you recall	0.0	0.0	0.0	2.0	0.0000000000	False
recall a binary search	0.0	0.0	0.0	2.0	0.0000000000	False
tree on h nodes	0.0	0.0	0.0	2.0	0.0000000000	False
tree of a height	0.0	0.0	0.0	2.0	0.0000000000	False
large number of nodes	0.0	0.0	0.0	2.0	0.0000000000	False
two rooted one node	0.0	0.0	0.0	2.0	0.0000000000	False
minimum i am counting	0.0	0.0	0.0	2.0	0.0000000000	False
end end two equals	0.0	0.0	0.0	2.0	0.0000000000	False
two the minimum number	0.0	0.0	0.0	2.0	0.0000000000	False
two in an avl	0.0	0.0	0.0	2.0	0.0000000000	False
side and an avl	0.0	0.0	0.0	2.0	0.0000000000	False
side why h minus	0.0	0.0	0.0	2.0	0.0000000000	False
children can have height	0.0	0.0	0.0	2.0	0.0000000000	False
height only h minus	0.0	0.0	0.0	2.0	0.0000000000	False
two or h minus	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree have height	0.0	0.0	0.0	2.0	0.0000000000	False
two why minimum number	0.0	0.0	0.0	2.0	0.0000000000	False
nodes so at tree	0.0	0.0	0.0	2.0	0.0000000000	False
smaller number of nodes	0.0	0.0	0.0	2.0	0.0000000000	False
tree have h minus	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the tree	0.0	0.0	0.0	4.0	0.0000000000	False
nodes in a tree	0.0	0.0	0.0	4.0	0.0000000000	False
two the h minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
small as little number	0.0	0.0	0.0	2.0	0.0000000000	False
minus two sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
nodes sorry the number	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the left	0.0	0.0	0.0	2.0	0.0000000000	False
minus one the number	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the right	0.0	0.0	0.0	2.0	0.0000000000	False
relationship look like right	0.0	0.0	0.0	2.0	0.0000000000	False
tree grows the number	0.0	0.0	0.0	2.0	0.0000000000	False
nodes can not reduce	0.0	0.0	0.0	2.0	0.0000000000	False
largest as h minus	0.0	0.0	0.0	2.0	0.0000000000	False
simple thing to solve	0.0	0.0	0.0	2.0	0.0000000000	False
two time two times	0.0	0.0	0.0	2.0	0.0000000000	False
four so this implies	0.0	0.0	0.0	2.0	0.0000000000	False
implies this entire thing	0.0	0.0	0.0	2.0	0.0000000000	False
minus four which implies	0.0	0.0	0.0	2.0	0.0000000000	False
great okay so suppose	0.0	0.0	0.0	2.0	0.0000000000	False
quantity is an integer	0.0	0.0	0.0	2.0	0.0000000000	False
avl tree has height	0.0	0.0	0.0	2.0	0.0000000000	False
maximum number of nodes	0.0	0.0	0.0	2.0	0.0000000000	False
tree on n nodes	0.0	0.0	5.99686520376	10.0	0.3782505910	False
avl tree whose height	0.0	0.0	0.0	2.0	0.0000000000	False
height on n nodes	0.0	0.0	0.0	2.0	0.0000000000	False
height at most login	0.0	0.0	0.0	2.0	0.0000000000	False
follow are you confused	0.0	0.0	0.0	2.0	0.0000000000	False
argued after taking algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
function do nt confused	0.0	0.0	0.0	0.0	0.0000000000	False
nodes you can replace	0.0	0.0	0.0	2.0	0.0000000000	False
call it m nodes	0.0	0.0	0.0	2.0	0.0000000000	False
equals big o log	0.0	0.0	0.0	2.0	0.0000000000	False
height this was number	0.0	0.0	0.0	2.0	0.0000000000	False
tree on m nodes	0.0	0.0	0.0	2.0	0.0000000000	False
times the two times	0.0	0.0	0.0	2.0	0.0000000000	False
log of the number	0.0	0.0	0.0	2.0	0.0000000000	False
question to this point	0.0	0.0	0.0	2.0	0.0000000000	False
tree will have height	0.0	0.0	0.0	4.0	0.0000000000	False
dense and every thing	0.0	0.0	0.0	2.0	0.0000000000	False
lets try and solve	0.0	0.0	0.0	2.0	0.0000000000	False
show you how recurrence	0.0	0.0	0.0	2.0	0.0000000000	False
bound on the height	0.0	0.0	0.0	2.0	0.0000000000	False
right now two times	0.0	0.0	0.0	2.0	0.0000000000	False
two to the half	0.0	0.0	0.0	2.0	0.0000000000	False
prove this by induction	0.0	0.0	0.0	2.0	0.0000000000	False
proving a certain statement	0.0	0.0	0.0	2.0	0.0000000000	False
statement without actually knowing	0.0	0.0	0.0	2.0	0.0000000000	False
base case h equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals one h equals	0.0	0.0	0.0	2.0	0.0000000000	False
minute so i assume	0.0	0.0	0.0	2.0	0.0000000000	False
assume to i made	0.0	0.0	0.0	2.0	0.0000000000	False
back this base case	0.0	0.0	0.0	2.0	0.0000000000	False
height of a tree	0.0	0.0	0.0	2.0	0.0000000000	False
back to this suppose	0.0	0.0	0.0	2.0	0.0000000000	False
lets try and prove	0.0	0.0	0.0	2.0	0.0000000000	False
back to this base	0.0	0.0	0.0	2.0	0.0000000000	False
case in a minute	0.0	0.0	0.0	2.0	0.0000000000	False
right i just ignore	0.0	0.0	0.0	2.0	0.0000000000	False
show that this quantity	0.0	0.0	0.0	2.0	0.0000000000	False
square minus c minus	0.0	0.0	0.0	2.0	0.0000000000	False
out c which satisfy	0.0	0.0	0.0	2.0	0.0000000000	False
equation this has roots	0.0	0.0	0.0	2.0	0.0000000000	False
roots right one minus	0.0	0.0	0.0	2.0	0.0000000000	False
right one minus root	0.0	0.0	0.0	2.0	0.0000000000	False
right but i wont	0.0	0.0	0.0	2.0	0.0000000000	False
mistake we have made	0.0	0.0	0.0	2.0	0.0000000000	False
made so one thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing is a base	0.0	0.0	0.0	2.0	0.0000000000	False
case have not worked	0.0	0.0	0.0	2.0	0.0000000000	False
right so i guess	0.0	0.0	0.0	2.0	0.0000000000	False
wrong thing to pick	0.0	0.0	0.0	2.0	0.0000000000	False
right so induction hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
make a different right	0.0	0.0	0.0	4.0	0.0000000000	False
precisely i am dividing	0.0	0.0	0.0	2.0	0.0000000000	False
satisfied if h equals	0.0	0.0	0.0	2.0	0.0000000000	False
require that the induction	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis is h minus	0.0	0.0	0.0	2.0	0.0000000000	False
two plus ck minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one h minus	0.0	0.0	0.0	2.0	0.0000000000	False
make that small correction	0.0	0.0	0.0	2.0	0.0000000000	False
nodes the same argument	0.0	0.0	0.0	2.0	0.0000000000	False
equal to one point	0.0	0.0	0.0	2.0	0.0000000000	False
log of both sides	0.0	0.0	0.0	2.0	0.0000000000	False
log base one point	0.0	0.0	0.0	2.0	0.0000000000	False
log i am taking	0.0	0.0	0.0	2.0	0.0000000000	False
log to the base	0.0	0.0	0.0	2.0	0.0000000000	False
implies h equals log	0.0	0.0	0.0	2.0	0.0000000000	False
log of one point	0.0	0.0	0.0	2.0	0.0000000000	False
equation does not satisfy	0.0	0.0	0.0	2.0	0.0000000000	False
great it also works	0.0	0.0	0.0	2.0	0.0000000000	False
works for n equals	0.0	0.0	0.0	2.0	0.0000000000	False
shown you two ways	0.0	0.0	0.0	2.0	0.0000000000	False
two ways of solving	0.0	0.0	0.0	2.0	0.0000000000	False
solving this same recurrence	0.0	0.0	0.0	2.0	0.0000000000	False
earlier we had root	0.0	0.0	0.0	2.0	0.0000000000	False
root two one point	0.0	0.0	0.0	2.0	0.0000000000	False
technique okay so lets	0.0	0.0	0.0	2.0	0.0000000000	False
structure of an avl	0.0	0.0	0.0	4.0	0.0000000000	False
leaf of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
closest to the root	0.0	0.0	2.99686520376	10.0	0.3285420945	False
leaves suppose this leaf	0.0	0.0	0.0	2.0	0.0000000000	False
leaf is at level	0.0	0.0	2.99811912226	6.0	0.0000000000	False
show that the height	0.0	0.0	0.0	2.0	0.0000000000	False
clear no this requires	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in that tree	0.0	0.0	0.0	2.0	0.0000000000	False
leaf of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
suppose its this leaf	0.0	0.0	0.0	2.0	0.0000000000	False
class for avl tree	0.0	0.0	0.0	2.0	0.0000000000	False
lets say we work	0.0	0.0	0.0	2.0	0.0000000000	False
work with level starting	0.0	0.0	0.0	2.0	0.0000000000	False
make a big difference	0.0	0.0	0.0	2.0	0.0000000000	False
lets say we start	0.0	0.0	0.0	2.0	0.0000000000	False
prove that the height	0.0	0.0	0.0	4.0	0.0000000000	False
height of this tree	0.0	0.0	0.0	4.0	0.0000000000	False
right from this node	0.0	0.0	0.0	2.0	0.0000000000	False
out from this node	0.0	0.0	0.0	2.0	0.0000000000	False
root level zero level	0.0	0.0	0.0	2.0	0.0000000000	False
height of this node	0.0	0.0	2.99811912226	6.0	0.0000000000	False
means that this sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree can have height	0.0	0.0	0.0	2.0	0.0000000000	False
node this sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
height that this sub	0.0	0.0	0.0	2.0	0.0000000000	False
maximum height this sub	0.0	0.0	0.0	2.0	0.0000000000	False
picture then the height	0.0	0.0	0.0	2.0	0.0000000000	False
argument so which means	0.0	0.0	0.0	2.0	0.0000000000	False
means that this entire	0.0	0.0	0.0	2.0	0.0000000000	False
leaf was at level	0.0	0.0	0.0	2.0	0.0000000000	False
property of avl tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree yes you understand	0.0	0.0	0.0	2.0	0.0000000000	False
leafs at any level	0.0	0.0	0.0	2.0	0.0000000000	False
level k that height	0.0	0.0	0.0	2.0	0.0000000000	False
leaf at this height	0.0	0.0	0.0	2.0	0.0000000000	False
basically all over leafs	0.0	0.0	0.0	2.0	0.0000000000	False
part only this band	0.0	0.0	0.0	2.0	0.0000000000	False
lets make another claim	0.0	0.0	0.0	2.0	0.0000000000	False
two have two children	0.0	0.0	0.0	2.0	0.0000000000	False
prove this by contradiction	0.0	0.0	0.0	2.0	0.0000000000	False
lets take some node	0.0	0.0	0.0	2.0	0.0000000000	False
right i have shown	0.0	0.0	0.0	2.0	0.0000000000	False
applied to any node	0.0	0.0	0.0	2.0	0.0000000000	False
leaf for that level	0.0	0.0	0.0	2.0	0.0000000000	False
child i have shown	0.0	0.0	0.0	2.0	0.0000000000	False
two children no right	0.0	0.0	0.0	2.0	0.0000000000	False
right but this guy	0.0	0.0	0.0	2.0	0.0000000000	False
child so sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree here has height	0.0	0.0	0.0	2.0	0.0000000000	False
imbalance at this problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem at this node	0.0	0.0	0.0	2.0	0.0000000000	False
node so the height	0.0	0.0	0.0	2.0	0.0000000000	False
balance property is violated	0.0	0.0	0.0	4.0	0.0000000000	False
node on this levels	0.0	0.0	0.0	2.0	0.0000000000	False
two children at level	0.0	0.0	0.0	2.0	0.0000000000	False
nodes only one child	0.0	0.0	0.0	2.0	0.0000000000	False
child that you understand	0.0	0.0	0.0	2.0	0.0000000000	False
understand right everyone understands	0.0	0.0	0.0	2.0	0.0000000000	False
child and that child	0.0	0.0	0.0	2.0	0.0000000000	False
child is this lets	0.0	0.0	0.0	2.0	0.0000000000	False
problem height balance property	0.0	0.0	0.0	2.0	0.0000000000	False
means that this guy	0.0	0.0	0.0	2.0	0.0000000000	False
children so which means	0.0	0.0	0.0	2.0	0.0000000000	False
level on that level	0.0	0.0	0.0	2.0	0.0000000000	False
two to the power	0.0	0.0	0.0	2.0	0.0000000000	False
nodes ya this implies	0.0	0.0	0.0	2.0	0.0000000000	False
height right lets substitute	0.0	0.0	0.0	2.0	0.0000000000	False
thing i am showing	0.0	0.0	0.0	2.0	0.0000000000	False
height h an avl	0.0	0.0	0.0	2.0	0.0000000000	False
nodes we had shown	0.0	0.0	0.0	2.0	0.0000000000	False
roughly the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
proved the sharper bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound i am coming	0.0	0.0	0.0	2.0	0.0000000000	False
back to the older	0.0	0.0	0.0	2.0	0.0000000000	False
older bound the point	0.0	0.0	0.0	2.0	0.0000000000	False
exponential number of nodes	0.0	0.0	0.0	2.0	0.0000000000	False
nodes it has number	0.0	0.0	0.0	2.0	0.0000000000	False
require solving the recurrence	0.0	0.0	0.0	2.0	0.0000000000	False
solving the recurrence relation	0.0	0.0	0.0	4.0	0.0000000000	False
two method we solving	0.0	0.0	0.0	2.0	0.0000000000	False
recurrence relation the shop	0.0	0.0	0.0	2.0	0.0000000000	False
avl tree is concerned	0.0	0.0	0.0	2.0	0.0000000000	False
concerned if the height	0.0	0.0	0.0	2.0	0.0000000000	False
give you an avl	0.0	0.0	0.0	2.0	0.0000000000	False
tree and n nodes	0.0	0.0	0.0	2.0	0.0000000000	False
root its atleast half	0.0	0.0	0.0	2.0	0.0000000000	False
atleast half the height	0.0	0.0	0.0	2.0	0.0000000000	False
nt require a proof	0.0	0.0	0.0	0.0	0.0000000000	False
two levels the avl	0.0	0.0	0.0	2.0	0.0000000000	False
levels the avl tree	0.0	0.0	0.0	2.0	0.0000000000	False
complete binary tree lets	0.0	0.0	0.0	2.0	0.0000000000	False
half of half levels	0.0	0.0	0.0	2.0	0.0000000000	False
right as its stars	0.0	0.0	0.0	2.0	0.0000000000	False
stars so it turn	0.0	0.0	0.0	2.0	0.0000000000	False
root at the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
edge by two levels	0.0	0.0	0.0	2.0	0.0000000000	False
two to the edge	0.0	0.0	0.0	2.0	0.0000000000	False
edge by two nodes	0.0	0.0	0.0	2.0	0.0000000000	False
means that the height	0.0	0.0	0.0	2.0	0.0000000000	False
log n two log	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the avl	0.0	0.0	0.0	2.0	0.0000000000	False
avl tree is atleast	0.0	0.0	0.0	2.0	0.0000000000	False
tree on h minus	0.0	0.0	0.0	2.0	0.0000000000	False
levels it has atleast	0.0	0.0	0.0	2.0	0.0000000000	False
mind about avl trees	0.0	0.0	0.0	2.0	0.0000000000	False
tree is in wise	0.0	0.0	0.0	2.0	0.0000000000	False
looked at this height	0.0	0.0	0.0	2.0	0.0000000000	False
search tree right forget	0.0	0.0	0.0	2.0	0.0000000000	False
right forget the height	0.0	0.0	0.0	2.0	0.0000000000	False
forget the height balance	0.0	0.0	0.0	2.0	0.0000000000	False
height order it height	0.0	0.0	0.0	2.0	0.0000000000	False
sense ok now suppose	0.0	0.0	0.0	2.0	0.0000000000	False
call this height balanced	0.0	0.0	0.0	2.0	0.0000000000	False
height balanced that treat	0.0	0.0	0.0	2.0	0.0000000000	False
treat to be height	0.0	0.0	0.0	2.0	0.0000000000	False
balanced if the difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference in the heights	0.0	0.0	0.0	2.0	0.0000000000	False
heights of its children	0.0	0.0	0.0	2.0	0.0000000000	False
node it can change	0.0	0.0	0.0	2.0	0.0000000000	False
height of some nodes	0.0	0.0	0.0	2.0	0.0000000000	False
consequence the height balanced	0.0	0.0	0.0	2.0	0.0000000000	False
property may get violated	0.0	0.0	0.0	2.0	0.0000000000	False
first step of insertion	0.0	0.0	0.0	2.0	0.0000000000	False
search for that element	0.0	0.0	0.0	2.0	0.0000000000	False
back to the route	0.0	0.0	0.0	2.0	0.0000000000	False
pointers ok and assume	0.0	0.0	0.0	2.0	0.0000000000	False
heights could have changed	0.0	0.0	0.0	2.0	0.0000000000	False
giving you the flavor	0.0	0.0	0.0	2.0	0.0000000000	False
nodes at whose height	0.0	0.0	0.0	2.0	0.0000000000	False
first place where height	0.0	0.0	0.0	2.0	0.0000000000	False
place where height change	0.0	0.0	0.0	2.0	0.0000000000	False
appears where height imbalance	0.0	0.0	0.0	2.0	0.0000000000	False
start from the node	0.0	0.0	0.0	2.0	0.0000000000	False
node where we inserted	0.0	0.0	0.0	2.0	0.0000000000	False
move up the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree towards the route	0.0	0.0	0.0	4.0	0.0000000000	False
basically keep going parent	0.0	0.0	0.0	2.0	0.0000000000	False
parent parent parent parent	0.0	0.0	0.0	2.0	0.0000000000	False
parent tell we hit	0.0	0.0	0.0	2.0	0.0000000000	False
path that we follow	0.0	0.0	0.0	2.0	0.0000000000	False
find the first node	0.0	0.0	0.0	2.0	0.0000000000	False
give you an idea	0.0	0.0	0.0	2.0	0.0000000000	False
right forget this empty	0.0	0.0	0.0	2.0	0.0000000000	False
forget this empty node	0.0	0.0	0.0	2.0	0.0000000000	False
avl tree height balance	0.0	0.0	0.0	2.0	0.0000000000	False
height balance is satisfied	0.0	0.0	0.0	2.0	0.0000000000	False
initially but now suppose	0.0	0.0	0.0	2.0	0.0000000000	False
right here and left	0.0	0.0	0.0	2.0	0.0000000000	False
route is the height	0.0	0.0	0.0	2.0	0.0000000000	False
two this is height	0.0	0.0	5.99811912226	6.0	0.0000000000	False
balance properties we call	0.0	0.0	0.0	2.0	0.0000000000	False
child of this node	0.0	0.0	0.0	2.0	0.0000000000	False
child on the path	0.0	0.0	0.0	2.0	0.0000000000	False
make it height balanced	0.0	0.0	0.0	2.0	0.0000000000	False
right all the things	0.0	0.0	0.0	2.0	0.0000000000	False
out of the window	0.0	0.0	0.0	2.0	0.0000000000	False
window if you leave	0.0	0.0	0.0	2.0	0.0000000000	False
tree like this right	0.0	0.0	0.0	2.0	0.0000000000	False
rotate do a kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of rotation operation	0.0	0.0	0.0	2.0	0.0000000000	False
move this up move	0.0	0.0	0.0	2.0	0.0000000000	False
understand how this rotation	0.0	0.0	0.0	2.0	0.0000000000	False
property is not violated	0.0	0.0	0.0	2.0	0.0000000000	False
violated at any node	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to draw	0.0	0.0	0.0	0.0	0.0000000000	False
picture and then figure	0.0	0.0	0.0	2.0	0.0000000000	False
figure out what rotation	0.0	0.0	0.0	2.0	0.0000000000	False
class look at insertion	0.0	0.0	0.0	2.0	0.0000000000	False
balance property is retained	0.0	0.0	0.0	2.0	0.0000000000	False
retained even after insertion	0.0	0.0	0.0	2.0	0.0000000000	False
class so in todays	0.0	0.0	0.0	2.0	0.0000000000	False
todays class we looked	0.0	0.0	0.0	2.0	0.0000000000	False
looked at avl trees	0.0	0.0	0.0	2.0	0.0000000000	False
avl trees are defined	0.0	0.0	0.0	2.0	0.0000000000	False
point six three today	0.0	0.0	0.0	2.0	0.0000000000	False
today right we spend	0.0	0.0	0.0	2.0	0.0000000000	False
lot of time figuring	0.0	0.0	0.0	2.0	0.0000000000	False
out how to solve	0.0	0.0	0.0	2.0	0.0000000000	False
solve that recurrence relations	0.0	0.0	0.0	4.0	0.0000000000	False
ways solving that recurrence	0.0	0.0	0.0	2.0	0.0000000000	False
property of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree which also proved	0.0	0.0	0.0	2.0	0.0000000000	False
proved a similar bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound and the height	0.0	0.0	0.0	2.0	0.0000000000	False
data structures and algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms dr naveen garg	0.0	0.0	0.0	2.0	0.0000000000	False
garg dept of computer	0.0	0.0	0.0	2.0	0.0000000000	False
dept of computer science	0.0	0.0	0.0	2.0	0.0000000000	False
computer science and engineering	0.0	0.0	0.0	2.0	0.0000000000	False
science and engineering iit	0.0	0.0	0.0	2.0	0.0000000000	False
engineering iit delhi lecture	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on avl trees	0.0	0.0	0.0	2.0	0.0000000000	False
insertion and deletion procedure	0.0	0.0	0.0	2.0	0.0000000000	True
procedure in an avl	0.0	0.0	0.0	2.0	0.0000000000	False
begin with the insertion	0.0	0.0	0.0	2.0	0.0000000000	False
insert a key right	0.0	0.0	0.0	2.0	0.0000000000	False
right but so whats	0.0	0.0	0.0	2.0	0.0000000000	False
tree first you find	0.0	0.0	0.0	2.0	0.0000000000	False
key is the node	0.0	0.0	0.0	2.0	0.0000000000	False
consequence of this insertion	0.0	0.0	0.0	4.0	0.0000000000	False
nt remain an avl	0.0	0.0	0.0	0.0	0.0000000000	False
remain an avl tree	0.0	0.0	0.0	2.0	0.0000000000	False
balance property is violated	0.0	0.0	0.0	2.0	0.0000000000	False
change as a result	0.0	0.0	0.0	2.0	0.0000000000	False
result of this insertion	0.0	0.0	0.0	4.0	0.0000000000	False
height of the node	0.0	0.0	0.0	2.0	0.0000000000	True
node as the height	0.0	0.0	0.0	2.0	0.0000000000	False
height of the sub	0.0	0.0	0.0	4.0	0.0000000000	False
rooted at that node	0.0	0.0	0.0	2.0	0.0000000000	False
insert a particular node	0.0	0.0	0.0	2.0	0.0000000000	False
ancestors of that node	0.0	0.0	0.0	2.0	0.0000000000	False
node would whose sub	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree has changed	0.0	0.0	0.0	2.0	0.0000000000	False
node its sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
flow so the ancestor	0.0	0.0	0.0	2.0	0.0000000000	False
ancestor of this node	0.0	0.0	2.99830508475	6.0	0.0000000000	False
right because we add	0.0	0.0	0.0	2.0	0.0000000000	False
increase as a consequence	0.0	0.0	0.0	2.0	0.0000000000	False
insertion cause the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree to become imbalance	0.0	0.0	0.0	2.0	0.0000000000	False
unbalanced then some ancestor	0.0	0.0	0.0	2.0	0.0000000000	False
culprit is the place	0.0	0.0	0.0	2.0	0.0000000000	False
height balance problem height	0.0	0.0	0.0	2.0	0.0000000000	False
balance problem height problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem height problem means	0.0	0.0	0.0	2.0	0.0000000000	False
height imbalanced height imbalance	0.0	0.0	0.0	2.0	0.0000000000	False
imbalanced height imbalance means	0.0	0.0	0.0	2.0	0.0000000000	False
imbalance means one left	0.0	0.0	0.0	2.0	0.0000000000	False
means one left sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree and right sub	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree the difference	0.0	0.0	0.0	2.0	0.0000000000	False
travel up the tree	0.0	0.0	1.99830508475	6.0	0.0000000000	False
tree from this node	0.0	0.0	0.0	2.0	0.0000000000	False
pin the parent pointer	0.0	0.0	0.0	2.0	0.0000000000	False
find the first node	0.0	0.0	0.0	4.0	0.0000000000	False
node x whose grandparent	0.0	0.0	0.0	2.0	0.0000000000	False
node z whose grandparent	0.0	0.0	0.0	2.0	0.0000000000	False
grandchild that we travels	0.0	0.0	0.0	2.0	0.0000000000	False
grandchild on the path	0.0	0.0	0.0	4.0	0.0000000000	False
right because the node	0.0	0.0	0.0	2.0	0.0000000000	False
insert let say fifty	0.0	0.0	0.0	2.0	0.0000000000	False
problem actually this tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree is not height	0.0	0.0	0.0	2.0	0.0000000000	False
changed earlier this node	0.0	0.0	0.0	2.0	0.0000000000	False
node had the height	0.0	0.0	0.0	2.0	0.0000000000	False
node on this path	0.0	0.0	0.0	4.0	0.0000000000	False
imbalanced this is imbalanced	0.0	0.0	0.0	2.0	0.0000000000	False
imbalanced fifty no difference	0.0	0.0	0.0	2.0	0.0000000000	False
imbalanced yes right difference	0.0	0.0	0.0	2.0	0.0000000000	False
right difference of height	0.0	0.0	0.0	2.0	0.0000000000	False
height of this node	0.0	0.0	0.0	4.0	0.0000000000	False
node is not changed	0.0	0.0	0.0	2.0	0.0000000000	False
understand why the heights	0.0	0.0	0.0	2.0	0.0000000000	False
heights of these nodes	0.0	0.0	0.0	4.0	0.0000000000	False
right so this node	0.0	0.0	0.0	2.0	0.0000000000	False
path and the parent	0.0	0.0	0.0	2.0	0.0000000000	False
find the first place	0.0	0.0	1.99830508475	6.0	0.0000000000	False
place where the imbalance	0.0	0.0	3.99830508475	6.0	0.0000000000	False
imbalance happens lets call	0.0	0.0	0.0	2.0	0.0000000000	False
grandchild of z grandchild	0.0	0.0	0.0	2.0	0.0000000000	False
means parent sorry childs	0.0	0.0	0.0	2.0	0.0000000000	False
parent sorry childs child	0.0	0.0	0.0	2.0	0.0000000000	False
childs child so child	0.0	0.0	0.0	2.0	0.0000000000	False
tree so to rebalance	0.0	0.0	0.0	2.0	0.0000000000	False
rebalance this sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree sub tree rooted	0.0	0.0	0.0	2.0	0.0000000000	False
happen after the rebalance	0.0	0.0	0.0	2.0	0.0000000000	False
change to this sub	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree which sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree which sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree this sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree this sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
nodes forty eight fifty	0.0	0.0	0.0	2.0	0.0000000000	False
forty eight fifty fifty	0.0	0.0	0.0	2.0	0.0000000000	False
fifty fifty four sixty	0.0	0.0	0.0	2.0	0.0000000000	False
four sixty two seventy	0.0	0.0	0.0	2.0	0.0000000000	False
two seventy eight eighty	0.0	0.0	0.0	2.0	0.0000000000	False
organized in the manner	0.0	0.0	0.0	2.0	0.0000000000	False
node is not height	0.0	0.0	0.0	2.0	0.0000000000	False
understand this process today	0.0	0.0	0.0	2.0	0.0000000000	False
rotation mean so rotation	0.0	0.0	0.0	2.0	0.0000000000	False
organizing the binary search	0.0	0.0	0.0	2.0	0.0000000000	False
rooted at the right	0.0	0.0	0.0	4.0	0.0000000000	False
rooted at the left	0.0	0.0	0.0	2.0	0.0000000000	False
null tree no node	0.0	0.0	0.0	2.0	0.0000000000	False
key in v keys	0.0	0.0	0.0	2.0	0.0000000000	False
property of binary search	0.0	0.0	0.0	2.0	0.0000000000	False
right so what happened	0.0	0.0	0.0	2.0	0.0000000000	False
binary search tree properties	0.0	0.0	0.0	4.0	0.0000000000	False
tree properties still holds	0.0	0.0	0.0	2.0	0.0000000000	False
earlier was the left	0.0	0.0	0.0	2.0	0.0000000000	False
child to the left	0.0	0.0	0.0	2.0	0.0000000000	False
remains to the left	0.0	0.0	0.0	4.0	0.0000000000	False
remains to the right	0.0	0.0	0.0	2.0	0.0000000000	False
clear what the links	0.0	0.0	0.0	2.0	0.0000000000	False
two are the children	0.0	0.0	1.99830508475	6.0	0.0000000000	False
four is the right	0.0	0.0	0.0	2.0	0.0000000000	False
clear what the relationships	0.0	0.0	0.0	2.0	0.0000000000	False
counted in the procedure	0.0	0.0	0.0	2.0	0.0000000000	False
path towards the root	0.0	0.0	0.0	2.0	0.0000000000	False
questions to this point	0.0	0.0	0.0	2.0	0.0000000000	False
left or the right	0.0	0.0	0.0	2.0	0.0000000000	False
left of the right	0.0	0.0	0.0	4.0	0.0000000000	False
two four different cases	0.0	0.0	0.0	2.0	0.0000000000	False
happened here so lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets say the height	0.0	0.0	0.0	2.0	0.0000000000	False
increased right and height	0.0	0.0	0.0	2.0	0.0000000000	False
node which was imbalanced	0.0	0.0	0.0	2.0	0.0000000000	False
originally x is imbalance	0.0	0.0	0.0	2.0	0.0000000000	False
imbalance because originally height	0.0	0.0	0.0	2.0	0.0000000000	False
imbalance even to begin	0.0	0.0	0.0	2.0	0.0000000000	False
height x to begin	0.0	0.0	0.0	2.0	0.0000000000	False
height of this increased	0.0	0.0	0.0	2.0	0.0000000000	False
fact that the height	0.0	0.0	0.0	2.0	0.0000000000	False
two right lets continue	0.0	0.0	0.0	2.0	0.0000000000	False
lets continue this argument	0.0	0.0	0.0	2.0	0.0000000000	False
argued that the height	0.0	0.0	0.0	4.0	0.0000000000	False
balanced the new height	0.0	0.0	0.0	2.0	0.0000000000	False
balanced this is height	0.0	0.0	0.0	4.0	0.0000000000	False
balanced so the height	0.0	0.0	0.0	2.0	0.0000000000	False
imbalanced because original height	0.0	0.0	0.0	2.0	0.0000000000	False
two then that means	0.0	0.0	0.0	4.0	0.0000000000	False
means that the height	0.0	0.0	0.0	2.0	0.0000000000	False
two then the height	0.0	0.0	0.0	2.0	0.0000000000	False
initially it was balanced	0.0	0.0	0.0	2.0	0.0000000000	False
balanced z was balanced	0.0	0.0	0.0	2.0	0.0000000000	False
final thing we argued	0.0	0.0	0.0	2.0	0.0000000000	False
rotation around this pair	0.0	0.0	0.0	2.0	0.0000000000	False
tree this come remains	0.0	0.0	0.0	2.0	0.0000000000	False
four recalls will remain	0.0	0.0	0.0	2.0	0.0000000000	False
remain at the right	0.0	0.0	0.0	2.0	0.0000000000	False
big piece will remain	0.0	0.0	0.0	2.0	0.0000000000	False
rotation was so lets	0.0	0.0	0.0	2.0	0.0000000000	False
clear what a links	0.0	0.0	0.0	2.0	0.0000000000	False
written down the heights	0.0	0.0	0.0	4.0	0.0000000000	False
rotation after a rotation	0.0	0.0	0.0	2.0	0.0000000000	False
tree properties are maintained	0.0	0.0	0.0	2.0	0.0000000000	False
argue that height balanced	0.0	0.0	0.0	2.0	0.0000000000	False
properties is also restored	0.0	0.0	0.0	2.0	0.0000000000	False
difference this is balanced	0.0	0.0	0.0	2.0	0.0000000000	False
constant number of operations	0.0	0.0	0.0	2.0	0.0000000000	False
independent of the number	0.0	0.0	0.0	2.0	0.0000000000	False
nodes in the graph	0.0	0.0	0.0	2.0	0.0000000000	False
graph in the tree	0.0	0.0	0.0	2.0	0.0000000000	False
interesting thing is happened	0.0	0.0	0.0	2.0	0.0000000000	False
happened the original height	0.0	0.0	0.0	2.0	0.0000000000	False
height of this sub	0.0	0.0	4.99774011299	8.0	0.4186046512	False
height before the insertion	0.0	0.0	0.0	4.0	0.0000000000	False
rotation the new height	0.0	0.0	0.0	2.0	0.0000000000	False
height would not change	0.0	0.0	0.0	2.0	0.0000000000	False
moving up i find	0.0	0.0	0.0	2.0	0.0000000000	False
handle because i trust	0.0	0.0	0.0	2.0	0.0000000000	False
lets repeat the argument	0.0	0.0	0.0	2.0	0.0000000000	False
assuming that the insertion	0.0	0.0	0.0	2.0	0.0000000000	False
right it could happen	0.0	0.0	0.0	4.0	0.0000000000	False
height of this guy	0.0	0.0	0.0	4.0	0.0000000000	False
insertion the new height	0.0	0.0	0.0	2.0	0.0000000000	False
balanced then that means	0.0	0.0	0.0	2.0	0.0000000000	False
height has not increased	0.0	0.0	0.0	2.0	0.0000000000	False
means y is height	0.0	0.0	0.0	2.0	0.0000000000	False
keys is the middle	0.0	0.0	0.0	2.0	0.0000000000	False
child so it means	0.0	0.0	0.0	2.0	0.0000000000	False
making y the root	0.0	0.0	0.0	2.0	0.0000000000	False
root the middle child	0.0	0.0	0.0	2.0	0.0000000000	False
child we the middle	0.0	0.0	0.0	2.0	0.0000000000	False
middle key we ended	0.0	0.0	0.0	2.0	0.0000000000	False
first i will rotate	0.0	0.0	0.0	2.0	0.0000000000	False
happen after i rotate	0.0	0.0	0.0	2.0	0.0000000000	False
remains the left child	0.0	0.0	0.0	2.0	0.0000000000	False
remains the right sub	0.0	0.0	0.0	4.0	0.0000000000	False
two switch is loyalties	0.0	0.0	0.0	2.0	0.0000000000	False
right of sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
copied the same height	0.0	0.0	0.0	2.0	0.0000000000	False
difference is this balanced	0.0	0.0	0.0	2.0	0.0000000000	False
imbalanced here and height	0.0	0.0	0.0	2.0	0.0000000000	False
right so this rotation	0.0	0.0	0.0	2.0	0.0000000000	False
rotation what other rotation	0.0	0.0	0.0	2.0	0.0000000000	False
left they will remain	0.0	0.0	0.0	2.0	0.0000000000	False
balanced here its balanced	0.0	0.0	0.0	2.0	0.0000000000	False
right so final tree	0.0	0.0	0.0	2.0	0.0000000000	False
key it was coming	0.0	0.0	0.0	2.0	0.0000000000	False
coming way down right	0.0	0.0	0.0	2.0	0.0000000000	False
split uniformly the heights	0.0	0.0	0.0	2.0	0.0000000000	False
uniformly the heights reduced	0.0	0.0	0.0	2.0	0.0000000000	False
roughly what is happening	0.0	0.0	0.0	2.0	0.0000000000	False
double rotation take constant	0.0	0.0	0.0	2.0	0.0000000000	False
ways to rotate node	0.0	0.0	0.0	2.0	0.0000000000	False
node in an avl	0.0	0.0	0.0	2.0	0.0000000000	False
picture is a balanced	0.0	0.0	0.0	2.0	0.0000000000	False
balanced picture height balanced	0.0	0.0	0.0	2.0	0.0000000000	False
picture height balanced picture	0.0	0.0	0.0	2.0	0.0000000000	False
sort the double rotations	0.0	0.0	0.0	2.0	0.0000000000	False
right and which case	0.0	0.0	0.0	2.0	0.0000000000	False
case again after rotation	0.0	0.0	0.0	2.0	0.0000000000	False
show you a picture	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to understand	0.0	0.0	0.0	0.0	0.0000000000	False
single and double rotations	0.0	0.0	0.0	2.0	0.0000000000	False
lets come to deletion	0.0	0.0	0.0	2.0	0.0000000000	False
binary tree the difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference between the height	0.0	0.0	0.0	2.0	0.0000000000	False
node here the difference	0.0	0.0	0.0	2.0	0.0000000000	False
tree when i delete	0.0	0.0	0.0	2.0	0.0000000000	False
cases if you remember	0.0	0.0	0.0	2.0	0.0000000000	False
children when i delete	0.0	0.0	0.0	2.0	0.0000000000	False
successor of that node	0.0	0.0	0.0	2.0	0.0000000000	False
content of their successor	0.0	0.0	0.0	2.0	0.0000000000	False
actual node i deleted	0.0	0.0	0.0	2.0	0.0000000000	False
deleted was the successor	0.0	0.0	0.0	2.0	0.0000000000	False
node and the successor	0.0	0.0	0.0	2.0	0.0000000000	False
child or no children	0.0	0.0	0.0	2.0	0.0000000000	False
successor only one child	0.0	0.0	0.0	2.0	0.0000000000	False
node that you end	0.0	0.0	0.0	4.0	0.0000000000	False
node or a node	0.0	0.0	0.0	2.0	0.0000000000	False
child in an avl	0.0	0.0	0.0	2.0	0.0000000000	False
child can this node	0.0	0.0	0.0	2.0	0.0000000000	False
node have the child	0.0	0.0	0.0	2.0	0.0000000000	False
child so which means	0.0	0.0	0.0	2.0	0.0000000000	False
node is a leaf	0.0	0.0	0.0	2.0	0.0000000000	False
avl tree and node	0.0	0.0	0.0	2.0	0.0000000000	False
child then the child	0.0	0.0	0.0	2.0	0.0000000000	False
child is a leaf	0.0	0.0	0.0	4.0	0.0000000000	False
child then that child	0.0	0.0	0.0	2.0	0.0000000000	False
deleting in an avl	0.0	0.0	0.0	2.0	0.0000000000	False
parent of a leaf	0.0	0.0	2.99830508475	6.0	0.0000000000	False
essentially deleting a leaf	0.0	0.0	0.0	2.0	0.0000000000	False
content of the leaf	0.0	0.0	0.0	2.0	0.0000000000	False
mind okay so lets	0.0	0.0	0.0	2.0	0.0000000000	False
node that the link	0.0	0.0	0.0	2.0	0.0000000000	False
root when i deleted	0.0	0.0	0.0	2.0	0.0000000000	False
whats going to happen	0.0	0.0	0.0	2.0	0.0000000000	False
height could reduce right	0.0	0.0	0.0	2.0	0.0000000000	False
ancestors will be unbalanced	0.0	0.0	0.0	2.0	0.0000000000	False
first unbalanced node encountered	0.0	0.0	0.0	2.0	0.0000000000	False
path but we defining	0.0	0.0	0.0	2.0	0.0000000000	False
defining y as child	0.0	0.0	0.0	2.0	0.0000000000	False
balance of the sub	0.0	0.0	0.0	2.0	0.0000000000	False
insertion what was happening	0.0	0.0	0.0	2.0	0.0000000000	False
continue up the tree	0.0	0.0	0.0	2.0	0.0000000000	False
node which is unbalanced	0.0	0.0	0.0	4.0	0.0000000000	False
unbalanced repeat the rotation	0.0	0.0	0.0	2.0	0.0000000000	False
root okay so lets	0.0	0.0	0.0	2.0	0.0000000000	False
understand what is happening	0.0	0.0	0.0	2.0	0.0000000000	False
question both the children	0.0	0.0	0.0	2.0	0.0000000000	False
ignore this h minus	0.0	0.0	0.0	2.0	0.0000000000	False
two for a minute	0.0	0.0	0.0	2.0	0.0000000000	False
right so the height	0.0	0.0	0.0	4.0	0.0000000000	False
decreased right so whats	0.0	0.0	0.0	2.0	0.0000000000	False
follow what using lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets see so question	0.0	0.0	0.0	2.0	0.0000000000	False
first node i identified	0.0	0.0	0.0	2.0	0.0000000000	False
node has two children	0.0	0.0	0.0	2.0	0.0000000000	False
things which was balanced	0.0	0.0	0.0	2.0	0.0000000000	False
imbalance to have happened	0.0	0.0	0.0	2.0	0.0000000000	False
originally its h minus	0.0	0.0	0.0	2.0	0.0000000000	False
right so this means	0.0	0.0	0.0	2.0	0.0000000000	False
kind of a thing	0.0	0.0	0.0	2.0	0.0000000000	False
initially it was unbalanced	0.0	0.0	0.0	2.0	0.0000000000	False
two are h minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus two h minus	0.0	0.0	0.0	4.0	0.0000000000	False
height of h minus	0.0	0.0	9.99717514124	10.0	0.1706161137	False
lets do a rotation	0.0	0.0	0.0	2.0	0.0000000000	False
kind of a picture	0.0	0.0	0.0	4.0	0.0000000000	False
height of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to continue	0.0	0.0	0.0	0.0	0.0000000000	False
wave is said height	0.0	0.0	0.0	2.0	0.0000000000	False
thing height as reduced	0.0	0.0	0.0	2.0	0.0000000000	False
good so after rotation	0.0	0.0	0.0	2.0	0.0000000000	False
rotation height of sub	0.0	0.0	0.0	2.0	0.0000000000	False
height of sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
height in that case	0.0	0.0	0.0	2.0	0.0000000000	False
continue of the tree	0.0	0.0	0.0	4.0	0.0000000000	False
reduced in which case	0.0	0.0	0.0	2.0	0.0000000000	False
rotation in the case	0.0	0.0	0.0	2.0	0.0000000000	False
part of the argument	0.0	0.0	0.0	2.0	0.0000000000	False
larger height and height	0.0	0.0	0.0	2.0	0.0000000000	False
mine the previous case	0.0	0.0	0.0	2.0	0.0000000000	False
case if the height	0.0	0.0	0.0	2.0	0.0000000000	False
thing that the question	0.0	0.0	0.0	2.0	0.0000000000	False
pick i will pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick the left child	0.0	0.0	0.0	4.0	0.0000000000	False
child or the right	0.0	0.0	0.0	2.0	0.0000000000	False
child i will pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick the right child	0.0	0.0	0.0	2.0	0.0000000000	False
process as an insertion	0.0	0.0	0.0	2.0	0.0000000000	False
children of y left	0.0	0.0	0.0	2.0	0.0000000000	False
right of the child	0.0	0.0	0.0	2.0	0.0000000000	False
imbalance at this node	0.0	0.0	0.0	2.0	0.0000000000	False
moves up z moves	0.0	0.0	0.0	2.0	0.0000000000	False
minus one h minus	0.0	0.0	0.0	2.0	0.0000000000	False
balanced yes h minus	0.0	0.0	0.0	2.0	0.0000000000	False
balanced but this height	0.0	0.0	0.0	2.0	0.0000000000	False
right what has happened	0.0	0.0	0.0	2.0	0.0000000000	False
happened is final tree	0.0	0.0	0.0	2.0	0.0000000000	False
final tree has height	0.0	0.0	0.0	2.0	0.0000000000	False
continue off the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree right you understand	0.0	0.0	0.0	2.0	0.0000000000	False
imbalanced at the ancestors	0.0	0.0	0.0	2.0	0.0000000000	False
node in the ancestor	0.0	0.0	0.0	2.0	0.0000000000	False
correct right so thing	0.0	0.0	0.0	2.0	0.0000000000	False
parent of this node	0.0	0.0	0.0	2.0	0.0000000000	False
node right so thing	0.0	0.0	0.0	2.0	0.0000000000	False
class okay so lets	0.0	0.0	0.0	2.0	0.0000000000	False
running time of insert	0.0	0.0	0.0	2.0	0.0000000000	False
login time in finding	0.0	0.0	0.0	2.0	0.0000000000	False
finding way to insert	0.0	0.0	0.0	2.0	0.0000000000	False
insert why login height	0.0	0.0	0.0	2.0	0.0000000000	False
height of the tree	0.0	0.0	5.99830508475	6.0	0.0000000000	False
tree we actually spent	0.0	0.0	0.0	2.0	0.0000000000	False
rotation and one rotation	0.0	0.0	0.0	2.0	0.0000000000	False
login deletion um recall	0.0	0.0	0.0	2.0	0.0000000000	False
first find the node	0.0	0.0	0.0	2.0	0.0000000000	False
tree whether the insertion	0.0	0.0	0.0	2.0	0.0000000000	False
moving up the tree	0.0	0.0	0.0	4.0	0.0000000000	False
occurs the first place	0.0	0.0	0.0	2.0	0.0000000000	False
satisfy the height balance	0.0	0.0	0.0	2.0	0.0000000000	False
insertion basically requires order	0.0	0.0	0.0	2.0	0.0000000000	False
basically requires order login	0.0	0.0	0.0	2.0	0.0000000000	False
login time to insert	0.0	0.0	0.0	2.0	0.0000000000	False
login time to move	0.0	0.0	0.0	2.0	0.0000000000	False
takes a login order	0.0	0.0	0.0	2.0	0.0000000000	False
login order time deletion	0.0	0.0	0.0	2.0	0.0000000000	False
requires only order login	0.0	0.0	0.0	2.0	0.0000000000	False
work right the reason	0.0	0.0	0.0	2.0	0.0000000000	False
deleting is leaf node	0.0	0.0	0.0	2.0	0.0000000000	False
success around the node	0.0	0.0	0.0	2.0	0.0000000000	False
left find the successor	0.0	0.0	0.0	2.0	0.0000000000	False
find the successor swap	0.0	0.0	0.0	2.0	0.0000000000	False
delete delete the successor	0.0	0.0	0.0	2.0	0.0000000000	False
delete the successor node	0.0	0.0	0.0	2.0	0.0000000000	False
node once you deleted	0.0	0.0	0.0	2.0	0.0000000000	False
imbalance occurs having found	0.0	0.0	0.0	2.0	0.0000000000	False
problem of height balanced	0.0	0.0	0.0	2.0	0.0000000000	False
nt restore height balance	0.0	0.0	0.0	0.0	0.0000000000	False
problem then you stop	0.0	0.0	0.0	2.0	0.0000000000	False
rotations you might require	0.0	0.0	0.0	2.0	0.0000000000	False
large as the height	0.0	0.0	0.0	2.0	0.0000000000	False
right because every rotation	0.0	0.0	0.0	2.0	0.0000000000	False
rotation you are moving	0.0	0.0	0.0	2.0	0.0000000000	False
login time to delete	0.0	0.0	0.0	2.0	0.0000000000	False
node all the rotations	0.0	0.0	0.0	2.0	0.0000000000	False
rotations also took order	0.0	0.0	0.0	2.0	0.0000000000	False
operation is still order	0.0	0.0	0.0	2.0	0.0000000000	False
end today s class	0.0	0.0	0.0	0.0	0.0000000000	False
deletion in avl trees	0.0	0.0	0.0	2.0	0.0000000000	False
trees and we argued	0.0	0.0	0.0	2.0	0.0000000000	False
login in the case	0.0	0.0	0.0	2.0	0.0000000000	False
case of an avl	0.0	0.0	0.0	2.0	0.0000000000	False
operations of insert search	0.0	0.0	0.0	2.0	0.0000000000	False
data structures and algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms dr naveen garg	0.0	0.0	0.0	2.0	0.0000000000	False
garg dept of computer	0.0	0.0	0.0	2.0	0.0000000000	False
dept of computer science	0.0	0.0	0.0	2.0	0.0000000000	False
computer science and engineering	0.0	0.0	0.0	2.0	0.0000000000	False
science and engineering iit	0.0	0.0	0.0	2.0	0.0000000000	False
engineering iit delhi lecture	0.0	0.0	0.0	2.0	0.0000000000	False
operation of insert search	0.0	0.0	0.0	2.0	0.0000000000	False
delete on this data	0.0	0.0	0.0	2.0	0.0000000000	False
kind of performance guarantee	0.0	0.0	0.0	2.0	0.0000000000	False
case in avl trees	0.0	0.0	0.0	2.0	0.0000000000	False
kind of search trees	0.0	0.0	0.0	2.0	0.0000000000	False
search trees so recall	0.0	0.0	0.0	2.0	0.0000000000	False
trees what was happening	0.0	0.0	0.0	2.0	0.0000000000	False
tree ya each node	0.0	0.0	0.0	2.0	0.0000000000	False
first point so nodes	0.0	0.0	0.0	2.0	0.0000000000	False
two three four trees	0.0	0.0	0.0	4.0	0.0000000000	False
refers to the number	0.0	0.0	0.0	2.0	0.0000000000	False
children right such trees	0.0	0.0	0.0	2.0	0.0000000000	False
satisfy a certain kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of search properties	0.0	0.0	0.0	2.0	0.0000000000	False
properties or called multi	0.0	0.0	0.0	2.0	0.0000000000	False
multi way search trees	0.0	0.0	7.99225352113	22.0	0.3070259865	True
node of a multi	0.0	0.0	0.0	2.0	0.0000000000	False
leas two which means	0.0	0.0	0.0	2.0	0.0000000000	False
children right any number	0.0	0.0	0.0	2.0	0.0000000000	False
items the form key	0.0	0.0	0.0	2.0	0.0000000000	False
form key coma element	0.0	0.0	0.0	2.0	0.0000000000	False
binary search each node	0.0	0.0	0.0	2.0	0.0000000000	False
key and the element	0.0	0.0	0.0	2.0	0.0000000000	False
element there was lets	0.0	0.0	0.0	2.0	0.0000000000	False
reference to the element	0.0	0.0	0.0	2.0	0.0000000000	False
element or the element	0.0	0.0	0.0	2.0	0.0000000000	False
lets say student record	0.0	0.0	0.0	2.0	0.0000000000	False
student record student entry	0.0	0.0	0.0	2.0	0.0000000000	False
record student entry number	0.0	0.0	0.0	2.0	0.0000000000	False
entry number the student	0.0	0.0	0.0	2.0	0.0000000000	False
number the student record	0.0	0.0	0.0	2.0	0.0000000000	False
stored in the node	0.0	0.0	0.0	2.0	0.0000000000	False
node containing a pairs	0.0	0.0	0.0	2.0	0.0000000000	False
pairs of this kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind key comma element	0.0	0.0	0.0	2.0	0.0000000000	False
pair and each node	0.0	0.0	0.0	2.0	0.0000000000	False
minus one search pairs	0.0	0.0	0.0	2.0	0.0000000000	False
search pairs or items	0.0	0.0	0.0	2.0	0.0000000000	False
children that particular node	0.0	0.0	0.0	2.0	0.0000000000	False
generalizing a binary search	0.0	0.0	0.0	2.0	0.0000000000	False
node has two children	0.0	0.0	2.99788732394	6.0	0.0000000000	False
children ya each node	0.0	0.0	0.0	2.0	0.0000000000	False
keys that is left	0.0	0.0	0.0	2.0	0.0000000000	False
node because that keys	0.0	0.0	0.0	2.0	0.0000000000	False
keys helps us helps	0.0	0.0	0.0	2.0	0.0000000000	False
first child second child	0.0	0.0	0.0	2.0	0.0000000000	False
minus one difference keys	0.0	0.0	0.0	2.0	0.0000000000	False
sitting in the node	0.0	0.0	0.0	2.0	0.0000000000	False
clear with that right	0.0	0.0	0.0	2.0	0.0000000000	False
keys in a node	0.0	0.0	0.0	4.0	0.0000000000	False
children in that node	0.0	0.0	0.0	2.0	0.0000000000	False
node has three children	0.0	0.0	0.0	4.0	0.0000000000	False
children and you read	0.0	0.0	0.0	2.0	0.0000000000	False
read need two keys	0.0	0.0	0.0	2.0	0.0000000000	False
keys in the node	0.0	0.0	0.0	4.0	0.0000000000	False
node determined what set	0.0	0.0	0.0	2.0	0.0000000000	False
keys the various sub	0.0	0.0	0.0	2.0	0.0000000000	False
tree so this sub	0.0	0.0	0.0	2.0	0.0000000000	False
lie in the middle	0.0	0.0	0.0	2.0	0.0000000000	False
right now you understand	0.0	0.0	0.0	2.0	0.0000000000	False
elements all the items	0.0	0.0	0.0	2.0	0.0000000000	False
child okay so lets	0.0	0.0	0.0	2.0	0.0000000000	False
search such as tree	0.0	0.0	0.0	2.0	0.0000000000	False
suppose we are searching	0.0	0.0	0.0	2.0	0.0000000000	False
compare eight with twenty	0.0	0.0	0.0	2.0	0.0000000000	False
ten but eight lies	0.0	0.0	0.0	2.0	0.0000000000	False
key in that node	0.0	0.0	0.0	4.0	0.0000000000	False
node and k lets	0.0	0.0	0.0	2.0	0.0000000000	False
node so you compare	0.0	0.0	0.0	2.0	0.0000000000	False
left most sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
right most sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
searching for the node	0.0	0.0	0.0	2.0	0.0000000000	False
instance when we searching	0.0	0.0	0.0	2.0	0.0000000000	False
twenty two eight lies	0.0	0.0	0.0	2.0	0.0000000000	False
steps and we found	0.0	0.0	0.0	2.0	0.0000000000	False
twelve yes we found	0.0	0.0	0.0	2.0	0.0000000000	False
key that you searching	0.0	0.0	0.0	2.0	0.0000000000	False
two keys is lies	0.0	0.0	0.0	2.0	0.0000000000	False
follow the appropriate child	0.0	0.0	0.0	2.0	0.0000000000	False
last key which keys	0.0	0.0	0.0	2.0	0.0000000000	False
keys is should follow	0.0	0.0	0.0	2.0	0.0000000000	False
follow either it left	0.0	0.0	0.0	2.0	0.0000000000	False
order driver in traversal	0.0	0.0	0.0	2.0	0.0000000000	False
driver in traversal tree	0.0	0.0	0.0	2.0	0.0000000000	False
traversal in a tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree so we recall	0.0	0.0	0.0	2.0	0.0000000000	False
inorder traversal says left	0.0	0.0	0.0	2.0	0.0000000000	False
left then you print	0.0	0.0	0.0	2.0	0.0000000000	False
data of the data	0.0	0.0	0.0	2.0	0.0000000000	False
first go the left	0.0	0.0	0.0	2.0	0.0000000000	False
left most then print	0.0	0.0	0.0	2.0	0.0000000000	False
right that would correspond	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to inorder traversal	0.0	0.0	0.0	2.0	0.0000000000	False
right so for instance	0.0	0.0	0.0	2.0	0.0000000000	False
first i would print	0.0	0.0	0.0	2.0	0.0000000000	False
first do an inorder	0.0	0.0	0.0	2.0	0.0000000000	False
traversal on this part	0.0	0.0	0.0	2.0	0.0000000000	False
part of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree ya which means	0.0	0.0	0.0	2.0	0.0000000000	False
traversal here which means	0.0	0.0	0.0	2.0	0.0000000000	False
print the next key	0.0	0.0	0.0	2.0	0.0000000000	False
traversal on this node	0.0	0.0	0.0	2.0	0.0000000000	False
finish the inorder traversal	0.0	0.0	0.0	4.0	0.0000000000	False
traversal on that node	0.0	0.0	0.0	2.0	0.0000000000	False
back to the parent	0.0	0.0	0.0	2.0	0.0000000000	False
first i went left	0.0	0.0	0.0	2.0	0.0000000000	False
left then i print	0.0	0.0	0.0	2.0	0.0000000000	False
key which i print	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree this sub tree	0.0	0.0	0.0	2.0	0.0000000000	False
sub tree this sub	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of this right	0.0	0.0	0.0	2.0	0.0000000000	False
eleven first thirteen fourteen	0.0	0.0	0.0	2.0	0.0000000000	False
seventeen eighteen nineteen twenty	0.0	0.0	0.0	2.0	0.0000000000	False
eighteen nineteen twenty twenty	0.0	0.0	0.0	2.0	0.0000000000	False
thing so i print	0.0	0.0	0.0	2.0	0.0000000000	False
print the key twenty	0.0	0.0	0.0	2.0	0.0000000000	False
keys in sorted order	0.0	0.0	0.0	2.0	0.0000000000	False
out all these keys	0.0	0.0	0.0	2.0	0.0000000000	False
out these key right	0.0	0.0	0.0	2.0	0.0000000000	False
right so which means	0.0	0.0	0.0	2.0	0.0000000000	False
printing all the keys	0.0	0.0	0.0	2.0	0.0000000000	False
key so which means	0.0	0.0	0.0	2.0	0.0000000000	False
children also for instance	0.0	0.0	0.0	2.0	0.0000000000	False
lets say five point	0.0	0.0	0.0	2.0	0.0000000000	False
node with five point	0.0	0.0	0.0	2.0	0.0000000000	False
manner but five point	0.0	0.0	0.0	2.0	0.0000000000	False
nodes here okay great	0.0	0.0	0.0	2.0	0.0000000000	False
great so now lets	0.0	0.0	1.99788732394	6.0	0.0000000000	False
search tree okay multi	0.0	0.0	0.0	2.0	0.0000000000	False
four tree each node	0.0	0.0	0.0	2.0	0.0000000000	False
right so the leaf	0.0	0.0	0.0	2.0	0.0000000000	False
forget this square boxes	0.0	0.0	0.0	2.0	0.0000000000	False
suppose we are numbering	0.0	0.0	0.0	2.0	0.0000000000	False
tree is a multi	0.0	0.0	0.0	2.0	0.0000000000	False
tree with two addition	0.0	0.0	0.0	2.0	0.0000000000	False
two addition properties search	0.0	0.0	0.0	2.0	0.0000000000	False
node with four children	0.0	0.0	0.0	4.0	0.0000000000	False
two four tree node	0.0	0.0	0.0	2.0	0.0000000000	False
height of the tree	0.0	0.0	7.99647887324	10.0	0.3805774278	False
case when would height	0.0	0.0	0.0	2.0	0.0000000000	False
tree and complete binary	0.0	0.0	0.0	2.0	0.0000000000	False
tree we were argued	0.0	0.0	0.0	2.0	0.0000000000	False
argued with the height	0.0	0.0	0.0	2.0	0.0000000000	False
height is login base	0.0	0.0	0.0	2.0	0.0000000000	False
thing like that right	0.0	0.0	0.0	2.0	0.0000000000	False
setting when the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree height is maximum	0.0	0.0	0.0	2.0	0.0000000000	False
maximum the tree height	0.0	0.0	0.0	2.0	0.0000000000	False
minimum when every node	0.0	0.0	0.0	2.0	0.0000000000	False
node has four children	0.0	0.0	0.0	2.0	0.0000000000	False
four and then sixteen	0.0	0.0	0.0	2.0	0.0000000000	False
four to the sixteen	0.0	0.0	0.0	2.0	0.0000000000	False
sixteen time four sixty	0.0	0.0	0.0	2.0	0.0000000000	False
analysis you will find	0.0	0.0	0.0	2.0	0.0000000000	False
height of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
login to the base	0.0	0.0	0.0	2.0	0.0000000000	False
tree on n nodes	0.0	0.0	0.0	2.0	0.0000000000	False
base two its lies	0.0	0.0	0.0	2.0	0.0000000000	False
lies between login base	0.0	0.0	0.0	2.0	0.0000000000	False
base two and login	0.0	0.0	0.0	2.0	0.0000000000	False
two and login base	0.0	0.0	0.0	2.0	0.0000000000	False
login base four login	0.0	0.0	0.0	2.0	0.0000000000	False
base four login base	0.0	0.0	0.0	2.0	0.0000000000	False
essentially half of login	0.0	0.0	0.0	2.0	0.0000000000	False
half of login base	0.0	0.0	0.0	2.0	0.0000000000	False
two four tree lies	0.0	0.0	0.0	2.0	0.0000000000	False
tree lies between half	0.0	0.0	0.0	2.0	0.0000000000	False
takes two for search	0.0	0.0	0.0	2.0	0.0000000000	False
search for eleven lets	0.0	0.0	0.0	2.0	0.0000000000	False
right i will change	0.0	0.0	0.0	2.0	0.0000000000	False
eleven i am comparing	0.0	0.0	0.0	2.0	0.0000000000	False
eleven here so found	0.0	0.0	0.0	2.0	0.0000000000	False
two four tree height	0.0	0.0	0.0	2.0	0.0000000000	False
correct it is order	0.0	0.0	0.0	2.0	0.0000000000	False
node how many keys	0.0	0.0	0.0	2.0	0.0000000000	False
children how many keys	0.0	0.0	0.0	4.0	0.0000000000	False
maximum number of keys	0.0	0.0	0.0	2.0	0.0000000000	False
keys do a require	0.0	0.0	0.0	2.0	0.0000000000	False
require one right node	0.0	0.0	0.0	2.0	0.0000000000	False
two or three keys	0.0	0.0	0.0	2.0	0.0000000000	False
key some what require	0.0	0.0	0.0	2.0	0.0000000000	False
comparison and all right	0.0	0.0	0.0	2.0	0.0000000000	False
determine which particular branch	0.0	0.0	0.0	4.0	0.0000000000	False
out some what require	0.0	0.0	0.0	2.0	0.0000000000	False
login is a number	0.0	0.0	0.0	2.0	0.0000000000	False
login ya so order	0.0	0.0	0.0	2.0	0.0000000000	False
careful about this right	0.0	0.0	0.0	2.0	0.0000000000	False
right within each node	0.0	0.0	0.0	2.0	0.0000000000	False
search tree you required	0.0	0.0	0.0	2.0	0.0000000000	False
required only one comparison	0.0	0.0	0.0	2.0	0.0000000000	False
great why three login	0.0	0.0	0.0	2.0	0.0000000000	False
start at the root	0.0	0.0	0.0	2.0	0.0000000000	False
key is a node	0.0	0.0	0.0	2.0	0.0000000000	False
node here this node	0.0	0.0	0.0	2.0	0.0000000000	False
out of that node	0.0	0.0	0.0	2.0	0.0000000000	False
lets look at insertion	0.0	0.0	0.0	2.0	0.0000000000	False
show you the process	0.0	0.0	0.0	2.0	0.0000000000	False
children i have shown	0.0	0.0	0.0	2.0	0.0000000000	False
node with three location	0.0	0.0	0.0	2.0	0.0000000000	False
node will have space	0.0	0.0	0.0	2.0	0.0000000000	False
space for three keys	0.0	0.0	0.0	2.0	0.0000000000	False
node has having space	0.0	0.0	0.0	2.0	0.0000000000	False
first we will search	0.0	0.0	0.0	2.0	0.0000000000	False
terminates if we found	0.0	0.0	0.0	2.0	0.0000000000	False
terminates we would insert	0.0	0.0	0.0	2.0	0.0000000000	False
element is so lets	0.0	0.0	0.0	2.0	0.0000000000	False
compare so here twenty	0.0	0.0	0.0	2.0	0.0000000000	False
two so which means	0.0	0.0	0.0	2.0	0.0000000000	False
branch out i compare	0.0	0.0	0.0	2.0	0.0000000000	False
compare against the eighty	0.0	0.0	0.0	2.0	0.0000000000	False
sit that particular node	0.0	0.0	0.0	2.0	0.0000000000	False
compare with the twenty	0.0	0.0	0.0	2.0	0.0000000000	False
hit the leaf node	0.0	0.0	0.0	2.0	0.0000000000	False
compare it with twenty	0.0	0.0	0.0	2.0	0.0000000000	False
right but right node	0.0	0.0	0.0	2.0	0.0000000000	False
empty the right pointer	0.0	0.0	0.0	2.0	0.0000000000	False
eighty we would continue	0.0	0.0	0.0	2.0	0.0000000000	False
heat the null pointer	0.0	0.0	0.0	4.0	0.0000000000	False
pointer so we comparing	0.0	0.0	0.0	2.0	0.0000000000	False
twenty one with twenty	0.0	0.0	0.0	2.0	0.0000000000	False
empty space no problem	0.0	0.0	0.0	2.0	0.0000000000	False
twenty two and thirty	0.0	0.0	3.99788732394	6.0	0.0000000000	False
key in a inserted	0.0	0.0	0.0	2.0	0.0000000000	False
four to the right	0.0	0.0	0.0	2.0	0.0000000000	False
place ya so insertion	0.0	0.0	0.0	2.0	0.0000000000	False
node at the leaf	0.0	0.0	0.0	2.0	0.0000000000	False
right to go left	0.0	0.0	0.0	2.0	0.0000000000	False
problem with forty forty	0.0	0.0	0.0	2.0	0.0000000000	False
compare forty with thirty	0.0	0.0	0.0	2.0	0.0000000000	False
thing that could happen	0.0	0.0	0.0	2.0	0.0000000000	False
happen right so twenty	0.0	0.0	0.0	2.0	0.0000000000	False
twenty nine between twenty	0.0	0.0	0.0	2.0	0.0000000000	False
two so i follow	0.0	0.0	0.0	2.0	0.0000000000	False
sit here between twenty	0.0	0.0	0.0	2.0	0.0000000000	False
twenty eight and thirty	0.0	0.0	0.0	2.0	0.0000000000	False
twenty nine and thirty	0.0	0.0	0.0	2.0	0.0000000000	False
link up this node	0.0	0.0	0.0	2.0	0.0000000000	False
children of this guy	0.0	0.0	0.0	2.0	0.0000000000	False
children of this node	0.0	0.0	1.99788732394	6.0	0.0000000000	False
child of this node	0.0	0.0	0.0	4.0	0.0000000000	False
key i should put	0.0	0.0	0.0	2.0	0.0000000000	False
twenty nine you understand	0.0	0.0	0.0	2.0	0.0000000000	False
problem then the search	0.0	0.0	0.0	2.0	0.0000000000	False
key from this node	0.0	0.0	0.0	2.0	0.0000000000	False
key to the parent	0.0	0.0	0.0	2.0	0.0000000000	False
key we could insert	0.0	0.0	0.0	2.0	0.0000000000	False
parent it might happen	0.0	0.0	0.0	2.0	0.0000000000	False
nt have any space	0.0	0.0	0.0	0.0	0.0000000000	False
follow the second child	0.0	0.0	0.0	2.0	0.0000000000	False
follow the second pointer	0.0	0.0	0.0	2.0	0.0000000000	False
node two nodes created	0.0	0.0	0.0	2.0	0.0000000000	False
read of this node	0.0	0.0	0.0	2.0	0.0000000000	False
split in the parent	0.0	0.0	0.0	2.0	0.0000000000	False
children of these guys	0.0	0.0	0.0	2.0	0.0000000000	False
smaller node and promoted	0.0	0.0	0.0	2.0	0.0000000000	False
create so the left	0.0	0.0	0.0	2.0	0.0000000000	False
children would be made	0.0	0.0	0.0	2.0	0.0000000000	False
right so that means	0.0	0.0	0.0	2.0	0.0000000000	False
left here which means	0.0	0.0	0.0	2.0	0.0000000000	False
two keys which means	0.0	0.0	0.0	2.0	0.0000000000	False
children and we promote	0.0	0.0	0.0	2.0	0.0000000000	False
right so we split	0.0	0.0	0.0	2.0	0.0000000000	False
space so we split	0.0	0.0	0.0	2.0	0.0000000000	False
node this will disappear	0.0	0.0	0.0	2.0	0.0000000000	False
thirteen will get promoted	0.0	0.0	0.0	2.0	0.0000000000	False
two will become children	0.0	0.0	0.0	2.0	0.0000000000	False
create a new root	0.0	0.0	2.99788732394	6.0	0.0000000000	False
two become the children	0.0	0.0	0.0	2.0	0.0000000000	False
children of this right	0.0	0.0	0.0	2.0	0.0000000000	False
create the new root	0.0	0.0	0.0	4.0	0.0000000000	False
tree till you hit	0.0	0.0	0.0	2.0	0.0000000000	False
space when you split	0.0	0.0	0.0	2.0	0.0000000000	False
lower two lower keys	0.0	0.0	0.0	2.0	0.0000000000	False
part would be promoted	0.0	0.0	0.0	2.0	0.0000000000	False
repeat the split process	0.0	0.0	0.0	2.0	0.0000000000	False
process of the parent	0.0	0.0	0.0	2.0	0.0000000000	False
right and these split	0.0	0.0	0.0	2.0	0.0000000000	False
root if its case	0.0	0.0	0.0	2.0	0.0000000000	False
root and the root	0.0	0.0	0.0	2.0	0.0000000000	False
root also get split	0.0	0.0	0.0	2.0	0.0000000000	False
insertion take so search	0.0	0.0	0.0	2.0	0.0000000000	False
search we take order	0.0	0.0	0.0	2.0	0.0000000000	False
node i will create	0.0	0.0	0.0	2.0	0.0000000000	False
two some two node	0.0	0.0	0.0	2.0	0.0000000000	False
independent of the number	0.0	0.0	0.0	2.0	0.0000000000	False
node split takes constant	0.0	0.0	0.0	2.0	0.0000000000	False
total time order login	0.0	0.0	0.0	2.0	0.0000000000	False
lets look at deletion	0.0	0.0	0.0	2.0	0.0000000000	False
wanted to delete twenty	0.0	0.0	0.0	2.0	0.0000000000	False
twenty one find out	0.0	0.0	0.0	2.0	0.0000000000	False
case of binary search	0.0	0.0	0.0	2.0	0.0000000000	False
search tree we recall	0.0	0.0	0.0	2.0	0.0000000000	False
tree we recall deletion	0.0	0.0	0.0	2.0	0.0000000000	False
require three different cases	0.0	0.0	0.0	2.0	0.0000000000	False
distinguish between one child	0.0	0.0	0.0	2.0	0.0000000000	False
child and two child	0.0	0.0	0.0	2.0	0.0000000000	False
child the one child	0.0	0.0	0.0	2.0	0.0000000000	False
cases not really happening	0.0	0.0	0.0	2.0	0.0000000000	False
internal node two children	0.0	0.0	0.0	2.0	0.0000000000	False
lets say with form	0.0	0.0	0.0	2.0	0.0000000000	False
predecessor and we move	0.0	0.0	0.0	2.0	0.0000000000	False
twenty one so twenty	0.0	0.0	0.0	2.0	0.0000000000	False
right and i find	0.0	0.0	0.0	2.0	0.0000000000	False
find twenty one right	0.0	0.0	0.0	2.0	0.0000000000	False
remove it without violating	0.0	0.0	0.0	2.0	0.0000000000	False
four tree we require	0.0	0.0	0.0	2.0	0.0000000000	False
keys so after deleting	0.0	0.0	0.0	2.0	0.0000000000	False
key so no problem	0.0	0.0	0.0	2.0	0.0000000000	False
process but this twenty	0.0	0.0	0.0	2.0	0.0000000000	False
deleted we just mark	0.0	0.0	0.0	2.0	0.0000000000	False
key to be deleted	0.0	0.0	0.0	2.0	0.0000000000	False
node fine for instance	0.0	0.0	0.0	2.0	0.0000000000	False
delete twenty five right	0.0	0.0	0.0	2.0	0.0000000000	False
right so i search	0.0	0.0	0.0	2.0	0.0000000000	False
key in this node	0.0	0.0	0.0	2.0	0.0000000000	False
node ya i find	0.0	0.0	0.0	2.0	0.0000000000	False
largest key its twenty	0.0	0.0	0.0	2.0	0.0000000000	False
twenty four so predecessor	0.0	0.0	0.0	2.0	0.0000000000	False
keys in the leaf	0.0	0.0	0.0	2.0	0.0000000000	False
problem note that predecessor	0.0	0.0	0.0	2.0	0.0000000000	False
leaf in this case	0.0	0.0	0.0	2.0	0.0000000000	False
binary search tree lets	0.0	0.0	0.0	2.0	0.0000000000	False
search tree lets check	0.0	0.0	0.0	2.0	0.0000000000	False
lets check this point	0.0	0.0	0.0	2.0	0.0000000000	False
out in the case	0.0	0.0	0.0	2.0	0.0000000000	False
search tree the predecessor	0.0	0.0	0.0	2.0	0.0000000000	False
predecessor of a node	0.0	0.0	0.0	2.0	0.0000000000	True
node but here predecessor	0.0	0.0	0.0	2.0	0.0000000000	False
predecessor i go left	0.0	0.0	0.0	2.0	0.0000000000	False
right when my right	0.0	0.0	0.0	2.0	0.0000000000	False
null then that means	0.0	0.0	0.0	2.0	0.0000000000	False
children are null right	0.0	0.0	0.0	2.0	0.0000000000	False
great so my predecessor	0.0	0.0	0.0	2.0	0.0000000000	False
remove that leaf node	0.0	0.0	0.0	2.0	0.0000000000	False
recall i was deleting	0.0	0.0	0.0	2.0	0.0000000000	False
twenty four and twenty	0.0	0.0	0.0	2.0	0.0000000000	False
key from a leaf	0.0	0.0	0.0	2.0	0.0000000000	False
empty then we borrow	0.0	0.0	0.0	2.0	0.0000000000	False
key from its sibling	0.0	0.0	0.0	2.0	0.0000000000	False
twenty so i search	0.0	0.0	0.0	2.0	0.0000000000	False
manner right i reach	0.0	0.0	0.0	2.0	0.0000000000	False
delete twenty so twenty	0.0	0.0	0.0	2.0	0.0000000000	False
twenty is removed problem	0.0	0.0	0.0	2.0	0.0000000000	False
empty node not permitted	0.0	0.0	0.0	2.0	0.0000000000	False
sibling what is borrow	0.0	0.0	0.0	2.0	0.0000000000	False
means only one sibling	0.0	0.0	0.0	2.0	0.0000000000	False
right because search property	0.0	0.0	0.0	2.0	0.0000000000	False
fifteen goes up eighteen	0.0	0.0	0.0	2.0	0.0000000000	False
thing you are wondering	0.0	0.0	0.0	2.0	0.0000000000	False
borrow from my sibling	0.0	0.0	0.0	4.0	0.0000000000	False
sibling when the sibling	0.0	0.0	0.0	2.0	0.0000000000	False
key then we merge	0.0	0.0	0.0	2.0	0.0000000000	False
merge with the sibling	0.0	0.0	3.99788732394	6.0	0.0000000000	False
combine with the sibling	0.0	0.0	0.0	2.0	0.0000000000	False
delete twenty three right	0.0	0.0	0.0	2.0	0.0000000000	False
borrow from a sibling	0.0	0.0	0.0	4.0	0.0000000000	False
promote something then twenty	0.0	0.0	0.0	2.0	0.0000000000	False
borrow from this guy	0.0	0.0	0.0	2.0	0.0000000000	False
combine then the number	0.0	0.0	0.0	2.0	0.0000000000	False
key in the parent	0.0	0.0	0.0	4.0	0.0000000000	False
separate this two sibling	0.0	0.0	0.0	2.0	0.0000000000	False
key which is separating	0.0	0.0	0.0	2.0	0.0000000000	False
separating these two siblings	0.0	0.0	0.0	2.0	0.0000000000	False
lets see i create	0.0	0.0	0.0	2.0	0.0000000000	False
create a new node	0.0	0.0	0.0	4.0	0.0000000000	False
node which is merge	0.0	0.0	0.0	2.0	0.0000000000	False
nodes this goes moves	0.0	0.0	0.0	2.0	0.0000000000	False
non here two keys	0.0	0.0	0.0	2.0	0.0000000000	False
two will now disappear	0.0	0.0	0.0	2.0	0.0000000000	False
keys from the parent	0.0	0.0	5.99788732394	6.0	0.0000000000	False
deletion in the parent	0.0	0.0	0.0	2.0	0.0000000000	False
parent node this procedure	0.0	0.0	0.0	2.0	0.0000000000	False
lead to the cascading	0.0	0.0	0.0	2.0	0.0000000000	False
cascading as in right	0.0	0.0	0.0	2.0	0.0000000000	False
left of it parent	0.0	0.0	0.0	2.0	0.0000000000	False
parent which is twenty	0.0	0.0	0.0	2.0	0.0000000000	False
deletion height can reduce	0.0	0.0	0.0	2.0	0.0000000000	False
means height has shrink	0.0	0.0	0.0	2.0	0.0000000000	False
shrink what could happen	0.0	0.0	0.0	2.0	0.0000000000	False
happen ya or insertion	0.0	0.0	0.0	2.0	0.0000000000	False
height so everyone understand	0.0	0.0	0.0	2.0	0.0000000000	False
copy try to borrow	0.0	0.0	0.0	2.0	0.0000000000	False
successful then you merge	0.0	0.0	0.0	2.0	0.0000000000	False
merge great so lets	0.0	0.0	0.0	2.0	0.0000000000	False
great so lets conclude	0.0	0.0	0.0	2.0	0.0000000000	False
conclude today s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
vaning time for deletion	0.0	0.0	0.0	2.0	0.0000000000	False
key that s login	0.0	0.0	0.0	0.0	0.0000000000	False
right so another login	0.0	0.0	0.0	2.0	0.0000000000	False
login step each step	0.0	0.0	0.0	2.0	0.0000000000	False
step where either borrowing	0.0	0.0	0.0	2.0	0.0000000000	False
right borrowing could corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
data structure called red	0.0	0.0	0.0	2.0	0.0000000000	False
data structure for implementing	0.0	0.0	0.0	2.0	0.0000000000	False
structure for implementing dictionaries	0.0	0.0	0.0	2.0	0.0000000000	False
two four trees today	0.0	0.0	0.0	2.0	0.0000000000	False
understanding how the red	0.0	0.0	0.0	2.0	0.0000000000	False
red black trees functions	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t.delhi	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t.delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
i.i.t.delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
high level programming languages	0.0	1.0	0.0	2.0	0.0000000000	True
imperative and functional languages	0.0	0.0	0.0	2.0	0.0000000000	False
respects so imperative language	0.0	0.0	0.0	2.0	0.0000000000	False
based languages where state	0.0	0.0	0.0	2.0	0.0000000000	False
languages where state updation	0.0	0.0	0.0	2.0	0.0000000000	False
languages are really value	0.0	0.0	0.0	2.0	0.0000000000	False
languages in the notion	0.0	0.0	0.0	2.0	0.0000000000	False
variables in functional languages	0.0	0.0	0.0	2.0	0.0000000000	False
mathematics whereas the notion	0.0	0.0	0.0	2.0	0.0000000000	False
notion of the variables	0.0	0.0	0.0	4.0	0.0000000000	False
physics which can change	0.0	0.0	0.0	2.0	0.0000000000	False
quantities like acceleration velocity	0.0	0.0	0.0	2.0	0.0000000000	False
state based languages means	0.0	0.0	0.0	2.0	0.0000000000	False
trimaxes though unlike physics	0.0	0.0	0.0	2.0	0.0000000000	False
case of functional languages	0.0	0.0	0.0	2.0	0.0000000000	False
functional languages the notion	0.0	0.0	0.0	2.0	0.0000000000	False
execution of a program	0.0	0.0	0.0	2.0	0.0000000000	False
languages is really concentrated	0.0	0.0	0.0	2.0	0.0000000000	False
hundreds of programming languages	0.0	0.0	0.0	4.0	0.0000000000	False
history you will find	0.0	0.0	0.0	2.0	0.0000000000	False
sixties a large portion	0.0	0.0	0.0	2.0	0.0000000000	False
features so which means	0.0	0.0	0.0	2.0	0.0000000000	False
means these these represent	0.0	0.0	0.0	2.0	0.0000000000	False
represent the basic control	0.0	0.0	0.0	2.0	0.0000000000	False
control structures the exploration	0.0	0.0	0.0	2.0	0.0000000000	False
data structures in order	0.0	0.0	0.0	2.0	0.0000000000	False
obtain clean readable programs	0.0	0.0	0.0	2.0	0.0000000000	False
efficiently implement able programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs um efficient running	0.0	0.0	0.0	2.0	0.0000000000	False
fixed in the seventies	0.0	0.0	0.0	2.0	0.0000000000	False
exploration of programming languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages was in terms	0.0	0.0	0.0	2.0	0.0000000000	False
pascal most important feature	0.0	0.0	0.0	2.0	0.0000000000	False
combines the module features	0.0	0.0	0.0	2.0	0.0000000000	False
module features of modula	0.0	0.0	0.0	2.0	0.0000000000	False
important feature exception handling	0.0	0.0	0.0	2.0	0.0000000000	False
feature exception handling generics	0.0	0.0	0.0	2.0	0.0000000000	False
handling generics or polymorphism	0.0	0.0	0.0	2.0	0.0000000000	False
clu is a module	0.0	0.0	0.0	2.0	0.0000000000	False
sense the basic control	0.0	0.0	0.0	2.0	0.0000000000	False
basic control structure remain	0.0	0.0	0.0	2.0	0.0000000000	False
structures in these languages	0.0	0.0	0.0	2.0	0.0000000000	False
mark denote the decendency	0.0	0.0	0.0	2.0	0.0000000000	False
structures so from simula	0.0	0.0	0.0	2.0	0.0000000000	False
small talk eighty control	0.0	0.0	0.0	2.0	0.0000000000	False
talk eighty control structures	0.0	0.0	0.0	2.0	0.0000000000	False
control structures or syntax	0.0	0.0	0.0	2.0	0.0000000000	False
simula which was extended	0.0	0.0	0.0	2.0	0.0000000000	False
features are these kinds	0.0	0.0	0.0	2.0	0.0000000000	False
nowadays biolarge their exploration	0.0	0.0	0.0	2.0	0.0000000000	False
terms of new features	0.0	0.0	0.0	2.0	0.0000000000	False
kind of new features	0.0	0.0	0.0	2.0	0.0000000000	False
current state of art	0.0	0.0	0.0	2.0	0.0000000000	False
large amount of work	0.0	0.0	0.0	2.0	0.0000000000	False
efficient trying to make	0.0	0.0	0.0	2.0	0.0000000000	False
data structures and controls	0.0	0.0	0.0	2.0	0.0000000000	False
controls and control structures	0.0	0.0	0.0	2.0	0.0000000000	False
control structures then languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages like ml caml	0.0	0.0	0.0	2.0	0.0000000000	False
addition of new features	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of ml expressions	0.0	0.0	0.0	2.0	0.0000000000	False
lisp in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
features like the introduction	0.0	0.0	0.0	2.0	0.0000000000	False
introduction of modules introduction	0.0	0.0	0.0	2.0	0.0000000000	False
introduction of exceptional handling	0.0	0.0	0.0	2.0	0.0000000000	False
exceptional handling the introduction	0.0	0.0	0.0	2.0	0.0000000000	False
powerful data abstraction mechanisms	0.0	0.0	0.0	2.0	0.0000000000	False
mechanisms and a type	0.0	0.0	0.0	2.0	0.0000000000	False
checking ok so lisp	0.0	0.0	0.0	2.0	0.0000000000	False
lisp has no type	0.0	0.0	0.0	2.0	0.0000000000	False
checking at all right	0.0	0.0	0.0	2.0	0.0000000000	False
study the basic features	0.0	0.0	0.0	2.0	0.0000000000	False
basic features of languages	0.0	0.0	0.0	2.0	0.0000000000	True
thing like language design	0.0	0.0	0.0	2.0	0.0000000000	False
issue that the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
implementation that the language	0.0	0.0	0.0	2.0	0.0000000000	False
language pascal has taught	0.0	0.0	0.0	2.0	0.0000000000	False
idea for a language	0.0	0.0	0.0	2.0	0.0000000000	False
unified primitives for expressing	0.0	0.0	0.0	2.0	0.0000000000	False
basically all your algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms and data structures	0.0	0.0	0.0	2.0	0.0000000000	False
algol sixty like languages	0.0	0.0	0.0	2.0	0.0000000000	False
variations of the dialect	0.0	0.0	0.0	2.0	0.0000000000	False
pascal or algol system	0.0	0.0	0.0	2.0	0.0000000000	False
set of primitive operations	0.0	0.0	0.0	2.0	0.0000000000	False
read the source code	0.0	0.0	5.9978021978	6.0	0.0000000000	False
code of the program	0.0	0.0	0.0	2.0	0.0000000000	False
program like a book	0.0	0.0	0.0	2.0	0.0000000000	False
software that you write	0.0	0.0	0.0	2.0	0.0000000000	False
permanently fixed what hsppens	0.0	0.0	0.0	2.0	0.0000000000	False
bugs might be detected	0.0	0.0	0.0	2.0	0.0000000000	False
detected years and years	0.0	0.0	0.0	2.0	0.0000000000	False
years after their software	0.0	0.0	0.0	2.0	0.0000000000	False
software is been commissioned	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms of the source	0.0	0.0	0.0	2.0	0.0000000000	False
contained so in fact	0.0	0.0	0.0	2.0	0.0000000000	False
efficiency and such consideration	0.0	0.0	0.0	2.0	0.0000000000	False
thing because it includes	0.0	0.0	0.0	2.0	0.0000000000	False
maintainability of the software	0.0	0.0	0.0	2.0	0.0000000000	False
persons who have written	0.0	0.0	0.0	2.0	0.0000000000	False
software so the software	0.0	0.0	0.0	2.0	0.0000000000	False
means that the source	0.0	0.0	0.0	2.0	0.0000000000	False
thing the second thing	0.0	0.0	0.0	2.0	0.0000000000	False
users use their piece	0.0	0.0	0.0	2.0	0.0000000000	False
adding some more conveniences	0.0	0.0	0.0	2.0	0.0000000000	False
part of the maintainability	0.0	0.0	0.0	2.0	0.0000000000	False
maintainability of a piece	0.0	0.0	0.0	2.0	0.0000000000	False
extensibility of the software	0.0	0.0	0.0	2.0	0.0000000000	False
original team that wrote	0.0	0.0	0.0	2.0	0.0000000000	False
abstraction the basic abstraction	0.0	0.0	0.0	2.0	0.0000000000	False
aware of the control	0.0	0.0	0.0	2.0	0.0000000000	False
control abstractions or things	0.0	0.0	0.0	2.0	0.0000000000	False
things like procedures functions	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of control abstractions	0.0	0.0	0.0	2.0	0.0000000000	False
primitive kind of data	0.0	0.0	0.0	2.0	0.0000000000	False
kind of data abstraction	0.0	0.0	0.0	2.0	0.0000000000	False
arrays are one data	0.0	0.0	0.0	2.0	0.0000000000	False
data abstraction that means	0.0	0.0	0.0	2.0	0.0000000000	False
logical unit um records	0.0	0.0	0.0	2.0	0.0000000000	False
unit um records variant	0.0	0.0	0.0	2.0	0.0000000000	False
ability to take sets	0.0	0.0	0.0	2.0	0.0000000000	False
single unit so combinations	0.0	0.0	0.0	2.0	0.0000000000	False
operations and data abstractions	0.0	0.0	0.0	2.0	0.0000000000	False
languages like ml ada	0.0	0.0	0.0	2.0	0.0000000000	False
ada provide the notion	0.0	0.0	0.0	2.0	0.0000000000	False
variables and change types	0.0	0.0	0.0	2.0	0.0000000000	False
change types and instantiate	0.0	0.0	0.0	2.0	0.0000000000	False
instantiate the same kinds	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms for example stacks	0.0	0.0	0.0	2.0	0.0000000000	False
talking of a stack	0.0	0.0	0.0	2.0	0.0000000000	False
stack of some record	0.0	0.0	0.0	2.0	0.0000000000	False
things the basic operation	0.0	0.0	0.0	2.0	0.0000000000	False
basic operation on stacks	0.0	0.0	0.0	2.0	0.0000000000	False
stacks are like pop	0.0	0.0	0.0	2.0	0.0000000000	False
push checking for emptiness	0.0	0.0	0.0	2.0	0.0000000000	False
repeat the code depending	0.0	0.0	0.0	2.0	0.0000000000	False
depending on the type	0.0	0.0	0.0	2.0	0.0000000000	False
type of the element	0.0	0.0	0.0	2.0	0.0000000000	False
element of the stack	0.0	0.0	0.0	2.0	0.0000000000	False
code carefully written verified	0.0	0.0	0.0	2.0	0.0000000000	False
right so the support	0.0	0.0	0.0	2.0	0.0000000000	False
important modern language design	0.0	0.0	0.0	2.0	0.0000000000	False
modern language design issue	0.0	0.0	0.0	2.0	0.0000000000	False
programs so the language	0.0	0.0	0.0	2.0	0.0000000000	False
language should also provide	0.0	0.0	0.0	2.0	0.0000000000	False
provide support for verification	0.0	0.0	0.0	2.0	0.0000000000	False
support for verification provability	0.0	0.0	0.0	2.0	0.0000000000	False
verification provability of programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs not necessarily machine	0.0	0.0	0.0	2.0	0.0000000000	False
necessarily machine based provability	0.0	0.0	0.0	2.0	0.0000000000	False
provability but possibly hand	0.0	0.0	0.0	2.0	0.0000000000	False
possibly hand based provability	0.0	0.0	0.0	2.0	0.0000000000	False
provability or a mixture	0.0	0.0	0.0	2.0	0.0000000000	False
mixture or a user	0.0	0.0	0.0	2.0	0.0000000000	False
interactive provability of programs	0.0	0.0	0.0	2.0	0.0000000000	False
sixties where a lot	0.0	0.0	0.0	2.0	0.0000000000	False
expended in the case	0.0	0.0	0.0	2.0	0.0000000000	False
fortan and cobol compilers	0.0	0.0	0.0	2.0	0.0000000000	False
cobol compilers was portability	0.0	0.0	0.0	2.0	0.0000000000	False
means what it means	0.0	0.0	0.0	2.0	0.0000000000	False
oriented towards an end	0.0	0.0	0.0	2.0	0.0000000000	False
architecture or machine independent	0.0	0.0	0.0	4.0	0.0000000000	False
machine independent or machine	0.0	0.0	0.0	2.0	0.0000000000	False
kind of assembly instruction	0.0	0.0	0.0	2.0	0.0000000000	False
related to the machine	0.0	0.0	0.0	2.0	0.0000000000	False
machines if you ensure	0.0	0.0	0.0	2.0	0.0000000000	False
ensure that you language	0.0	0.0	0.0	2.0	0.0000000000	False
language is really architecture	0.0	0.0	0.0	2.0	0.0000000000	False
independent in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that your main	0.0	0.0	0.0	2.0	0.0000000000	False
convenience the abstractions required	0.0	0.0	0.0	2.0	0.0000000000	False
required for the user	0.0	0.0	0.0	2.0	0.0000000000	False
specific to particular machine	0.0	0.0	0.0	2.0	0.0000000000	False
sets of particular architecture	0.0	0.0	0.0	2.0	0.0000000000	False
based architectures or stack	0.0	0.0	0.0	2.0	0.0000000000	False
architectures or stack based	0.0	0.0	0.0	2.0	0.0000000000	False
architecture specific or machine	0.0	0.0	0.0	2.0	0.0000000000	False
move the entire language	0.0	0.0	0.0	2.0	0.0000000000	False
language to another machine	0.0	0.0	0.0	2.0	0.0000000000	False
minimum amount of effort	0.0	0.0	0.0	2.0	0.0000000000	False
changed when i move	0.0	0.0	0.0	2.0	0.0000000000	False
move an entire language	0.0	0.0	0.0	2.0	0.0000000000	False
implementation from one machine	0.0	0.0	0.0	2.0	0.0000000000	False
idea of the language	0.0	0.0	0.0	2.0	0.0000000000	False
design or the design	0.0	0.0	0.0	2.0	0.0000000000	False
design of its implementation	0.0	0.0	0.0	2.0	0.0000000000	False
ease of the implementation	0.0	0.0	0.0	4.0	0.0000000000	False
availability of ready algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
ready algorithms for implementing	0.0	0.0	0.0	2.0	0.0000000000	False
reason for the success	0.0	0.0	0.0	2.0	0.0000000000	False
reason c c programs	0.0	0.0	0.0	2.0	0.0000000000	False
implementers trying to implement	0.0	0.0	0.0	2.0	0.0000000000	False
syntax common clear semantics	0.0	0.0	0.0	2.0	0.0000000000	False
semantics or the specification	0.0	0.0	0.0	2.0	0.0000000000	False
effects of each language	0.0	0.0	0.0	2.0	0.0000000000	False
language construct each construct	0.0	0.0	0.0	2.0	0.0000000000	False
construct in the language	0.0	0.0	0.0	2.0	0.0000000000	False
programs have to run	0.0	0.0	0.0	2.0	0.0000000000	False
efficiency of the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
means compile time efficiency	0.0	0.0	0.0	2.0	0.0000000000	False
fast can you compile	0.0	0.0	0.0	2.0	0.0000000000	False
written in the language	0.0	0.0	3.99633699634	10.0	0.3824362606	False
language whereas this runtime	0.0	0.0	0.0	2.0	0.0000000000	False
support and the program	0.0	0.0	0.0	2.0	0.0000000000	False
fast as the programs	0.0	0.0	0.0	2.0	0.0000000000	False
run fast yeah ease	0.0	0.0	0.0	2.0	0.0000000000	False
talking about the maintenance	0.0	0.0	0.0	2.0	0.0000000000	False
maintenance of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language by an implementation	0.0	0.0	0.0	2.0	0.0000000000	False
maintenance of the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
implementation of the language	0.0	0.0	0.0	4.0	0.0000000000	False
bugs in the language	0.0	0.0	0.0	2.0	0.0000000000	False
compilation translation and support	0.0	0.0	0.0	2.0	0.0000000000	False
language should support subsets	0.0	0.0	0.0	2.0	0.0000000000	False
subsets of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
smaller set of operations	0.0	0.0	0.0	2.0	0.0000000000	False
features of the language	0.0	0.0	0.0	2.0	0.0000000000	False
divide up the language	0.0	0.0	0.0	2.0	0.0000000000	False
large sort of extensions	0.0	0.0	0.0	2.0	0.0000000000	False
kernel any way run	0.0	0.0	0.0	2.0	0.0000000000	False
run on all machines	0.0	0.0	0.0	2.0	0.0000000000	False
subsets and their reasons	0.0	0.0	0.0	2.0	0.0000000000	False
portability of programs written	0.0	0.0	0.0	2.0	0.0000000000	False
important language for embedded	0.0	0.0	0.0	2.0	0.0000000000	False
language for embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
systems that control sensors	0.0	0.0	0.0	2.0	0.0000000000	False
control sensors various kinds	0.0	0.0	0.0	2.0	0.0000000000	False
affects it could affect	0.0	0.0	0.0	2.0	0.0000000000	False
program to another implementation	0.0	0.0	0.0	2.0	0.0000000000	False
feature like your programs	0.0	0.0	0.0	2.0	0.0000000000	False
right so the portability	0.0	0.0	0.0	2.0	0.0000000000	False
portability of actually programs	0.0	0.0	0.0	2.0	0.0000000000	False
divide up the study	0.0	0.0	0.0	2.0	0.0000000000	False
study of programming languages	0.0	0.0	0.0	2.0	0.0000000000	False
theory of programming languages	0.0	0.0	0.0	4.0	0.0000000000	False
general theory of programming	0.0	0.0	0.0	2.0	0.0000000000	False
programming languages is based	0.0	0.0	0.0	2.0	0.0000000000	False
based on three things	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of the language	0.0	0.0	0.0	2.0	0.0000000000	True
highly simplified natural language	0.0	0.0	0.0	2.0	0.0000000000	False
right so which means	0.0	0.0	0.0	2.0	0.0000000000	False
sentences of the language	0.0	0.0	2.99633699634	10.0	0.4251968504	False
written in that language	0.0	0.0	0.0	2.0	0.0000000000	False
languageit has various parts	0.0	0.0	0.0	2.0	0.0000000000	False
languages all natural languages	0.0	0.0	0.0	2.0	0.0000000000	False
natural languages one thing	0.0	0.0	0.0	2.0	0.0000000000	False
syntactic category called predicates	0.0	0.0	0.0	2.0	0.0000000000	False
clause or a phrase	0.0	0.0	0.0	2.0	0.0000000000	False
subject too in addition	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in natural language	0.0	0.0	0.0	2.0	0.0000000000	False
predicate no complete sentence	0.0	0.0	0.0	2.0	0.0000000000	False
predicate ok so run	0.0	0.0	0.0	2.0	0.0000000000	False
subject well subject phrases	0.0	0.0	0.0	2.0	0.0000000000	False
phrases may be noun	0.0	0.0	0.0	2.0	0.0000000000	False
noun phrases which means	0.0	0.0	0.0	2.0	0.0000000000	False
nouns qualified by object	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of this programming	0.0	0.0	0.0	2.0	0.0000000000	False
programming language and parse	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of these things	0.0	0.0	0.0	2.0	0.0000000000	False
similarities with natural language	0.0	0.0	0.0	2.0	0.0000000000	False
lot of the theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory of the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
syntax was actually inspired	0.0	0.0	0.0	2.0	0.0000000000	False
inspired by natural languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages where the construction	0.0	0.0	0.0	2.0	0.0000000000	False
construction of artificial languages	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of a programming	0.0	0.0	0.0	2.0	0.0000000000	False
study of pascal programming	0.0	0.0	0.0	2.0	0.0000000000	False
iso standard pascal reference	0.0	0.0	0.0	2.0	0.0000000000	False
reference manual by janson	0.0	0.0	0.0	2.0	0.0000000000	False
manual by janson edward	0.0	0.0	0.0	2.0	0.0000000000	False
reference manual really specifies	0.0	0.0	0.0	2.0	0.0000000000	False
effect to be expected	0.0	0.0	0.0	2.0	0.0000000000	False
executing that syntactic entity	0.0	0.0	0.0	2.0	0.0000000000	False
natural language the notion	0.0	0.0	0.0	2.0	0.0000000000	False
mathematically in a machine	0.0	0.0	0.0	2.0	0.0000000000	False
talking about this semantics	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of this programming	0.0	0.0	0.0	2.0	0.0000000000	False
language we are talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking about a pure	0.0	0.0	0.0	2.0	0.0000000000	False
general we are talking	0.0	0.0	0.0	2.0	0.0000000000	False
meanings in a abstract	0.0	0.0	0.0	2.0	0.0000000000	False
settings in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that you assume	0.0	0.0	0.0	2.0	0.0000000000	False
restrictions on the word	0.0	0.0	0.0	2.0	0.0000000000	False
restrictions on computational power	0.0	0.0	0.0	2.0	0.0000000000	False
finite number of operations	0.0	0.0	5.9978021978	6.0	0.0000000000	False
operations at any instance	0.0	0.0	0.0	2.0	0.0000000000	False
right so you assume	0.0	0.0	0.0	2.0	0.0000000000	False
semantic the programming language	0.0	0.0	0.0	2.0	0.0000000000	False
thinking of some kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of an ideal	0.0	0.0	0.0	2.0	0.0000000000	False
restrictions except one restriction	0.0	0.0	0.0	2.0	0.0000000000	False
operations can be performed	0.0	0.0	0.0	2.0	0.0000000000	False
infinite number of operations	0.0	0.0	0.0	2.0	0.0000000000	False
entity in some ideal	0.0	0.0	0.0	2.0	0.0000000000	False
constructs of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language in that ideal	0.0	0.0	0.0	2.0	0.0000000000	False
independent of any machine	0.0	0.0	0.0	2.0	0.0000000000	False
language as an entity	0.0	0.0	0.0	2.0	0.0000000000	False
devoid of any machine	0.0	0.0	0.0	2.0	0.0000000000	False
general the semantics follow	0.0	0.0	0.0	2.0	0.0000000000	False
semantics follow the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
semantics so the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
elements and some compound	0.0	0.0	0.0	2.0	0.0000000000	False
operations they are connectives	0.0	0.0	0.0	2.0	0.0000000000	False
meanings of the connectives	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of programs	0.0	0.0	0.0	2.0	0.0000000000	False
discipline that you express	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the effect	0.0	0.0	0.0	2.0	0.0000000000	False
elements of the language	0.0	0.0	0.0	4.0	0.0000000000	False
general possible to predict	0.0	0.0	0.0	2.0	0.0000000000	False
behavior of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language of a program	0.0	0.0	0.0	2.0	0.0000000000	False
language unless you follow	0.0	0.0	0.0	2.0	0.0000000000	False
feature of any kind	0.0	0.0	0.0	2.0	0.0000000000	False
derivation of the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
infinite number of programs	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of the program	0.0	0.0	0.0	4.0	0.0000000000	False
complex elements are formed	0.0	0.0	0.0	2.0	0.0000000000	False
formed so the meaning	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
elements and the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
formed a complex element	0.0	0.0	0.0	2.0	0.0000000000	False
means is that semantics	0.0	0.0	0.0	2.0	0.0000000000	False
related to the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
set of allowable objects	0.0	0.0	0.0	4.0	0.0000000000	False
objects are the programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language or the sentences	0.0	0.0	0.0	2.0	0.0000000000	False
language and the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
syntax gives you finitary	0.0	0.0	0.0	2.0	0.0000000000	False
notation right the set	0.0	0.0	0.0	2.0	0.0000000000	False
right the set builder	0.0	0.0	0.0	2.0	0.0000000000	False
give a finitary specification	0.0	0.0	0.0	2.0	0.0000000000	False
program is its structure	0.0	0.0	0.0	2.0	0.0000000000	False
terms of its syntax	0.0	0.0	0.0	2.0	0.0000000000	False
syntax the finitary specification	0.0	0.0	0.0	2.0	0.0000000000	False
specification so the meaning	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of a language	0.0	0.0	0.0	2.0	0.0000000000	False
sort of an ideal	0.0	0.0	0.0	2.0	0.0000000000	False
worry about machine constraints	0.0	0.0	0.0	2.0	0.0000000000	False
worry about word lengths	0.0	0.0	0.0	2.0	0.0000000000	False
worry about limits don	0.0	0.0	0.0	2.0	0.0000000000	False
worry about memory constraints	0.0	0.0	0.0	2.0	0.0000000000	False
constraints assume infinite amount	0.0	0.0	0.0	2.0	0.0000000000	False
infinite amount of memory	0.0	0.0	0.0	2.0	0.0000000000	False
features are really pragmatics	0.0	0.0	0.0	2.0	0.0000000000	False
associate a disc file	0.0	0.0	0.0	2.0	0.0000000000	False
file variable in side	0.0	0.0	0.0	2.0	0.0000000000	False
feature which will vary	0.0	0.0	0.0	2.0	0.0000000000	False
depending upon the operating	0.0	0.0	0.0	2.0	0.0000000000	False
firstly um firstly involves	0.0	0.0	0.0	2.0	0.0000000000	False
machine and architectural constraints	0.0	0.0	0.0	2.0	0.0000000000	False
maxint the maximum integer	0.0	0.0	0.0	2.0	0.0000000000	False
typically implementation dependant feature	0.0	0.0	0.0	2.0	0.0000000000	False
depends upon word length	0.0	0.0	0.0	2.0	0.0000000000	False
word length or byte	0.0	0.0	0.0	2.0	0.0000000000	False
length or byte length	0.0	0.0	0.0	2.0	0.0000000000	False
length or um byte	0.0	0.0	0.0	2.0	0.0000000000	False
two bytes for representing	0.0	0.0	0.0	2.0	0.0000000000	False
right so the value	0.0	0.0	0.0	2.0	0.0000000000	False
value of the maxint	0.0	0.0	0.0	2.0	0.0000000000	False
machine or a register	0.0	0.0	0.0	2.0	0.0000000000	False
machine um those things	0.0	0.0	0.0	2.0	0.0000000000	False
implement um those things	0.0	0.0	0.0	2.0	0.0000000000	False
things are implementation dependent	0.0	0.0	0.0	2.0	0.0000000000	False
portable we will separate	0.0	0.0	0.0	2.0	0.0000000000	False
out the basic algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
basic algorithms of implementation	0.0	0.0	0.0	2.0	0.0000000000	False
nature of the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
features the actual code	0.0	0.0	0.0	2.0	0.0000000000	False
nature of the input	0.0	0.0	0.0	2.0	0.0000000000	False
file based terminal based	0.0	0.0	0.0	2.0	0.0000000000	False
based terminal based sensor	0.0	0.0	0.0	2.0	0.0000000000	False
terminal based sensor based	0.0	0.0	0.0	2.0	0.0000000000	False
includes the file server	0.0	0.0	0.0	2.0	0.0000000000	False
server how the language	0.0	0.0	0.0	2.0	0.0000000000	False
language has to interact	0.0	0.0	0.0	4.0	0.0000000000	False
interact with the file	0.0	0.0	0.0	2.0	0.0000000000	False
general with the directory	0.0	0.0	0.0	2.0	0.0000000000	False
service of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
errors and by errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors i mean errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors written by errors	0.0	0.0	0.0	2.0	0.0000000000	False
written by errors introduced	0.0	0.0	0.0	2.0	0.0000000000	False
errors introduced by users	0.0	0.0	0.0	2.0	0.0000000000	False
users in their programs	0.0	0.0	0.0	2.0	0.0000000000	False
errors as a blanket	0.0	0.0	0.0	2.0	0.0000000000	False
nature of the error	0.0	0.0	0.0	2.0	0.0000000000	False
throw out the program	0.0	0.0	0.0	2.0	0.0000000000	False
out all the errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors in the program	0.0	0.0	0.0	2.0	0.0000000000	False
things that are errors	0.0	0.0	0.0	2.0	0.0000000000	False
amount of compilation effort	0.0	0.0	0.0	2.0	0.0000000000	False
decent error reporting mechanism	0.0	0.0	0.0	2.0	0.0000000000	False
reporting mechanism some error	0.0	0.0	0.0	2.0	0.0000000000	False
mechanism some error handling	0.0	0.0	0.0	2.0	0.0000000000	False
policy and different languages	0.0	0.0	0.0	2.0	0.0000000000	False
implementations take different attitudes	0.0	0.0	0.0	2.0	0.0000000000	False
study all three issues	0.0	0.0	0.0	2.0	0.0000000000	False
semantic and pragmatic issues	0.0	0.0	0.0	2.0	0.0000000000	False
issues will closely depend	0.0	0.0	0.0	2.0	0.0000000000	False
depend upon the syntax	0.0	0.0	0.0	4.0	0.0000000000	False
preferable that they depend	0.0	0.0	0.0	2.0	0.0000000000	False
possibly an abstract object	0.0	0.0	0.0	2.0	0.0000000000	False
century attitude towards numbers	0.0	0.0	0.0	2.0	0.0000000000	False
conception of the mind	0.0	0.0	0.0	2.0	0.0000000000	False
representation in the form	0.0	0.0	0.0	2.0	0.0000000000	False
representing the same number	0.0	0.0	0.0	2.0	0.0000000000	False
hexadecimal and i hope	0.0	0.0	0.0	2.0	0.0000000000	False
representations of the number	0.0	0.0	0.0	2.0	0.0000000000	False
differs from the theonagri	0.0	0.0	0.0	2.0	0.0000000000	False
representation in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that the characters	0.0	0.0	0.0	2.0	0.0000000000	False
positional representation of numbers	0.0	0.0	0.0	2.0	0.0000000000	False
unified by the fact	0.0	0.0	0.0	2.0	0.0000000000	False
representations yeah positional representations	0.0	0.0	0.0	2.0	0.0000000000	False
positional representations i hope	0.0	0.0	0.0	2.0	0.0000000000	False
numerals which is non	0.0	0.0	0.0	2.0	0.0000000000	False
alphabet you could represent	0.0	0.0	0.0	2.0	0.0000000000	False
difference about this representation	0.0	0.0	0.0	2.0	0.0000000000	False
change in character set	0.0	0.0	0.0	2.0	0.0000000000	False
character set what makes	0.0	0.0	0.0	2.0	0.0000000000	False
two ok what make	0.0	0.0	0.0	2.0	0.0000000000	False
makes these two classes	0.0	0.0	0.0	2.0	0.0000000000	False
numeral of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language used for representing	0.0	0.0	0.0	2.0	0.0000000000	False
identical the character sets	0.0	0.0	0.0	2.0	0.0000000000	False
sets but the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
compound forms from simpler	0.0	0.0	0.0	2.0	0.0000000000	False
forms from simpler forms	0.0	0.0	0.0	2.0	0.0000000000	False
roman and arabic case	0.0	0.0	0.0	2.0	0.0000000000	False
setting of the programming	0.0	0.0	0.0	2.0	0.0000000000	False
call a complete dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
complete dictionary of words	0.0	0.0	0.0	2.0	0.0000000000	False
words of the language	0.0	0.0	0.0	4.0	0.0000000000	False
language and a word	0.0	0.0	0.0	2.0	0.0000000000	False
word of a language	0.0	0.0	0.0	2.0	0.0000000000	False
formed from a character	0.0	0.0	0.0	2.0	0.0000000000	False
set from a fixed	0.0	0.0	0.0	2.0	0.0000000000	False
words as allowable words	0.0	0.0	0.0	2.0	0.0000000000	False
allowable words as part	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary of the language	0.0	0.0	0.0	4.0	0.0000000000	False
dictionary of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language is what constitutes	0.0	0.0	0.0	4.0	0.0000000000	False
natural languages like konkani	0.0	0.0	0.0	2.0	0.0000000000	False
written by different people	0.0	0.0	0.0	2.0	0.0000000000	False
people some people write	0.0	0.0	0.0	2.0	0.0000000000	False
people write in devanagri	0.0	0.0	0.0	2.0	0.0000000000	False
devanagri some people write	0.0	0.0	0.0	2.0	0.0000000000	False
script the arabic script	0.0	0.0	0.0	2.0	0.0000000000	False
collection of the words	0.0	0.0	0.0	2.0	0.0000000000	False
person who knows devanagri	0.0	0.0	0.0	2.0	0.0000000000	False
communicate with the person	0.0	0.0	0.0	2.0	0.0000000000	False
urdu script by speech	0.0	0.0	0.0	2.0	0.0000000000	False
speech because the words	0.0	0.0	0.0	2.0	0.0000000000	False
fixed collection of words	0.0	0.0	0.0	2.0	0.0000000000	False
words whose actual form	0.0	0.0	0.0	2.0	0.0000000000	False
actual form might depend	0.0	0.0	0.0	2.0	0.0000000000	False
depend on the character	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary there are ways	0.0	0.0	0.0	2.0	0.0000000000	False
ways of combining words	0.0	0.0	0.0	2.0	0.0000000000	False
language to form sentences	0.0	0.0	0.0	2.0	0.0000000000	False
finite set of formation	0.0	0.0	0.0	2.0	0.0000000000	False
set of formation rules	0.0	0.0	0.0	2.0	0.0000000000	False
rules are called productions	0.0	0.0	0.0	2.0	0.0000000000	False
generate all possible sentences	0.0	0.0	0.0	2.0	0.0000000000	False
sentences in the language	0.0	0.0	0.0	2.0	0.0000000000	False
character set really depends	0.0	0.0	0.0	2.0	0.0000000000	False
depends upon the kind	0.0	0.0	0.0	2.0	0.0000000000	False
codes you use nowadays	0.0	0.0	0.0	2.0	0.0000000000	False
pcs and seven bit	0.0	0.0	0.0	2.0	0.0000000000	False
main frame the character	0.0	0.0	0.0	2.0	0.0000000000	False
frame the character sets	0.0	0.0	0.0	2.0	0.0000000000	False
constitutes the a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
four tuple of objects	0.0	0.0	0.0	2.0	0.0000000000	False
set of non terminals	0.0	0.0	3.9978021978	6.0	0.0000000000	False
terminals and this set	0.0	0.0	0.0	2.0	0.0000000000	False
non terminals really specifies	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of grammatical categories	0.0	0.0	0.0	2.0	0.0000000000	False
categories of the language	0.0	0.0	0.0	2.0	0.0000000000	False
parts of speech noun	0.0	0.0	0.0	2.0	0.0000000000	False
speech noun phrase verb	0.0	0.0	0.0	2.0	0.0000000000	False
noun phrase verb phrase	0.0	0.0	0.0	2.0	0.0000000000	False
phrase verb phrase adjectival	0.0	0.0	0.0	2.0	0.0000000000	False
verb phrase adjectival phrase	0.0	0.0	0.0	2.0	0.0000000000	False
phrase adjectival phrase noun	0.0	0.0	0.0	2.0	0.0000000000	False
adjectival phrase noun clause	0.0	0.0	0.0	2.0	0.0000000000	False
phrase noun clause subject	0.0	0.0	0.0	2.0	0.0000000000	False
noun clause subject clauses	0.0	0.0	0.0	2.0	0.0000000000	False
clause subject clauses subject	0.0	0.0	0.0	2.0	0.0000000000	False
subject clauses subject phrases	0.0	0.0	0.0	2.0	0.0000000000	False
clauses subject phrases object	0.0	0.0	0.0	2.0	0.0000000000	False
subject phrases object clauses	0.0	0.0	0.0	2.0	0.0000000000	False
phrases object clauses predicates	0.0	0.0	0.0	2.0	0.0000000000	False
symbols or terminal words	0.0	0.0	0.0	2.0	0.0000000000	False
collection of formation rules	0.0	0.0	0.0	2.0	0.0000000000	False
represents a grammatical category	0.0	0.0	0.0	2.0	0.0000000000	False
grammar specifying boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
symbol s every grammar	0.0	0.0	0.0	2.0	0.0000000000	False
categories the grammatical categories	0.0	0.0	0.0	2.0	0.0000000000	False
stand for an add	0.0	0.0	0.0	2.0	0.0000000000	False
expression or a complement	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary of this language	0.0	0.0	0.0	2.0	0.0000000000	False
left and right parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
productions from the start	0.0	0.0	0.0	2.0	0.0000000000	False
belonging to this set	0.0	0.0	0.0	2.0	0.0000000000	False
set of boolean variables	0.0	0.0	0.0	2.0	0.0000000000	False
expression so the sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of this languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages are boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
fully parenthesized boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions an and clause	0.0	0.0	0.0	2.0	0.0000000000	False
two boolean expressions enclosed	0.0	0.0	0.0	4.0	0.0000000000	False
expressions enclosed in parenthesis	0.0	0.0	0.0	4.0	0.0000000000	False
separated by the word	0.0	0.0	0.0	2.0	0.0000000000	False
variables whenever you find	0.0	0.0	0.0	2.0	0.0000000000	False
sentence generation you start	0.0	0.0	0.0	2.0	0.0000000000	False
replacing i have circled	0.0	0.0	0.0	2.0	0.0000000000	False
replacing this s leaving	0.0	0.0	0.0	2.0	0.0000000000	False
leaving everything else intact	0.0	0.0	0.0	2.0	0.0000000000	False
chosen here to replace	0.0	0.0	0.0	2.0	0.0000000000	False
possibility is to replace	0.0	0.0	0.0	2.0	0.0000000000	False
chosen it to replace	0.0	0.0	0.0	2.0	0.0000000000	False
two and i proceed	0.0	0.0	0.0	2.0	0.0000000000	False
proceed in this fashion	0.0	0.0	0.0	2.0	0.0000000000	False
generated by this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
talk of a language	0.0	0.0	0.0	2.0	0.0000000000	False
language as being generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated from a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar as a set	0.0	0.0	0.0	2.0	0.0000000000	False
generated from the start	0.0	0.0	0.0	4.0	0.0000000000	False
symbol s important warnings	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and the set	0.0	0.0	0.0	2.0	0.0000000000	False
set of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
disjoint and a production	0.0	0.0	0.0	2.0	0.0000000000	False
terminal by a string	0.0	0.0	0.0	2.0	0.0000000000	False
string consisting of terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals or non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals yeah and sentence	0.0	0.0	0.0	2.0	0.0000000000	False
string of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t.delhi	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t.delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
i.i.t.delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
today we will continue	0.0	0.0	0.0	2.0	0.0000000000	False
grammar on last lecture	0.0	0.0	0.0	2.0	0.0000000000	False
symbols or grammatical categories	0.0	0.0	0.0	2.0	0.0000000000	False
set of terminal symbols	0.0	0.0	2.99261311173	16.0	0.3793103448	False
symbols which usually constitutes	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary of programming language	0.0	0.0	0.0	2.0	0.0000000000	False
finite collection of formation	0.0	0.0	0.0	2.0	0.0000000000	False
collection of formation rules	0.0	0.0	0.0	2.0	0.0000000000	False
formation rules or productions	0.0	0.0	0.0	2.0	0.0000000000	False
replacement and a start	0.0	0.0	0.0	2.0	0.0000000000	False
symbol which really signifies	0.0	0.0	0.0	2.0	0.0000000000	False
signifies the grammatical category	0.0	0.0	0.0	2.0	0.0000000000	False
category called a sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of the language	0.0	0.0	0.0	4.0	0.0000000000	False
language of a language	0.0	0.0	0.0	2.0	0.0000000000	False
generation of boolean expression	0.0	0.0	0.0	2.0	0.0000000000	False
set of non terminals	0.0	0.0	2.9972299169	6.0	0.0000000000	False
essentially the and expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions the v stands	0.0	0.0	0.0	2.0	0.0000000000	False
stands for or expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions the c stand	0.0	0.0	0.0	2.0	0.0000000000	False
stand for conditional exp	0.0	0.0	0.0	2.0	0.0000000000	False
conditional exp um complement	0.0	0.0	0.0	2.0	0.0000000000	False
exp um complement expressions	0.0	0.0	0.0	2.0	0.0000000000	False
symbol the terminal set	0.0	0.0	0.0	2.0	0.0000000000	False
open and close parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis and the connectives	0.0	0.0	0.0	2.0	0.0000000000	False
black for terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
categories are a level	0.0	0.0	0.0	2.0	0.0000000000	False
green um light green	0.0	0.0	0.0	2.0	0.0000000000	False
green for some things	0.0	0.0	0.0	2.0	0.0000000000	False
string of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
symbols can be generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated from this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
cases i have circled	0.0	0.0	0.0	2.0	0.0000000000	False
number of other sentences	0.0	0.0	0.0	4.0	0.0000000000	False
sentences you will generate	0.0	0.0	0.0	2.0	0.0000000000	False
generate a large number	0.0	0.0	0.0	2.0	0.0000000000	False
case of this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
generate an infinite set	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of sentences	0.0	0.0	0.0	2.0	0.0000000000	False
set a large part	0.0	0.0	0.0	2.0	0.0000000000	False
large part of computer	0.0	0.0	0.0	2.0	0.0000000000	False
part of computer science	0.0	0.0	0.0	2.0	0.0000000000	False
science mathematics and logic	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and the set	0.0	0.0	0.0	2.0	0.0000000000	False
symbols should be disjoint	0.0	0.0	0.0	2.0	0.0000000000	False
binary relation from non	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols to strings	0.0	0.0	0.0	2.0	0.0000000000	False
right so the replacement	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbol and replace	0.0	0.0	0.0	2.0	0.0000000000	False
replace that this set	0.0	0.0	0.0	2.0	0.0000000000	False
generated from this set	0.0	0.0	0.0	2.0	0.0000000000	False
general for any set	0.0	0.0	0.0	2.0	0.0000000000	False
set a a star	0.0	0.0	0.0	2.0	0.0000000000	False
star is the set	0.0	0.0	0.0	2.0	0.0000000000	False
strings of finite length	0.0	0.0	0.0	4.0	0.0000000000	False
letter epsilon to denote	0.0	0.0	0.0	2.0	0.0000000000	False
set of all non	0.0	0.0	5.9972299169	6.0	0.0000000000	False
non empty strings generated	0.0	0.0	0.0	2.0	0.0000000000	False
string of zero length	0.0	0.0	0.0	2.0	0.0000000000	False
equal to a star	0.0	0.0	0.0	2.0	0.0000000000	False
star with epsilon removed	0.0	0.0	0.0	2.0	0.0000000000	False
side of the arrow	0.0	0.0	0.0	2.0	0.0000000000	False
single non terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and non terminals	0.0	0.0	5.99630655586	8.0	0.4313725490	False
grammar right a context	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive grammar has production	0.0	0.0	0.0	2.0	0.0000000000	False
grammar has production rules	0.0	0.0	0.0	2.0	0.0000000000	False
symbols you are allowed	0.0	0.0	0.0	2.0	0.0000000000	False
string of non terminals	0.0	0.0	4.9972299169	6.0	0.0000000000	False
assume we are choosing	0.0	0.0	0.0	2.0	0.0000000000	False
choosing this arbitrary string	0.0	0.0	0.0	2.0	0.0000000000	False
appears in a context	0.0	0.0	1.99630655586	8.0	0.4313725490	False
context and the rest	0.0	0.0	0.0	2.0	0.0000000000	False
appears in this context	0.0	0.0	0.0	2.0	0.0000000000	False
calling this grammar context	0.0	0.0	0.0	2.0	0.0000000000	False
non terminals and terminals	0.0	0.0	4.9972299169	6.0	0.0000000000	False
context that s appears	0.0	0.0	0.0	2.0	0.0000000000	False
uniform rule the production	0.0	0.0	0.0	2.0	0.0000000000	False
rule the production rule	0.0	0.0	0.0	2.0	0.0000000000	False
rule says that uniform	0.0	0.0	0.0	2.0	0.0000000000	False
uniform in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
replacement ok as suppose	0.0	0.0	0.0	2.0	0.0000000000	False
terminal can be replaced	0.0	0.0	0.0	2.0	0.0000000000	False
replaced by a string	0.0	0.0	0.0	2.0	0.0000000000	False
general than a context	0.0	0.0	0.0	2.0	0.0000000000	False
context free grammar production	0.0	0.0	0.0	2.0	0.0000000000	False
consists of the empty	0.0	0.0	0.0	4.0	0.0000000000	False
worry about some simpler	0.0	0.0	0.0	2.0	0.0000000000	False
rules in its context	0.0	0.0	0.0	2.0	0.0000000000	False
languages the language generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated by any grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar is a set	0.0	0.0	0.0	2.0	0.0000000000	False
generated from the start	0.0	0.0	0.0	4.0	0.0000000000	False
located in some context	0.0	0.0	0.0	2.0	0.0000000000	False
general we would call	0.0	0.0	0.0	2.0	0.0000000000	False
call it a language	0.0	0.0	0.0	2.0	0.0000000000	False
language on the set	0.0	0.0	0.0	2.0	0.0000000000	False
symbols and a language	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of strings	0.0	0.0	0.0	2.0	0.0000000000	False
subset of t star	0.0	0.0	0.0	4.0	0.0000000000	False
star is a language	0.0	0.0	0.0	2.0	0.0000000000	False
define on any set	0.0	0.0	0.0	2.0	0.0000000000	False
empty set for strings	0.0	0.0	0.0	2.0	0.0000000000	False
single element the empty	0.0	0.0	0.0	2.0	0.0000000000	False
element the empty string	0.0	0.0	0.0	2.0	0.0000000000	False
lot of other languages	0.0	0.0	0.0	2.0	0.0000000000	False
star as two extreme	0.0	0.0	0.0	2.0	0.0000000000	False
extreme as one extreme	0.0	0.0	0.0	2.0	0.0000000000	False
language and the language	0.0	0.0	0.0	2.0	0.0000000000	False
language containing the empty	0.0	0.0	0.0	2.0	0.0000000000	False
set of possible programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs and the problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem is of defining	0.0	0.0	0.0	2.0	0.0000000000	False
defining exactly what grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammars called regular grammars	0.0	0.0	0.0	2.0	0.0000000000	False
regular grammar every production	0.0	0.0	0.0	2.0	0.0000000000	False
form where this capital	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbol this capital	0.0	0.0	0.0	2.0	0.0000000000	False
denotes a terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbol in fact	0.0	0.0	0.0	2.0	0.0000000000	False
form then we call	0.0	0.0	0.0	2.0	0.0000000000	False
call this a right	0.0	0.0	0.0	2.0	0.0000000000	False
right linear regular grammar	0.0	0.0	4.9944598338	12.0	0.3666666667	True
first thing to realize	0.0	0.0	0.0	2.0	0.0000000000	False
difference ok a context	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar allows productions	0.0	0.0	0.0	2.0	0.0000000000	False
linear regular grammar means	0.0	0.0	0.0	2.0	0.0000000000	False
appearing in this order	0.0	0.0	0.0	2.0	0.0000000000	False
order the terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
symbol in a context	0.0	0.0	0.0	2.0	0.0000000000	False
terminal to be generated	0.0	0.0	0.0	2.0	0.0000000000	False
strings of the language	0.0	0.0	0.0	2.0	0.0000000000	False
form the terminal set	0.0	0.0	0.0	2.0	0.0000000000	False
non terminal symbols appearing	0.0	0.0	0.0	2.0	0.0000000000	False
appearing on the right	0.0	0.0	0.0	4.0	0.0000000000	False
generate a full sentence	0.0	0.0	0.0	2.0	0.0000000000	False
language so a right	0.0	0.0	0.0	2.0	0.0000000000	False
similarly you might define	0.0	0.0	0.0	2.0	0.0000000000	False
define a left linear	0.0	0.0	0.0	4.0	0.0000000000	False
left linear regular grammar	0.0	0.0	3.9972299169	6.0	0.0000000000	True
defined for example designed	0.0	0.0	0.0	2.0	0.0000000000	False
designed some hard ware	0.0	0.0	0.0	2.0	0.0000000000	False
hard ware using finite	0.0	0.0	0.0	2.0	0.0000000000	False
ware using finite state	0.0	0.0	0.0	2.0	0.0000000000	False
state machines it turns	0.0	0.0	0.0	2.0	0.0000000000	False
linear grammars actually represents	0.0	0.0	0.0	2.0	0.0000000000	False
represents finite state machines	0.0	0.0	0.0	2.0	0.0000000000	False
machines you know machines	0.0	0.0	0.0	2.0	0.0000000000	False
output i am talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking of those kinds	0.0	0.0	0.0	2.0	0.0000000000	False
right so in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact you can represent	0.0	0.0	0.0	2.0	0.0000000000	False
diagram of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
state as a non	0.0	0.0	0.0	2.0	0.0000000000	False
input symbol the input	0.0	0.0	0.0	2.0	0.0000000000	False
input into that state	0.0	0.0	0.0	2.0	0.0000000000	False
state machine automatically defines	0.0	0.0	0.0	2.0	0.0000000000	False
automatically defines a right	0.0	0.0	0.0	2.0	0.0000000000	False
defines a right linear	0.0	0.0	0.0	2.0	0.0000000000	False
machines have a start	0.0	0.0	0.0	2.0	0.0000000000	False
start symbol the start	0.0	0.0	0.0	2.0	0.0000000000	False
symbol the start symbol	0.0	0.0	0.0	2.0	0.0000000000	False
symbol is the start	0.0	0.0	0.0	2.0	0.0000000000	False
suma let us summarize	0.0	0.0	0.0	2.0	0.0000000000	False
general properties of grammars	0.0	0.0	0.0	2.0	0.0000000000	True
firstly every regular grammar	0.0	0.0	0.0	2.0	0.0000000000	False
regular grammar whether right	0.0	0.0	0.0	2.0	0.0000000000	False
grammar whether right linear	0.0	0.0	0.0	2.0	0.0000000000	False
right linear or left	0.0	0.0	0.0	4.0	0.0000000000	False
left linear every regular	0.0	0.0	0.0	2.0	0.0000000000	False
linear every regular grammar	0.0	0.0	0.0	2.0	0.0000000000	False
context free every context	0.0	0.0	0.0	4.0	0.0000000000	False
productions of the context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar can be considered	0.0	0.0	0.0	2.0	0.0000000000	False
considered in the context	0.0	0.0	0.0	2.0	0.0000000000	False
context of empty strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings on both sides	0.0	0.0	0.0	2.0	0.0000000000	False
sides of the non	0.0	0.0	0.0	2.0	0.0000000000	False
symbol then an empty	0.0	0.0	0.0	2.0	0.0000000000	False
bracket then an empty	0.0	0.0	0.0	2.0	0.0000000000	False
production as being padded	0.0	0.0	0.0	2.0	0.0000000000	False
context which contains empty	0.0	0.0	0.0	2.0	0.0000000000	False
string and the empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty string implicitly appears	0.0	0.0	0.0	2.0	0.0000000000	False
ultimately in generating languages	0.0	0.0	0.0	2.0	0.0000000000	False
language supposing that language	0.0	0.0	0.0	2.0	0.0000000000	False
language can be generated	0.0	0.0	0.0	4.0	0.0000000000	False
generated by a right	0.0	0.0	3.99630655586	8.0	0.3548387097	False
grammar which will generate	0.0	0.0	0.0	2.0	0.0000000000	False
generated by a left	0.0	0.0	3.9972299169	6.0	0.0000000000	False
left linear grammar left	0.0	0.0	0.0	2.0	0.0000000000	False
general kind of production	0.0	0.0	0.0	2.0	0.0000000000	False
star for any set	0.0	0.0	0.0	2.0	0.0000000000	False
set of all strings	0.0	0.0	0.0	4.0	0.0000000000	False
terminal symbol ok obtained	0.0	0.0	0.0	2.0	0.0000000000	False
symbol ok obtained form	0.0	0.0	0.0	2.0	0.0000000000	False
string ok the set	0.0	0.0	0.0	2.0	0.0000000000	False
cross t the set	0.0	0.0	0.0	2.0	0.0000000000	False
right so t star	0.0	0.0	0.0	2.0	0.0000000000	False
set which is obtained	0.0	0.0	0.0	2.0	0.0000000000	False
obtained as the union	0.0	0.0	0.0	2.0	0.0000000000	False
union of cartesian products	0.0	0.0	0.0	2.0	0.0000000000	False
equal to zero right	0.0	0.0	0.0	2.0	0.0000000000	False
define a binary operation	0.0	0.0	0.0	2.0	0.0000000000	False
binary operation called catenation	0.0	0.0	0.0	2.0	0.0000000000	False
catenation ok the effect	0.0	0.0	0.0	2.0	0.0000000000	False
two strings and put	0.0	0.0	0.0	2.0	0.0000000000	False
simplicity let us assume	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the set	0.0	0.0	0.0	2.0	0.0000000000	False
call those two symbols	0.0	0.0	0.0	2.0	0.0000000000	False
string in t star	0.0	0.0	0.0	4.0	0.0000000000	False
string in the set	0.0	0.0	0.0	2.0	0.0000000000	False
dot for the moment	0.0	0.0	0.0	2.0	0.0000000000	False
produce the string ababbbab	0.0	0.0	0.0	2.0	0.0000000000	False
juxtapose the two strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings the two strings	0.0	0.0	0.0	2.0	0.0000000000	False
binary operation on strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings it just puts	0.0	0.0	0.0	2.0	0.0000000000	False
puts the two strings	0.0	0.0	0.0	2.0	0.0000000000	False
string is of length	0.0	0.0	0.0	4.0	0.0000000000	False
belongs to the set	0.0	0.0	2.9972299169	6.0	0.0000000000	False
length three this belongs	0.0	0.0	0.0	2.0	0.0000000000	False
cube and this string	0.0	0.0	0.0	2.0	0.0000000000	False
star and so catenation	0.0	0.0	0.0	2.0	0.0000000000	False
operation from t star	0.0	0.0	0.0	2.0	0.0000000000	False
star cross t star	0.0	0.0	0.0	2.0	0.0000000000	False
star to t star	0.0	0.0	0.0	2.0	0.0000000000	False
finite length and juxtapose	0.0	0.0	0.0	2.0	0.0000000000	False
juxtapose an empty string	0.0	0.0	0.0	2.0	0.0000000000	False
back the same string	0.0	0.0	0.0	2.0	0.0000000000	False
juxtapose some other string	0.0	0.0	0.0	2.0	0.0000000000	False
back the other string	0.0	0.0	0.0	2.0	0.0000000000	False
string so the empty	0.0	0.0	0.0	2.0	0.0000000000	False
string satisfies these conditions	0.0	0.0	0.0	2.0	0.0000000000	False
belonging to t star	0.0	0.0	0.0	2.0	0.0000000000	False
concatenated with the empty	0.0	0.0	0.0	2.0	0.0000000000	False
catenation is juxtaposition operation	0.0	0.0	0.0	2.0	0.0000000000	False
rid of the dot	0.0	0.0	0.0	2.0	0.0000000000	False
dot in between right	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon is in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact the identity element	0.0	0.0	0.0	2.0	0.0000000000	False
identity element for catenation	0.0	0.0	0.0	2.0	0.0000000000	False
addition right secondly catenation	0.0	0.0	0.0	2.0	0.0000000000	False
associative in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
catenation and under catenation	0.0	0.0	0.0	2.0	0.0000000000	False
monoid because this operation	0.0	0.0	0.0	2.0	0.0000000000	False
arbitrary context sensitive grammar	0.0	0.0	0.0	2.0	0.0000000000	False
production of a context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar what it specifies	0.0	0.0	0.0	2.0	0.0000000000	False
appears in some context	0.0	0.0	0.0	2.0	0.0000000000	False
string so which means	0.0	0.0	0.0	2.0	0.0000000000	False
means that the context	0.0	0.0	0.0	2.0	0.0000000000	False
rewriting i can replace	0.0	0.0	0.0	2.0	0.0000000000	False
drew what this production	0.0	0.0	0.0	2.0	0.0000000000	False
large in the generation	0.0	0.0	0.0	2.0	0.0000000000	False
arbitrary string and turns	0.0	0.0	0.0	2.0	0.0000000000	False
minimal a minimal shell	0.0	0.0	0.0	2.0	0.0000000000	False
case of our context	0.0	0.0	2.9972299169	6.0	0.0000000000	False
epsilon on both sides	0.0	0.0	0.0	2.0	0.0000000000	False
appears in an empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty context which means	0.0	0.0	0.0	2.0	0.0000000000	False
means that you don	0.0	0.0	0.0	2.0	0.0000000000	False
appears on either side	0.0	0.0	0.0	2.0	0.0000000000	False
specifies the smallest kernel	0.0	0.0	0.0	2.0	0.0000000000	False
string in the generation	0.0	0.0	0.0	2.0	0.0000000000	False
occurs in the string	0.0	0.0	0.0	2.0	0.0000000000	False
replacing by this rule	0.0	0.0	0.0	2.0	0.0000000000	False
sense that this padding	0.0	0.0	0.0	2.0	0.0000000000	False
inclusive meaning of context	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of context sensitiveness	0.0	0.0	0.0	2.0	0.0000000000	False
padding around that non	0.0	0.0	0.0	2.0	0.0000000000	False
symbol which will enable	0.0	0.0	0.0	2.0	0.0000000000	False
case of a context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar the minimal padding	0.0	0.0	0.0	2.0	0.0000000000	False
rules can be thought	0.0	0.0	0.0	2.0	0.0000000000	False
thought of as rules	0.0	0.0	0.0	2.0	0.0000000000	False
rules in the context	0.0	0.0	0.0	2.0	0.0000000000	False
sides of the padding	0.0	0.0	0.0	2.0	0.0000000000	False
padding the minimal padding	0.0	0.0	0.0	2.0	0.0000000000	False
padding that you require	0.0	0.0	0.0	2.0	0.0000000000	False
require is the empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty string which means	0.0	0.0	0.0	2.0	0.0000000000	False
care what the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the string	0.0	0.0	0.0	4.0	0.0000000000	False
out that the context	0.0	0.0	0.0	2.0	0.0000000000	False
context sensitivity into account	0.0	0.0	0.0	2.0	0.0000000000	False
deal with the programming	0.0	0.0	0.0	2.0	0.0000000000	False
language as a context	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar as generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated by a context	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar and deal	0.0	0.0	0.0	2.0	0.0000000000	False
deal with a context	0.0	0.0	0.0	2.0	0.0000000000	False
typical context sensitive feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature even in languages	0.0	0.0	0.0	2.0	0.0000000000	False
check on these context	0.0	0.0	0.0	2.0	0.0000000000	False
issues ok so undeclared	0.0	0.0	0.0	2.0	0.0000000000	False
efficient algorithms to recognize	0.0	0.0	0.0	4.0	0.0000000000	False
pause context sensitive languages	0.0	0.0	0.0	2.0	0.0000000000	False
context sensitive languages represented	0.0	0.0	0.0	2.0	0.0000000000	False
pause context free grammars	0.0	0.0	0.0	2.0	0.0000000000	False
linear algorithms available linear	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms available for phrasing	0.0	0.0	0.0	2.0	0.0000000000	False
phrasing context sensitive grammars	0.0	0.0	0.0	2.0	0.0000000000	False
part of the semantics	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive aspects many people	0.0	0.0	0.0	2.0	0.0000000000	False
synonymous with the semantics	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of the language	0.0	0.0	0.0	4.0	0.0000000000	False
context sensitive every language	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive every language generated	0.0	0.0	0.0	2.0	0.0000000000	False
regular one every language	0.0	0.0	0.0	2.0	0.0000000000	False
rules may be left	0.0	0.0	0.0	2.0	0.0000000000	False
left linear such grammars	0.0	0.0	0.0	2.0	0.0000000000	False
conversion is what helps	0.0	0.0	0.0	2.0	0.0000000000	False
helps us to design	0.0	0.0	0.0	2.0	0.0000000000	False
design machines for recognizing	0.0	0.0	0.0	2.0	0.0000000000	False
machines for recognizing languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages of this grammars	0.0	0.0	0.0	2.0	0.0000000000	False
subject of the theory	0.0	0.0	0.0	2.0	0.0000000000	False
regular if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
exists a regular grammar	0.0	0.0	0.0	2.0	0.0000000000	False
regular grammar which generates	0.0	0.0	0.0	2.0	0.0000000000	False
free it there exists	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar that generates	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive grammar that generates	0.0	0.0	0.0	2.0	0.0000000000	False
language you have generated	0.0	0.0	0.0	2.0	0.0000000000	False
free but the language	0.0	0.0	0.0	2.0	0.0000000000	False
generate you have written	0.0	0.0	0.0	2.0	0.0000000000	False
written context sensitive grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar for a language	0.0	0.0	0.0	2.0	0.0000000000	False
free in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
out with a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
purely which is context	0.0	0.0	0.0	2.0	0.0000000000	False
generated by the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
long before any grammar	0.0	0.0	0.0	2.0	0.0000000000	False
large number of numerals	0.0	0.0	0.0	2.0	0.0000000000	False
notion of the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar in natural language	0.0	0.0	0.0	2.0	0.0000000000	False
language and um sanskrit	0.0	0.0	0.0	2.0	0.0000000000	False
rigorous um art form	0.0	0.0	0.0	2.0	0.0000000000	False
neat we have evolved	0.0	0.0	0.0	2.0	0.0000000000	False
evolved such neat notation	0.0	0.0	0.0	2.0	0.0000000000	False
neat notation for numbers	0.0	0.0	0.0	2.0	0.0000000000	False
numerals the terminal set	0.0	0.0	0.0	2.0	0.0000000000	False
set is the set	0.0	0.0	0.0	2.0	0.0000000000	False
require just one non	0.0	0.0	0.0	2.0	0.0000000000	False
replaced on a digit	0.0	0.0	0.0	2.0	0.0000000000	False
replaced by a digit	0.0	0.0	0.0	2.0	0.0000000000	False
nice and simple grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar which is equivalent	0.0	0.0	0.0	2.0	0.0000000000	False
sense that the romans	0.0	0.0	0.0	2.0	0.0000000000	False
romans had a pattern	0.0	0.0	0.0	2.0	0.0000000000	False
pattern in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
fifty hundred five hundred	0.0	0.0	0.0	2.0	0.0000000000	False
hundred five hundred thousand	0.0	0.0	0.0	2.0	0.0000000000	False
thousand they had symbols	0.0	0.0	0.0	2.0	0.0000000000	False
symbols also for ten	0.0	0.0	0.0	2.0	0.0000000000	False
ten thousand fifty thousand	0.0	0.0	0.0	2.0	0.0000000000	False
fifty thousand um hundred	0.0	0.0	0.0	2.0	0.0000000000	False
thousand um hundred thousand	0.0	0.0	0.0	2.0	0.0000000000	False
thousand five hundred thousand	0.0	0.0	0.0	2.0	0.0000000000	False
require if you continue	0.0	0.0	0.0	2.0	0.0000000000	False
require an infinite set	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols ok supposing	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols which means	0.0	0.0	0.0	2.0	0.0000000000	False
grammar already is violated	0.0	0.0	0.0	2.0	0.0000000000	False
ten can not precede	0.0	0.0	0.0	2.0	0.0000000000	False
sense the roman numerals	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent after all remember	0.0	0.0	0.0	2.0	0.0000000000	False
aim is to represent	0.0	0.0	0.0	2.0	0.0000000000	False
set but the language	0.0	0.0	0.0	2.0	0.0000000000	False
right so the language	0.0	0.0	0.0	2.0	0.0000000000	False
previewed for the context	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent context free grammar	0.0	0.0	0.0	2.0	0.0000000000	False
introduce a new non	0.0	0.0	0.0	2.0	0.0000000000	False
rid of the non	0.0	0.0	0.0	2.0	0.0000000000	False
quickly see that grammar	0.0	0.0	0.0	2.0	0.0000000000	False
common occurrence of left	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of left parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent way of writing	0.0	0.0	0.0	2.0	0.0000000000	False
make a grammar smaller	0.0	0.0	0.0	2.0	0.0000000000	False
grammar smaller to reduce	0.0	0.0	0.0	2.0	0.0000000000	False
number of non terminals	0.0	0.0	5.9972299169	6.0	0.0000000000	False
important thing to reduce	0.0	0.0	0.0	2.0	0.0000000000	False
parsing of the language	0.0	0.0	0.0	2.0	0.0000000000	False
depends how many non	0.0	0.0	0.0	2.0	0.0000000000	False
idea so which means	0.0	0.0	0.0	2.0	0.0000000000	False
matter of decision making	0.0	0.0	0.0	2.0	0.0000000000	False
decision making to choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose the right kind	0.0	0.0	0.0	2.0	0.0000000000	False
right kind of grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar right correct kind	0.0	0.0	0.0	2.0	0.0000000000	False
correct kind of grammar	0.0	0.0	0.0	2.0	0.0000000000	False
facilitate an easy explanation	0.0	0.0	0.0	2.0	0.0000000000	False
explanation of the semantics	0.0	0.0	0.0	2.0	0.0000000000	False
fact the arabic numerals	0.0	0.0	0.0	2.0	0.0000000000	False
numerals um the left	0.0	0.0	0.0	2.0	0.0000000000	False
linear and the right	0.0	0.0	0.0	2.0	0.0000000000	False
difference they both equivalent	0.0	0.0	0.0	2.0	0.0000000000	False
terms of actual generation	0.0	0.0	0.0	2.0	0.0000000000	False
generation but the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact of the matter	0.0	0.0	0.0	2.0	0.0000000000	False
semantics for the left	0.0	0.0	0.0	2.0	0.0000000000	False
thatn the right linear	0.0	0.0	0.0	2.0	0.0000000000	False
semantics for the right	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms actually will choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose the right linear	0.0	0.0	0.0	2.0	0.0000000000	False
linear over the left	0.0	0.0	0.0	2.0	0.0000000000	False
constraint in those parsing	0.0	0.0	0.0	2.0	0.0000000000	False
calls in this case	0.0	0.0	0.0	2.0	0.0000000000	False
case will could lead	0.0	0.0	0.0	2.0	0.0000000000	False
case they would lead	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t delhi	0.0	0.0	0.0	2.0	0.0000000000	False
technology i.i.t delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
kumar deptt of comp.sc	0.0	0.0	0.0	2.0	0.0000000000	False
today we will talk	0.0	0.0	0.0	2.0	0.0000000000	False
grammar our favorite context	0.0	0.0	0.0	2.0	0.0000000000	False
favorite context free grammar	0.0	0.0	0.0	2.0	0.0000000000	False
sentence that we generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated using this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
aim is to generate	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
out of three possibilities	0.0	0.0	0.0	2.0	0.0000000000	False
chose one in fact	0.0	0.0	0.0	2.0	0.0000000000	False
possibility will not give	0.0	0.0	0.0	2.0	0.0000000000	False
give you this sentence	0.0	0.0	0.0	4.0	0.0000000000	False
sentence ok so out	0.0	0.0	0.0	2.0	0.0000000000	False
possibility a this possibility	0.0	0.0	0.0	2.0	0.0000000000	False
generate this ultimate sentence	0.0	0.0	0.0	2.0	0.0000000000	False
essential in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
chosen this um chosen	0.0	0.0	0.0	2.0	0.0000000000	False
open bracket open bracket	0.0	0.0	0.0	2.0	0.0000000000	False
possibility of either firing	0.0	0.0	0.0	2.0	0.0000000000	False
supposing you had chosen	0.0	0.0	0.0	2.0	0.0000000000	False
derivation of a sentence	0.0	0.0	0.0	4.0	0.0000000000	False
sentence this particular order	0.0	0.0	0.0	2.0	0.0000000000	False
derivations after same sentence	0.0	0.0	0.0	2.0	0.0000000000	False
depending upon the order	0.0	0.0	0.0	2.0	0.0000000000	False
chose to apply productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions in a sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in other words	0.0	0.0	0.0	2.0	0.0000000000	False
give you various orders	0.0	0.0	0.0	2.0	0.0000000000	False
chosen any particular order	0.0	0.0	0.0	2.0	0.0000000000	False
leftmost non terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
derivations of this sentence	0.0	0.0	0.0	2.0	0.0000000000	False
talking about a context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar and the replacement	0.0	0.0	0.0	2.0	0.0000000000	False
replacement of non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals by their right	0.0	0.0	0.0	2.0	0.0000000000	False
sides in the production	0.0	0.0	0.0	2.0	0.0000000000	False
non terminal is chosen	0.0	0.0	0.0	2.0	0.0000000000	False
chosen first for replacement	0.0	0.0	0.0	2.0	0.0000000000	False
first for replacement provided	0.0	0.0	0.0	2.0	0.0000000000	False
steps in this derivation	0.0	0.0	0.0	2.0	0.0000000000	False
production you have applied	0.0	0.0	0.0	2.0	0.0000000000	False
justification which just tells	0.0	0.0	0.0	2.0	0.0000000000	False
tells you which production	0.0	0.0	0.0	2.0	0.0000000000	False
production number you applied	0.0	0.0	0.0	2.0	0.0000000000	False
essentially you could permute	0.0	0.0	0.0	2.0	0.0000000000	False
order of the productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions of these applications	0.0	0.0	0.0	2.0	0.0000000000	False
choices either an application	0.0	0.0	0.0	2.0	0.0000000000	False
productions but your intermediate	0.0	0.0	0.0	2.0	0.0000000000	False
intermediate sentences your intermediate	0.0	0.0	0.0	2.0	0.0000000000	False
sentences your intermediate sentences	0.0	0.0	0.0	2.0	0.0000000000	False
application of these productions	0.0	0.0	0.0	2.0	0.0000000000	False
derived the same sentence	0.0	0.0	0.0	2.0	0.0000000000	False
productions for the derivation	0.0	0.0	0.0	2.0	0.0000000000	False
sentences in a context	0.0	0.0	0.0	2.0	0.0000000000	False
freeness of the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
derivation by just applying	0.0	0.0	0.0	2.0	0.0000000000	False
applying the same productions	0.0	0.0	0.0	2.0	0.0000000000	False
apply is still place	0.0	0.0	0.0	2.0	0.0000000000	False
alternative but to replace	0.0	0.0	0.0	2.0	0.0000000000	False
ordering on the application	0.0	0.0	0.0	2.0	0.0000000000	False
application of the productions	0.0	0.0	0.0	4.0	0.0000000000	False
order but other productions	0.0	0.0	0.0	2.0	0.0000000000	False
collapse them to give	0.0	0.0	0.0	2.0	0.0000000000	False
independence look for independence	0.0	0.0	0.0	2.0	0.0000000000	False
draw draw a tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree of exact dependences	0.0	0.0	0.0	2.0	0.0000000000	False
dependencies in the applications	0.0	0.0	0.0	2.0	0.0000000000	False
applications of various productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions so the root	0.0	0.0	0.0	2.0	0.0000000000	False
root of the parse	0.0	0.0	0.0	2.0	0.0000000000	False
generation of this sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence the first production	0.0	0.0	0.0	2.0	0.0000000000	False
production that was applied	0.0	0.0	0.0	2.0	0.0000000000	False
symbol ok open parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
single symbol um remember	0.0	0.0	0.0	2.0	0.0000000000	False
convention that black denotes	0.0	0.0	0.0	2.0	0.0000000000	False
black denotes terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
symbols the eventual strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings that you generate	0.0	0.0	0.0	2.0	0.0000000000	False
strings in black strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language the colors denote	0.0	0.0	0.0	2.0	0.0000000000	False
colors denote um denote	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis s close parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
generated then the right	0.0	0.0	0.0	2.0	0.0000000000	False
hand s be expanded	0.0	0.0	0.0	2.0	0.0000000000	False
expanded into open parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
matter in which order	0.0	0.0	0.0	4.0	0.0000000000	False
perform these two productions	0.0	0.0	0.0	2.0	0.0000000000	False
first s should produce	0.0	0.0	0.0	2.0	0.0000000000	False
color for the productions	0.0	0.0	0.0	2.0	0.0000000000	False
call the parse tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree and the branches	0.0	0.0	0.0	2.0	0.0000000000	False
leaves of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
read if you read	0.0	0.0	0.0	2.0	0.0000000000	False
tree if you read	0.0	0.0	0.0	2.0	0.0000000000	False
sentence that you generated	0.0	0.0	0.0	2.0	0.0000000000	False
open parenthesis open parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
close parenthesis close parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree for generating	0.0	0.0	0.0	2.0	0.0000000000	False
defined for every sentence	0.0	0.0	0.0	2.0	0.0000000000	False
important from the point	0.0	0.0	0.0	2.0	0.0000000000	False
view of compiling language	0.0	0.0	0.0	2.0	0.0000000000	False
implementation from the point	0.0	0.0	0.0	2.0	0.0000000000	False
view of specifying semantics	0.0	0.0	0.0	2.0	0.0000000000	False
sacrocite and the fact	0.0	0.0	0.0	2.0	0.0000000000	False
traversing this parse parse	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree as presenting	0.0	0.0	0.0	2.0	0.0000000000	False
presenting the partial order	0.0	0.0	0.0	2.0	0.0000000000	False
order in the firing	0.0	0.0	0.0	2.0	0.0000000000	False
traversals of the parse	0.0	0.0	0.0	2.0	0.0000000000	False
tree of the sentence	0.0	0.0	0.0	2.0	0.0000000000	False
necessarily a unique derivation	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
topological sort just takes	0.0	0.0	0.0	2.0	0.0000000000	False
takes a partial order	0.0	0.0	0.0	2.0	0.0000000000	False
partial order and linearizes	0.0	0.0	0.0	2.0	0.0000000000	False
linearizes it you sort	0.0	0.0	0.0	2.0	0.0000000000	False
provide a linear order	0.0	0.0	0.0	2.0	0.0000000000	False
linear order a total	0.0	0.0	0.0	2.0	0.0000000000	False
order a total order	0.0	0.0	0.0	2.0	0.0000000000	False
partial order are maintained	0.0	0.0	0.0	2.0	0.0000000000	False
maintained but their dependencies	0.0	0.0	0.0	2.0	0.0000000000	False
dependencies do not exists	0.0	0.0	0.0	2.0	0.0000000000	False
exists you might place	0.0	0.0	0.0	2.0	0.0000000000	False
linearization of a tree	0.0	0.0	0.0	2.0	0.0000000000	False
fact for partial orders	0.0	0.0	0.0	2.0	0.0000000000	False
order is completely defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined by the set	0.0	0.0	0.0	4.0	0.0000000000	False
essentially a parsed tree	0.0	0.0	0.0	2.0	0.0000000000	False
order by the set	0.0	0.0	0.0	2.0	0.0000000000	False
traverses you can make	0.0	0.0	0.0	2.0	0.0000000000	False
property in the theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory of partial orders	0.0	0.0	0.0	2.0	0.0000000000	False
orders of that set	0.0	0.0	0.0	2.0	0.0000000000	False
syntactical in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
compiling or language def	0.0	0.0	0.0	2.0	0.0000000000	False
def um or language	0.0	0.0	0.0	2.0	0.0000000000	False
language implementation it doesn	0.0	0.0	0.0	2.0	0.0000000000	False
symbols that are coming	0.0	0.0	0.0	2.0	0.0000000000	False
symbols but any kind	0.0	0.0	0.0	2.0	0.0000000000	False
type of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
make a clear distinction	0.0	0.0	0.0	2.0	0.0000000000	False
identifier and a operator	0.0	0.0	0.0	2.0	0.0000000000	False
call a concrete parse	0.0	0.0	0.0	2.0	0.0000000000	False
tree where we make	0.0	0.0	0.0	2.0	0.0000000000	False
symbols they are leaves	0.0	0.0	0.0	2.0	0.0000000000	False
leaves of the parse	0.0	0.0	0.0	2.0	0.0000000000	False
sentence you actually make	0.0	0.0	0.0	2.0	0.0000000000	False
clear that our intention	0.0	0.0	0.0	2.0	0.0000000000	False
intention was to define	0.0	0.0	0.0	2.0	0.0000000000	False
language of boolean expressions	0.0	0.0	3.9974533107	6.0	0.0000000000	False
expressions where the operations	0.0	0.0	0.0	2.0	0.0000000000	False
distinction between the operands	0.0	0.0	0.0	2.0	0.0000000000	False
operators is what leads	0.0	0.0	0.0	2.0	0.0000000000	False
call abstract syntax tree	0.0	0.0	0.0	2.0	0.0000000000	False
syntax tree actually elevates	0.0	0.0	0.0	2.0	0.0000000000	False
tree actually elevates replaces	0.0	0.0	0.0	2.0	0.0000000000	False
elevates replaces non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
easily elevate the operators	0.0	0.0	0.0	2.0	0.0000000000	False
nodes of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree we could talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk we can talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk of a root	0.0	0.0	0.0	2.0	0.0000000000	False
syntax tree the operators	0.0	0.0	0.0	2.0	0.0000000000	False
identifiers of the operands	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
language the ultimate programming	0.0	0.0	0.0	2.0	0.0000000000	False
interested in the non	0.0	0.0	0.0	2.0	0.0000000000	False
symbols the concrete parts	0.0	0.0	0.0	2.0	0.0000000000	False
parts of the language	0.0	0.0	0.0	2.0	0.0000000000	False
real down to earth	0.0	0.0	0.0	2.0	0.0000000000	False
symbols in any programming	0.0	0.0	0.0	2.0	0.0000000000	False
language have some meaning	0.0	0.0	0.0	2.0	0.0000000000	False
bring about this distinction	0.0	0.0	0.0	2.0	0.0000000000	False
interested in what order	0.0	0.0	0.0	2.0	0.0000000000	False
operators on the operands	0.0	0.0	0.0	2.0	0.0000000000	False
reason why we included	0.0	0.0	0.0	2.0	0.0000000000	False
essential to have parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
uniform post fix notion	0.0	0.0	0.0	2.0	0.0000000000	False
notion or a uniform	0.0	0.0	0.0	2.0	0.0000000000	False
fact every language construct	0.0	0.0	0.0	2.0	0.0000000000	False
construct can be regarded	0.0	0.0	0.0	2.0	0.0000000000	False
regarded as a operator	0.0	0.0	0.0	2.0	0.0000000000	False
interested in giving meanings	0.0	0.0	0.0	2.0	0.0000000000	False
giving meanings to languages	0.0	0.0	0.0	2.0	0.0000000000	False
interested in the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
arithmetic calculations in school	0.0	0.0	0.0	2.0	0.0000000000	False
expression you can choose	0.0	0.0	0.0	2.0	0.0000000000	False
order so the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
syntax to an abstract	0.0	0.0	0.0	2.0	0.0000000000	False
tree of the expression	0.0	0.0	0.0	2.0	0.0000000000	False
oftenly using these abstract	0.0	0.0	0.0	2.0	0.0000000000	False
mind so now keeping	0.0	0.0	0.0	2.0	0.0000000000	False
mind let us define	0.0	0.0	0.0	2.0	0.0000000000	False
define a small programming	0.0	0.0	0.0	2.0	0.0000000000	False
boolean variables and expressions	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of this programming	0.0	0.0	0.0	2.0	0.0000000000	False
programs in the language	0.0	0.0	0.0	2.0	0.0000000000	False
language i can generate	0.0	0.0	0.0	2.0	0.0000000000	False
generate from the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
programs of the language	0.0	0.0	0.0	2.0	0.0000000000	False
programs we are talking	0.0	0.0	0.0	2.0	0.0000000000	False
formalizing it and giving	0.0	0.0	0.0	2.0	0.0000000000	False
giving rules production rules	0.0	0.0	0.0	2.0	0.0000000000	False
rules for the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
compiler or a translator	0.0	0.0	0.0	2.0	0.0000000000	False
translator for this language	0.0	0.0	0.0	2.0	0.0000000000	False
require to specify things	0.0	0.0	0.0	2.0	0.0000000000	False
coding of various constructs	0.0	0.0	0.0	2.0	0.0000000000	False
part of the context	0.0	0.0	0.0	2.0	0.0000000000	False
context free grammar notation	0.0	0.0	0.0	2.0	0.0000000000	False
bark of a tree	0.0	0.0	0.0	2.0	0.0000000000	False
branches of parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
coded in this color	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of entities commands	0.0	0.0	0.0	2.0	0.0000000000	False
commands and boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
brown for boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
atomic commands the assignment	0.0	0.0	0.0	2.0	0.0000000000	False
green all other compound	0.0	0.0	0.0	2.0	0.0000000000	False
program or the sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of the language	0.0	0.0	2.9974533107	6.0	0.0000000000	False
change my color coding	0.0	0.0	0.0	2.0	0.0000000000	False
coding i will inform	0.0	0.0	0.0	2.0	0.0000000000	False
language and the sentences	0.0	0.0	0.0	2.0	0.0000000000	False
sentences of this language	0.0	0.0	0.0	2.0	0.0000000000	False
language are all programs	0.0	0.0	0.0	2.0	0.0000000000	False
unlike say a language	0.0	0.0	0.0	2.0	0.0000000000	False
program in this language	0.0	0.0	0.0	2.0	0.0000000000	False
language so this rule	0.0	0.0	0.0	2.0	0.0000000000	False
specifies that a program	0.0	0.0	0.0	2.0	0.0000000000	False
program is any command	0.0	0.0	0.0	2.0	0.0000000000	False
program of this language	0.0	0.0	0.0	2.0	0.0000000000	False
command of this language	0.0	0.0	0.0	2.0	0.0000000000	False
language well a command	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of two commands	0.0	0.0	0.0	2.0	0.0000000000	False
four productions c arrow	0.0	0.0	0.0	2.0	0.0000000000	False
arrow a c arrow	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon c c arrow	0.0	0.0	0.0	2.0	0.0000000000	False
right so this bar	0.0	0.0	0.0	2.0	0.0000000000	False
specifies the various alternatives	0.0	0.0	0.0	2.0	0.0000000000	False
languages are called statement	0.0	0.0	0.0	2.0	0.0000000000	False
level this the thing	0.0	0.0	0.0	2.0	0.0000000000	False
definitions of the programming	0.0	0.0	0.0	2.0	0.0000000000	False
programming language in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of several levels	0.0	0.0	0.0	2.0	0.0000000000	False
level ok this command	0.0	0.0	0.0	2.0	0.0000000000	False
command level essentially tells	0.0	0.0	0.0	2.0	0.0000000000	False
commands from simpler commands	0.0	0.0	0.0	2.0	0.0000000000	False
command is a command	0.0	0.0	0.0	4.0	0.0000000000	False
command and the sequence	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of two sequencing	0.0	0.0	0.0	2.0	0.0000000000	False
simple or compound commands	0.0	0.0	0.0	2.0	0.0000000000	False
blue this semi colon	0.0	0.0	0.0	2.0	0.0000000000	False
colon is the reserved	0.0	0.0	0.0	2.0	0.0000000000	False
word of the language	0.0	0.0	0.0	2.0	0.0000000000	False
black so the sequence	0.0	0.0	0.0	2.0	0.0000000000	False
command this conditional compound	0.0	0.0	0.0	2.0	0.0000000000	False
possibly a compound command	0.0	0.0	0.0	2.0	0.0000000000	False
level of grammar specification	0.0	0.0	0.0	2.0	0.0000000000	False
form let us assume	0.0	0.0	0.0	2.0	0.0000000000	False
expression then v assigned	0.0	0.0	0.0	2.0	0.0000000000	False
boolean so the language	0.0	0.0	0.0	2.0	0.0000000000	False
expressions i am defining	0.0	0.0	0.0	2.0	0.0000000000	False
defining a different grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar just for variation	0.0	0.0	0.0	2.0	0.0000000000	False
defined but that grammar	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a hatch	0.0	0.0	0.0	2.0	0.0000000000	False
thing in that grammar	0.0	0.0	0.0	2.0	0.0000000000	False
constant true and false	0.0	0.0	0.0	2.0	0.0000000000	False
expression the terminal false	0.0	0.0	0.0	2.0	0.0000000000	False
symbols of the language	0.0	0.0	0.0	2.0	0.0000000000	False
make compound boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
grammar in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
designed a fully parenthesized	0.0	0.0	0.0	2.0	0.0000000000	False
atomic i have enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
enclosed a new parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
supposing instead we defined	0.0	0.0	0.0	2.0	0.0000000000	False
define such a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
generated by this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
expand this and replace	0.0	0.0	4.99575551783	10.0	0.1726618705	False
make a different derivation	0.0	0.0	0.0	2.0	0.0000000000	False
expand this and give	0.0	0.0	0.0	2.0	0.0000000000	False
two then i chose	0.0	0.0	0.0	2.0	0.0000000000	False
brackets in the language	0.0	0.0	0.0	2.0	0.0000000000	False
give you the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
derivations with different syntax	0.0	0.0	0.0	2.0	0.0000000000	False
two different syntax trees	0.0	0.0	0.0	2.0	0.0000000000	False
syntax trees actually affect	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of this language	0.0	0.0	0.0	2.0	0.0000000000	False
two had the values	0.0	0.0	0.0	2.0	0.0000000000	False
false then the evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
evaluation of this syntax	0.0	0.0	0.0	4.0	0.0000000000	False
syntax tree would give	0.0	0.0	0.0	4.0	0.0000000000	False
true and the evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
give you a value	0.0	0.0	0.0	2.0	0.0000000000	False
grammar for example falls	0.0	0.0	0.0	2.0	0.0000000000	False
language with unique meanings	0.0	0.0	0.0	2.0	0.0000000000	False
call such a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous but the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
handle for the specification	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in the language	0.0	0.0	0.0	4.0	0.0000000000	False
right so so ambiguity	0.0	0.0	0.0	2.0	0.0000000000	False
constraint in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
two different parse tree	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree those parse	0.0	0.0	0.0	2.0	0.0000000000	False
tree those parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
translating which means running	0.0	0.0	0.0	2.0	0.0000000000	False
problem of executing programs	0.0	0.0	0.0	2.0	0.0000000000	False
executing programs in order	0.0	0.0	0.0	2.0	0.0000000000	False
order to get meanings	0.0	0.0	0.0	2.0	0.0000000000	False
program to be interpreted	0.0	0.0	0.0	2.0	0.0000000000	False
compiler for that program	0.0	0.0	0.0	2.0	0.0000000000	False
program and the user	0.0	0.0	0.0	2.0	0.0000000000	False
user of that programming	0.0	0.0	0.0	2.0	0.0000000000	False
interpreted right so ambiguity	0.0	0.0	0.0	2.0	0.0000000000	False
means the execution behavior	0.0	0.0	0.0	2.0	0.0000000000	False
execution behavior of programs	0.0	0.0	0.0	2.0	0.0000000000	False
lot of our programming	0.0	0.0	0.0	4.0	0.0000000000	False
unambiguous yeah this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
tree for every sentence	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguity in most languages	0.0	0.0	0.0	2.0	0.0000000000	False
implicit order of evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
expression without any parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
assumed that the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
tree for this expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression if you remove	0.0	0.0	0.0	2.0	0.0000000000	False
tree of this form	0.0	0.0	0.0	2.0	0.0000000000	False
construct a syntax tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree supposing i removed	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguity then the order	0.0	0.0	0.0	2.0	0.0000000000	False
multiplication should precede addition	0.0	0.0	0.0	2.0	0.0000000000	False
precede addition other wise	0.0	0.0	0.0	2.0	0.0000000000	False
mathematical notation most programming	0.0	0.0	0.0	2.0	0.0000000000	False
notation most programming languages	0.0	0.0	0.0	2.0	0.0000000000	False
construct has a perfect	0.0	0.0	0.0	2.0	0.0000000000	False
case of one construct	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t delhi	0.0	0.0	0.0	2.0	0.0000000000	False
technology i.i.t delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
kumar deptt of comp.sc	0.0	0.0	0.0	2.0	0.0000000000	False
syntax welcome to lecture	0.0	0.0	0.0	2.0	0.0000000000	False
lecture five so today	0.0	0.0	0.0	2.0	0.0000000000	False
slightly more complicated programming	0.0	0.0	0.0	2.0	0.0000000000	False
brown i will change	0.0	0.0	0.0	2.0	0.0000000000	False
change um so programs	0.0	0.0	0.0	2.0	0.0000000000	False
commands and atomic commands	0.0	0.0	0.0	2.0	0.0000000000	False
commands and a context	0.0	0.0	0.0	2.0	0.0000000000	False
context free grammar notation	0.0	0.0	0.0	4.0	0.0000000000	False
grammar notation will remain	0.0	0.0	0.0	2.0	0.0000000000	False
grammar firstly the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
black are reserve words	0.0	0.0	0.0	2.0	0.0000000000	False
reserve words so including	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in the language	0.0	0.0	0.0	2.0	0.0000000000	False
tree the same sentence	0.0	0.0	0.0	2.0	0.0000000000	False
tree because the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
tree is just obtained	0.0	0.0	0.0	2.0	0.0000000000	False
obtained from the parse	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree by elevating	0.0	0.0	0.0	2.0	0.0000000000	False
operators to the root	0.0	0.0	0.0	2.0	0.0000000000	False
root nodes and replacing	0.0	0.0	0.0	2.0	0.0000000000	False
restricted class of parse	0.0	0.0	0.0	2.0	0.0000000000	False
class of parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
conditional and the loop	0.0	0.0	0.0	2.0	0.0000000000	False
loop i have eliminated	0.0	0.0	0.0	2.0	0.0000000000	False
introducing two reserved words	0.0	0.0	0.0	2.0	0.0000000000	False
words the closing bracket	0.0	0.0	0.0	2.0	0.0000000000	False
composition or the sequencing	0.0	0.0	0.0	2.0	0.0000000000	False
binary operator on commands	0.0	0.0	0.0	2.0	0.0000000000	False
assume c one semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon c two semicolon	0.0	0.0	0.0	4.0	0.0000000000	False
semicolon c three semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
atomic or compound commands	0.0	0.0	0.0	2.0	0.0000000000	False
compound commands i don	0.0	0.0	0.0	2.0	0.0000000000	False
two different parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
triangles here to denote	0.0	0.0	0.0	2.0	0.0000000000	False
denote that these seats	0.0	0.0	0.0	2.0	0.0000000000	False
commands themselves can expand	0.0	0.0	0.0	2.0	0.0000000000	False
first this first semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon is the root	0.0	0.0	0.0	4.0	0.0000000000	False
semicolon is a right	0.0	0.0	0.0	2.0	0.0000000000	False
circle is a root	0.0	0.0	0.0	2.0	0.0000000000	False
root of the right	0.0	0.0	0.0	2.0	0.0000000000	False
case in which case	0.0	0.0	0.0	2.0	0.0000000000	False
root of the left	0.0	0.0	0.0	2.0	0.0000000000	False
root of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree so strictly speaking	0.0	0.0	0.0	2.0	0.0000000000	False
speaking there is ambiguity	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguity in this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
operation in any programming	0.0	0.0	0.0	2.0	0.0000000000	False
two trees really correspond	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to different bracketing	0.0	0.0	0.0	2.0	0.0000000000	False
tree for example corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to the bracketing	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to the case	0.0	0.0	0.0	2.0	0.0000000000	False
right so this corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
two the whole thing	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon c three right	0.0	0.0	0.0	2.0	0.0000000000	False
general um sequencing operation	0.0	0.0	0.0	2.0	0.0000000000	False
operation and the function	0.0	0.0	0.0	2.0	0.0000000000	False
implementation of the language	0.0	0.0	0.0	2.0	0.0000000000	False
regard to the semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
operation so the fact	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous does not matter	0.0	0.0	0.0	2.0	0.0000000000	False
behavior or the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
meanings of the programs	0.0	0.0	0.0	2.0	0.0000000000	False
case things can change	0.0	0.0	0.0	2.0	0.0000000000	False
expression of boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
value of boolean expression	0.0	0.0	0.0	2.0	0.0000000000	False
parse the boolean expression	0.0	0.0	0.0	2.0	0.0000000000	False
languages since algol sixty	0.0	0.0	0.0	2.0	0.0000000000	False
sixty use a notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation called the backus	0.0	0.0	0.0	2.0	0.0000000000	False
created by john backus	0.0	0.0	0.0	2.0	0.0000000000	False
john backus and peter	0.0	0.0	0.0	2.0	0.0000000000	False
backus and peter naur	0.0	0.0	0.0	2.0	0.0000000000	False
naur in the definition	0.0	0.0	0.0	2.0	0.0000000000	False
algol sixty the algol	0.0	0.0	0.0	2.0	0.0000000000	False
sixty the algol sixty	0.0	0.0	0.0	2.0	0.0000000000	False
rigorous syntactic form based	0.0	0.0	0.0	2.0	0.0000000000	False
free grammars to define	0.0	0.0	0.0	2.0	0.0000000000	False
define the language abs	0.0	0.0	0.0	2.0	0.0000000000	False
involved in the creation	0.0	0.0	0.0	2.0	0.0000000000	False
fortan language every fortan	0.0	0.0	0.0	2.0	0.0000000000	False
language every fortan compiler	0.0	0.0	0.0	2.0	0.0000000000	False
written by various people	0.0	0.0	0.0	2.0	0.0000000000	False
people gave different interpretations	0.0	0.0	0.0	2.0	0.0000000000	False
interpretations to the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
fortan comp fortan programs	0.0	0.0	0.0	2.0	0.0000000000	False
treated um the fortan	0.0	0.0	0.0	2.0	0.0000000000	False
compiler and moving programs	0.0	0.0	0.0	2.0	0.0000000000	False
machine or one compiler	0.0	0.0	0.0	2.0	0.0000000000	False
compiler to another compiler	0.0	0.0	0.0	2.0	0.0000000000	False
problem in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that you required	0.0	0.0	0.0	2.0	0.0000000000	False
required a whole team	0.0	0.0	0.0	2.0	0.0000000000	False
suit the new compiler	0.0	0.0	0.0	2.0	0.0000000000	False
architecture of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
machine or it required	0.0	0.0	0.0	2.0	0.0000000000	False
patching up of programs	0.0	0.0	0.0	2.0	0.0000000000	False
form of theoretical study	0.0	0.0	0.0	2.0	0.0000000000	False
theoretical study and backus	0.0	0.0	0.0	2.0	0.0000000000	False
backus and naur define	0.0	0.0	0.0	2.0	0.0000000000	False
naur define the algol	0.0	0.0	0.0	2.0	0.0000000000	False
define the algol sixty	0.0	0.0	0.0	2.0	0.0000000000	False
language using this notation	0.0	0.0	0.0	2.0	0.0000000000	False
single symbol um single	0.0	0.0	0.0	2.0	0.0000000000	False
symbol um single character	0.0	0.0	0.0	2.0	0.0000000000	False
character non terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
words so they wrote	0.0	0.0	0.0	2.0	0.0000000000	False
statements within angle brackets	0.0	0.0	0.0	2.0	0.0000000000	False
mark on the type	0.0	0.0	0.0	2.0	0.0000000000	False
wrote all the productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions in this form	0.0	0.0	0.0	2.0	0.0000000000	False
full the non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
non terminals being enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
enclosed in angle brackets	0.0	0.0	0.0	2.0	0.0000000000	False
brackets and the arrow	0.0	0.0	0.0	2.0	0.0000000000	False
double colon and equals	0.0	0.0	0.0	2.0	0.0000000000	False
extended backus naur form	0.0	0.0	3.99786019971	6.0	0.0000000000	False
convince we should remember	0.0	0.0	0.0	2.0	0.0000000000	False
means is the introduction	0.0	0.0	0.0	2.0	0.0000000000	False
introduction of new non	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols to aloow	0.0	0.0	0.0	2.0	0.0000000000	False
aloow for those kinds	0.0	0.0	0.0	2.0	0.0000000000	False
essentially uses the backus	0.0	0.0	0.0	2.0	0.0000000000	False
backus naur form extended	0.0	0.0	0.0	2.0	0.0000000000	False
form extended to include	0.0	0.0	0.0	2.0	0.0000000000	False
extended to include iterations	0.0	0.0	0.0	2.0	0.0000000000	False
include iterations in choice	0.0	0.0	0.0	2.0	0.0000000000	False
backus naur form production	0.0	0.0	0.0	2.0	0.0000000000	False
production of this form	0.0	0.0	2.99786019971	6.0	0.0000000000	False
form ok where alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha beta and gamma	0.0	0.0	0.0	2.0	0.0000000000	False
terminals or non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
notation for the backus	0.0	0.0	0.0	2.0	0.0000000000	False
backus naur form notation	0.0	0.0	0.0	2.0	0.0000000000	False
set of non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon or to beta	0.0	0.0	0.0	2.0	0.0000000000	False
notation this extended backus	0.0	0.0	0.0	2.0	0.0000000000	False
extended backus form notation	0.0	0.0	0.0	2.0	0.0000000000	False
machine if you run	0.0	0.0	0.0	2.0	0.0000000000	False
run the man pages	0.0	0.0	0.0	2.0	0.0000000000	False
pages for some command	0.0	0.0	0.0	2.0	0.0000000000	False
command you will find	0.0	0.0	0.0	2.0	0.0000000000	False
brackets of one kind	0.0	0.0	0.0	2.0	0.0000000000	False
square brackets to represent	0.0	0.0	0.0	2.0	0.0000000000	False
represent the various options	0.0	0.0	0.0	2.0	0.0000000000	False
options the several options	0.0	0.0	0.0	2.0	0.0000000000	False
options are either separated	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent to this set	0.0	0.0	0.0	2.0	0.0000000000	False
definition of a programming	0.0	0.0	0.0	2.0	0.0000000000	False
aide in writing out	0.0	0.0	0.0	2.0	0.0000000000	False
writing out a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
logical significance you wouldn	0.0	0.0	0.0	2.0	0.0000000000	False
allowed both the statements	0.0	0.0	0.0	2.0	0.0000000000	False
clause is an option	0.0	0.0	0.0	2.0	0.0000000000	False
ideally could be sep	0.0	0.0	0.0	2.0	0.0000000000	False
entity so you wouldn	0.0	0.0	0.0	2.0	0.0000000000	False
put that else clause	0.0	0.0	0.0	2.0	0.0000000000	False
clause in the definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of your language	0.0	0.0	0.0	2.0	0.0000000000	False
language if your language	0.0	0.0	0.0	2.0	0.0000000000	False
allowed an else clause	0.0	0.0	0.0	2.0	0.0000000000	False
put the else clause	0.0	0.0	0.0	2.0	0.0000000000	False
amount of the number	0.0	0.0	0.0	2.0	0.0000000000	False
non terminal symbols remember	0.0	0.0	0.0	2.0	0.0000000000	False
remember that a programming	0.0	0.0	0.0	2.0	0.0000000000	False
language a real world	0.0	0.0	0.0	2.0	0.0000000000	False
real world programming language	0.0	0.0	0.0	2.0	0.0000000000	False
large piece of syntax	0.0	0.0	0.0	2.0	0.0000000000	False
adding these extra non	0.0	0.0	0.0	2.0	0.0000000000	False
significance for the compiler	0.0	0.0	0.0	2.0	0.0000000000	False
compiler which have significance	0.0	0.0	0.0	2.0	0.0000000000	False
accurately specifying the language	0.0	0.0	0.0	2.0	0.0000000000	False
language but other wise	0.0	0.0	0.0	2.0	0.0000000000	False
respect to ambiguity parsing	0.0	0.0	0.0	2.0	0.0000000000	False
significance from the non	0.0	0.0	0.0	2.0	0.0000000000	False
repetitions of some option	0.0	0.0	0.0	2.0	0.0000000000	False
alpha within braces beta	0.0	0.0	0.0	2.0	0.0000000000	False
productions of the form	0.0	0.0	0.0	2.0	0.0000000000	False
repetitions of the string	0.0	0.0	0.0	2.0	0.0000000000	False
production of the string	0.0	0.0	0.0	2.0	0.0000000000	False
denotes a zero number	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of a beta	0.0	0.0	0.0	2.0	0.0000000000	False
pascal manual the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
manual the syntax diagrams	0.0	0.0	0.0	2.0	0.0000000000	False
follow the arrow marks	0.0	0.0	0.0	2.0	0.0000000000	False
marks in the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
give you the productions	0.0	0.0	0.0	2.0	0.0000000000	False
ordinary context free notation	0.0	0.0	0.0	2.0	0.0000000000	False
reading manuals for learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning a new language	0.0	0.0	0.0	2.0	0.0000000000	False
last time we looked	0.0	0.0	0.0	2.0	0.0000000000	False
looked at a toy	0.0	0.0	0.0	2.0	0.0000000000	False
toy language which didn	0.0	0.0	0.0	2.0	0.0000000000	False
designed for the purposes	0.0	0.0	0.0	2.0	0.0000000000	False
purposes of teaching programming	0.0	0.0	0.0	2.0	0.0000000000	False
teaching programming languages compilers	0.0	0.0	0.0	2.0	0.0000000000	False
first course by nicolas	0.0	0.0	0.0	2.0	0.0000000000	False
worth himself the designer	0.0	0.0	0.0	2.0	0.0000000000	False
type the main features	0.0	0.0	0.0	2.0	0.0000000000	False
assignment sequencing bracketing looping	0.0	0.0	0.0	2.0	0.0000000000	False
arm conditional that means	0.0	0.0	0.0	2.0	0.0000000000	False
two one arm conditions	0.0	0.0	0.0	2.0	0.0000000000	False
arm conditions in sequence	0.0	0.0	0.0	2.0	0.0000000000	False
wise refinement of programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs to be written	0.0	0.0	0.0	2.0	0.0000000000	False
written in a structured	0.0	0.0	0.0	2.0	0.0000000000	False
true to be nested	0.0	0.0	0.0	2.0	0.0000000000	False
refinement in the development	0.0	0.0	0.0	2.0	0.0000000000	False
equals for a production	0.0	0.0	0.0	2.0	0.0000000000	False
fashion so a program	0.0	0.0	0.0	2.0	0.0000000000	False
program my start symbol	0.0	0.0	0.0	2.0	0.0000000000	False
symbols and the non	0.0	0.0	0.0	2.0	0.0000000000	False
explicitly specify the terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and the non	0.0	0.0	0.0	2.0	0.0000000000	False
black and the non	0.0	0.0	0.0	2.0	0.0000000000	False
terminates with a dot	0.0	0.0	0.0	2.0	0.0000000000	False
dot with a period	0.0	0.0	0.0	2.0	0.0000000000	False
case of pascal programs	0.0	0.0	0.0	2.0	0.0000000000	False
pascal programs you terminate	0.0	0.0	0.0	2.0	0.0000000000	False
program with a dot	0.0	0.0	0.0	2.0	0.0000000000	False
dot right a block	0.0	0.0	0.0	2.0	0.0000000000	False
right a block consists	0.0	0.0	0.0	2.0	0.0000000000	False
consists of a declaration	0.0	0.0	0.0	4.0	0.0000000000	False
declaration and a statement	0.0	0.0	0.0	2.0	0.0000000000	False
names for the non	0.0	0.0	0.0	2.0	0.0000000000	False
single um single letter	0.0	0.0	0.0	2.0	0.0000000000	False
letter non terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
enclosed in light brown	0.0	0.0	0.0	2.0	0.0000000000	False
constant declaration a constant	0.0	0.0	0.0	2.0	0.0000000000	False
declaration a constant declaration	0.0	0.0	0.0	2.0	0.0000000000	False
constant declaration which means	0.0	0.0	0.0	2.0	0.0000000000	False
means this word const	0.0	0.0	0.0	2.0	0.0000000000	False
const is a reserved	0.0	0.0	0.0	2.0	0.0000000000	False
put these in dark	0.0	0.0	0.0	2.0	0.0000000000	False
reason i have put	0.0	0.0	0.0	2.0	0.0000000000	False
put them in dark	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of numbers	0.0	0.0	0.0	2.0	0.0000000000	False
syntax the actual limits	0.0	0.0	0.0	2.0	0.0000000000	False
limits on the numbers	0.0	0.0	0.0	2.0	0.0000000000	False
numbers and the lengths	0.0	0.0	0.0	2.0	0.0000000000	False
lengths of the identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
part of the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
definition of the language	0.0	0.0	0.0	2.0	0.0000000000	False
light um this dark	0.0	0.0	0.0	2.0	0.0000000000	False
phase value as identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of data type	0.0	0.0	0.0	4.0	0.0000000000	False
commas so the commas	0.0	0.0	0.0	2.0	0.0000000000	False
commas are reserved word	0.0	0.0	0.0	2.0	0.0000000000	False
word of this language	0.0	0.0	0.0	2.0	0.0000000000	False
moment the word const	0.0	0.0	0.0	2.0	0.0000000000	False
occurrences of the clause	0.0	0.0	0.0	2.0	0.0000000000	False
terminated by a semi	0.0	0.0	3.99714693295	8.0	0.2978723404	False
single declaration and terminate	0.0	0.0	0.0	2.0	0.0000000000	False
constants the um terminate	0.0	0.0	0.0	2.0	0.0000000000	False
terminate the entire declaration	0.0	0.0	0.0	2.0	0.0000000000	False
declaration by a semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
declarations but you don	0.0	0.0	0.0	2.0	0.0000000000	False
variables separated by commas	0.0	0.0	0.0	2.0	0.0000000000	False
commas but the moment	0.0	0.0	0.0	2.0	0.0000000000	False
moment and the moment	0.0	0.0	0.0	2.0	0.0000000000	False
reserved word var occurring	0.0	0.0	0.0	2.0	0.0000000000	False
procedures and a procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedure has a procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedure as a reserved	0.0	0.0	0.0	2.0	0.0000000000	False
entire the entire procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedures in your program	0.0	0.0	0.0	2.0	0.0000000000	False
clauses they should occur	0.0	0.0	0.0	2.0	0.0000000000	False
occur in this order	0.0	0.0	0.0	2.0	0.0000000000	False
declarations this so declarations	0.0	0.0	0.0	2.0	0.0000000000	False
implicitly allows the production	0.0	0.0	0.0	2.0	0.0000000000	False
means an empty string	0.0	0.0	0.0	2.0	0.0000000000	False
case but a statement	0.0	0.0	0.0	2.0	0.0000000000	False
assignment an assignment statement	0.0	0.0	0.0	2.0	0.0000000000	False
statement is a statement	0.0	0.0	0.0	2.0	0.0000000000	False
statement where an assignment	0.0	0.0	0.0	2.0	0.0000000000	False
identifier um colon equals	0.0	0.0	0.0	2.0	0.0000000000	False
colon equals an expression	0.0	0.0	0.0	2.0	0.0000000000	False
equals an expression note	0.0	0.0	0.0	2.0	0.0000000000	False
relation between what identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
declared in this declaration	0.0	0.0	0.0	2.0	0.0000000000	False
declaration and what identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
statement so the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
free but the language	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of the language	0.0	0.0	0.0	4.0	0.0000000000	False
explicit procedure called statement	0.0	0.0	0.0	2.0	0.0000000000	False
identifier and implicit meaning	0.0	0.0	0.0	2.0	0.0000000000	False
declared as a procedure	0.0	0.0	0.0	2.0	0.0000000000	False
call is a reserved	0.0	0.0	0.0	2.0	0.0000000000	False
condition then a statement	0.0	0.0	0.0	2.0	0.0000000000	False
statement this whole thing	0.0	0.0	0.0	2.0	0.0000000000	False
statements you can call	0.0	0.0	0.0	2.0	0.0000000000	False
call as a sequence	0.0	0.0	0.0	2.0	0.0000000000	False
pair of brackets begin	0.0	0.0	0.0	2.0	0.0000000000	False
separated by a semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
define in the end	0.0	0.0	0.0	2.0	0.0000000000	False
defined at the expense	0.0	0.0	0.0	2.0	0.0000000000	False
introducing new non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
condition well the language	0.0	0.0	0.0	2.0	0.0000000000	False
expression e um note	0.0	0.0	0.0	2.0	0.0000000000	False
type available is integers	0.0	0.0	0.0	2.0	0.0000000000	False
integers the only expressions	0.0	0.0	0.0	2.0	0.0000000000	False
unary data type applies	0.0	0.0	0.0	2.0	0.0000000000	False
applies over all expressions	0.0	0.0	0.0	2.0	0.0000000000	False
unary condition this unary	0.0	0.0	0.0	2.0	0.0000000000	False
condition this unary predicate	0.0	0.0	0.0	2.0	0.0000000000	False
applies over all condi	0.0	0.0	0.0	2.0	0.0000000000	False
condi over all expressions	0.0	0.0	0.0	2.0	0.0000000000	False
predicate some unary predicate	0.0	0.0	0.0	2.0	0.0000000000	False
reason for choosing odd	0.0	0.0	0.0	2.0	0.0000000000	False
jump on not equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals in most hardware	0.0	0.0	0.0	2.0	0.0000000000	False
programs a large number	0.0	0.0	0.0	2.0	0.0000000000	False
number of your programs	0.0	0.0	0.0	2.0	0.0000000000	False
cases you could check	0.0	0.0	0.0	2.0	0.0000000000	False
simplified the original language	0.0	0.0	0.0	2.0	0.0000000000	False
single letter relational symbols	0.0	0.0	0.0	2.0	0.0000000000	False
greater than or equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals this is equals	0.0	0.0	0.0	2.0	0.0000000000	False
compiler for example allowed	0.0	0.0	0.0	2.0	0.0000000000	False
original pl zero compiler	0.0	0.0	0.0	2.0	0.0000000000	False
case of the expression	0.0	0.0	0.0	2.0	0.0000000000	False
two diff two extremes	0.0	0.0	0.0	2.0	0.0000000000	False
addition subtraction multiplication division	0.0	0.0	0.0	4.0	0.0000000000	False
sum of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
two expressions a difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
two expressions a product	0.0	0.0	0.0	2.0	0.0000000000	False
product of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions or a quotient	0.0	0.0	0.0	2.0	0.0000000000	False
quotient of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
sequences which you understand	0.0	0.0	0.0	2.0	0.0000000000	False
priority order of evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
define the expression language	0.0	0.0	0.0	4.0	0.0000000000	False
variable is an expression	0.0	0.0	0.0	2.0	0.0000000000	False
constant an integer constant	0.0	0.0	0.0	2.0	0.0000000000	False
statements of this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
fully bracket every expression	0.0	0.0	0.0	2.0	0.0000000000	False
binary operator you put	0.0	0.0	0.0	2.0	0.0000000000	False
operator you put bracket	0.0	0.0	0.0	2.0	0.0000000000	False
bracket around the pair	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis and e divided	0.0	0.0	0.0	2.0	0.0000000000	False
divided by e enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis over every thing	0.0	0.0	0.0	2.0	0.0000000000	False
key key in parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
language in our abstract	0.0	0.0	0.0	2.0	0.0000000000	False
abstract syntax in string	0.0	0.0	0.0	2.0	0.0000000000	False
syntax in string form	0.0	0.0	0.0	2.0	0.0000000000	False
syntax as in tree	0.0	0.0	0.0	2.0	0.0000000000	False
notation can be translated	0.0	0.0	0.0	2.0	0.0000000000	False
abstract tree which preserves	0.0	0.0	0.0	2.0	0.0000000000	False
evaluation of the expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions and vice versa	0.0	0.0	0.0	2.0	0.0000000000	False
versa given any abstract	0.0	0.0	0.0	2.0	0.0000000000	False
tree you can transform	0.0	0.0	0.0	2.0	0.0000000000	False
bracketed string of symbols	0.0	0.0	0.0	2.0	0.0000000000	False
view of the compiler	0.0	0.0	0.0	2.0	0.0000000000	False
tedious for every programmer	0.0	0.0	0.0	2.0	0.0000000000	False
write fully parenthesized versions	0.0	0.0	0.0	2.0	0.0000000000	False
fully parenthesized versions makes	0.0	0.0	0.0	2.0	0.0000000000	False
versions makes it makes	0.0	0.0	0.0	2.0	0.0000000000	False
strike a reasonable compromise	0.0	0.0	0.0	2.0	0.0000000000	False
conventions of mathematical notation	0.0	0.0	0.0	2.0	0.0000000000	False
parsing let me mention	0.0	0.0	0.0	2.0	0.0000000000	False
minus are also overloaded	0.0	0.0	0.0	2.0	0.0000000000	False
minus of a non	0.0	0.0	0.0	2.0	0.0000000000	False
minus are binary operators	0.0	0.0	0.0	2.0	0.0000000000	False
programming too um addition	0.0	0.0	0.0	2.0	0.0000000000	False
division multilic and multiplication	0.0	0.0	0.0	2.0	0.0000000000	False
types and over integer	0.0	0.0	0.0	2.0	0.0000000000	False
unary operators usually bind	0.0	0.0	0.0	2.0	0.0000000000	False
tightest ok that means	0.0	0.0	0.0	2.0	0.0000000000	False
means a unary operator	0.0	0.0	0.0	2.0	0.0000000000	False
expression enclosed in parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
symbol after the expression	0.0	0.0	0.0	2.0	0.0000000000	False
multiplication and division bind	0.0	0.0	0.0	2.0	0.0000000000	False
operators plus and minus	0.0	0.0	0.0	4.0	0.0000000000	False
minus ok however multiplication	0.0	0.0	0.0	2.0	0.0000000000	False
multiplication and division looses	0.0	0.0	0.0	2.0	0.0000000000	False
expression of this form	0.0	0.0	0.0	2.0	0.0000000000	False
form minus five star	0.0	0.0	0.0	2.0	0.0000000000	False
minus five star minus	0.0	0.0	0.0	2.0	0.0000000000	False
entire expression this minus	0.0	0.0	0.0	2.0	0.0000000000	False
expression this minus refers	0.0	0.0	0.0	2.0	0.0000000000	False
bracketing is this right	0.0	0.0	0.0	2.0	0.0000000000	False
account for the purpose	0.0	0.0	0.0	2.0	0.0000000000	False
giving your friendly user	0.0	0.0	0.0	2.0	0.0000000000	False
expression language is concerned	0.0	0.0	0.0	2.0	0.0000000000	False
concerned so that people	0.0	0.0	0.0	2.0	0.0000000000	False
normal knowledge of mathematics	0.0	0.0	0.0	2.0	0.0000000000	False
mathematic notation mathematical conventions	0.0	0.0	0.0	2.0	0.0000000000	False
mathematical conventions can write	0.0	0.0	0.0	2.0	0.0000000000	False
conventions can write programs	0.0	0.0	0.0	2.0	0.0000000000	False
write programs can write	0.0	0.0	0.0	2.0	0.0000000000	False
programs can write expressions	0.0	0.0	0.0	2.0	0.0000000000	False
provision of this convenience	0.0	0.0	0.0	2.0	0.0000000000	False
means that you require	0.0	0.0	0.0	2.0	0.0000000000	False
large number of non	0.0	0.0	0.0	2.0	0.0000000000	False
number of non terminals	0.0	0.0	0.0	4.0	0.0000000000	False
account all the conventions	0.0	0.0	0.0	2.0	0.0000000000	False
right so an expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression is a term	0.0	0.0	0.0	2.0	0.0000000000	False
optionally an addition operator	0.0	0.0	0.0	2.0	0.0000000000	False
operator and a term	0.0	0.0	0.0	4.0	0.0000000000	False
right the addition operators	0.0	0.0	0.0	2.0	0.0000000000	False
binary plus and minus	0.0	0.0	0.0	2.0	0.0000000000	False
expression can be regarded	0.0	0.0	0.0	2.0	0.0000000000	False
signed or unsigned term	0.0	0.0	0.0	4.0	0.0000000000	False
term with an addition	0.0	0.0	0.0	2.0	0.0000000000	False
term um a term	0.0	0.0	0.0	2.0	0.0000000000	False
product of two factors	0.0	0.0	0.0	2.0	0.0000000000	False
factors or the quotient	0.0	0.0	0.0	2.0	0.0000000000	False
quotient of two factors	0.0	0.0	0.0	4.0	0.0000000000	False
multiplicative operator so star	0.0	0.0	0.0	2.0	0.0000000000	False
division are multiplicative operators	0.0	0.0	0.0	2.0	0.0000000000	False
factors right a factor	0.0	0.0	0.0	2.0	0.0000000000	False
factor is anything regarded	0.0	0.0	0.0	2.0	0.0000000000	False
number specified as part	0.0	0.0	0.0	2.0	0.0000000000	False
part of the expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression in itself enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
mutually and circularly non	0.0	0.0	0.0	2.0	0.0000000000	False
sum of two things	0.0	0.0	0.0	2.0	0.0000000000	False
out into a term	0.0	0.0	0.0	2.0	0.0000000000	False
large expression whose root	0.0	0.0	0.0	2.0	0.0000000000	False
expression whose root operation	0.0	0.0	0.0	2.0	0.0000000000	False
operation is an addition	0.0	0.0	0.0	2.0	0.0000000000	False
addition operation that means	0.0	0.0	0.0	2.0	0.0000000000	False
grammar really takes precedence	0.0	0.0	0.0	2.0	0.0000000000	False
takes precedence of operators	0.0	0.0	0.0	2.0	0.0000000000	False
absolutely essential for writing	0.0	0.0	0.0	2.0	0.0000000000	False
kind of syntactic definition	0.0	0.0	0.0	2.0	0.0000000000	False
expression as a signed	0.0	0.0	0.0	2.0	0.0000000000	False
signed or unsigned expression	0.0	0.0	0.0	2.0	0.0000000000	False
operator just in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of abstract trees	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesized expressions or abstract	0.0	0.0	0.0	2.0	0.0000000000	False
expressions or abstract syntax	0.0	0.0	0.0	2.0	0.0000000000	False
definition of the number	0.0	0.0	0.0	2.0	0.0000000000	False
number so a number	0.0	0.0	0.0	2.0	0.0000000000	False
signed or unsigned integer	0.0	0.0	0.0	2.0	0.0000000000	False
clause and the definition	0.0	0.0	0.0	2.0	0.0000000000	False
digits ok and digit	0.0	0.0	0.0	2.0	0.0000000000	False
defined as a character	0.0	0.0	0.0	2.0	0.0000000000	False
follow normal pascal rules	0.0	0.0	0.0	2.0	0.0000000000	False
pascal rules an identifier	0.0	0.0	0.0	2.0	0.0000000000	False
start with a letter	0.0	0.0	0.0	2.0	0.0000000000	False
letter in the case	0.0	0.0	0.0	2.0	0.0000000000	False
compiler all the alphabet	0.0	0.0	0.0	2.0	0.0000000000	False
modify it to include	0.0	0.0	0.0	2.0	0.0000000000	False
include lower case letters	0.0	0.0	0.0	2.0	0.0000000000	False
number from an identifier	0.0	0.0	0.0	2.0	0.0000000000	False
identifier is the occurrence	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of a letter	0.0	0.0	0.0	2.0	0.0000000000	False
symbol or a digit	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of the letter	0.0	0.0	0.0	2.0	0.0000000000	False
begin with a letter	0.0	0.0	0.0	2.0	0.0000000000	False
right and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
rules also for recognizing	0.0	0.0	0.0	2.0	0.0000000000	False
recognizing that the word	0.0	0.0	0.0	2.0	0.0000000000	False
single word the word	0.0	0.0	0.0	2.0	0.0000000000	False
word the word begin	0.0	0.0	0.0	2.0	0.0000000000	False
begin has been recognized	0.0	0.0	0.0	2.0	0.0000000000	False
part of the process	0.0	0.0	0.0	2.0	0.0000000000	False
scanning or lexical analysis	0.0	0.0	0.0	2.0	0.0000000000	False
written in this language	0.0	0.0	0.0	2.0	0.0000000000	False
language it just consists	0.0	0.0	0.0	2.0	0.0000000000	False
divide up the program	0.0	0.0	0.0	2.0	0.0000000000	False
entity in the program	0.0	0.0	0.0	2.0	0.0000000000	False
recognize all those reserved	0.0	0.0	0.0	2.0	0.0000000000	False
words you should scan	0.0	0.0	0.0	2.0	0.0000000000	False
scan all the words	0.0	0.0	0.0	2.0	0.0000000000	False
treat them as identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
out the entire constant	0.0	0.0	0.0	2.0	0.0000000000	False
constant in this case	0.0	0.0	0.0	2.0	0.0000000000	False
string of digits representing	0.0	0.0	0.0	4.0	0.0000000000	False
digits representing an integer	0.0	0.0	0.0	4.0	0.0000000000	False
unit so a scanner	0.0	0.0	0.0	2.0	0.0000000000	False
typically takes a file	0.0	0.0	0.0	2.0	0.0000000000	False
lexemes yeah the word	0.0	0.0	0.0	2.0	0.0000000000	False
desk file it means	0.0	0.0	0.0	2.0	0.0000000000	False
means any unbounded sequence	0.0	0.0	0.0	2.0	0.0000000000	False
unbounded sequence ordered sequence	0.0	0.0	0.0	2.0	0.0000000000	False
ordered sequence of object	0.0	0.0	0.0	2.0	0.0000000000	False
object so the process	0.0	0.0	0.0	2.0	0.0000000000	False
process of scanning converts	0.0	0.0	0.0	2.0	0.0000000000	False
scanning converts the file	0.0	0.0	0.0	2.0	0.0000000000	False
takes over the handling	0.0	0.0	0.0	2.0	0.0000000000	False
scanning would have created	0.0	0.0	0.0	2.0	0.0000000000	False
created a single lexeme	0.0	0.0	0.0	2.0	0.0000000000	False
scanning they would lose	0.0	0.0	0.0	2.0	0.0000000000	False
unit in the form	0.0	0.0	0.0	2.0	0.0000000000	False
form of some structured	0.0	0.0	0.0	2.0	0.0000000000	False
structured um an element	0.0	0.0	0.0	2.0	0.0000000000	False
element of some structured	0.0	0.0	0.0	2.0	0.0000000000	False
constant it is striped	0.0	0.0	0.0	2.0	0.0000000000	False
create a huge table	0.0	0.0	0.0	2.0	0.0000000000	False
table of the amount	0.0	0.0	0.0	2.0	0.0000000000	False
extract from the program	0.0	0.0	0.0	2.0	0.0000000000	False
checking for example type	0.0	0.0	0.0	2.0	0.0000000000	False
type checking runtime type	0.0	0.0	0.0	2.0	0.0000000000	False
checking runtime type checks	0.0	0.0	0.0	2.0	0.0000000000	False
runtime type checks compile	0.0	0.0	0.0	2.0	0.0000000000	False
checks compile time type	0.0	0.0	0.0	2.0	0.0000000000	False
compile time type checks	0.0	0.0	0.0	2.0	0.0000000000	False
type checks to detect	0.0	0.0	0.0	2.0	0.0000000000	False
detect un declared variables	0.0	0.0	0.0	2.0	0.0000000000	False
good way of detecting	0.0	0.0	0.0	2.0	0.0000000000	False
resident always in memory	0.0	0.0	0.0	2.0	0.0000000000	False
reference during the process	0.0	0.0	0.0	2.0	0.0000000000	False
context sensitive um issues	0.0	0.0	0.0	2.0	0.0000000000	False
assigned the right type	0.0	0.0	0.0	2.0	0.0000000000	False
expression in the right	0.0	0.0	0.0	2.0	0.0000000000	False
type so you require	0.0	0.0	0.0	2.0	0.0000000000	False
word or each lexeme	0.0	0.0	0.0	2.0	0.0000000000	False
correctly in the program	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of the language	0.0	0.0	0.0	2.0	0.0000000000	True
start the next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
basic notions of semantics	0.0	0.0	0.0	2.0	0.0000000000	False
toy language new features	0.0	0.0	0.0	2.0	0.0000000000	False
defined the syntactic definitions	0.0	0.0	0.0	2.0	0.0000000000	False
long as you parenthesizes	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesizes the new features	0.0	0.0	0.0	2.0	0.0000000000	False
long as you define	0.0	0.0	0.0	2.0	0.0000000000	False
important how the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
give to the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
good morning welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
reminder – i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve actually seen project	0.0	0.0	0.0	2.0	0.0000000000	False
proposals start to trickle	0.0	0.0	0.0	2.0	0.0000000000	False
great as a reminder	0.0	0.0	0.0	2.0	0.0000000000	False
chat more about project	0.0	0.0	0.0	2.0	0.0000000000	False
hours immediately after lecture	0.0	0.0	0.0	2.0	0.0000000000	False
immediately after lecture today	0.0	0.0	0.0	2.0	0.0000000000	False
started today ? great	0.0	0.0	0.0	2.0	0.0000000000	False
great okay welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
wrap up our discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on support vector	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the idea	0.0	0.0	0.0	4.0	0.0000000000	False
kernels and then talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the smo	0.0	0.0	0.0	2.0	0.0000000000	False
solving the optimization problem	0.0	0.0	1.99833147942	6.0	0.0000000000	False
problem that we posed	0.0	0.0	0.0	2.0	0.0000000000	False
last time to recap	0.0	0.0	0.0	2.0	0.0000000000	False
assuming that the data	0.0	0.0	0.0	2.0	0.0000000000	False
find the optimal margin	0.0	0.0	0.0	4.0	0.0000000000	False
classifier for the data	0.0	0.0	0.0	2.0	0.0000000000	False
data set that maximizes	0.0	0.0	0.0	2.0	0.0000000000	False
maximizes this geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin from your training	0.0	0.0	0.0	2.0	0.0000000000	False
dual of this problem	0.0	0.0	0.0	2.0	0.0000000000	False
angle brackets to denote	0.0	0.0	0.0	2.0	0.0000000000	False
transpose xj for vectors	0.0	0.0	0.0	2.0	0.0000000000	False
worked out the ways	0.0	0.0	0.0	2.0	0.0000000000	False
sum over i alpha	0.0	0.0	3.9977753059	8.0	0.4180790960	False
value of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
threshold function that outputs	0.0	0.0	0.0	2.0	0.0000000000	False
terms of inner products	0.0	0.0	2.9977753059	8.0	0.0000000000	False
products between input vectors	0.0	0.0	0.0	2.0	0.0000000000	False
property because it turns	0.0	0.0	0.0	2.0	0.0000000000	False
dependers of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
write the entire algorithm	0.0	0.0	0.0	4.0	0.0000000000	False
vector between input feature	0.0	0.0	0.0	2.0	0.0000000000	False
vectors and the idea	0.0	0.0	0.0	2.0	0.0000000000	False
area of a house	0.0	0.0	0.0	2.0	0.0000000000	False
house that you re	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to make	0.0	0.0	0.0	2.0	0.0000000000	False
ll take this feature	0.0	0.0	0.0	2.0	0.0000000000	False
richer set of features	0.0	0.0	0.0	2.0	0.0000000000	False
acutely call this mapping	0.0	0.0	0.0	2.0	0.0000000000	False
call this mapping phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi of x denote	0.0	0.0	0.0	2.0	0.0000000000	False
dimensional set of features	0.0	0.0	0.0	2.0	0.0000000000	False
back to the learning	0.0	0.0	0.0	2.0	0.0000000000	False
running a support vector	0.0	0.0	3.99833147942	6.0	0.0000000000	False
machine with the features	0.0	0.0	0.0	2.0	0.0000000000	False
features given by phi	0.0	0.0	0.0	2.0	0.0000000000	False
original one-dimensional input feature	0.0	0.0	0.0	2.0	0.0000000000	False
high degree polynomial features	0.0	0.0	0.0	2.0	0.0000000000	False
polynomial features sometimes phi	0.0	0.0	0.0	2.0	0.0000000000	False
dimensional vector of features	0.0	0.0	0.0	2.0	0.0000000000	False
question is if phi	0.0	0.0	0.0	2.0	0.0000000000	False
computers need to represent	0.0	0.0	0.0	2.0	0.0000000000	False
extremely high dimensional feature	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional feature vector	0.0	0.0	2.9977753059	8.0	0.0000000000	False
call the kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
product between those feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature vectors it turns	0.0	0.0	0.0	4.0	0.0000000000	False
special cases where computing	0.0	0.0	0.0	2.0	0.0000000000	False
cases where computing phi	0.0	0.0	0.0	2.0	0.0000000000	False
compute infinite dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
special cases where phi	0.0	0.0	0.0	2.0	0.0000000000	False
compute the inner product	0.0	0.0	6.9977753059	8.0	0.5285714286	False
two vectors very inexpensively	0.0	0.0	0.0	2.0	0.0000000000	False
idea of the support	0.0	0.0	0.0	2.0	0.0000000000	False
re going to replace	0.0	0.0	0.0	2.0	0.0000000000	False
work in feature spaces	0.0	0.0	0.0	2.0	0.0000000000	False
concrete examples of phi	0.0	0.0	0.0	2.0	0.0000000000	False
explicitly this best illustrates	0.0	0.0	0.0	2.0	0.0000000000	False
right ? x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
thing is x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to the feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature mapping where phi	0.0	0.0	0.0	2.0	0.0000000000	False
case of n equals	0.0	0.0	0.0	2.0	0.0000000000	False
product between two vectors	0.0	0.0	3.99833147942	6.0	0.0000000000	False
elements of the vectors	0.0	0.0	0.0	4.0	0.0000000000	False
elements of this vector	0.0	0.0	2.9977753059	8.0	0.0000000000	False
times the corresponding elements	0.0	0.0	0.0	2.0	0.0000000000	False
order to compute phi	0.0	0.0	0.0	2.0	0.0000000000	False
vector of all pairs	0.0	0.0	0.0	2.0	0.0000000000	False
squared you need order	0.0	0.0	0.0	2.0	0.0000000000	False
compute the kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
kernel function is defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined as x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
ve computed this kernel	0.0	0.0	0.0	2.0	0.0000000000	False
computed this kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
vectors where each vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector has n squared	0.0	0.0	0.0	2.0	0.0000000000	False
kernel later please raise	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	0.0	2.0	0.0000000000	False
couple of quick generalizations	0.0	0.0	0.0	2.0	0.0000000000	False
equal to x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
turns out to correspond	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to a feature	0.0	0.0	0.0	4.0	0.0000000000	False
elements at the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
bottom where you add	0.0	0.0	0.0	2.0	0.0000000000	False
creating a feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
meaning the first order	0.0	0.0	0.0	2.0	0.0000000000	False
control the relative waiting	0.0	0.0	0.0	2.0	0.0000000000	False
features of all monomials	0.0	0.0	0.0	2.0	0.0000000000	False
terms up to degree	0.0	0.0	0.0	2.0	0.0000000000	False
implicitly construct the feature	0.0	0.0	0.0	2.0	0.0000000000	False
construct the feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
number to the power	0.0	0.0	0.0	2.0	0.0000000000	False
extremely high dimensional computing	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional computing space	0.0	0.0	0.0	2.0	0.0000000000	False
specific examples of kernels	0.0	0.0	0.0	2.0	0.0000000000	False
generally if you re	0.0	0.0	0.0	0.0	0.0000000000	False
intuition that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
feature vector of phi	0.0	0.0	0.0	2.0	0.0000000000	False
input feature vector phi	0.0	0.0	0.0	2.0	0.0000000000	False
nt as rigorous intuition	0.0	0.0	0.0	0.0	0.0000000000	False
product would be large	0.0	0.0	0.0	2.0	0.0000000000	False
large whereas in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
product may be small	0.0	0.0	0.0	2.0	0.0000000000	False
give you some random	0.0	0.0	0.0	2.0	0.0000000000	False
random thing to classify	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to classify	0.0	0.0	0.0	4.0	0.0000000000	False
thing – you re	0.0	0.0	0.0	0.0	0.0000000000	False
classify or dna sequences	0.0	0.0	0.0	2.0	0.0000000000	False
write down the function	0.0	0.0	0.0	4.0	0.0000000000	False
write down this function	0.0	0.0	0.0	2.0	0.0000000000	False
phi such that kxz	0.0	0.0	0.0	4.0	0.0000000000	False
valid kernel it turns	0.0	0.0	0.0	2.0	0.0000000000	False
part of that result	0.0	0.0	0.0	2.0	0.0000000000	False
exist some function phi	0.0	0.0	0.0	2.0	0.0000000000	False
matrix k i apologize	0.0	0.0	0.0	2.0	0.0000000000	False
apologize for overloading notation	0.0	0.0	0.0	2.0	0.0000000000	False
denote both the kernel	0.0	0.0	0.0	2.0	0.0000000000	False
find the kernel matrix	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the kernel	0.0	0.0	0.0	2.0	0.0000000000	False
two of my examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples then it turns	0.0	0.0	0.0	2.0	0.0000000000	False
transpose kz by definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of matrix multiplication	0.0	0.0	0.0	2.0	0.0000000000	False
kij is a kernel	0.0	0.0	0.0	2.0	0.0000000000	False
exist such a value	0.0	0.0	0.0	2.0	0.0000000000	False
product between two feature	0.0	0.0	0.0	2.0	0.0000000000	False
make that inner product	0.0	0.0	0.0	2.0	0.0000000000	False
sum over the elements	0.0	0.0	0.0	2.0	0.0000000000	False
denote the k element	0.0	0.0	0.0	2.0	0.0000000000	False
vector just rearrange sums	0.0	0.0	0.0	2.0	0.0000000000	False
sums you get sum	0.0	0.0	0.0	2.0	0.0000000000	False
steps and just make	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you buy	0.0	0.0	0.0	2.0	0.0000000000	False
product between the vector	0.0	0.0	0.0	2.0	0.0000000000	False
vectors is the sum	0.0	0.0	0.0	2.0	0.0000000000	False
transpose b equals sum	0.0	0.0	0.0	2.0	0.0000000000	False
make sure it makes	0.0	0.0	0.0	2.0	0.0000000000	False
definitions of a matrix	0.0	0.0	0.0	2.0	0.0000000000	False
matrix k being posisemidefinite	0.0	0.0	0.0	2.0	0.0000000000	False
posisemidefinite when a matrix	0.0	0.0	0.0	2.0	0.0000000000	False
matrix must be posisemidefinite	0.0	0.0	0.0	2.0	0.0000000000	False
out that the converse	0.0	0.0	0.0	2.0	0.0000000000	False
theorem due to mercer	0.0	0.0	0.0	2.0	0.0000000000	False
mercer kernels it means	0.0	0.0	0.0	2.0	0.0000000000	False
means the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing it just means	0.0	0.0	0.0	2.0	0.0000000000	False
phi of x transpose	0.0	0.0	0.0	4.0	0.0000000000	False
set of m examples	0.0	0.0	0.0	2.0	0.0000000000	False
means for any set	0.0	0.0	0.0	2.0	0.0000000000	False
set of m points	0.0	0.0	0.0	4.0	0.0000000000	False
necessarily a training set	0.0	0.0	0.0	2.0	0.0000000000	False
points you may choose	0.0	0.0	0.0	2.0	0.0000000000	False
true that the kernel	0.0	0.0	0.0	2.0	0.0000000000	False
proved only one direction	0.0	0.0	0.0	2.0	0.0000000000	False
direction of this result	0.0	0.0	0.0	2.0	0.0000000000	False
nt show it turns	0.0	0.0	0.0	0.0	0.0000000000	False
choose is a kernel	0.0	0.0	0.0	2.0	0.0000000000	False
functions that will fail	0.0	0.0	0.0	2.0	0.0000000000	False
conditions of this theorem	0.0	0.0	0.0	2.0	0.0000000000	False
products of a vector	0.0	0.0	0.0	2.0	0.0000000000	False
explicitly to an svm	0.0	0.0	0.0	2.0	0.0000000000	False
machine with a kernel	0.0	0.0	0.0	2.0	0.0000000000	False
turns out that function	0.0	0.0	0.0	2.0	0.0000000000	False
galceans so you choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose some kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
apply a support vector	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine kernel	0.0	0.0	0.0	2.0	0.0000000000	False
depend on your problem	0.0	0.0	0.0	2.0	0.0000000000	False
back to our formulation	0.0	0.0	0.0	2.0	0.0000000000	False
formulation of support vector	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine algorithm	0.0	0.0	0.0	2.0	0.0000000000	True
ve taken a support	0.0	0.0	0.0	2.0	0.0000000000	False
machine and you ve	0.0	0.0	0.0	0.0	0.0000000000	False
infinite dimensional feature vectors	0.0	0.0	0.0	4.0	0.0000000000	False
dimensional feature vectors explicitly	0.0	0.0	0.0	2.0	0.0000000000	False
idea ? it turns	0.0	0.0	0.0	2.0	0.0000000000	False
talking about support vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector machines i started	0.0	0.0	0.0	2.0	0.0000000000	False
develop non-linear learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
nt mean to draw	0.0	0.0	0.0	0.0	0.0000000000	False
takes your original input	0.0	0.0	0.0	2.0	0.0000000000	False
input data and maps	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional feature space	0.0	0.0	3.99833147942	6.0	0.0000000000	False
space in the case	0.0	0.0	0.0	2.0	0.0000000000	False
case of galcean kernels	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature space	0.0	0.0	0.0	4.0	0.0000000000	False
ll draw two dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
takes all your data	0.0	0.0	0.0	2.0	0.0000000000	False
machine in this infinite	0.0	0.0	0.0	2.0	0.0000000000	False
exponentially high dimensional space	0.0	0.0	0.0	2.0	0.0000000000	False
largest possible geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
originally one dimensional space	0.0	0.0	0.0	2.0	0.0000000000	False
classifier to which data	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machines output	0.0	0.0	0.0	2.0	0.0000000000	False
machines output nonlinear decision	0.0	0.0	0.0	2.0	0.0000000000	False
output nonlinear decision boundaries	0.0	0.0	0.0	2.0	0.0000000000	False
solve complex optimization problems	0.0	0.0	0.0	2.0	0.0000000000	False
complex optimization problems questions	0.0	0.0	0.0	2.0	0.0000000000	False
amount of your data	0.0	0.0	0.0	2.0	0.0000000000	False
thirds of your data	0.0	0.0	0.0	2.0	0.0000000000	False
data try different values	0.0	0.0	0.0	2.0	0.0000000000	False
separate hold out cross	0.0	0.0	0.0	2.0	0.0000000000	False
hold out cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation set	0.0	0.0	0.0	2.0	0.0000000000	False
set that you re	0.0	0.0	0.0	0.0	0.0000000000	False
testing something about learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms we talked	0.0	0.0	0.0	2.0	0.0000000000	False
locally linear aggressions bandwidth	0.0	0.0	0.0	2.0	0.0000000000	False
linear aggressions bandwidth parameter	0.0	0.0	0.0	2.0	0.0000000000	False
choose ids by saving	0.0	0.0	0.0	2.0	0.0000000000	False
saving aside some data	0.0	0.0	0.0	2.0	0.0000000000	False
talk more about model	0.0	0.0	0.0	2.0	0.0000000000	False
separation ? good question	0.0	0.0	0.0	2.0	0.0000000000	False
separable if you tend	0.0	0.0	0.0	2.0	0.0000000000	False
linearly separated by mapping	0.0	0.0	0.0	2.0	0.0000000000	False
mapping a higher dimension	0.0	0.0	0.0	2.0	0.0000000000	False
work with a discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion of soft margin	0.0	0.0	0.0	2.0	0.0000000000	False
run an svm algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
svm algorithm that assumes	0.0	0.0	0.0	2.0	0.0000000000	False
linearly separable on data	0.0	0.0	0.0	2.0	0.0000000000	False
separable ? you guys	0.0	0.0	0.0	2.0	0.0000000000	False
guys are really giving	0.0	0.0	0.0	2.0	0.0000000000	False
data s linearly separable	0.0	0.0	0.0	0.0	0.0000000000	False
linearly separable it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm wo nt work	0.0	0.0	0.0	0.0	0.0000000000	False
work if the data	0.0	0.0	0.0	2.0	0.0000000000	False
work if i move	0.0	0.0	0.0	2.0	0.0000000000	False
move on to talk	0.0	0.0	0.0	2.0	0.0000000000	False
final word about kernels	0.0	0.0	0.0	2.0	0.0000000000	False
kernels in a context	0.0	0.0	0.0	2.0	0.0000000000	False
context of support vector	0.0	0.0	0.0	2.0	0.0000000000	False
made support vector machines	0.0	0.0	0.0	2.0	0.0000000000	False
out that the idea	0.0	0.0	0.0	2.0	0.0000000000	False
general than support vector	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm and we derived	0.0	0.0	0.0	2.0	0.0000000000	False
entire algorithm in terms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms that you ve	0.0	0.0	0.0	0.0	0.0000000000	False
class – in fact	0.0	0.0	0.0	2.0	0.0000000000	False
linear algorithms we talked	0.0	0.0	0.0	2.0	0.0000000000	False
regression and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
means you can replace	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms and implicitly map	0.0	0.0	0.0	2.0	0.0000000000	False
implicitly map the features	0.0	0.0	0.0	2.0	0.0000000000	False
map the features vectors	0.0	0.0	0.0	2.0	0.0000000000	False
widely used with support	0.0	0.0	0.0	2.0	0.0000000000	False
write them in terms	0.0	0.0	0.0	2.0	0.0000000000	False
products and thereby kernalize	0.0	0.0	0.0	2.0	0.0000000000	False
apply them to infinite	0.0	0.0	0.0	2.0	0.0000000000	False
set let s talk	0.0	0.0	0.0	0.0	0.0000000000	False
talk about non-linear decision	0.0	0.0	0.0	2.0	0.0000000000	False
norm soft margin svm	0.0	0.0	3.99833147942	6.0	0.0000000000	False
soft margin svm machine	0.0	0.0	0.0	2.0	0.0000000000	False
svm machine only people	0.0	0.0	0.0	2.0	0.0000000000	False
nt great at coming	0.0	0.0	0.0	0.0	0.0000000000	False
linearly separable data set	0.0	0.0	0.0	4.0	0.0000000000	False
couple of other examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples there that makes	0.0	0.0	0.0	2.0	0.0000000000	False
decision boundary that separates	0.0	0.0	0.0	2.0	0.0000000000	False
linearly separate this data	0.0	0.0	0.0	2.0	0.0000000000	False
separate this data set	0.0	0.0	0.0	2.0	0.0000000000	False
slightly suspicious example skew	0.0	0.0	0.0	2.0	0.0000000000	False
skew my entire decision	0.0	0.0	0.0	2.0	0.0000000000	False
boundary by a lot	0.0	0.0	0.0	2.0	0.0000000000	False
formulation of the svm	0.0	0.0	0.0	2.0	0.0000000000	False
choose that original decision	0.0	0.0	0.0	2.0	0.0000000000	False
formulation our svm primal	0.0	0.0	0.0	2.0	0.0000000000	False
problem was to minimize	0.0	0.0	0.0	2.0	0.0000000000	False
minimize one-half w squared	0.0	0.0	0.0	2.0	0.0000000000	False
modify this by adding	0.0	0.0	0.0	2.0	0.0000000000	False
add these penalty terms	0.0	0.0	0.0	2.0	0.0000000000	False
training examples is separated	0.0	0.0	0.0	2.0	0.0000000000	False
separated with functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
equal to one minus	0.0	0.0	0.0	2.0	0.0000000000	False
misclassified it by setting	0.0	0.0	0.0	2.0	0.0000000000	False
examples with functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
examples of the training	0.0	0.0	0.0	2.0	0.0000000000	False
ll encourage the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
adding to the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
sort of penalty term	0.0	0.0	0.0	2.0	0.0000000000	False
penalty term that penalizes	0.0	0.0	0.0	2.0	0.0000000000	False
term that penalizes setting	0.0	0.0	0.0	2.0	0.0000000000	False
cis to be large	0.0	0.0	0.0	4.0	0.0000000000	False
problem where the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem it turns	0.0	0.0	0.0	4.0	0.0000000000	False
dual of the support	0.0	0.0	0.0	2.0	0.0000000000	False
dual for this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
show you the steps	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective minus sum	0.0	0.0	0.0	2.0	0.0000000000	False
minus or plus alpha	0.0	0.0	0.0	2.0	0.0000000000	False
dual of this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
out when you derive	0.0	0.0	0.0	2.0	0.0000000000	False
constraint that the alpha	0.0	0.0	5.99721913237	10.0	0.3752535497	False
essentially the same math	0.0	0.0	0.0	2.0	0.0000000000	False
constraints of the alphas	0.0	0.0	0.0	2.0	0.0000000000	False
out that – remember	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down the conditions	0.0	0.0	0.0	2.0	0.0000000000	False
lecture the necessary conditions	0.0	0.0	0.0	2.0	0.0000000000	False
optimal solution to constrain	0.0	0.0	0.0	2.0	0.0000000000	False
solution to constrain optimization	0.0	0.0	0.0	2.0	0.0000000000	False
solve this optimization problem	0.0	0.0	7.9977753059	8.0	0.0000000000	False
optimum ? it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out from the conditions	0.0	0.0	0.0	2.0	0.0000000000	False
conditions you can derive	0.0	0.0	0.0	2.0	0.0000000000	False
conditions for an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the alphas	0.0	0.0	0.0	2.0	0.0000000000	False
handle non-linearly separable data	0.0	0.0	0.0	2.0	0.0000000000	False
non-linearly separable data sets	0.0	0.0	0.0	2.0	0.0000000000	False
choose not to separate	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this stuff	0.0	0.0	0.0	2.0	0.0000000000	False
sense at all great	0.0	0.0	0.0	2.0	0.0000000000	False
talk about an algorithm	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm for actually solving	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem we wrote	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem with convergence	0.0	0.0	0.0	2.0	0.0000000000	False
problem with convergence criteria	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to actually solve	0.0	0.0	0.0	2.0	0.0000000000	False
give me an excuse	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm called coordinate assent	0.0	0.0	0.0	4.0	0.0000000000	False
apply in the simplest	0.0	0.0	0.0	2.0	0.0000000000	False
form to this problem	0.0	0.0	0.0	2.0	0.0000000000	False
efficient algorithm for solving	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm like the smo	0.0	0.0	0.0	2.0	0.0000000000	False
talk about coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
optimization algorithm to describe	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one through alpha	0.0	0.0	0.0	4.0	0.0000000000	False
forget about the constraint	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm it will repeat	0.0	0.0	0.0	2.0	0.0000000000	False
coordinate assent essentially holds	0.0	0.0	0.0	2.0	0.0000000000	False
holds all the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters let me write	0.0	0.0	0.0	2.0	0.0000000000	False
write that as alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i gets updated	0.0	0.0	0.0	2.0	0.0000000000	False
updated as over alpha	0.0	0.0	0.0	2.0	0.0000000000	False
hat of w alpha	0.0	0.0	0.0	2.0	0.0000000000	False
hold everything except alpha	0.0	0.0	0.0	2.0	0.0000000000	False
optimize w by optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective with respect	0.0	0.0	0.0	2.0	0.0000000000	False
respect to only alpha	0.0	0.0	0.0	2.0	0.0000000000	False
fancy way of writing	0.0	0.0	0.0	2.0	0.0000000000	False
coordinate assent one picture	0.0	0.0	0.0	2.0	0.0000000000	False
picture that s kind	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to optimize	0.0	0.0	0.0	4.0	0.0000000000	False
optimize a quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
function and the minimums	0.0	0.0	0.0	2.0	0.0000000000	False
ll call this alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one my alpha	0.0	0.0	0.0	2.0	0.0000000000	False
minimizing this with respect	0.0	0.0	0.0	2.0	0.0000000000	False
ll minimize with respect	0.0	0.0	0.0	4.0	0.0000000000	False
taking these axis-aligned steps	0.0	0.0	0.0	2.0	0.0000000000	False
order we always optimize	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one then alpha	0.0	0.0	0.0	2.0	0.0000000000	False
choose to always visit	0.0	0.0	0.0	2.0	0.0000000000	False
order you may choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose which alphas update	0.0	0.0	0.0	2.0	0.0000000000	False
alphas update next depending	0.0	0.0	0.0	2.0	0.0000000000	False
make the most progress	0.0	0.0	0.0	2.0	0.0000000000	False
makes sense to alternate	0.0	0.0	0.0	2.0	0.0000000000	False
progress towards the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out that coordinate assent	0.0	0.0	0.0	4.0	0.0000000000	False
advantage of coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
assent when it works	0.0	0.0	0.0	2.0	0.0000000000	False
optimize w with respect	0.0	0.0	2.99833147942	6.0	0.0000000000	False
group of coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
coordinate assent with optimizing	0.0	0.0	0.0	2.0	0.0000000000	False
true when we modify	0.0	0.0	0.0	2.0	0.0000000000	False
solve the svm optimization	0.0	0.0	0.0	2.0	0.0000000000	False
svm optimization problem questions	0.0	0.0	0.0	2.0	0.0000000000	False
vector machine dual optimization	0.0	0.0	0.0	2.0	0.0000000000	False
machine dual optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
form does not work	0.0	0.0	0.0	2.0	0.0000000000	False
constrains on the alpha	0.0	0.0	0.0	2.0	0.0000000000	False
constraint that the sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum of y alpha	0.0	0.0	0.0	2.0	0.0000000000	False
fix all the alphas	0.0	0.0	0.0	2.0	0.0000000000	False
nt change one alpha	0.0	0.0	0.0	0.0	0.0000000000	False
determined as a function	0.0	0.0	0.0	2.0	0.0000000000	False
due to john platt	0.0	0.0	0.0	2.0	0.0000000000	False
microsoft the smo algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization and the term	0.0	0.0	0.0	2.0	0.0000000000	False
refers to the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that we re	0.0	0.0	0.0	0.0	0.0000000000	False
choosing the smallest number	0.0	0.0	0.0	2.0	0.0000000000	False
smallest number of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha is to change	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm we will select	0.0	0.0	0.0	2.0	0.0000000000	False
two alphas to change	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i and alpha	0.0	0.0	8.99388209121	22.0	0.2574320051	False
thumb we ll hold	0.0	0.0	0.0	0.0	0.0000000000	False
hold all the alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha j and optimize	0.0	0.0	0.0	2.0	0.0000000000	False
out the key step	0.0	0.0	0.0	2.0	0.0000000000	False
optimize w of alpha	0.0	0.0	0.0	4.0	0.0000000000	False
subject to the constraints	0.0	0.0	0.0	2.0	0.0000000000	False
satisfied these convergence criteria	0.0	0.0	0.0	2.0	0.0000000000	False
criteria up to epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
efficiently that the smo	0.0	0.0	0.0	2.0	0.0000000000	False
large number of iterations	0.0	0.0	0.0	2.0	0.0000000000	False
iteration is very cheap	0.0	0.0	0.0	2.0	0.0000000000	False
cheap let s talk	0.0	0.0	0.0	0.0	0.0000000000	False
step where we update	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one and alpha	0.0	0.0	11.9949944383	18.0	0.3019038985	False
notation on the board	0.0	0.0	0.0	2.0	0.0000000000	False
analogous on every step	0.0	0.0	0.0	2.0	0.0000000000	False
step of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem this means	0.0	0.0	0.0	2.0	0.0000000000	False
constraints on our dual	0.0	0.0	0.0	2.0	0.0000000000	False
constraint that the values	0.0	0.0	0.0	2.0	0.0000000000	False
alpha two must lie	0.0	0.0	0.0	2.0	0.0000000000	False
lie within this box	0.0	0.0	0.0	2.0	0.0000000000	False
picture of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
two y2 must equal	0.0	0.0	0.0	2.0	0.0000000000	False
equal to zeta minus	0.0	0.0	0.0	4.0	0.0000000000	False
plug in my definition	0.0	0.0	0.0	2.0	0.0000000000	False
alphas – it turns	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic function of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
two if you hold	0.0	0.0	0.0	2.0	0.0000000000	False
simplified to some expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression of the form	0.0	0.0	0.0	2.0	0.0000000000	False
squared plus b alpha	0.0	0.0	0.0	2.0	0.0000000000	False
high school or undergrad	0.0	0.0	0.0	2.0	0.0000000000	False
optimal value for alpha	0.0	0.0	0.0	2.0	0.0000000000	False
value for alpha two	0.0	0.0	0.0	2.0	0.0000000000	False
two the last step	0.0	0.0	0.0	2.0	0.0000000000	False
step with a bosk	0.0	0.0	0.0	2.0	0.0000000000	False
lie on this line	0.0	0.0	0.0	4.0	0.0000000000	False
ll be some sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
function over this line	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
lies in the box	0.0	0.0	0.0	2.0	0.0000000000	False
optimize your quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
solution just to map	0.0	0.0	0.0	2.0	0.0000000000	False
map it back inside	0.0	0.0	0.0	2.0	0.0000000000	False
back inside the box	0.0	0.0	0.0	2.0	0.0000000000	False
box that ll give	0.0	0.0	0.0	0.0	0.0000000000	False
quadratic optimization problem subject	0.0	0.0	0.0	2.0	0.0000000000	False
subject to your solution	0.0	0.0	0.0	2.0	0.0000000000	False
solution satisfying this box	0.0	0.0	0.0	2.0	0.0000000000	False
satisfying this box constraint	0.0	0.0	0.0	2.0	0.0000000000	False
box constraint and lying	0.0	0.0	0.0	2.0	0.0000000000	False
subject to the solution	0.0	0.0	0.0	2.0	0.0000000000	False
segment within the box	0.0	0.0	0.0	2.0	0.0000000000	False
back within the box	0.0	0.0	0.0	2.0	0.0000000000	False
makes the inner loop	0.0	0.0	0.0	2.0	0.0000000000	False
loop of the smo	0.0	0.0	0.0	2.0	0.0000000000	False
smo algorithm very efficient	0.0	0.0	0.0	2.0	0.0000000000	False
talking about ascent suppose	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum from i equals	0.0	0.0	0.0	4.0	0.0000000000	False
two to m alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i yi divided	0.0	0.0	0.0	2.0	0.0000000000	False
alpha four through alpha	0.0	0.0	0.0	2.0	0.0000000000	False
choose to change alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha two must satisfy	0.0	0.0	0.0	2.0	0.0000000000	False
satisfy that linear constraint	0.0	0.0	0.0	2.0	0.0000000000	False
two accordingly to make	0.0	0.0	0.0	2.0	0.0000000000	False
make sure this satisfies	0.0	0.0	0.0	2.0	0.0000000000	False
setting of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to talk	0.0	0.0	0.0	0.0	0.0000000000	False
ll say a couple	0.0	0.0	0.0	2.0	0.0000000000	False
outline of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
iteration of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
re going to select	0.0	0.0	0.0	2.0	0.0000000000	False
alpha j to update	0.0	0.0	0.0	4.0	0.0000000000	False
procedure i just described	0.0	0.0	0.0	2.0	0.0000000000	False
described to actually update	0.0	0.0	0.0	2.0	0.0000000000	False
alpha is that function	0.0	0.0	0.0	2.0	0.0000000000	False
function we had previously	0.0	0.0	0.0	2.0	0.0000000000	False
previously w of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha was the sum	0.0	0.0	0.0	2.0	0.0000000000	False
problem for the svm	0.0	0.0	0.0	2.0	0.0000000000	False
farther from its optimal	0.0	0.0	0.0	2.0	0.0000000000	False
optimal let me translate	0.0	0.0	0.0	2.0	0.0000000000	False
differently what we re	0.0	0.0	0.0	0.0	0.0000000000	False
optimize the objective function	0.0	0.0	0.0	2.0	0.0000000000	False
function w of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
progress that we care	0.0	0.0	0.0	2.0	0.0000000000	False
true for coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
assent and for smo	0.0	0.0	0.0	2.0	0.0000000000	False
alpha can only increase	0.0	0.0	0.0	2.0	0.0000000000	False
increase it may stay	0.0	0.0	0.0	2.0	0.0000000000	False
converge at some value	0.0	0.0	0.0	2.0	0.0000000000	False
true that in intervening	0.0	0.0	0.0	2.0	0.0000000000	False
true just a couple	0.0	0.0	0.0	2.0	0.0000000000	False
smo before i wrap	0.0	0.0	0.0	2.0	0.0000000000	False
platt s original algorithm	0.0	0.0	0.0	0.0	0.0000000000	False
john platt s paper	0.0	0.0	0.0	0.0	0.0000000000	False
paper on the smo	0.0	0.0	0.0	2.0	0.0000000000	False
pretty easy to read	0.0	0.0	0.0	2.0	0.0000000000	False
readings in more details	0.0	0.0	0.0	2.0	0.0000000000	False
details one other thing	0.0	0.0	0.0	2.0	0.0000000000	False
solving all your alphas	0.0	0.0	0.0	2.0	0.0000000000	False
ll let you read	0.0	0.0	0.0	2.0	0.0000000000	False
briefly about a couple	0.0	0.0	0.0	2.0	0.0000000000	False
handler s integer recognition	0.0	0.0	0.0	0.0	0.0000000000	False
integer recognition in handler	0.0	0.0	0.0	2.0	0.0000000000	False
re given a pixel	0.0	0.0	0.0	2.0	0.0000000000	False
array with a scanned	0.0	0.0	0.0	2.0	0.0000000000	False
code somewhere in britain	0.0	0.0	0.0	2.0	0.0000000000	False
character one the question	0.0	0.0	0.0	2.0	0.0000000000	False
ten pixels by ten	0.0	0.0	0.0	4.0	0.0000000000	False
pixels by ten pixels	0.0	0.0	0.0	4.0	0.0000000000	False
hundred dimensional feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
binary features of xb01	0.0	0.0	0.0	2.0	0.0000000000	False
out for many years	0.0	0.0	0.0	2.0	0.0000000000	False
champion algorithm for handler	0.0	0.0	0.0	2.0	0.0000000000	False
recognition and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
writing down this kernel	0.0	0.0	0.0	2.0	0.0000000000	False
neuronetworks this is surprising	0.0	0.0	0.0	2.0	0.0000000000	False
surprising because support vector	0.0	0.0	0.0	2.0	0.0000000000	False
nt take into account	0.0	0.0	0.0	0.0	0.0000000000	False
knowledge about the pixels	0.0	0.0	0.0	2.0	0.0000000000	False
representing the pixel intensity	0.0	0.0	0.0	2.0	0.0000000000	False
value as a vector	0.0	0.0	0.0	2.0	0.0000000000	False
shuffle all the pixels	0.0	0.0	0.0	2.0	0.0000000000	False
development for many years	0.0	0.0	0.0	2.0	0.0000000000	False
sequences into different classes	0.0	0.0	0.0	2.0	0.0000000000	False
biologists in the room	0.0	0.0	0.0	2.0	0.0000000000	False
proteins in our bodies	0.0	0.0	0.0	2.0	0.0000000000	False
made up by sequences	0.0	0.0	0.0	2.0	0.0000000000	False
sequences of amino acids	0.0	0.0	0.0	4.0	0.0000000000	False
acids by the alphabet	0.0	0.0	0.0	2.0	0.0000000000	False
apologizes to the biologists	0.0	0.0	0.0	2.0	0.0000000000	False
amino acid sequence represented	0.0	0.0	0.0	2.0	0.0000000000	False
represented by a series	0.0	0.0	0.0	2.0	0.0000000000	False
depending on what type	0.0	0.0	0.0	2.0	0.0000000000	False
construct my feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
challenging for many reasons	0.0	0.0	0.0	2.0	0.0000000000	False
nt have a feature	0.0	0.0	0.0	0.0	0.0000000000	False
position in this protein	0.0	0.0	0.0	2.0	0.0000000000	False
combinations of four alphabets	0.0	0.0	0.0	4.0	0.0000000000	False
aaac down to aaaz	0.0	0.0	0.0	2.0	0.0000000000	False
aaaz and then aaba	0.0	0.0	0.0	2.0	0.0000000000	False
alphabets and my feature	0.0	0.0	0.0	2.0	0.0000000000	False
scan through this sequence	0.0	0.0	0.0	2.0	0.0000000000	False
amino acids and count	0.0	0.0	0.0	2.0	0.0000000000	False
feature representation for protein	0.0	0.0	0.0	2.0	0.0000000000	False
protein this representation applies	0.0	0.0	0.0	2.0	0.0000000000	False
representation applies no matter	0.0	0.0	0.0	2.0	0.0000000000	False
long my protein sequence	0.0	0.0	0.0	2.0	0.0000000000	False
160,000 dimensional feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
dimensional feature vectors imagine	0.0	0.0	0.0	2.0	0.0000000000	False
examples and you store	0.0	0.0	0.0	2.0	0.0000000000	False
efficient dynamic programming algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
efficiently compute inner products	0.0	0.0	0.0	2.0	0.0000000000	False
products between these feature	0.0	0.0	0.0	2.0	0.0000000000	False
apply this feature representation	0.0	0.0	0.0	2.0	0.0000000000	False
ridiculously high feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
feature vector to classify	0.0	0.0	0.0	2.0	0.0000000000	False
vector to classify protein	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for finding subsequences	0.0	0.0	0.0	2.0	0.0000000000	False
choose a standard kernel	0.0	0.0	0.0	2.0	0.0000000000	False
problem two last sentences	0.0	0.0	0.0	2.0	0.0000000000	False
effective off the shelf	0.0	0.0	0.0	2.0	0.0000000000	False
lot of learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
class by saying congrats	0.0	0.0	0.0	2.0	0.0000000000	False
re now well qualified	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms to a lot	0.0	0.0	0.0	2.0	0.0000000000	False
re still in week	0.0	0.0	0.0	2.0	0.0000000000	False
four of the quarter	0.0	0.0	0.0	2.0	0.0000000000	False
understand the learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
assume that your project	0.0	0.0	0.0	2.0	0.0000000000	False
working on your proposals	0.0	0.0	0.0	2.0	0.0000000000	False
working on your project	0.0	0.0	0.0	2.0	0.0000000000	False
session at the end	0.0	0.0	0.0	2.0	0.0000000000	False
end of the quarter	0.0	0.0	0.0	2.0	0.0000000000	False
start a new chapter	0.0	0.0	0.0	2.0	0.0000000000	False
talk about learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
learned about a lot	0.0	0.0	0.0	2.0	0.0000000000	False
lot of learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
powerful tools of machine	0.0	0.0	0.0	2.0	0.0000000000	False
tools of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
sort of well qualified	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to learn	0.0	0.0	0.0	2.0	0.0000000000	False
re going to carpentry	0.0	0.0	0.0	2.0	0.0000000000	False
carpentry school to learn	0.0	0.0	0.0	2.0	0.0000000000	False
tools if you learn	0.0	0.0	0.0	2.0	0.0000000000	False
walk in and pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick up a tool	0.0	0.0	0.0	2.0	0.0000000000	False
give you a sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense of the mastery	0.0	0.0	0.0	2.0	0.0000000000	False
mastery of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
deeply about the properties	0.0	0.0	0.0	2.0	0.0000000000	False
properties of different machine	0.0	0.0	0.0	2.0	0.0000000000	False
common scenarios in machine	0.0	0.0	0.0	2.0	0.0000000000	False
scenarios in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
machine learning is someday	0.0	0.0	0.0	2.0	0.0000000000	False
ll be doing research	0.0	0.0	0.0	2.0	0.0000000000	False
research or a company	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms you learned	0.0	0.0	0.0	2.0	0.0000000000	False
people that really understand	0.0	0.0	0.0	2.0	0.0000000000	False
people that maybe read	0.0	0.0	0.0	2.0	0.0000000000	False
work through the math	0.0	0.0	0.0	2.0	0.0000000000	False
apply a support vector	0.0	0.0	0.0	2.0	0.0000000000	False
understand enough about support	0.0	0.0	0.0	2.0	0.0000000000	False
separates the great people	0.0	0.0	0.0	2.0	0.0000000000	False
great people in machine	0.0	0.0	0.0	2.0	0.0000000000	False
people in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning versus the people	0.0	0.0	0.0	2.0	0.0000000000	False
people that like read	0.0	0.0	0.0	2.0	0.0000000000	False
read the text book	0.0	0.0	0.0	2.0	0.0000000000	False
ll have just understood	0.0	0.0	0.0	2.0	0.0000000000	False
ll start to talk	0.0	0.0	0.0	2.0	0.0000000000	False
theoretical results of machine	0.0	0.0	0.0	2.0	0.0000000000	False
results of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning the next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
problems that the learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning theory will point	0.0	0.0	0.0	2.0	0.0000000000	False
first thing we re	0.0	0.0	0.0	0.0	0.0000000000	False
re gon na talk	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm we learned	0.0	0.0	0.0	2.0	0.0000000000	False
line through these datas	0.0	0.0	0.0	2.0	0.0000000000	False
structure in the data	0.0	0.0	0.0	4.0	0.0000000000	False
bias of the learning	0.0	0.0	0.0	4.0	0.0000000000	False
learning algorithm as representing	0.0	0.0	0.0	2.0	0.0000000000	False
infinite amount of training	0.0	0.0	0.0	4.0	0.0000000000	False
amount of training data	0.0	0.0	0.0	4.0	0.0000000000	False
tons of training data	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm would still fail	0.0	0.0	0.0	2.0	0.0000000000	False
fit the quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm with high bias	0.0	0.0	0.0	2.0	0.0000000000	False
dataset if you fit	0.0	0.0	0.0	2.0	0.0000000000	False
fourth of the polynomials	0.0	0.0	0.0	2.0	0.0000000000	False
polynomials into this dataset	0.0	0.0	0.0	2.0	0.0000000000	False
interpolate the five data	0.0	0.0	0.0	2.0	0.0000000000	False
model to the structure	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has a problem	0.0	0.0	0.0	2.0	0.0000000000	False
alternatively that this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has high variance	0.0	0.0	0.0	2.0	0.0000000000	False
overfitting a high variance	0.0	0.0	0.0	2.0	0.0000000000	False
patterns in the data	0.0	0.0	0.0	2.0	0.0000000000	False
dataset of housing prices	0.0	0.0	0.0	2.0	0.0000000000	False
happy medium of fitting	0.0	0.0	0.0	2.0	0.0000000000	False
fitting a quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
nt interpolate your data	0.0	0.0	0.0	0.0	0.0000000000	False
interpolate your data points	0.0	0.0	0.0	2.0	0.0000000000	False
multi-structure in your data	0.0	0.0	0.0	2.0	0.0000000000	False
model which under fits	0.0	0.0	0.0	2.0	0.0000000000	False
picture of classification problems	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative examples	0.0	0.0	0.0	2.0	0.0000000000	False
equals the sigmoid function	0.0	0.0	0.0	2.0	0.0000000000	False
applied to a tenth	0.0	0.0	0.0	2.0	0.0000000000	False
tenth of the polynomial	0.0	0.0	0.0	2.0	0.0000000000	False
boundary like this right	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative classes	0.0	0.0	0.0	2.0	0.0000000000	False
regression into this model	0.0	0.0	0.0	2.0	0.0000000000	False
problem of overfitting versus	0.0	0.0	0.0	2.0	0.0000000000	False
bias versus high variance	0.0	0.0	0.0	2.0	0.0000000000	False
formal model of machine	0.0	0.0	0.0	2.0	0.0000000000	False
model of machine learning	0.0	0.0	7.99783432593	8.0	0.0000000000	False
initial foray into learning	0.0	0.0	0.0	2.0	0.0000000000	False
foray into learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
talk about learning classification	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine lectures	0.0	0.0	0.0	2.0	0.0000000000	False
ll be a bit	0.0	0.0	0.0	2.0	0.0000000000	False
cleaner if i switch	0.0	0.0	0.0	2.0	0.0000000000	False
back to y equals	0.0	0.0	0.0	2.0	0.0000000000	False
model as a model	0.0	0.0	0.0	2.0	0.0000000000	False
forum as logistic regressions	0.0	0.0	0.0	2.0	0.0000000000	False
similar to logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
re going to force	0.0	0.0	0.0	2.0	0.0000000000	False
force the logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
involved in the probabilities	0.0	0.0	0.0	2.0	0.0000000000	False
re given a training	0.0	0.0	0.0	2.0	0.0000000000	False
set of m examples	0.0	0.0	0.0	4.0	0.0000000000	False
ranging from i equals	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the training	0.0	0.0	0.0	2.0	0.0000000000	False
training example is xiyi	0.0	0.0	0.0	2.0	0.0000000000	False
xiyi i ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
identically and definitively distributed	0.0	0.0	0.0	2.0	0.0000000000	False
running a classification problem	0.0	0.0	0.0	2.0	0.0000000000	False
classification problem on houses	0.0	0.0	0.0	2.0	0.0000000000	False
features of the house	0.0	0.0	0.0	2.0	0.0000000000	False
house will be sold	0.0	0.0	0.0	2.0	0.0000000000	False
priority distribution over features	0.0	0.0	0.0	2.0	0.0000000000	False
assume that training examples	0.0	0.0	0.0	2.0	0.0000000000	False
training examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
examples we ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
iid from some probability	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to build	0.0	0.0	0.0	2.0	0.0000000000	False
build a spam classifier	0.0	0.0	0.0	2.0	0.0000000000	False
distribution of what emails	0.0	0.0	0.0	2.0	0.0000000000	False
simplify – to understand	0.0	0.0	0.0	2.0	0.0000000000	False
phenomena of bias invariance	0.0	0.0	0.0	2.0	0.0000000000	False
simplified model of machine	0.0	0.0	5.99837574445	6.0	0.0000000000	False
regression fits this parameters	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood but in order	0.0	0.0	0.0	2.0	0.0000000000	False
order to understand learning	0.0	0.0	0.0	2.0	0.0000000000	False
assume a simplified model	0.0	0.0	0.0	2.0	0.0000000000	False
error of a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis x subscript data	0.0	0.0	0.0	2.0	0.0000000000	False
data write this epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon hat of subscript	0.0	0.0	0.0	2.0	0.0000000000	False
hat of subscript data	0.0	0.0	0.0	2.0	0.0000000000	False
dependence on a training	0.0	0.0	0.0	2.0	0.0000000000	False
sum of indicator functions	0.0	0.0	0.0	2.0	0.0000000000	False
fraction of training examples	0.0	0.0	0.0	4.0	0.0000000000	False
training examples your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
examples your hypothesis classifies	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis classifies so defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined as a training	0.0	0.0	0.0	2.0	0.0000000000	False
training error and training	0.0	0.0	0.0	2.0	0.0000000000	False
error and training error	0.0	0.0	0.0	2.0	0.0000000000	False
risk the simplified model	0.0	0.0	0.0	2.0	0.0000000000	False
minimize my training error	0.0	0.0	0.0	4.0	0.0000000000	False
minimizes your training error	0.0	0.0	0.0	2.0	0.0000000000	False
training error it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out that logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression and support	0.0	0.0	0.0	4.0	0.0000000000	False
regression and support vector	0.0	0.0	0.0	4.0	0.0000000000	False
formally viewed as approximation	0.0	0.0	0.0	2.0	0.0000000000	False
viewed as approximation cities	0.0	0.0	0.0	2.0	0.0000000000	False
solve this optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem and logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
approximations to this nonconvex	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem by finding	0.0	0.0	0.0	2.0	0.0000000000	False
finding the convex approximation	0.0	0.0	0.0	2.0	0.0000000000	False
similar to what algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
definition of empirical risk	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm as not choosing	0.0	0.0	0.0	2.0	0.0000000000	False
define the hypothesis class	0.0	0.0	0.0	4.0	0.0000000000	False
class of all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
words as the class	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm is choosing	0.0	0.0	0.0	2.0	0.0000000000	False
mapping from the input	0.0	0.0	0.0	2.0	0.0000000000	False
class of all functions	0.0	0.0	0.0	4.0	0.0000000000	False
logistic regression can choose	0.0	0.0	0.0	2.0	0.0000000000	False
redefine empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
function into hypothesis class	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class of script	0.0	0.0	0.0	2.0	0.0000000000	False
script h that minimizes	0.0	0.0	0.0	2.0	0.0000000000	False
minimizes – that minimizes	0.0	0.0	0.0	2.0	0.0000000000	False
hand if it makes	0.0	0.0	0.0	2.0	0.0000000000	False
function from the class	0.0	0.0	0.0	2.0	0.0000000000	False
general case this set	0.0	0.0	0.0	2.0	0.0000000000	False
functions represented by viewer	0.0	0.0	0.0	2.0	0.0000000000	False
represented by viewer network	0.0	0.0	0.0	2.0	0.0000000000	False
functions the learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm wants to choose	0.0	0.0	0.0	2.0	0.0000000000	False
definition for empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
minimization will still apply	0.0	0.0	0.0	2.0	0.0000000000	False
understand whether empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
alex ? a function	0.0	0.0	0.0	2.0	0.0000000000	False
function that s defined	0.0	0.0	0.0	0.0	0.0000000000	False
question is h data	0.0	0.0	0.0	2.0	0.0000000000	False
purpose of this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
data is the class	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm or logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
mapping from the infa	0.0	0.0	0.0	2.0	0.0000000000	False
domain to the center	0.0	0.0	0.0	2.0	0.0000000000	False
center of class label	0.0	0.0	0.0	2.0	0.0000000000	False
perform empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
minimization over any hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
class for the purpose	0.0	0.0	0.0	2.0	0.0000000000	False
restrict myself to talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking about binary classification	0.0	0.0	0.0	2.0	0.0000000000	False
regression in other problem	0.0	0.0	0.0	2.0	0.0000000000	False
question ? yes cool	0.0	0.0	0.0	2.0	0.0000000000	False
right so i wan	0.0	0.0	0.0	2.0	0.0000000000	False
understand if empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
things we can prove	0.0	0.0	0.0	2.0	0.0000000000	False
care about training error	0.0	0.0	0.0	2.0	0.0000000000	False
predictions on the training	0.0	0.0	0.0	2.0	0.0000000000	False
goal the ultimate goal	0.0	0.0	0.0	2.0	0.0000000000	False
makes predictions on examples	0.0	0.0	0.0	2.0	0.0000000000	False
predicts prices or sale	0.0	0.0	0.0	2.0	0.0000000000	False
sale or no sale	0.0	0.0	0.0	2.0	0.0000000000	False
sale outcomes of houses	0.0	0.0	0.0	2.0	0.0000000000	False
care about is generalization	0.0	0.0	0.0	2.0	0.0000000000	False
defined as the probability	0.0	0.0	0.0	2.0	0.0000000000	False
terms of notational convention	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon hat training error	0.0	0.0	0.0	2.0	0.0000000000	False
error as an attempt	0.0	0.0	0.0	2.0	0.0000000000	False
attempt to approximate generalization	0.0	0.0	0.0	2.0	0.0000000000	False
things with the hats	0.0	0.0	0.0	2.0	0.0000000000	False
re using to estimate	0.0	0.0	0.0	2.0	0.0000000000	False
hat is a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis output by learning	0.0	0.0	0.0	2.0	0.0000000000	False
output by learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
estimate what the functions	0.0	0.0	0.0	2.0	0.0000000000	False
giving us low generalization	0.0	0.0	0.0	2.0	0.0000000000	False
care about in order	0.0	0.0	0.0	2.0	0.0000000000	False
prove our first learning	0.0	0.0	0.0	2.0	0.0000000000	False
first learning theory result	0.0	0.0	0.0	2.0	0.0000000000	False
first is the union	0.0	0.0	0.0	2.0	0.0000000000	False
events in a sense	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over the events	0.0	0.0	0.0	2.0	0.0000000000	False
sort of just set	0.0	0.0	0.0	2.0	0.0000000000	False
set notation for probability	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the probability	0.0	0.0	0.0	4.0	0.0000000000	False
ve seen venn diagrams	0.0	0.0	0.0	2.0	0.0000000000	False
diagrams depictions of probability	0.0	0.0	0.0	2.0	0.0000000000	False
great – the probability	0.0	0.0	0.0	2.0	0.0000000000	False
mass in the union	0.0	0.0	0.0	2.0	0.0000000000	False
things to the sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum of the masses	0.0	0.0	0.0	2.0	0.0000000000	False
turns out that depending	0.0	0.0	0.0	2.0	0.0000000000	False
axioms that probably varies	0.0	0.0	0.0	2.0	0.0000000000	False
written as an axiom	0.0	0.0	0.0	2.0	0.0000000000	False
avitivity are probably measured	0.0	0.0	0.0	2.0	0.0000000000	False
commonly called the union	0.0	0.0	0.0	2.0	0.0000000000	False
variables with mean phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi so the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability of zi equals	0.0	0.0	0.0	2.0	0.0000000000	False
iid for newly random	0.0	0.0	0.0	2.0	0.0000000000	False
equals one through mzi	0.0	0.0	0.0	2.0	0.0000000000	False
random variables by sort	0.0	0.0	0.0	2.0	0.0000000000	False
true value of phi	0.0	0.0	0.0	2.0	0.0000000000	False
holds – this lemma	0.0	0.0	0.0	2.0	0.0000000000	False
variables you will remember	0.0	0.0	0.0	2.0	0.0000000000	False
undergraduate probability or statistics	0.0	0.0	0.0	2.0	0.0000000000	False
probability or statistics class	0.0	0.0	0.0	2.0	0.0000000000	False
average all the things	0.0	0.0	0.0	2.0	0.0000000000	False
coins with bias phi	0.0	0.0	0.0	2.0	0.0000000000	False
observe these m benuve	0.0	0.0	0.0	2.0	0.0000000000	False
probability distribution of phi	0.0	0.0	0.0	2.0	0.0000000000	False
distribution function of phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi hat will converse	0.0	0.0	0.0	2.0	0.0000000000	False
discreet set of values	0.0	0.0	0.0	2.0	0.0000000000	False
roughly to a gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
put s one interval	0.0	0.0	0.0	2.0	0.0000000000	False
mass of the details	0.0	0.0	0.0	2.0	0.0000000000	False
probability that my value	0.0	0.0	0.0	2.0	0.0000000000	False
mass in these tails	0.0	0.0	0.0	2.0	0.0000000000	False
negative two gamma squared	0.0	0.0	10.9967514889	12.0	0.4408352668	False
side of the bound	0.0	0.0	0.0	2.0	0.0000000000	False
two e to negative	0.0	0.0	0.0	2.0	0.0000000000	False
gamma squared so balance	0.0	0.0	0.0	2.0	0.0000000000	False
probability that you make	0.0	0.0	0.0	2.0	0.0000000000	False
variable and the cool	0.0	0.0	0.0	2.0	0.0000000000	False
thing about this bound	0.0	0.0	0.0	2.0	0.0000000000	False
thing behind this bound	0.0	0.0	0.0	2.0	0.0000000000	False
fixed value of gamma	0.0	0.0	0.0	4.0	0.0000000000	False
size of your training	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian will actually shrink	0.0	0.0	0.0	2.0	0.0000000000	False
left in the tails	0.0	0.0	0.0	2.0	0.0000000000	False
tend – are sort	0.0	0.0	0.0	2.0	0.0000000000	False
works for any finer	0.0	0.0	0.0	2.0	0.0000000000	False
central limit theorem approximation	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon to help explain	0.0	0.0	0.0	2.0	0.0000000000	False
reference to central limit	0.0	0.0	0.0	2.0	0.0000000000	False
limit theorem all right	0.0	0.0	0.0	2.0	0.0000000000	False
right so lets start	0.0	0.0	0.0	2.0	0.0000000000	False
lets start to understand	0.0	0.0	0.0	2.0	0.0000000000	False
understand empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
studying empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
minimization for a case	0.0	0.0	0.0	2.0	0.0000000000	False
case of finite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
class of k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
function mapping from inputs	0.0	0.0	0.0	2.0	0.0000000000	False
whichever of these functions	0.0	0.0	0.0	2.0	0.0000000000	False
continuous infinitely large class	0.0	0.0	0.0	2.0	0.0000000000	False
large class of hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
prove the first row	0.0	0.0	0.0	2.0	0.0000000000	False
describe our first learning	0.0	0.0	0.0	2.0	0.0000000000	False
classes so empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
empirical risk minimization takes	0.0	0.0	0.0	2.0	0.0000000000	False
minimization takes the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
bound on the generalization	0.0	0.0	2.99837574445	6.0	0.0000000000	False
error of h hat	0.0	0.0	5.9967514889	12.0	0.4408352668	False
prove that somehow minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
step in this prove	0.0	0.0	0.0	2.0	0.0000000000	False
show that training error	0.0	0.0	0.0	2.0	0.0000000000	False
good approximation to generalization	0.0	0.0	0.0	2.0	0.0000000000	False
approximation to generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
show that this implies	0.0	0.0	0.0	2.0	0.0000000000	False
error of the hypothesis	0.0	0.0	1.99783432593	8.0	0.5277777778	False
hypothesis of empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
slightly notation heavy class	0.0	0.0	0.0	2.0	0.0000000000	False
notation heavy class round	0.0	0.0	0.0	2.0	0.0000000000	False
set of new symbols	0.0	0.0	0.0	2.0	0.0000000000	False
understand what the notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation i was defining	0.0	0.0	0.0	2.0	0.0000000000	False
errors that give approximation	0.0	0.0	0.0	2.0	0.0000000000	False
give approximation generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
imply that minimizing training	0.0	0.0	0.0	2.0	0.0000000000	False
pretty well in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of minimizing generalization	0.0	0.0	0.0	2.0	0.0000000000	False
give us a bound	0.0	0.0	0.0	2.0	0.0000000000	False
output by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
lets pick any hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
fixed hypothesis so pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick any one hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis misclassifies the ife	0.0	0.0	0.0	2.0	0.0000000000	False
ife example – excuse	0.0	0.0	0.0	2.0	0.0000000000	False
training set is drawn	0.0	0.0	0.0	2.0	0.0000000000	False
drawn randomly from sum	0.0	0.0	0.0	2.0	0.0000000000	False
randomly from sum distribution	0.0	0.0	0.0	2.0	0.0000000000	False
depending on what training	0.0	0.0	0.0	2.0	0.0000000000	False
training examples i ve	0.0	0.0	0.0	0.0	0.0000000000	False
out what the probability	0.0	0.0	0.0	2.0	0.0000000000	False
takes on the value	0.0	0.0	0.0	2.0	0.0000000000	False
sample my training set	0.0	0.0	0.0	2.0	0.0000000000	False
set iid from distribution	0.0	0.0	0.0	2.0	0.0000000000	False
chance that my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
error of my hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
error of this hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis raise your hand	0.0	0.0	0.0	2.0	0.0000000000	False
hand if that made	0.0	0.0	0.0	2.0	0.0000000000	False
examples i ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
ve drawn are iid	0.0	0.0	0.0	2.0	0.0000000000	False
training examples were drawn	0.0	0.0	0.0	2.0	0.0000000000	False
assumption if you read	0.0	0.0	0.0	2.0	0.0000000000	False
definition of training error	0.0	0.0	0.0	2.0	0.0000000000	False
average of my zis	0.0	0.0	0.0	2.0	0.0000000000	False
drawn from benuve distribution	0.0	0.0	0.0	2.0	0.0000000000	False
average of miid benuve	0.0	0.0	0.0	2.0	0.0000000000	False
miid benuve random variables	0.0	0.0	0.0	2.0	0.0000000000	False
probability that the difference	0.0	0.0	0.0	2.0	0.0000000000	False
training and generalization error	0.0	0.0	0.0	4.0	0.0000000000	False
large than this thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing on the right	0.0	0.0	0.0	4.0	0.0000000000	False
probability my training error	0.0	0.0	0.0	2.0	0.0000000000	False
bounded by this thing	0.0	0.0	0.0	2.0	0.0000000000	False
ve done is approve	0.0	0.0	0.0	2.0	0.0000000000	False
bound for one fixed	0.0	0.0	0.0	2.0	0.0000000000	False
prove is that training	0.0	0.0	0.0	2.0	0.0000000000	False
good estimate for generalization	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in my hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
board so in order	0.0	0.0	0.0	2.0	0.0000000000	False
define a random event	0.0	0.0	0.0	2.0	0.0000000000	False
gamma on a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
bound is the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability that there exists	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis in my class	0.0	0.0	0.0	4.0	0.0000000000	False
make a large error	0.0	0.0	7.99729290742	10.0	0.3259005146	False
error in my estimate	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of generalization error	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis one and make	0.0	0.0	0.0	2.0	0.0000000000	False
large error in estimating	0.0	0.0	0.0	4.0	0.0000000000	False
estimating the generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis two and make	0.0	0.0	0.0	2.0	0.0000000000	False
error in estimating generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error in this estimate	0.0	0.0	0.0	2.0	0.0000000000	False
make a small error	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error in taking	0.0	0.0	0.0	2.0	0.0000000000	False
minus on the right	0.0	0.0	0.0	2.0	0.0000000000	False
sign of the inequality	0.0	0.0	0.0	2.0	0.0000000000	False
sides the minus sign	0.0	0.0	0.0	2.0	0.0000000000	False
sign flips the sign	0.0	0.0	0.0	2.0	0.0000000000	False
sign of the equality	0.0	0.0	0.0	2.0	0.0000000000	False
probability – which abbreviates	0.0	0.0	0.0	2.0	0.0000000000	False
simultaneously for all hypotheses	0.0	0.0	0.0	4.0	0.0000000000	False
hypotheses in our class	0.0	0.0	0.0	2.0	0.0000000000	False
conversions – this sort	0.0	0.0	0.0	2.0	0.0000000000	False
alludes to the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that this shows	0.0	0.0	0.0	2.0	0.0000000000	False
simultaneously converge to epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
close to generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
fact that this converges	0.0	0.0	0.0	2.0	0.0000000000	False
converges for all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
value of gamma computed	0.0	0.0	0.0	4.0	0.0000000000	False
gamma computed ? right	0.0	0.0	0.0	2.0	0.0000000000	False
gamma is a constant	0.0	0.0	0.0	2.0	0.0000000000	False
constant imagine a gamma	0.0	0.0	0.0	2.0	0.0000000000	False
constant that we chose	0.0	0.0	0.0	2.0	0.0000000000	False
true for any fixed	0.0	0.0	0.0	2.0	0.0000000000	False
bound and then sort	0.0	0.0	0.0	2.0	0.0000000000	False
ll choose specific values	0.0	0.0	0.0	2.0	0.0000000000	False
specific values of gamma	0.0	0.0	0.0	2.0	0.0000000000	False
re proved this holds	0.0	0.0	0.0	2.0	0.0000000000	False
proved this holds true	0.0	0.0	0.0	2.0	0.0000000000	False
true for any value	0.0	0.0	0.0	2.0	0.0000000000	False
labs in the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
result wo nt work	0.0	0.0	0.0	0.0	0.0000000000	False
work in this present	0.0	0.0	0.0	2.0	0.0000000000	False
lecture to infinite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
talk concretely about algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
consequences of the understanding	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of these things	0.0	0.0	0.0	2.0	0.0000000000	False
hand if the things	0.0	0.0	0.0	2.0	0.0000000000	False
things i ve proved	0.0	0.0	0.0	0.0	0.0000000000	False
proved so far make	0.0	0.0	0.0	2.0	0.0000000000	False
sense ? okay cool	0.0	0.0	0.0	2.0	0.0000000000	False
great thanks all right	0.0	0.0	0.0	2.0	0.0000000000	False
couple of other forms	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a bound	0.0	0.0	0.0	2.0	0.0000000000	False
fix my training set	0.0	0.0	0.0	4.0	0.0000000000	False
set and then fix	0.0	0.0	0.0	2.0	0.0000000000	False
training set – fix	0.0	0.0	0.0	2.0	0.0000000000	False
probability that uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
probability of something happening	0.0	0.0	0.0	2.0	0.0000000000	False
value of this error	0.0	0.0	0.0	2.0	0.0000000000	False
two other equivalent forms	0.0	0.0	0.0	2.0	0.0000000000	False
forms of the bounds	0.0	0.0	0.0	2.0	0.0000000000	False
proved was given gamma	0.0	0.0	0.0	2.0	0.0000000000	False
probability of uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
gamma and the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability delta of making	0.0	0.0	0.0	2.0	0.0000000000	False
large a training set	0.0	0.0	4.99729290742	10.0	0.2883156297	False
give a uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
conversions bound with parameters	0.0	0.0	0.0	2.0	0.0000000000	False
bound with parameters gamma	0.0	0.0	0.0	2.0	0.0000000000	False
parameters gamma and delta	0.0	0.0	0.0	2.0	0.0000000000	False
form of this result	0.0	0.0	0.0	2.0	0.0000000000	False
long as your training	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that with probability	0.0	0.0	0.0	2.0	0.0000000000	False
error is within gamma	0.0	0.0	0.0	2.0	0.0000000000	False
gamma of generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
undergrad computer science classes	0.0	0.0	0.0	2.0	0.0000000000	False
heard of computational complexity	0.0	0.0	0.0	2.0	0.0000000000	False
sample complexity just means	0.0	0.0	0.0	2.0	0.0000000000	False
achieve a certain bound	0.0	0.0	0.0	2.0	0.0000000000	False
error and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out you can pose	0.0	0.0	0.0	2.0	0.0000000000	False
pose them in sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a form	0.0	0.0	0.0	2.0	0.0000000000	False
form of probability bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound or a sample	0.0	0.0	0.0	2.0	0.0000000000	False
find the sample complexity	0.0	0.0	0.0	2.0	0.0000000000	False
give a certain bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound on the errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors and in fact	0.0	0.0	0.0	2.0	0.0000000000	False
complexity bounds often sort	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to achieve	0.0	0.0	0.0	2.0	0.0000000000	False
grows like the log	0.0	0.0	0.0	4.0	0.0000000000	False
log of k grows	0.0	0.0	0.0	2.0	0.0000000000	False
slowly as a function	0.0	0.0	0.0	2.0	0.0000000000	False
right – i learned	0.0	0.0	0.0	2.0	0.0000000000	False
purposes for all values	0.0	0.0	0.0	2.0	0.0000000000	False
fact that m sample	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
class quite a lot	0.0	0.0	0.0	2.0	0.0000000000	False
lot and the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of the training	0.0	0.0	0.0	2.0	0.0000000000	False
talk about infinite hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
classes the final form	0.0	0.0	0.0	2.0	0.0000000000	False
hold m and delta	0.0	0.0	0.0	2.0	0.0000000000	False
delta fixed and solved	0.0	0.0	0.0	2.0	0.0000000000	False
difference in the training	0.0	0.0	0.0	2.0	0.0000000000	False
result of the training	0.0	0.0	0.0	2.0	0.0000000000	False
essentially that uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
uniform conversions will hold	0.0	0.0	0.0	2.0	0.0000000000	False
true with high probability	0.0	0.0	0.0	2.0	0.0000000000	False
assume that uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon of h minus	0.0	0.0	0.0	2.0	0.0000000000	False
prove about the bound	0.0	0.0	0.0	2.0	0.0000000000	False
prove about the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
suppose this holds true	0.0	0.0	0.0	2.0	0.0000000000	False
hat was the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
selected by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
make one more definition	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense of minimizing generalization	0.0	0.0	0.0	2.0	0.0000000000	False
sort of makes sense	0.0	0.0	0.0	2.0	0.0000000000	False
makes sense to compare	0.0	0.0	0.0	2.0	0.0000000000	False
performance of our learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to the performance	0.0	0.0	0.0	2.0	0.0000000000	False
performance of h star	0.0	0.0	0.0	2.0	0.0000000000	False
class is a class	0.0	0.0	0.0	2.0	0.0000000000	False
hope that your learning	0.0	0.0	0.0	2.0	0.0000000000	False
result in three steps	0.0	0.0	0.0	2.0	0.0000000000	False
steps so the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
hat will then gamma	0.0	0.0	0.0	2.0	0.0000000000	False
chosen to minimize training	0.0	0.0	0.0	2.0	0.0000000000	False
nt be any hypothesis	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis with lower training	0.0	0.0	0.0	2.0	0.0000000000	False
error than h hat	0.0	0.0	0.0	2.0	0.0000000000	False
hat so the training	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the training	0.0	0.0	0.0	2.0	0.0000000000	False
error of h star	0.0	0.0	5.99783432593	8.0	0.0000000000	False
hypothesis that minimizes training	0.0	0.0	0.0	2.0	0.0000000000	False
training error h hat	0.0	0.0	0.0	2.0	0.0000000000	False
apply this uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
hat of h star	0.0	0.0	0.0	2.0	0.0000000000	False
star must be moving	0.0	0.0	0.0	4.0	0.0000000000	False
moving gamma of epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon of h star	0.0	0.0	1.99837574445	6.0	0.0000000000	False
gamma of the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error with estimate	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis – a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
training examples it misclassifies	0.0	0.0	0.0	2.0	0.0000000000	False
misclassifies ? and generalization	0.0	0.0	0.0	2.0	0.0000000000	False
hat is the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that s chosen	0.0	0.0	0.0	0.0	0.0000000000	False
chosen by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that minimizes training	0.0	0.0	0.0	2.0	0.0000000000	False
defined as the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
out of all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in my class	0.0	0.0	0.0	2.0	0.0000000000	False
minimizes training error epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
tie all these things	0.0	0.0	0.0	2.0	0.0000000000	False
set of k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
fixed m and delta	0.0	0.0	0.0	4.0	0.0000000000	False
form of the theorem	0.0	0.0	0.0	2.0	0.0000000000	False
minimum over all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
prove this we set	0.0	0.0	0.0	2.0	0.0000000000	False
two times the square	0.0	0.0	0.0	2.0	0.0000000000	False
times the square root	0.0	0.0	0.0	2.0	0.0000000000	False
root term to prove	0.0	0.0	0.0	2.0	0.0000000000	False
theorem we set gamma	0.0	0.0	0.0	2.0	0.0000000000	False
equal to that square	0.0	0.0	0.0	2.0	0.0000000000	False
great so set gamma	0.0	0.0	0.0	2.0	0.0000000000	False
gamma to that square	0.0	0.0	0.0	2.0	0.0000000000	False
board holds with probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability one minus delta	0.0	0.0	0.0	4.0	0.0000000000	False
minus delta right equation	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta this uniform	0.0	0.0	0.0	2.0	0.0000000000	False
delta this uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
star ” i guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess and whenever uniform	0.0	0.0	0.0	2.0	0.0000000000	False
boards that this result	0.0	0.0	0.0	2.0	0.0000000000	False
two – generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
star plus two times	0.0	0.0	0.0	2.0	0.0000000000	False
theorem so this result	0.0	0.0	0.0	2.0	0.0000000000	False
result sort of helps	0.0	0.0	0.0	2.0	0.0000000000	False
helps us to quantify	0.0	0.0	0.0	2.0	0.0000000000	False
quantify a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit that bias variance	0.0	0.0	0.0	2.0	0.0000000000	False
tradeoff that i talked	0.0	0.0	0.0	2.0	0.0000000000	False
start of this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
functions and linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
functions and the subset	0.0	0.0	0.0	2.0	0.0000000000	False
subset of the class	0.0	0.0	0.0	2.0	0.0000000000	False
subset of h prime	0.0	0.0	0.0	2.0	0.0000000000	False
holds for infinite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
linear to quadratic functions	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic functions then epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis in my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
sense of generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
error – the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
function so by switching	0.0	0.0	0.0	2.0	0.0000000000	False
larger class of hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
term k will increase	0.0	0.0	0.0	2.0	0.0000000000	False
finding a better function	0.0	0.0	0.0	2.0	0.0000000000	False
sort of not fitting	0.0	0.0	0.0	2.0	0.0000000000	False
size of your hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
bias of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
variance in your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
fit this hypothesis class	0.0	0.0	0.0	2.0	0.0000000000	False
class to the data	0.0	0.0	0.0	2.0	0.0000000000	False
data and by switching	0.0	0.0	0.0	2.0	0.0000000000	False
increases and your bias	0.0	0.0	0.0	2.0	0.0000000000	False
decreases as a note	0.0	0.0	0.0	2.0	0.0000000000	False
statistics class you ve	0.0	0.0	0.0	0.0	0.0000000000	False
terms of squared error	0.0	0.0	0.0	2.0	0.0000000000	False
out that for classification	0.0	0.0	0.0	2.0	0.0000000000	False
universally accepted formal definition	0.0	0.0	0.0	2.0	0.0000000000	False
formal definition of bias	0.0	0.0	0.0	2.0	0.0000000000	False
variance for classification problems	0.0	0.0	0.0	2.0	0.0000000000	False
classification problems for regression	0.0	0.0	0.0	2.0	0.0000000000	False
problems for regression problems	0.0	0.0	0.0	2.0	0.0000000000	False
error definition for classification	0.0	0.0	0.0	2.0	0.0000000000	False
definition for classification problems	0.0	0.0	0.0	2.0	0.0000000000	False
classification problems it turns	0.0	0.0	0.0	2.0	0.0000000000	False
ve been several competing	0.0	0.0	0.0	2.0	0.0000000000	False
competing proposals for definitions	0.0	0.0	0.0	2.0	0.0000000000	False
definitions okay the cartoon	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon associated with intuition	0.0	0.0	0.0	2.0	0.0000000000	False
fixed training set size	0.0	0.0	0.0	2.0	0.0000000000	False
size m vertical axis	0.0	0.0	0.0	2.0	0.0000000000	False
axis i ll plot	0.0	0.0	0.0	0.0	0.0000000000	False
ll plot model complexity	0.0	0.0	0.0	2.0	0.0000000000	False
complexity and by model	0.0	0.0	0.0	2.0	0.0000000000	False
complexity i mean sort	0.0	0.0	0.0	2.0	0.0000000000	False
remember the bandwidth parameter	0.0	0.0	0.0	2.0	0.0000000000	False
parameter from locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
locally weighted linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
similar effect in controlling	0.0	0.0	0.0	2.0	0.0000000000	False
model is model complexity	0.0	0.0	0.0	2.0	0.0000000000	False
complexity polynomial i guess	0.0	0.0	0.0	2.0	0.0000000000	False
training error will tend	0.0	0.0	0.0	2.0	0.0000000000	False
complexity of your model	0.0	0.0	0.0	2.0	0.0000000000	False
fit your training set	0.0	0.0	0.0	2.0	0.0000000000	False
find that generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
regime on the left	0.0	0.0	0.0	2.0	0.0000000000	False
re underfitting the data	0.0	0.0	0.0	2.0	0.0000000000	False
bias and this regime	0.0	0.0	0.0	2.0	0.0000000000	False
regime on the right	0.0	0.0	0.0	2.0	0.0000000000	False
variance or you re	0.0	0.0	0.0	0.0	0.0000000000	False
re overfitting the data	0.0	0.0	0.0	2.0	0.0000000000	False
sort of intermediate complexity	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the number	0.0	0.0	0.0	2.0	0.0000000000	False
automatically select model complexities	0.0	0.0	0.0	2.0	0.0000000000	False
area of minimized generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error the last thing	0.0	0.0	0.0	2.0	0.0000000000	False
back to the theorem	0.0	0.0	0.0	2.0	0.0000000000	False
out was an error	0.0	0.0	0.0	2.0	0.0000000000	False
last thing i wan	0.0	0.0	0.0	4.0	0.0000000000	False
wan na do today	0.0	0.0	0.0	2.0	0.0000000000	False
back to this theorem	0.0	0.0	0.0	2.0	0.0000000000	False
fix my error bound	0.0	0.0	0.0	2.0	0.0000000000	False
fix delta and solve	0.0	0.0	0.0	2.0	0.0000000000	False
fixed with k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
fixed then in order	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
choose with empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
two times gamma worse	0.0	0.0	0.0	2.0	0.0000000000	False
error i could obtain	0.0	0.0	0.0	2.0	0.0000000000	False
obtain with this hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hold true with probability	0.0	0.0	0.0	2.0	0.0000000000	False
solving for the error	0.0	0.0	0.0	2.0	0.0000000000	False
re going to convince	0.0	0.0	0.0	2.0	0.0000000000	False
set that term gamma	0.0	0.0	0.0	2.0	0.0000000000	False
term gamma and solve	0.0	0.0	0.0	2.0	0.0000000000	False
result really holds true	0.0	0.0	0.0	2.0	0.0000000000	False
theorem we ve proved	0.0	0.0	0.0	0.0	0.0000000000	False
proved in other words	0.0	0.0	0.0	2.0	0.0000000000	False
bounds in learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
learning theory it turns	0.0	0.0	0.0	2.0	0.0000000000	False
loose so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
bounds usually we re	0.0	0.0	0.0	0.0	0.0000000000	False
interested in the constants	0.0	0.0	0.0	2.0	0.0000000000	False
log k over delta	0.0	0.0	0.0	2.0	0.0000000000	False
size of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class is logarithmic	0.0	0.0	0.0	2.0	0.0000000000	False
cool so next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
start from this result	0.0	0.0	0.0	2.0	0.0000000000	False
generalize these to infinite	0.0	0.0	0.0	2.0	0.0000000000	False
classes and then talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about practical algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
practical algorithms for model	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms for model spectrum	0.0	0.0	0.0	2.0	0.0000000000	False
ll see you guys	0.0	0.0	0.0	2.0	0.0000000000	False
guys in a couple	0.0	0.0	0.0	2.0	0.0000000000	False
couple of quick announcements	0.0	0.0	0.0	2.0	0.0000000000	False
ve all been graded	0.0	0.0	0.0	2.0	0.0000000000	False
end of lecture today	0.0	0.0	0.0	4.0	0.0000000000	False
today if you re	0.0	0.0	0.0	0.0	0.0000000000	False
re an sepd student	0.0	0.0	2.9985	6.0	0.0000000000	False
submitted your problem set	0.0	0.0	0.0	2.0	0.0000000000	False
copy of your homework	0.0	0.0	0.0	2.0	0.0000000000	False
late hand in box	0.0	0.0	0.0	4.0	0.0000000000	False
classroom at the end	0.0	0.0	0.0	2.0	0.0000000000	False
pick up and homework	0.0	0.0	0.0	2.0	0.0000000000	False
nt picked up today	0.0	0.0	0.0	0.0	0.0000000000	False
basement of the gates	0.0	0.0	0.0	2.0	0.0000000000	False
end of class today	0.0	0.0	0.0	2.0	0.0000000000	False
posted on the web	0.0	0.0	0.0	2.0	0.0000000000	False
posted online last week	0.0	0.0	0.0	2.0	0.0000000000	False
week so do make	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you download	0.0	0.0	0.0	2.0	0.0000000000	False
sort of personally gratifying	0.0	0.0	0.0	2.0	0.0000000000	False
people in this class	0.0	0.0	0.0	2.0	0.0000000000	False
late on monday night	0.0	0.0	0.0	2.0	0.0000000000	False
announcement just a reminder	0.0	0.0	0.0	2.0	0.0000000000	False
midterm for this class	0.0	0.0	0.0	2.0	0.0000000000	False
p.m so the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
guess so the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
bring but no laptops	0.0	0.0	0.0	2.0	0.0000000000	False
laptops and computers sepd	0.0	0.0	0.0	2.0	0.0000000000	False
live in the bay	0.0	0.0	0.0	2.0	0.0000000000	False
person on the evening	0.0	0.0	0.0	2.0	0.0000000000	False
november if you re	0.0	0.0	0.0	0.0	0.0000000000	False
live outside the bay	0.0	0.0	0.0	4.0	0.0000000000	False
nt drive to stanford	0.0	0.0	0.0	0.0	0.0000000000	False
usual class mailing address	0.0	0.0	0.0	2.0	0.0000000000	False
midterm because you live	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you email	0.0	0.0	0.0	2.0	0.0000000000	False
arrangements for the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
taking this via sepd	0.0	0.0	0.0	2.0	0.0000000000	False
equal or greater importance	0.0	0.0	0.0	2.0	0.0000000000	False
midterm of another class	0.0	0.0	0.0	2.0	0.0000000000	False
usual staff mailing address	0.0	0.0	0.0	2.0	0.0000000000	False
showing up in person	0.0	0.0	0.0	2.0	0.0000000000	False
person for the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
midterm okay any questions	0.0	0.0	0.0	2.0	0.0000000000	False
lecture s technical material	0.0	0.0	0.0	0.0	0.0000000000	False
week s discussion section	0.0	0.0	0.0	0.0	0.0000000000	False
talking about convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
last week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
discussion section they discussed	0.0	0.0	0.0	2.0	0.0000000000	False
discussed total convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization and this week	0.0	0.0	0.0	2.0	0.0000000000	False
week they ll wrap	0.0	0.0	0.0	0.0	0.0000000000	False
wrap up the material	0.0	0.0	0.0	2.0	0.0000000000	False
present on convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
today in this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
talk a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit more about learning	0.0	0.0	0.0	2.0	0.0000000000	False
talk about vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
building on the issues	0.0	0.0	0.0	2.0	0.0000000000	False
issues of bias variance	0.0	0.0	0.0	2.0	0.0000000000	False
tradeoffs of under fitting	0.0	0.0	0.0	2.0	0.0000000000	False
fitting and over fitting	0.0	0.0	0.0	2.0	0.0000000000	False
talk about model selection	0.0	0.0	3.9985	6.0	0.0000000000	False
algorithms for automatically making	0.0	0.0	0.0	2.0	0.0000000000	False
decisions for this bias	0.0	0.0	0.0	2.0	0.0000000000	False
previous lecture and depending	0.0	0.0	0.0	2.0	0.0000000000	False
set of k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that this holds	0.0	0.0	2.9985	6.0	0.0000000000	False
minus delta it suffices	0.0	0.0	0.0	2.0	0.0000000000	False
talked about empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
simplified modern machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class of script	0.0	0.0	0.0	2.0	0.0000000000	False
empirical risk minimization-learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
attains the smallest error	0.0	0.0	0.0	2.0	0.0000000000	False
error on the training	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error ; right	0.0	0.0	0.0	2.0	0.0000000000	False
probability of a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
distribution as the training	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
output by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
class plus two times	0.0	0.0	0.0	2.0	0.0000000000	False
times gamma two times	0.0	0.0	0.0	2.0	0.0000000000	False
two times this error	0.0	0.0	0.0	2.0	0.0000000000	False
times this error threshold	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta we show	0.0	0.0	0.0	2.0	0.0000000000	False
show that it suffices	0.0	0.0	0.0	2.0	0.0000000000	False
suffices for your training	0.0	0.0	0.0	2.0	0.0000000000	False
two gamma square log	0.0	0.0	0.0	2.0	0.0000000000	False
two k over delta	0.0	0.0	0.0	2.0	0.0000000000	False
size of your hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
bound in the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of training examples	0.0	0.0	9.994	24.0	0.3925233645	False
case of infinite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
script h is sort	0.0	0.0	0.0	2.0	0.0000000000	False
model like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
parameterized by real numbers	0.0	0.0	0.0	2.0	0.0000000000	False
first going to give	0.0	0.0	0.0	2.0	0.0000000000	False
argument that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
sort of formally broken	0.0	0.0	0.0	2.0	0.0000000000	False
formally broken just sort	0.0	0.0	0.0	2.0	0.0000000000	False
proof is somewhat involved	0.0	0.0	0.0	2.0	0.0000000000	False
apply this result analyzing	0.0	0.0	0.0	2.0	0.0000000000	False
result analyzing logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
script h is parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
re applying logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression to find	0.0	0.0	0.0	2.0	0.0000000000	False
find the linear position	0.0	0.0	0.0	2.0	0.0000000000	False
endless one real numbers	0.0	0.0	0.0	2.0	0.0000000000	False
class is really represented	0.0	0.0	0.0	2.0	0.0000000000	False
represented in a computer	0.0	0.0	0.0	2.0	0.0000000000	False
double position floating point	0.0	0.0	0.0	2.0	0.0000000000	False
position floating point numbers	0.0	0.0	0.0	2.0	0.0000000000	False
real number is represented	0.0	0.0	0.0	2.0	0.0000000000	False
64-bit representation ; right	0.0	0.0	0.0	2.0	0.0000000000	False
times d bits computers	0.0	0.0	0.0	2.0	0.0000000000	False
computers ca nt represent	0.0	0.0	0.0	0.0	0.0000000000	False
nt represent real numbers	0.0	0.0	0.0	0.0	0.0000000000	False
numbers they only represent	0.0	0.0	0.0	2.0	0.0000000000	False
represent used to speed	0.0	0.0	0.0	2.0	0.0000000000	False
class in your computer	0.0	0.0	0.0	2.0	0.0000000000	False
number of possible values	0.0	0.0	0.0	2.0	0.0000000000	False
ways you can flip	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that a hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
returned by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in your hypotheses	0.0	0.0	0.0	4.0	0.0000000000	False
sort of error bound	0.0	0.0	0.0	2.0	0.0000000000	False
intuition that this conveys	0.0	0.0	0.0	2.0	0.0000000000	False
linear in the number	0.0	0.0	3.9985	6.0	0.0000000000	False
parameters of your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
order of something linear	0.0	0.0	0.0	2.0	0.0000000000	False
sense that it relies	0.0	0.0	0.0	2.0	0.0000000000	False
representation of 14-point numbers	0.0	0.0	0.0	2.0	0.0000000000	False
right way to show	0.0	0.0	0.0	4.0	0.0000000000	False
formally ; all right	0.0	0.0	0.0	2.0	0.0000000000	False
turns out the right	0.0	0.0	0.0	2.0	0.0000000000	False
involves a much longer	0.0	0.0	0.0	2.0	0.0000000000	False
longer because the proof	0.0	0.0	0.0	2.0	0.0000000000	False
proof is extremely involved	0.0	0.0	0.0	2.0	0.0000000000	False
prove it farther proof	0.0	0.0	0.0	2.0	0.0000000000	False
proof be a source	0.0	0.0	0.0	2.0	0.0000000000	False
source of learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis classes this definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition given a set	0.0	0.0	0.0	2.0	0.0000000000	False
set of d points	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class h shatters	0.0	0.0	0.0	2.0	0.0000000000	False
informal way of thinking	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class has shattered	0.0	0.0	0.0	2.0	0.0000000000	False
associate these d points	0.0	0.0	0.0	2.0	0.0000000000	False
points with any caught	0.0	0.0	0.0	2.0	0.0000000000	False
caught set of labels	0.0	0.0	0.0	2.0	0.0000000000	False
labels y ; right	0.0	0.0	0.0	2.0	0.0000000000	False
labels those d examples	0.0	0.0	0.0	2.0	0.0000000000	False
points you can choose	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class h classed	0.0	0.0	0.0	2.0	0.0000000000	False
classed all linear classifiers	0.0	0.0	0.0	2.0	0.0000000000	False
find a linear classifier	0.0	0.0	0.0	2.0	0.0000000000	False
linear classifier that attains	0.0	0.0	0.0	2.0	0.0000000000	False
attains zero training error	0.0	0.0	0.0	2.0	0.0000000000	False
labelings of this set	0.0	0.0	0.0	2.0	0.0000000000	False
set of two points	0.0	0.0	0.0	2.0	0.0000000000	False
class script h shatters	0.0	0.0	0.0	2.0	0.0000000000	False
set of three points	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis in the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class that labels	0.0	0.0	0.0	2.0	0.0000000000	False
labels these examples correctly	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class also shatters	0.0	0.0	0.0	2.0	0.0000000000	False
terminology h can realize	0.0	0.0	0.0	2.0	0.0000000000	False
give it any set	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that perfectly separates	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative examples	0.0	0.0	0.0	2.0	0.0000000000	False
set of four points	0.0	0.0	2.9985	6.0	0.0000000000	False
labelings we can choose	0.0	0.0	0.0	2.0	0.0000000000	False
boundary that can realize	0.0	0.0	0.0	2.0	0.0000000000	False
points that the class	0.0	0.0	0.0	2.0	0.0000000000	False
linear classifiers can shatter	0.0	0.0	0.0	2.0	0.0000000000	False
dimension these two people	0.0	0.0	0.0	2.0	0.0000000000	False
vapnik and chervonenkis dimension	0.0	0.0	0.0	2.0	0.0000000000	False
set that is shattered	0.0	0.0	0.0	2.0	0.0000000000	False
shattered by this set	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class can shatter	0.0	0.0	0.0	2.0	0.0000000000	False
shatter arbitrarily large sets	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the set	0.0	0.0	0.0	2.0	0.0000000000	False
set s of size	0.0	0.0	0.0	2.0	0.0000000000	False
absolutely so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
exists some other set	0.0	0.0	0.0	2.0	0.0000000000	False
size three being shattered	0.0	0.0	0.0	2.0	0.0000000000	False
four that can shatter	0.0	0.0	0.0	2.0	0.0000000000	False
nt shatter this set	0.0	0.0	0.0	0.0	0.0000000000	False
shatter and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out this result	0.0	0.0	0.0	2.0	0.0000000000	False
out this result holds	0.0	0.0	0.0	2.0	0.0000000000	False
dimensions the vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the class	0.0	0.0	0.0	4.0	0.0000000000	False
class of linear classifiers	0.0	0.0	2.9985	6.0	0.0000000000	False
classifiers in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
dimension in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
arguably the best-known result	0.0	0.0	0.0	2.0	0.0000000000	False
probability of one minus	0.0	0.0	0.0	4.0	0.0000000000	False
formula on the right	0.0	0.0	0.0	2.0	0.0000000000	False
right looks a bit	0.0	0.0	0.0	2.0	0.0000000000	False
out the essential aspects	0.0	0.0	0.0	2.0	0.0000000000	False
key to this result	0.0	0.0	0.0	2.0	0.0000000000	False
class with vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
vapnik and chervonenkis show	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta you enjoy	0.0	0.0	0.0	2.0	0.0000000000	False
sort of uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
error of h minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus the training error	0.0	0.0	0.0	2.0	0.0000000000	False
two things is bounded	0.0	0.0	0.0	2.0	0.0000000000	False
re probably one minus	0.0	0.0	0.0	2.0	0.0000000000	False
step to this step	0.0	0.0	0.0	4.0	0.0000000000	False
previous lecture we proved	0.0	0.0	0.0	2.0	0.0000000000	False
implies that it appears	0.0	0.0	0.0	2.0	0.0000000000	False
showed that if generalization	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error and training	0.0	0.0	0.0	2.0	0.0000000000	False
error and training error	0.0	0.0	0.0	2.0	0.0000000000	False
error of the hypotheses	0.0	0.0	0.0	4.0	0.0000000000	False
times the best generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error plus two times	0.0	0.0	0.0	2.0	0.0000000000	False
notation so that formula	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta we re	0.0	0.0	0.0	0.0	0.0000000000	False
put gamma and delta	0.0	0.0	0.0	2.0	0.0000000000	False
subscript error to denote	0.0	0.0	0.0	2.0	0.0000000000	False
treat gamma and delta	0.0	0.0	0.0	2.0	0.0000000000	False
absorb turns that depend	0.0	0.0	0.0	2.0	0.0000000000	False
dimension and hypotheses class	0.0	0.0	0.0	2.0	0.0000000000	False
empirical risk minimization algorithms	0.0	0.0	0.0	4.0	0.0000000000	False
algorithms in other words	0.0	0.0	0.0	2.0	0.0000000000	False
training error the intuition	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
shows that sample complexity	0.0	0.0	0.0	2.0	0.0000000000	False
complexity is upper bounded	0.0	0.0	0.0	4.0	0.0000000000	False
model and logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression linear classification	0.0	0.0	0.0	2.0	0.0000000000	False
classification in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
regression in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of your model	0.0	0.0	0.0	4.0	0.0000000000	False
fit in those models	0.0	0.0	0.0	2.0	0.0000000000	False
parameters in your model	0.0	0.0	0.0	2.0	0.0000000000	False
source of not learning	0.0	0.0	0.0	2.0	0.0000000000	False
result shows the sample	0.0	0.0	0.0	2.0	0.0000000000	False
shows the sample complexity	0.0	0.0	0.0	2.0	0.0000000000	False
bounded by vc dimension	0.0	0.0	0.0	4.0	0.0000000000	False
worse case some complexity	0.0	0.0	0.0	2.0	0.0000000000	False
perfectly nasty learning problem	0.0	0.0	0.0	2.0	0.0000000000	False
bound so i guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess in the worse	0.0	0.0	0.0	2.0	0.0000000000	False
complexity in the number	0.0	0.0	0.0	2.0	0.0000000000	False
bounded and lower bounded	0.0	0.0	0.0	2.0	0.0000000000	False
proof of this assume	0.0	0.0	0.0	2.0	0.0000000000	False
entirety of the theorem	0.0	0.0	0.0	2.0	0.0000000000	False
theorem this is true	0.0	0.0	0.0	2.0	0.0000000000	False
out in the proof	0.0	0.0	0.0	2.0	0.0000000000	False
reconstruction called an epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
working through this proof	0.0	0.0	0.0	2.0	0.0000000000	False
start reading the book	0.0	0.0	0.0	2.0	0.0000000000	False
thought i would inflict	0.0	0.0	0.0	2.0	0.0000000000	False
couple of loose ends	0.0	0.0	0.0	4.0	0.0000000000	False
mention a few things	0.0	0.0	0.0	2.0	0.0000000000	False
feel a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit like random facts	0.0	0.0	0.0	2.0	0.0000000000	False
proved for an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
minimizes 0-1 training error	0.0	0.0	0.0	2.0	0.0000000000	False
error so one question	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on support vector	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature space	0.0	0.0	0.0	2.0	0.0000000000	False
infinite so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out that the class	0.0	0.0	0.0	2.0	0.0000000000	False
class of linear separators	0.0	0.0	0.0	2.0	0.0000000000	False
separators with large margin	0.0	0.0	0.0	4.0	0.0000000000	False
give you a set	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class will comprise	0.0	0.0	0.0	2.0	0.0000000000	False
comprise only the linear	0.0	0.0	0.0	2.0	0.0000000000	False
nt allow a point	0.0	0.0	0.0	0.0	0.0000000000	False
point that comes closer	0.0	0.0	0.0	2.0	0.0000000000	False
nt allow that line	0.0	0.0	0.0	0.0	0.0000000000	False
data points all lie	0.0	0.0	0.0	2.0	0.0000000000	False
lie within some sphere	0.0	0.0	0.0	2.0	0.0000000000	False
data with a margin	0.0	0.0	0.0	2.0	0.0000000000	False
equal to r squared	0.0	0.0	0.0	2.0	0.0000000000	False
squared over four gamma	0.0	0.0	0.0	2.0	0.0000000000	False
symbol ; it means	0.0	0.0	0.0	2.0	0.0000000000	False
turns out you prove	0.0	0.0	0.0	2.0	0.0000000000	False
things about this result	0.0	0.0	0.0	2.0	0.0000000000	False
talk about but turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns they can prove	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers with large margins	0.0	0.0	0.0	2.0	0.0000000000	False
margins is actually bounded	0.0	0.0	0.0	2.0	0.0000000000	False
bounded the surprising thing	0.0	0.0	0.0	2.0	0.0000000000	False
bound on vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dependents on the dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the points	0.0	0.0	0.0	2.0	0.0000000000	False
data points x combine	0.0	0.0	0.0	2.0	0.0000000000	False
long as you restrict	0.0	0.0	0.0	2.0	0.0000000000	False
attention to the class	0.0	0.0	0.0	2.0	0.0000000000	False
class of your separators	0.0	0.0	0.0	2.0	0.0000000000	False
find a large margin	0.0	0.0	0.0	2.0	0.0000000000	False
examples with large margin	0.0	0.0	0.0	2.0	0.0000000000	False
automatically trying to find	0.0	0.0	0.0	2.0	0.0000000000	False
find a hypothesis class	0.0	0.0	0.0	2.0	0.0000000000	False
constantly infinite dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
equal to some equals	0.0	0.0	0.0	2.0	0.0000000000	False
tie empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
strongly to the source	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms we ve talked	0.0	0.0	0.0	0.0	0.0000000000	False
talked about it turns	0.0	0.0	0.0	2.0	0.0000000000	False
minimization so that view	0.0	0.0	0.0	2.0	0.0000000000	False
training example your training	0.0	0.0	0.0	2.0	0.0000000000	False
value of this data	0.0	0.0	0.0	2.0	0.0000000000	False
guess if your training	0.0	0.0	0.0	2.0	0.0000000000	False
subscript x not equals	0.0	0.0	0.0	2.0	0.0000000000	False
minimize this step function	0.0	0.0	0.0	4.0	0.0000000000	False
step function ; right	0.0	0.0	0.0	2.0	0.0000000000	False
correct classification on setting	0.0	0.0	0.0	2.0	0.0000000000	False
turns out this step	0.0	0.0	0.0	2.0	0.0000000000	False
out this step function	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers minimizing the training	0.0	0.0	0.0	2.0	0.0000000000	False
minimizing the training error	0.0	0.0	0.0	2.0	0.0000000000	False
error is an empty	0.0	0.0	0.0	2.0	0.0000000000	False
heart problem it turns	0.0	0.0	0.0	2.0	0.0000000000	False
machines can be viewed	0.0	0.0	0.0	2.0	0.0000000000	False
approximation for this problem	0.0	0.0	0.0	2.0	0.0000000000	False
out that logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
ll be a function	0.0	0.0	0.0	2.0	0.0000000000	False
approximation to this step	0.0	0.0	0.0	2.0	0.0000000000	False
approximate empirical risk minimization	0.0	0.0	0.0	4.0	0.0000000000	False
line above this curve	0.0	0.0	0.0	2.0	0.0000000000	False
problem you can find	0.0	0.0	0.0	2.0	0.0000000000	False
find the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
parameters for logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
viewed as approximated dysfunction	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine turns	0.0	0.0	0.0	2.0	0.0000000000	False
approximate this step function	0.0	0.0	0.0	2.0	0.0000000000	False
two over different approximation	0.0	0.0	0.0	2.0	0.0000000000	False
linear that our results	0.0	0.0	0.0	2.0	0.0000000000	False
regression and the support	0.0	0.0	0.0	2.0	0.0000000000	False
machine as different approximations	0.0	0.0	0.0	2.0	0.0000000000	False
developed even though svm	0.0	0.0	0.0	2.0	0.0000000000	False
due to empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
last of the loose	0.0	0.0	0.0	2.0	0.0000000000	False
move on to talk	0.0	0.0	0.0	2.0	0.0000000000	False
theory that we started	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
important not to choose	0.0	0.0	0.0	2.0	0.0000000000	False
simple or too complex	0.0	0.0	0.0	2.0	0.0000000000	False
choose a linear function	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis with high bias	0.0	0.0	0.0	2.0	0.0000000000	False
generalize well so model	0.0	0.0	0.0	2.0	0.0000000000	False
model selection algorithms provide	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms provide a class	0.0	0.0	0.0	2.0	0.0000000000	False
methods to automatically trade	0.0	0.0	0.0	2.0	0.0000000000	False
trade make these tradeoffs	0.0	0.0	0.0	2.0	0.0000000000	False
last time of generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error ? i drew	0.0	0.0	0.0	2.0	0.0000000000	False
x-axis was model complexity	0.0	0.0	0.0	2.0	0.0000000000	False
number of the degree	0.0	0.0	0.0	2.0	0.0000000000	False
polynomial ; the regression	0.0	0.0	0.0	2.0	0.0000000000	False
polynomial to five data	0.0	0.0	0.0	2.0	0.0000000000	False
selection in the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
abstract ; all right	0.0	0.0	0.0	2.0	0.0000000000	False
right ? some examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples of model selection	0.0	0.0	0.0	4.0	0.0000000000	False
selection problems will include	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to choose	0.0	0.0	7.998	8.0	0.0000000000	False
right ? what degree	0.0	0.0	0.0	2.0	0.0000000000	False
parameter in locally awaited	0.0	0.0	0.0	2.0	0.0000000000	False
locally awaited linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
local way to regression	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective ; right	0.0	0.0	0.0	2.0	0.0000000000	False
penalize in this class	0.0	0.0	0.0	2.0	0.0000000000	False
specific examples of model	0.0	0.0	0.0	2.0	0.0000000000	False
method for semantically choosing	0.0	0.0	0.0	2.0	0.0000000000	False
finite set of models	0.0	0.0	0.0	2.0	0.0000000000	False
bandwidth parameter and discretize	0.0	0.0	0.0	2.0	0.0000000000	False
discrete of the values	0.0	0.0	0.0	2.0	0.0000000000	False
select an appropriate model	0.0	0.0	0.0	2.0	0.0000000000	False
model ; all right	0.0	0.0	0.0	2.0	0.0000000000	False
laughing that i asked	0.0	0.0	0.0	2.0	0.0000000000	False
terrible idea to choose	0.0	0.0	0.0	2.0	0.0000000000	False
complex model ; right	0.0	0.0	0.0	2.0	0.0000000000	False
choose a 10th degree	0.0	0.0	0.0	2.0	0.0000000000	False
fits the training set	0.0	0.0	0.0	2.0	0.0000000000	False
selection in a training	0.0	0.0	0.0	2.0	0.0000000000	False
set several standard procedures	0.0	0.0	0.0	2.0	0.0000000000	False
hold out cross validation	0.0	0.0	9.994	24.0	0.3559322034	False
teach a training set	0.0	0.0	0.0	2.0	0.0000000000	False
randomly split the training	0.0	0.0	0.0	2.0	0.0000000000	False
split the training set	0.0	0.0	0.0	2.0	0.0000000000	False
set into two subsets	0.0	0.0	0.0	2.0	0.0000000000	False
two subsets we call	0.0	0.0	0.0	2.0	0.0000000000	False
call it the training	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation subset	0.0	0.0	0.0	4.0	0.0000000000	False
model on just trading	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation set	0.0	0.0	0.0	4.0	0.0000000000	False
set and you pick	0.0	0.0	0.0	2.0	0.0000000000	False
error on the hold	0.0	0.0	0.0	2.0	0.0000000000	False
percent of the data	0.0	0.0	2.998	8.0	0.0000000000	False
smallest hold out cross	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation error	0.0	0.0	0.0	4.0	0.0000000000	False
error on your hold	0.0	0.0	0.0	2.0	0.0000000000	False
model that you selected	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that was trained	0.0	0.0	0.0	2.0	0.0000000000	False
percent of your data	0.0	0.0	3.998	8.0	0.0000000000	False
cross validation does sort	0.0	0.0	0.0	2.0	0.0000000000	False
working with a company	0.0	0.0	0.0	2.0	0.0000000000	False
acquired at great cost	0.0	0.0	0.0	2.0	0.0000000000	False
great cost ; right	0.0	0.0	0.0	2.0	0.0000000000	False
acquired by medical experiments	0.0	0.0	0.0	2.0	0.0000000000	False
represents a sick man	0.0	0.0	0.0	2.0	0.0000000000	False
sick man in amounts	0.0	0.0	0.0	2.0	0.0000000000	False
amounts of physical human	0.0	0.0	0.0	2.0	0.0000000000	False
couple of other variations	0.0	0.0	0.0	2.0	0.0000000000	False
variations on hold out	0.0	0.0	0.0	2.0	0.0000000000	False
cross validation that makes	0.0	0.0	0.0	2.0	0.0000000000	False
train on k minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one pieces test	0.0	0.0	0.0	2.0	0.0000000000	False
test on the remaining	0.0	0.0	0.0	4.0	0.0000000000	False
out i will hold	0.0	0.0	0.0	2.0	0.0000000000	False
train on the remaining	0.0	0.0	0.0	2.0	0.0000000000	False
remove the third piece	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error of my model	0.0	0.0	0.0	2.0	0.0000000000	False
selected on the entirety	0.0	0.0	0.0	2.0	0.0000000000	False
entirety of your training	0.0	0.0	0.0	2.0	0.0000000000	False
set so i drew	0.0	0.0	0.0	2.0	0.0000000000	False
validation and the advantage	0.0	0.0	0.0	2.0	0.0000000000	False
hold out cross option	0.0	0.0	0.0	2.0	0.0000000000	False
data into ten pieces	0.0	0.0	0.0	2.0	0.0000000000	False
out in simple hold	0.0	0.0	0.0	2.0	0.0000000000	False
simple hold out cross	0.0	0.0	0.0	4.0	0.0000000000	False
split is fairly common	0.0	0.0	0.0	4.0	0.0000000000	False
common choice the disadvantage	0.0	0.0	0.0	2.0	0.0000000000	False
disadvantage of k-fold cross	0.0	0.0	0.0	2.0	0.0000000000	False
train your model ten	0.0	0.0	0.0	2.0	0.0000000000	False
ten times per model	0.0	0.0	0.0	2.0	0.0000000000	False
expensive but k equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals ten works great	0.0	0.0	0.0	2.0	0.0000000000	False
examples and this procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedure is called leave	0.0	0.0	0.0	2.0	0.0000000000	False
leave one out cross	0.0	0.0	2.998	8.0	0.4158415842	False
out the first training	0.0	0.0	0.0	2.0	0.0000000000	False
train on the rest	0.0	0.0	0.0	4.0	0.0000000000	False
out the second training	0.0	0.0	0.0	2.0	0.0000000000	False
data than k-fold cross	0.0	0.0	0.0	2.0	0.0000000000	False
leave one example out	0.0	0.0	0.0	2.0	0.0000000000	False
run your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm on m minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one training examples	0.0	0.0	0.0	2.0	0.0000000000	False
re extremely data scarce	0.0	0.0	0.0	2.0	0.0000000000	False
validation is maybe preferred	0.0	0.0	0.0	2.0	0.0000000000	False
proved that the difference	0.0	0.0	0.0	2.0	0.0000000000	False
examples in your training	0.0	0.0	0.0	2.0	0.0000000000	False
set and vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dimension so maybe examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples into different groups	0.0	0.0	0.0	2.0	0.0000000000	False
compute the training error	0.0	0.0	0.0	2.0	0.0000000000	False
people in structure risk	0.0	0.0	0.0	2.0	0.0000000000	False
risk minimization that propose	0.0	0.0	0.0	2.0	0.0000000000	False
questions for cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
points do you sort	0.0	0.0	0.0	2.0	0.0000000000	False
re proving learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
proving learning theory bounds	0.0	0.0	0.0	2.0	0.0000000000	False
loose because you re	0.0	0.0	0.0	0.0	0.0000000000	False
re sort of proving	0.0	0.0	0.0	2.0	0.0000000000	False
proving the worse case	0.0	0.0	0.0	2.0	0.0000000000	False
worse case upper bound	0.0	0.0	0.0	2.0	0.0000000000	False
upper bound that holds	0.0	0.0	0.0	2.0	0.0000000000	False
bounds that i proved	0.0	0.0	0.0	2.0	0.0000000000	False
right ? that holds	0.0	0.0	0.0	2.0	0.0000000000	False
absolutely any probability distribution	0.0	0.0	0.0	4.0	0.0000000000	False
probability distribution over training	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over training examples	0.0	0.0	0.0	2.0	0.0000000000	False
assume the training examples	0.0	0.0	0.0	2.0	0.0000000000	False
training examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
examples we ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
iid from some distribution	0.0	0.0	0.0	2.0	0.0000000000	False
probability distribution over script	0.0	0.0	0.0	2.0	0.0000000000	False
script d and chances	0.0	0.0	0.0	2.0	0.0000000000	False
houses and their prices	0.0	0.0	0.0	2.0	0.0000000000	False
plug in the constants	0.0	0.0	0.0	2.0	0.0000000000	False
constants of learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
numbers take logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression you have ten	0.0	0.0	0.0	2.0	0.0000000000	False
probability how many training	0.0	0.0	0.0	2.0	0.0000000000	False
plug in actual constants	0.0	0.0	0.0	2.0	0.0000000000	False
constants into the text	0.0	0.0	0.0	2.0	0.0000000000	False
text for learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
estimates with the number	0.0	0.0	0.0	2.0	0.0000000000	False
training examples to fit	0.0	0.0	0.0	2.0	0.0000000000	False
examples to fit ten	0.0	0.0	0.0	2.0	0.0000000000	False
write papers on learning	0.0	0.0	0.0	2.0	0.0000000000	False
papers on learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
ignore the constant factors	0.0	0.0	0.0	2.0	0.0000000000	False
factors because the bounds	0.0	0.0	0.0	2.0	0.0000000000	False
bounds to give guidelines	0.0	0.0	0.0	2.0	0.0000000000	False
linearly in the number	0.0	0.0	0.0	2.0	0.0000000000	False
shape of the bounds	0.0	0.0	0.0	2.0	0.0000000000	False
fact that the number	0.0	0.0	0.0	2.0	0.0000000000	False
training examples the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that some complexity	0.0	0.0	0.0	2.0	0.0000000000	False
magnitude of the bound	0.0	0.0	0.0	2.0	0.0000000000	False
looser than will hold	0.0	0.0	0.0	2.0	0.0000000000	False
problem you are working	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to fit	0.0	0.0	0.0	2.0	0.0000000000	False
fit a logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
training examples is ten	0.0	0.0	0.0	2.0	0.0000000000	False
examples is ten times	0.0	0.0	0.0	2.0	0.0000000000	False
ten times your number	0.0	0.0	0.0	2.0	0.0000000000	False
examples is like tiny	0.0	0.0	0.0	2.0	0.0000000000	False
tiny times the number	0.0	0.0	0.0	2.0	0.0000000000	False
bounds in cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
validation do we assume	0.0	0.0	0.0	2.0	0.0000000000	False
convention we usually split	0.0	0.0	0.0	2.0	0.0000000000	False
split the train testers	0.0	0.0	0.0	2.0	0.0000000000	False
randomly one more thing	0.0	0.0	0.0	2.0	0.0000000000	False
talk about for model	0.0	0.0	0.0	2.0	0.0000000000	False
special case of model	0.0	0.0	0.0	2.0	0.0000000000	False
case of model selections	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional feature space	0.0	0.0	0.0	2.0	0.0000000000	False
classification and i wan	0.0	0.0	0.0	2.0	0.0000000000	False
talk about this text	0.0	0.0	0.0	2.0	0.0000000000	False
classification example that spam	0.0	0.0	0.0	2.0	0.0000000000	False
30,000 or 50,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
depending on what learning	0.0	0.0	0.0	2.0	0.0000000000	False
risk of over fitting	0.0	0.0	3.9985	6.0	0.0000000000	False
variance of your learning	0.0	0.0	0.0	2.0	0.0000000000	False
specific case of text	0.0	0.0	0.0	2.0	0.0000000000	False
case of text classification	0.0	0.0	0.0	4.0	0.0000000000	False
number of relevant features	0.0	0.0	0.0	2.0	0.0000000000	False
smaller number of features	0.0	0.0	0.0	2.0	0.0000000000	False
relevant to the learning	0.0	0.0	0.0	2.0	0.0000000000	False
word buy or viagra	0.0	0.0	0.0	2.0	0.0000000000	False
non-spam so in feature	0.0	0.0	0.0	2.0	0.0000000000	False
subset of the features	0.0	0.0	0.0	2.0	0.0000000000	False
give ourselves a simpler	0.0	0.0	0.0	2.0	0.0000000000	False
simpler learning a simpler	0.0	0.0	0.0	2.0	0.0000000000	False
learning a simpler hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class to choose	0.0	0.0	0.0	2.0	0.0000000000	False
space so in feature	0.0	0.0	0.0	2.0	0.0000000000	False
searcheristics sort of simple	0.0	0.0	0.0	2.0	0.0000000000	False
sort of simple search	0.0	0.0	0.0	2.0	0.0000000000	False
search through this space	0.0	0.0	0.0	2.0	0.0000000000	False
find a good subset	0.0	0.0	0.0	2.0	0.0000000000	False
good subset of features	0.0	0.0	0.0	2.0	0.0000000000	False
enumerate all possible feature	0.0	0.0	0.0	2.0	0.0000000000	False
initialize the sets script	0.0	0.0	0.0	2.0	0.0000000000	False
repeat for i equals	0.0	0.0	0.0	2.0	0.0000000000	False
model using cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
validation and by cross	0.0	0.0	0.0	2.0	0.0000000000	False
validation or k-fold cross	0.0	0.0	0.0	2.0	0.0000000000	False
cross validation or leave	0.0	0.0	0.0	2.0	0.0000000000	False
equal to f union	0.0	0.0	0.0	2.0	0.0000000000	False
follow through the empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty set of features	0.0	0.0	0.0	2.0	0.0000000000	False
feature to your set	0.0	0.0	0.0	4.0	0.0000000000	False
set then you train	0.0	0.0	0.0	2.0	0.0000000000	False
single feature to add	0.0	0.0	0.0	2.0	0.0000000000	False
add to your set	0.0	0.0	0.0	2.0	0.0000000000	False
script f in step	0.0	0.0	0.0	2.0	0.0000000000	False
feature or best model	0.0	0.0	0.0	2.0	0.0000000000	False
model according to hold	0.0	0.0	0.0	2.0	0.0000000000	False
feature addition that results	0.0	0.0	0.0	2.0	0.0000000000	False
lowest hold out cross	0.0	0.0	0.0	2.0	0.0000000000	False
lowest cross validation error	0.0	0.0	0.0	4.0	0.0000000000	False
added all the features	0.0	0.0	0.0	2.0	0.0000000000	False
entire set of features	0.0	0.0	0.0	4.0	0.0000000000	False
exceeded some threshold number	0.0	0.0	0.0	2.0	0.0000000000	False
threshold number of features	0.0	0.0	0.0	2.0	0.0000000000	False
re fitting logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
features added to set	0.0	0.0	0.0	2.0	0.0000000000	False
output of best hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
training lots of hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
testing them using cross	0.0	0.0	0.0	2.0	0.0000000000	False
output best hypothesis found	0.0	0.0	0.0	2.0	0.0000000000	False
selection and the term	0.0	0.0	0.0	2.0	0.0000000000	False
fact that this feature	0.0	0.0	0.0	2.0	0.0000000000	False
described is a forward	0.0	0.0	0.0	2.0	0.0000000000	False
selection or forward search	0.0	0.0	0.0	2.0	0.0000000000	False
software that you write	0.0	0.0	0.0	2.0	0.0000000000	False
wraps around your learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that to perform	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to train	0.0	0.0	0.0	2.0	0.0000000000	False
wrapper model feature selection	0.0	1.0	0.0	4.0	0.0000000000	True
re performing the search	0.0	0.0	0.0	2.0	0.0000000000	False
performing the search process	0.0	0.0	0.0	2.0	0.0000000000	False
repeatedly training your learning	0.0	0.0	0.0	2.0	0.0000000000	False
training your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
backward search or backward	0.0	0.0	0.0	4.0	0.0000000000	False
search or backward selection	0.0	0.0	0.0	4.0	0.0000000000	False
start with f equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals the entire set	0.0	0.0	0.0	2.0	0.0000000000	False
nt even make sense	0.0	0.0	0.0	0.0	0.0000000000	False
make sense to initialize	0.0	0.0	0.0	4.0	0.0000000000	False
set of all features	0.0	0.0	0.0	2.0	0.0000000000	False
examples and 10,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
emails and 10,000 training	0.0	0.0	0.0	2.0	0.0000000000	False
10,000 training 10,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
10,000 features in email	0.0	0.0	0.0	2.0	0.0000000000	False
training examples then depending	0.0	0.0	0.0	2.0	0.0000000000	False
depending on the learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm you re	0.0	0.0	0.0	0.0	0.0000000000	False
model feature selection algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
feature selection algorithms tend	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms tend to work	0.0	0.0	0.0	2.0	0.0000000000	False
re computationally very expensive	0.0	0.0	0.0	2.0	0.0000000000	False
right so forward search	0.0	0.0	0.0	2.0	0.0000000000	False
forward search and backward	0.0	0.0	0.0	2.0	0.0000000000	False
search and backward search	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee they ll find	0.0	0.0	0.0	0.0	0.0000000000	False
find the best subset	0.0	0.0	0.0	4.0	0.0000000000	False
features it actually turns	0.0	0.0	0.0	2.0	0.0000000000	False
formulizations of the feature	0.0	0.0	0.0	2.0	0.0000000000	False
problems it actually turns	0.0	0.0	0.0	2.0	0.0000000000	False
features but in practice	0.0	0.0	0.0	2.0	0.0000000000	False
forward selection backward selection	0.0	0.0	0.0	2.0	0.0000000000	False
selection backward selection work	0.0	0.0	0.0	2.0	0.0000000000	False
envision other search algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms where you sort	0.0	0.0	0.0	2.0	0.0000000000	False
search through the space	0.0	0.0	0.0	2.0	0.0000000000	False
end possible feature subsets	0.0	0.0	0.0	2.0	0.0000000000	False
selection tends to work	0.0	0.0	0.0	2.0	0.0000000000	False
computationally but for problems	0.0	0.0	0.0	2.0	0.0000000000	False
problems such as text	0.0	0.0	0.0	2.0	0.0000000000	False
text classification it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out for text	0.0	0.0	0.0	2.0	0.0000000000	False
out for text classification	0.0	0.0	0.0	2.0	0.0000000000	False
easily have 50,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
50,000 features forward selection	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms that will give	0.0	0.0	0.0	2.0	0.0000000000	False
sense of generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
error so you tend	0.0	0.0	0.0	2.0	0.0000000000	False
computationally much less expensive	0.0	0.0	0.0	2.0	0.0000000000	False
filter feature selection methods	0.0	0.0	0.0	2.0	0.0000000000	False
feature i will compute	0.0	0.0	0.0	2.0	0.0000000000	False
compute some rough estimate	0.0	0.0	0.0	2.0	0.0000000000	False
rough estimate or compute	0.0	0.0	0.0	2.0	0.0000000000	False
top k most correlated	0.0	0.0	0.0	2.0	0.0000000000	False
ideas in problem sets	0.0	0.0	0.0	2.0	0.0000000000	False
major information between feature	0.0	0.0	0.0	2.0	0.0000000000	False
write out the definition	0.0	0.0	0.0	2.0	0.0000000000	False
values of y times	0.0	0.0	0.0	2.0	0.0000000000	False
times the distribution times	0.0	0.0	0.0	2.0	0.0000000000	False
estimate from your training	0.0	0.0	0.0	2.0	0.0000000000	False
estimate from the training	0.0	0.0	0.0	2.0	0.0000000000	False
standard information theoretic measure	0.0	0.0	0.0	2.0	0.0000000000	False
class in information theory	0.0	0.0	0.0	2.0	0.0000000000	False
concepts of mutual information	0.0	0.0	0.0	2.0	0.0000000000	False
information is a measure	0.0	0.0	0.0	2.0	0.0000000000	False
distribution and this distribution	0.0	0.0	0.0	2.0	0.0000000000	False
non-independent in other words	0.0	0.0	0.0	2.0	0.0000000000	False
divergence will be large	0.0	0.0	0.0	2.0	0.0000000000	False
non-independent then that means	0.0	0.0	0.0	2.0	0.0000000000	False
information and this measure	0.0	0.0	0.0	2.0	0.0000000000	False
correlation or major information	0.0	0.0	0.0	2.0	0.0000000000	False
meaning that you compute	0.0	0.0	0.0	2.0	0.0000000000	False
features of mutual information	0.0	0.0	0.0	2.0	0.0000000000	False
include in your learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm the k features	0.0	0.0	0.0	2.0	0.0000000000	False
correlation with the label	0.0	0.0	0.0	2.0	0.0000000000	False
largest mutual information label	0.0	0.0	0.0	2.0	0.0000000000	False
sort them in decreasing	0.0	0.0	0.0	2.0	0.0000000000	False
order of mutual information	0.0	0.0	0.0	2.0	0.0000000000	False
decide how many features	0.0	0.0	0.0	2.0	0.0000000000	False
features includes using cross	0.0	0.0	0.0	2.0	0.0000000000	False
includes using cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
choose this by hand	0.0	0.0	0.0	2.0	0.0000000000	False
great so next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
lecture i ll continue	0.0	0.0	0.0	0.0	0.0000000000	False
continue i ll wrap	0.0	0.0	0.0	0.0	0.0000000000	False
good morning welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
today is actually wrap	0.0	0.0	0.0	2.0	0.0000000000	False
wrap up our discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
learning theory and sort	0.0	0.0	0.0	2.0	0.0000000000	False
talking about bayesian statistics	0.0	0.0	0.0	4.0	0.0000000000	False
bayesian statistics and regularization	0.0	0.0	0.0	4.0	0.0000000000	False
applying machine learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms to problems	0.0	0.0	0.0	2.0	0.0000000000	False
project or other problems	0.0	0.0	0.0	2.0	0.0000000000	False
graduate from this class	0.0	0.0	0.0	2.0	0.0000000000	False
regularization so you remember	0.0	0.0	0.0	2.0	0.0000000000	False
remember from last week	0.0	0.0	0.0	2.0	0.0000000000	False
talk about learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory and we learned	0.0	0.0	0.0	2.0	0.0000000000	False
variance and i guess	0.0	0.0	0.0	2.0	0.0000000000	False
lecture talking about algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms for model selection	0.0	0.0	0.0	2.0	0.0000000000	False
selection and for feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature selection we talked	0.0	0.0	0.0	2.0	0.0000000000	False
talked about cross-validation right	0.0	0.0	0.0	2.0	0.0000000000	False
previous lecture were ways	0.0	0.0	0.0	2.0	0.0000000000	False
selection algorithms we talked	0.0	0.0	0.0	2.0	0.0000000000	False
fit and thereby reduce	0.0	0.0	0.0	2.0	0.0000000000	False
feature selection algorithms choose	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms choose a subset	0.0	0.0	0.0	2.0	0.0000000000	False
subset of the features	0.0	0.0	0.0	2.0	0.0000000000	False
today is to talk	0.0	0.0	0.0	2.0	0.0000000000	False
first model we learned	0.0	0.0	0.0	2.0	0.0000000000	False
parameters via maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
choose the parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
parameters theta that maximized	0.0	0.0	0.0	4.0	0.0000000000	False
probability of the data	0.0	0.0	0.0	4.0	0.0000000000	False
philosophical view behind writing	0.0	0.0	0.0	2.0	0.0000000000	False
true parameter theta out	0.0	0.0	0.0	2.0	0.0000000000	False
out there that generated	0.0	0.0	0.0	2.0	0.0000000000	False
parameter theta that govern	0.0	0.0	0.0	2.0	0.0000000000	False
theta that govern housing	0.0	0.0	0.0	2.0	0.0000000000	False
estimating the unknown value	0.0	0.0	0.0	2.0	0.0000000000	False
unknown value for theta	0.0	0.0	0.0	2.0	0.0000000000	False
procedure called maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
maximum likelihood for estimating	0.0	0.0	0.0	2.0	0.0000000000	False
frequencies procedure the alternative	0.0	0.0	0.0	2.0	0.0000000000	False
frequency school of statistics	0.0	0.0	0.0	2.0	0.0000000000	False
nt know what theta	0.0	0.0	0.0	0.0	0.0000000000	False
matrix given by tau	0.0	0.0	0.0	2.0	0.0000000000	False
denote my training set	0.0	0.0	0.0	2.0	0.0000000000	False
theta represents my beliefs	0.0	0.0	0.0	2.0	0.0000000000	False
absence of any data	0.0	0.0	0.0	2.0	0.0000000000	False
theta it probably represents	0.0	0.0	0.0	2.0	0.0000000000	False
sort of bayesian procedure	0.0	0.0	0.0	2.0	0.0000000000	False
posterior probability by parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters given my training	0.0	0.0	0.0	4.0	0.0000000000	False
board so my posterior	0.0	0.0	0.0	2.0	0.0000000000	False
posterior on my parameters	0.0	0.0	0.0	2.0	0.0000000000	False
rule let s call	0.0	0.0	0.0	0.0	0.0000000000	False
posterior and this distribution	0.0	0.0	0.0	2.0	0.0000000000	False
beliefs about what theta	0.0	0.0	0.0	2.0	0.0000000000	False
ve seen the training	0.0	0.0	0.0	2.0	0.0000000000	False
make a new prediction	0.0	0.0	0.0	2.0	0.0000000000	False
prediction on the price	0.0	0.0	0.0	2.0	0.0000000000	False
size of the house	0.0	0.0	0.0	2.0	0.0000000000	False
features of the house	0.0	0.0	0.0	2.0	0.0000000000	False
integral over my parameters	0.0	0.0	0.0	2.0	0.0000000000	False
times the posterior distribution	0.0	0.0	0.0	2.0	0.0000000000	False
posterior distribution of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta given the training	0.0	0.0	0.0	2.0	0.0000000000	False
input x in training	0.0	0.0	0.0	2.0	0.0000000000	False
integrate over y times	0.0	0.0	0.0	2.0	0.0000000000	False
respect to your posterior	0.0	0.0	0.0	2.0	0.0000000000	False
theta because this formula	0.0	0.0	0.0	2.0	0.0000000000	False
property of y conditioned	0.0	0.0	0.0	2.0	0.0000000000	False
conditioned on the values	0.0	0.0	0.0	2.0	0.0000000000	False
values of the random	0.0	0.0	0.0	2.0	0.0000000000	False
variables x and theta	0.0	0.0	0.0	2.0	0.0000000000	False
longer writing semicolon theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta as a random	0.0	0.0	0.0	2.0	0.0000000000	False
check are there questions	0.0	0.0	0.0	2.0	0.0000000000	False
make this more concrete	0.0	0.0	0.0	2.0	0.0000000000	False
steps in the computation	0.0	0.0	0.0	2.0	0.0000000000	False
difficult to compute integrals	0.0	0.0	0.0	2.0	0.0000000000	False
computing a full posterior	0.0	0.0	0.0	2.0	0.0000000000	False
quantity on the right-hand	0.0	0.0	0.0	4.0	0.0000000000	False
side and just maximize	0.0	0.0	0.0	2.0	0.0000000000	False
computing the full posterior	0.0	0.0	0.0	2.0	0.0000000000	False
maximum a posteriori estimate	0.0	0.0	0.0	2.0	0.0000000000	False
posteriori estimate of theta	0.0	0.0	0.0	2.0	0.0000000000	False
probable value of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta onto your posterior	0.0	0.0	0.0	2.0	0.0000000000	False
max chi of theta	0.0	0.0	0.0	2.0	0.0000000000	False
map value of theta	0.0	0.0	0.0	2.0	0.0000000000	False
vector you d choose	0.0	0.0	0.0	0.0	0.0000000000	False
standard maximum likelihood estimation	0.0	0.0	0.0	2.0	0.0000000000	False
choosing the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood value for theta	0.0	0.0	0.0	2.0	0.0000000000	False
times this other quantity	0.0	0.0	0.0	2.0	0.0000000000	False
centered around the point	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on feature selection	0.0	0.0	0.0	2.0	0.0000000000	False
reminiscent of feature selection	0.0	0.0	0.0	2.0	0.0000000000	False
points and you fit	0.0	0.0	0.0	2.0	0.0000000000	False
mind if you fit	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood estimation all right	0.0	0.0	0.0	2.0	0.0000000000	False
right ? in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
sort of bayesian regularization	0.0	0.0	5.99890789953	6.0	0.0000000000	False
sort of a smoother	0.0	0.0	0.0	2.0	0.0000000000	False
smoother and smoother fit	0.0	0.0	0.0	2.0	0.0000000000	False
fit to the data	0.0	0.0	0.0	2.0	0.0000000000	False
data as you decrease	0.0	0.0	0.0	2.0	0.0000000000	False
re driving the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
practice it s sort	0.0	0.0	0.0	0.0	0.0000000000	False
fitting a large number	0.0	0.0	0.0	2.0	0.0000000000	False
large number of parameters	0.0	0.0	0.0	2.0	0.0000000000	False
last piece of intuition	0.0	0.0	0.0	2.0	0.0000000000	False
ideas more in problem	0.0	0.0	0.0	2.0	0.0000000000	False
online later this week	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood tries to minimize	0.0	0.0	0.0	2.0	0.0000000000	False
right ? whereas maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out to be minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
add this prior term	0.0	0.0	0.0	2.0	0.0000000000	False
out that the authorization	0.0	0.0	0.0	2.0	0.0000000000	False
authorization objective you end	0.0	0.0	0.0	2.0	0.0000000000	False
end up optimizing turns	0.0	0.0	0.0	2.0	0.0000000000	False
add an extra term	0.0	0.0	0.0	2.0	0.0000000000	False
penalizes your parameter theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta as being large	0.0	0.0	0.0	2.0	0.0000000000	False
similar to maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
expect that you tend	0.0	0.0	0.0	2.0	0.0000000000	False
parameters has the effect	0.0	0.0	0.0	2.0	0.0000000000	False
sense when you play	0.0	0.0	0.0	2.0	0.0000000000	False
play with these ideas	0.0	0.0	0.0	2.0	0.0000000000	False
models like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression and linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
generalized in your models	0.0	0.0	0.0	2.0	0.0000000000	False
sorts of smoothing effects	0.0	0.0	0.0	2.0	0.0000000000	False
smoothing effects all right	0.0	0.0	0.0	2.0	0.0000000000	False
effects all right cool	0.0	0.0	0.0	2.0	0.0000000000	False
out that for problems	0.0	0.0	0.0	2.0	0.0000000000	False
problems like text classification	0.0	0.0	0.0	2.0	0.0000000000	False
features or 50,000 features	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
right ? so imagine	0.0	0.0	0.0	2.0	0.0000000000	False
imagine trying to build	0.0	0.0	0.0	2.0	0.0000000000	False
build a spam classifier	0.0	0.0	0.0	2.0	0.0000000000	False
effective text classification algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm with this sort	0.0	0.0	0.0	2.0	0.0000000000	False
pick and to pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick either tau squared	0.0	0.0	0.0	4.0	0.0000000000	False
tau squared or lambda	0.0	0.0	0.0	4.0	0.0000000000	False
relation is lambda equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals one over tau	0.0	0.0	0.0	2.0	0.0000000000	False
cool so all right	0.0	0.0	0.0	2.0	0.0000000000	False
methods for preventing overfitting	0.0	0.0	0.0	2.0	0.0000000000	False
minutes talking about online	0.0	0.0	0.0	2.0	0.0000000000	False
talking about online learning	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a digression	0.0	0.0	0.0	2.0	0.0000000000	False
re designing the syllabus	0.0	0.0	0.0	2.0	0.0000000000	False
syllabus of a class	0.0	0.0	0.0	2.0	0.0000000000	False
good place to fit	0.0	0.0	0.0	2.0	0.0000000000	False
disjointed from the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the class	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
algorithms we ve talked	0.0	0.0	0.0	0.0	0.0000000000	False
re given a training	0.0	0.0	0.0	2.0	0.0000000000	False
run your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm on the training	0.0	0.0	0.0	2.0	0.0000000000	False
learning setting called online	0.0	0.0	0.0	2.0	0.0000000000	False
setting called online learning	0.0	0.0	0.0	2.0	0.0000000000	False
problem sees all right	0.0	0.0	0.0	2.0	0.0000000000	False
first gon na give	0.0	0.0	0.0	4.0	0.0000000000	False
make a guess right	0.0	0.0	0.0	2.0	0.0000000000	False
right ? you guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess we ll call	0.0	0.0	0.0	0.0	0.0000000000	False
ll call your guess	0.0	0.0	0.0	2.0	0.0000000000	False
ve made your prediction	0.0	0.0	0.0	2.0	0.0000000000	False
show you x two	0.0	0.0	0.0	2.0	0.0000000000	False
slightly more educated guess	0.0	0.0	0.0	2.0	0.0000000000	False
educated guess and call	0.0	0.0	0.0	2.0	0.0000000000	False
ve made your guess	0.0	0.0	0.0	2.0	0.0000000000	False
reveal the true label	0.0	0.0	0.0	2.0	0.0000000000	False
lot of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
machine learning and batch	0.0	0.0	0.0	2.0	0.0000000000	False
learning and batch learning	0.0	0.0	0.0	2.0	0.0000000000	False
user likes or dislikes	0.0	0.0	0.0	2.0	0.0000000000	False
examples so in online	0.0	0.0	0.0	2.0	0.0000000000	False
learning what you care	0.0	0.0	0.0	2.0	0.0000000000	False
sum from i equals	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of m examples	0.0	0.0	0.0	2.0	0.0000000000	False
total number of mistakes	0.0	0.0	0.0	2.0	0.0000000000	False
make on a sequence	0.0	0.0	0.0	2.0	0.0000000000	False
finish all the learning	0.0	0.0	0.0	2.0	0.0000000000	False
apply to this setting	0.0	0.0	0.0	2.0	0.0000000000	False
re asked to make	0.0	0.0	0.0	2.0	0.0000000000	False
asked to make prediction	0.0	0.0	0.0	2.0	0.0000000000	False
prediction on y hat	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm and run	0.0	0.0	0.0	2.0	0.0000000000	False
run the learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
previous to being asked	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to make	0.0	0.0	0.0	2.0	0.0000000000	False
remember the perceptron algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
initial the parameter theta	0.0	0.0	0.0	2.0	0.0000000000	False
ve see this reel	0.0	0.0	0.0	2.0	0.0000000000	False
standard perceptron learning rule	0.0	0.0	0.0	2.0	0.0000000000	False
run one-step stochastic gradient	0.0	0.0	0.0	2.0	0.0000000000	False
one-step stochastic gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
reason i ve put	0.0	0.0	0.0	0.0	0.0000000000	False
sort of learning theorysection	0.0	0.0	0.0	2.0	0.0000000000	False
theorysection of this class	0.0	0.0	0.0	2.0	0.0000000000	False
prove fairly amazing results	0.0	0.0	0.0	2.0	0.0000000000	False
online error using algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
main lecture to prove	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature vectors	0.0	0.0	0.0	2.0	0.0000000000	False
infinite feature dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
vectors may use kernel	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative examples	0.0	0.0	3.99854386604	8.0	0.0000000000	False
negative examples are separated	0.0	0.0	0.0	2.0	0.0000000000	False
separated by a margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin down there separating	0.0	0.0	0.0	2.0	0.0000000000	False
prove that perceptron algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
perceptron algorithm will converge	0.0	0.0	0.0	2.0	0.0000000000	False
converge to a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that perfectly separates	0.0	0.0	0.0	2.0	0.0000000000	False
finite number of examples	0.0	0.0	0.0	2.0	0.0000000000	False
ll converge to digital	0.0	0.0	0.0	2.0	0.0000000000	False
boundary that perfectly separates	0.0	0.0	0.0	2.0	0.0000000000	False
sort of other things	0.0	0.0	0.0	2.0	0.0000000000	False
notes that i posted	0.0	0.0	0.0	2.0	0.0000000000	False
online for the purposes	0.0	0.0	0.0	2.0	0.0000000000	False
purposes of this class	0.0	0.0	0.0	2.0	0.0000000000	False
proof of this result	0.0	0.0	0.0	2.0	0.0000000000	False
specifically in the problem	0.0	0.0	0.0	2.0	0.0000000000	False
svms can have bounded	0.0	0.0	0.0	2.0	0.0000000000	False
prove learning theory results	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature spaces	0.0	0.0	0.0	2.0	0.0000000000	False
read in like half	0.0	0.0	0.0	2.0	0.0000000000	False
bound is actually proved	0.0	0.0	0.0	2.0	0.0000000000	False
based on stochastic gradient	0.0	0.0	0.0	2.0	0.0000000000	False
switch to powerpoint slides	0.0	0.0	0.0	2.0	0.0000000000	False
spend most of today	0.0	0.0	0.0	2.0	0.0000000000	False
today s lecture sort	0.0	0.0	0.0	0.0	0.0000000000	False
lecture sort of talking	0.0	0.0	0.0	2.0	0.0000000000	False
applying different machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
tools known to humankind	0.0	0.0	0.0	2.0	0.0000000000	False
humankind in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
give you some advice	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you re	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms to work	0.0	0.0	0.0	2.0	0.0000000000	False
work well in problems	0.0	0.0	0.0	2.0	0.0000000000	False
conceptually most difficult material	0.0	0.0	0.0	2.0	0.0000000000	False
material in this class	0.0	0.0	0.0	2.0	0.0000000000	False
good machine learning people	0.0	0.0	0.0	2.0	0.0000000000	False
learning people will agree	0.0	0.0	0.0	2.0	0.0000000000	False
advice for doing machine	0.0	0.0	0.0	2.0	0.0000000000	False
work if you work	0.0	0.0	0.0	2.0	0.0000000000	False
work in the company	0.0	0.0	0.0	2.0	0.0000000000	False
product or you re	0.0	0.0	0.0	0.0	0.0000000000	False
learning system to work	0.0	0.0	0.0	2.0	0.0000000000	False
advice if you goal	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to invent	0.0	0.0	2.99890789953	6.0	0.0000000000	False
invent a new machine	0.0	0.0	0.0	2.0	0.0000000000	False
make machine learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
machine learning algorithm work	0.0	0.0	0.0	2.0	0.0000000000	False
deploy a working system	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics for debugging learning	0.0	0.0	0.0	2.0	0.0000000000	False
talk briefly about error	0.0	0.0	0.0	2.0	0.0000000000	False
briefly about error analyses	0.0	0.0	0.0	2.0	0.0000000000	False
analyses and ablative analysis	0.0	0.0	0.0	4.0	0.0000000000	False
talk about just advice	0.0	0.0	0.0	2.0	0.0000000000	False
problem and one theme	0.0	0.0	0.0	2.0	0.0000000000	False
turns out you ve	0.0	0.0	0.0	0.0	0.0000000000	False
out you ve heard	0.0	0.0	0.0	0.0	0.0000000000	False
ve heard about premature	0.0	0.0	0.0	2.0	0.0000000000	False
heard about premature optimization	0.0	0.0	0.0	2.0	0.0000000000	False
over-designs from the start	0.0	0.0	0.0	2.0	0.0000000000	False
writing piece of code	0.0	0.0	0.0	2.0	0.0000000000	False
code and they choose	0.0	0.0	0.0	2.0	0.0000000000	False
subroutine to optimize heavily	0.0	0.0	0.0	2.0	0.0000000000	False
guilty of premature optimization	0.0	0.0	0.0	2.0	0.0000000000	False
code to run faster	0.0	0.0	0.0	2.0	0.0000000000	False
faster and we choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose probably a piece	0.0	0.0	0.0	2.0	0.0000000000	False
code and we implement	0.0	0.0	0.0	2.0	0.0000000000	False
quickly and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
bottleneck in the code	0.0	0.0	0.0	2.0	0.0000000000	False
call that premature optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization and in undergraduate	0.0	0.0	0.0	2.0	0.0000000000	False
premature optimization and people	0.0	0.0	0.0	2.0	0.0000000000	False
right ? and turns	0.0	0.0	0.0	2.0	0.0000000000	False
thing happens in building	0.0	0.0	0.0	2.0	0.0000000000	False
systems that many people	0.0	0.0	0.0	2.0	0.0000000000	False
part of a machine	0.0	0.0	0.0	2.0	0.0000000000	False
system and that turns	0.0	0.0	0.0	2.0	0.0000000000	False
first talk about debugging	0.0	0.0	0.0	2.0	0.0000000000	False
talk about debugging learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms as a motivating	0.0	0.0	0.0	2.0	0.0000000000	False
build an anti-spam system	0.0	0.0	1.99890789953	6.0	0.0000000000	False
chosen a small set	0.0	0.0	0.0	2.0	0.0000000000	False
implement bayesian logistic regression	0.0	0.0	0.0	4.0	0.0000000000	False
additional lambda squared term	0.0	0.0	0.0	2.0	0.0000000000	False
term and we re	0.0	0.0	0.0	0.0	0.0000000000	False
maximizing rather than minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
minus lambda theta square	0.0	0.0	0.0	2.0	0.0000000000	False
squared so the question	0.0	0.0	0.0	2.0	0.0000000000	False
bayesian logistic regression algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ways you could improve	0.0	0.0	0.0	2.0	0.0000000000	False
ll try to improve	0.0	0.0	0.0	2.0	0.0000000000	False
examples maybe you suspect	0.0	0.0	0.0	2.0	0.0000000000	False
smaller set of features	0.0	0.0	0.0	4.0	0.0000000000	False
figure out better features	0.0	0.0	0.0	2.0	0.0000000000	False
emails or whatever right	0.0	0.0	0.0	2.0	0.0000000000	False
suspect that gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent a bit	0.0	0.0	0.0	2.0	0.0000000000	False
descent a bit longer	0.0	0.0	0.0	2.0	0.0000000000	False
run gradient descent longer	0.0	0.0	0.0	2.0	0.0000000000	False
remember hearing from class	0.0	0.0	0.0	2.0	0.0000000000	False
class that maybe newton	0.0	0.0	0.0	2.0	0.0000000000	False
newton s method converges	0.0	0.0	0.0	0.0	0.0000000000	False
improve a learning system	0.0	0.0	0.0	2.0	0.0000000000	False
picking ways to improve	0.0	0.0	0.0	2.0	0.0000000000	False
improve the learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm and picking	0.0	0.0	0.0	2.0	0.0000000000	False
work in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
largely largely a matter	0.0	0.0	0.0	2.0	0.0000000000	False
fixing what the problem	0.0	0.0	0.0	2.0	0.0000000000	False
fix very different problems	0.0	0.0	0.0	2.0	0.0000000000	False
save yourself a lot	0.0	0.0	0.0	2.0	0.0000000000	False
industry and in research	0.0	0.0	0.0	2.0	0.0000000000	False
change a learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
randomly there are lots	0.0	0.0	0.0	2.0	0.0000000000	False
things that obviously improve	0.0	0.0	0.0	2.0	0.0000000000	False
improve your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
good ones that run	0.0	0.0	0.0	2.0	0.0000000000	False
figure out the problem	0.0	0.0	0.0	4.0	0.0000000000	False
bayesian logistic regression test	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression test error	0.0	0.0	0.0	2.0	0.0000000000	False
problem is either overfitting	0.0	0.0	0.0	2.0	0.0000000000	False
forget forget the tables	0.0	0.0	0.0	2.0	0.0000000000	False
forget the tables suppose	0.0	0.0	0.0	2.0	0.0000000000	False
tables suppose you suspect	0.0	0.0	0.0	2.0	0.0000000000	False
bias or high variance	0.0	0.0	5.99854386604	8.0	0.0000000000	False
features classified as spam	0.0	0.0	0.0	2.0	0.0000000000	False
out whether the problem	0.0	0.0	0.0	2.0	0.0000000000	False
high variance ? right	0.0	0.0	0.0	2.0	0.0000000000	False
problem is high bias	0.0	0.0	0.0	2.0	0.0000000000	False
variance if you remember	0.0	0.0	0.0	2.0	0.0000000000	False
previously for high variance	0.0	0.0	0.0	2.0	0.0000000000	False
high variance the training	0.0	0.0	0.0	2.0	0.0000000000	False
variance the training error	0.0	0.0	0.0	2.0	0.0000000000	False
lower than the test	0.0	0.0	0.0	2.0	0.0000000000	False
test error all right	0.0	0.0	0.0	2.0	0.0000000000	False
re fitting your training	0.0	0.0	0.0	2.0	0.0000000000	False
fitting your training set	0.0	0.0	0.0	4.0	0.0000000000	False
data points all right	0.0	0.0	0.0	2.0	0.0000000000	False
fitting the data set	0.0	0.0	0.0	2.0	0.0000000000	False
lower than your test	0.0	0.0	0.0	2.0	0.0000000000	False
error and in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
fitting a linear function	0.0	0.0	0.0	2.0	0.0000000000	False
curve for high variance	0.0	0.0	0.0	2.0	0.0000000000	False
plotting the training set	0.0	0.0	0.0	2.0	0.0000000000	False
notice as the training	0.0	0.0	0.0	2.0	0.0000000000	False
increase the training set	0.0	0.0	0.0	2.0	0.0000000000	False
extrapolate the green curve	0.0	0.0	0.0	2.0	0.0000000000	False
set error will decrease	0.0	0.0	0.0	2.0	0.0000000000	False
right ? another thing	0.0	0.0	0.0	2.0	0.0000000000	False
line is the desired	0.0	0.0	0.0	2.0	0.0000000000	False
desired performance you re	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to reach	0.0	0.0	0.0	2.0	0.0000000000	False
out that your training	0.0	0.0	0.0	2.0	0.0000000000	False
error will actually grow	0.0	0.0	0.0	4.0	0.0000000000	False
grow as a function	0.0	0.0	3.99890789953	6.0	0.0000000000	False
function of the training	0.0	0.0	0.0	2.0	0.0000000000	False
larger your training set	0.0	0.0	0.0	2.0	0.0000000000	False
training set perfectly right	0.0	0.0	0.0	2.0	0.0000000000	False
function of your training	0.0	0.0	0.0	4.0	0.0000000000	False
set size because smart	0.0	0.0	0.0	2.0	0.0000000000	False
size because smart training	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostic for high variance	0.0	0.0	0.0	2.0	0.0000000000	False
training versus test error	0.0	0.0	0.0	2.0	0.0000000000	False
case of high variance	0.0	0.0	0.0	2.0	0.0000000000	False
curve for test error	0.0	0.0	0.0	2.0	0.0000000000	False
test error has flattened	0.0	0.0	0.0	2.0	0.0000000000	False
property of high bias	0.0	0.0	0.0	2.0	0.0000000000	False
hold out test set	0.0	0.0	0.0	2.0	0.0000000000	False
out test set error	0.0	0.0	0.0	2.0	0.0000000000	False
error if you find	0.0	0.0	0.0	2.0	0.0000000000	False
right ? in fact	0.0	0.0	0.0	2.0	0.0000000000	False
level of desired performance	0.0	0.0	0.0	4.0	0.0000000000	False
reduce your training error	0.0	0.0	0.0	2.0	0.0000000000	False
desired level of performance	0.0	0.0	0.0	2.0	0.0000000000	False
level of performance right	0.0	0.0	0.0	2.0	0.0000000000	False
green curve on test	0.0	0.0	0.0	2.0	0.0000000000	False
curve on test error	0.0	0.0	0.0	2.0	0.0000000000	False
personally tend to find	0.0	0.0	0.0	2.0	0.0000000000	False
problem or a variance	0.0	0.0	0.0	2.0	0.0000000000	False
training and test error	0.0	0.0	0.0	4.0	0.0000000000	False
back to the list	0.0	0.0	0.0	2.0	0.0000000000	False
high variance all right	0.0	0.0	0.0	2.0	0.0000000000	False
larger set of features	0.0	0.0	0.0	2.0	0.0000000000	False
features or adding email	0.0	0.0	0.0	2.0	0.0000000000	False
nt have enough features	0.0	0.0	0.0	0.0	0.0000000000	False
people working on machine	0.0	0.0	0.0	2.0	0.0000000000	False
working on machine learning	0.0	0.0	0.0	4.0	0.0000000000	False
ll build a learning	0.0	0.0	0.0	2.0	0.0000000000	False
build a learning system	0.0	0.0	0.0	2.0	0.0000000000	False
money and effort collecting	0.0	0.0	0.0	2.0	0.0000000000	False
effort collecting more training	0.0	0.0	0.0	2.0	0.0000000000	False
collecting more training data	0.0	0.0	0.0	2.0	0.0000000000	False
months or six months	0.0	0.0	0.0	2.0	0.0000000000	False
silicon valley and companies	0.0	0.0	0.0	2.0	0.0000000000	False
people building various machine	0.0	0.0	0.0	2.0	0.0000000000	False
building various machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
people spending six months	0.0	0.0	0.0	2.0	0.0000000000	False
spending six months working	0.0	0.0	0.0	2.0	0.0000000000	False
months working on fixing	0.0	0.0	0.0	2.0	0.0000000000	False
fixing a learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
told them six months	0.0	0.0	0.0	2.0	0.0000000000	False
nt possibly have helped	0.0	0.0	0.0	0.0	0.0000000000	False
easily spend six months	0.0	0.0	0.0	2.0	0.0000000000	False
months trying to invent	0.0	0.0	0.0	2.0	0.0000000000	False
depressing you could ve	0.0	0.0	0.0	0.0	0.0000000000	False
told you six months	0.0	0.0	0.0	2.0	0.0000000000	False
two of these solutions	0.0	0.0	0.0	2.0	0.0000000000	False
save yourself many months	0.0	0.0	0.0	2.0	0.0000000000	False
months of fruitless effort	0.0	0.0	0.0	2.0	0.0000000000	False
four at the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
great so bias versus	0.0	0.0	0.0	2.0	0.0000000000	False
variance is one thing	0.0	0.0	0.0	2.0	0.0000000000	False
out your own diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
out what s wrong	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm is nt working	0.0	0.0	0.0	0.0	0.0000000000	False
construct your own tests	0.0	0.0	0.0	2.0	0.0000000000	False
difference training and test	0.0	0.0	0.0	2.0	0.0000000000	False
construct your own diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
illustrate another common question	0.0	0.0	0.0	2.0	0.0000000000	False
percent error on spam	0.0	0.0	0.0	4.0	0.0000000000	False
error on spam mail	0.0	0.0	0.0	2.0	0.0000000000	False
percent error non-spam mail	0.0	0.0	0.0	2.0	0.0000000000	False
error non-spam mail right	0.0	0.0	0.0	2.0	0.0000000000	False
percent of your spam	0.0	0.0	0.0	2.0	0.0000000000	False
percent of all spam	0.0	0.0	0.0	2.0	0.0000000000	False
percent of the email	0.0	0.0	0.0	2.0	0.0000000000	False
email from your friends	0.0	0.0	0.0	2.0	0.0000000000	False
machine using a linear	0.0	0.0	0.0	2.0	0.0000000000	False
percent error on non-spam	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to build	0.0	0.0	0.0	2.0	0.0000000000	False
regression to your customers	0.0	0.0	0.0	2.0	0.0000000000	False
retrain overnight every day	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression just runs	0.0	0.0	0.0	2.0	0.0000000000	False
out well so question	0.0	0.0	0.0	2.0	0.0000000000	False
problem with logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
iterations and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing j of theta	0.0	0.0	0.0	4.0	0.0000000000	False
objective as a function	0.0	0.0	0.0	2.0	0.0000000000	False
function of the number	0.0	0.0	0.0	2.0	0.0000000000	False
curve has already flattened	0.0	0.0	0.0	2.0	0.0000000000	False
flattened out all right	0.0	0.0	0.0	2.0	0.0000000000	False
run this ten times	0.0	0.0	0.0	4.0	0.0000000000	False
logistic regression is converged	0.0	0.0	0.0	4.0	0.0000000000	False
curve the other question	0.0	0.0	0.0	2.0	0.0000000000	False
thing you might suspect	0.0	0.0	0.0	2.0	0.0000000000	False
suspect is a problem	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing the right function	0.0	0.0	0.0	2.0	0.0000000000	False
sum over your examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples of some weights	0.0	0.0	0.0	2.0	0.0000000000	False
non-spam than for spam	0.0	0.0	0.0	2.0	0.0000000000	False
mail because you care	0.0	0.0	0.0	2.0	0.0000000000	False
predictions correct for spam	0.0	0.0	0.0	2.0	0.0000000000	False
correct for spam email	0.0	0.0	0.0	2.0	0.0000000000	False
theta is the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
sort of maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
function to be optimizing	0.0	0.0	0.0	2.0	0.0000000000	False
switching to support vector	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine optimization	0.0	0.0	0.0	2.0	0.0000000000	False
vector machine optimization objective	0.0	0.0	0.0	2.0	0.0000000000	False
out is the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
problem with the optimization	0.0	0.0	0.0	4.0	0.0000000000	False
optimization objective i chose	0.0	0.0	0.0	2.0	0.0000000000	False
outperforms bayesian logistic regression	0.0	0.0	0.0	4.0	0.0000000000	False
deploy bayesian logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression to your problem	0.0	0.0	0.0	2.0	0.0000000000	False
learned by an svm	0.0	0.0	0.0	2.0	0.0000000000	False
ll let theta subscript	0.0	0.0	0.0	2.0	0.0000000000	False
blr be the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
regression so the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective you care	0.0	0.0	0.0	2.0	0.0000000000	False
criteria that i talked	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine outperforms	0.0	0.0	0.0	2.0	0.0000000000	False
regression tries to optimize	0.0	0.0	0.0	2.0	0.0000000000	False
optimize an optimization objective	0.0	0.0	0.0	2.0	0.0000000000	False
less-than j of blr	0.0	0.0	0.0	2.0	0.0000000000	False
weighted accuracy of support	0.0	0.0	0.0	2.0	0.0000000000	False
accuracy of support vector	0.0	0.0	0.0	2.0	0.0000000000	False
bigger than this weighted	0.0	0.0	0.0	2.0	0.0000000000	False
regression so in order	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing the wrong objective	0.0	0.0	0.0	2.0	0.0000000000	False
check if this equality	0.0	0.0	0.0	2.0	0.0000000000	False
copied over in case	0.0	0.0	0.0	2.0	0.0000000000	False
maximize j of theta	0.0	0.0	5.99890789953	6.0	0.0000000000	False
regression so this means	0.0	0.0	0.0	2.0	0.0000000000	False
value of theta output	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression actually fails	0.0	0.0	0.0	2.0	0.0000000000	False
support back to machine	0.0	0.0	5.99890789953	6.0	0.0000000000	False
optimization algorithm the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm the optimization algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has nt converged	0.0	0.0	0.0	0.0	0.0000000000	False
converged the other case	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression actually attains	0.0	0.0	0.0	2.0	0.0000000000	False
attains the higher value	0.0	0.0	0.0	2.0	0.0000000000	False
value for the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
worse on your optimization	0.0	0.0	0.0	4.0	0.0000000000	False
maximizing your weighted accuracy	0.0	0.0	0.0	2.0	0.0000000000	False
objective to be maximizing	0.0	0.0	0.0	2.0	0.0000000000	False
nt a good objective	0.0	0.0	0.0	0.0	0.0000000000	False
objective to be choosing	0.0	0.0	0.0	2.0	0.0000000000	False
choosing if you care	0.0	0.0	0.0	2.0	0.0000000000	False
care about the weighted	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this made	0.0	0.0	0.0	2.0	0.0000000000	False
made sense ? cool	0.0	0.0	0.0	2.0	0.0000000000	False
good so that tells	0.0	0.0	0.0	2.0	0.0000000000	False
descent for more iterations	0.0	0.0	0.0	2.0	0.0000000000	False
fixes the optimization algorithm	0.0	0.0	5.99890789953	6.0	0.0000000000	False
method fixes the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
times norm of data	0.0	0.0	0.0	2.0	0.0000000000	False
norm of data squared	0.0	0.0	0.0	2.0	0.0000000000	False
fixes the optimization objective	0.0	0.0	5.99890789953	6.0	0.0000000000	False
optimization objective and changing	0.0	0.0	0.0	2.0	0.0000000000	False
changing to an svm	0.0	0.0	0.0	2.0	0.0000000000	False
objective and be working	0.0	0.0	0.0	2.0	0.0000000000	False
pattern that the problem	0.0	0.0	0.0	2.0	0.0000000000	False
iterations of gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
descent like trying newton	0.0	0.0	0.0	2.0	0.0000000000	False
method and trying conjugate	0.0	0.0	0.0	2.0	0.0000000000	False
nt going to fix	0.0	0.0	0.0	0.0	0.0000000000	False
fixing your optimization algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization algorithm or fixing	0.0	0.0	0.0	2.0	0.0000000000	False
work on flying helicopters	0.0	0.0	0.0	2.0	0.0000000000	False
draws on reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
close to the end	0.0	0.0	0.0	2.0	0.0000000000	False
ve talked about reinforcement	0.0	0.0	0.0	2.0	0.0000000000	False
talked about reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning in the class	0.0	0.0	0.0	2.0	0.0000000000	False
understand it more deeply	0.0	0.0	0.0	2.0	0.0000000000	False
machine-learning algorithm to design	0.0	0.0	0.0	2.0	0.0000000000	False
step was you build	0.0	0.0	0.0	2.0	0.0000000000	False
simulator for a helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
screenshot of our simulator	0.0	0.0	0.0	2.0	0.0000000000	False
choose a cost function	0.0	0.0	0.0	2.0	0.0000000000	False
ll call it cost	0.0	0.0	0.0	2.0	0.0000000000	False
call it cost function	0.0	0.0	0.0	2.0	0.0000000000	False
error in your helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
run a reinforcement-learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learn about rl algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
run reinforcement learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm in your simulator	0.0	0.0	0.0	2.0	0.0000000000	False
minimize this cost function	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the squared error	0.0	0.0	0.0	2.0	0.0000000000	False
re controlling your helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm will output	0.0	0.0	0.0	2.0	0.0000000000	False
run this learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
set of controller parameters	0.0	0.0	0.0	2.0	0.0000000000	False
capture the aerodynamic effects	0.0	0.0	0.0	2.0	0.0000000000	False
aerodynamic effects more accurately	0.0	0.0	0.0	2.0	0.0000000000	False
airflow and the turbulence	0.0	0.0	0.0	2.0	0.0000000000	False
affects around the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
modify the cost function	0.0	0.0	0.0	2.0	0.0000000000	False
function maybe your square	0.0	0.0	0.0	2.0	0.0000000000	False
error is nt cutting	0.0	0.0	0.0	0.0	0.0000000000	False
reasoning that i wanted	0.0	0.0	0.0	2.0	0.0000000000	False
reinforcement-learning algorithm does poorly	0.0	0.0	0.0	2.0	0.0000000000	False
things hold true suppose	0.0	0.0	0.0	2.0	0.0000000000	False
true suppose the contrary	0.0	0.0	0.0	2.0	0.0000000000	False
suppose that the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
model of our helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
suppose that the reinforcement	0.0	0.0	0.0	2.0	0.0000000000	False
correctly controls the helicopter	0.0	0.0	0.0	4.0	0.0000000000	False
run a learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm in simulation	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm can crash	0.0	0.0	0.0	2.0	0.0000000000	False
assume our reinforcement-learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
reinforcement-learning algorithm correctly controls	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the cost function	0.0	0.0	3.99854386604	8.0	0.2914572864	False
function j of theta	0.0	0.0	0.0	4.0	0.0000000000	False
minimizing j of theta	0.0	0.0	2.99890789953	6.0	0.0000000000	False
theta does indeed correspond	0.0	0.0	0.0	2.0	0.0000000000	False
means that the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
fact that the learning	0.0	0.0	0.0	2.0	0.0000000000	False
flies well in simulation	0.0	0.0	0.0	2.0	0.0000000000	False
simulator of the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
tells me the problem	0.0	0.0	0.0	4.0	0.0000000000	False
right ? my simulator	0.0	0.0	0.0	2.0	0.0000000000	False
simulator predicts the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
spend out efforts improving	0.0	0.0	0.0	2.0	0.0000000000	False
efforts improving the accuracy	0.0	0.0	0.0	2.0	0.0000000000	False
accuracy of our simulator	0.0	0.0	0.0	2.0	0.0000000000	False
write theta subscript human	0.0	0.0	0.0	2.0	0.0000000000	False
control policy all right	0.0	0.0	0.0	2.0	0.0000000000	False
human pilot s flight	0.0	0.0	0.0	0.0	0.0000000000	False
optimizing this objective function	0.0	0.0	0.0	2.0	0.0000000000	False
good human pilot attains	0.0	0.0	0.0	2.0	0.0000000000	False
pilot attains a worse	0.0	0.0	0.0	2.0	0.0000000000	False
attains a worse value	0.0	0.0	0.0	2.0	0.0000000000	False
value on my optimization	0.0	0.0	0.0	2.0	0.0000000000	False
attains a lower value	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm s not managing	0.0	0.0	0.0	0.0	0.0000000000	False
theta and that tells	0.0	0.0	0.0	2.0	0.0000000000	False
attains a larger value	0.0	0.0	0.0	4.0	0.0000000000	False
larger value for theta	0.0	0.0	0.0	2.0	0.0000000000	False
value for theta excuse	0.0	0.0	0.0	2.0	0.0000000000	False
larger mean squared error	0.0	0.0	0.0	2.0	0.0000000000	False
error for the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
worse on my cost	0.0	0.0	0.0	2.0	0.0000000000	False
cost function but flies	0.0	0.0	0.0	2.0	0.0000000000	False
cost function it means	0.0	0.0	0.0	2.0	0.0000000000	False
cost function my learning	0.0	0.0	0.0	2.0	0.0000000000	False
function my learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
job minimizing the cost	0.0	0.0	0.0	2.0	0.0000000000	False
pilot so that tells	0.0	0.0	0.0	2.0	0.0000000000	False
tells you that minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
function does nt correspond	0.0	0.0	0.0	0.0	0.0000000000	False
change j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
work often reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms just work	0.0	0.0	0.0	2.0	0.0000000000	False
focusing on the simulator	0.0	0.0	0.0	2.0	0.0000000000	False
changing the cost function	0.0	0.0	0.0	2.0	0.0000000000	False
changing the reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
building a better simulator	0.0	0.0	0.0	2.0	0.0000000000	False
simulator for your helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
helicopter but it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out that modeling	0.0	0.0	0.0	2.0	0.0000000000	False
out that modeling helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
active area of research	0.0	0.0	0.0	2.0	0.0000000000	False
research there are people	0.0	0.0	0.0	2.0	0.0000000000	False
writing entire phd theses	0.0	0.0	0.0	2.0	0.0000000000	False
write a phd thesis	0.0	0.0	0.0	2.0	0.0000000000	False
phd thesis and build	0.0	0.0	0.0	2.0	0.0000000000	False
fixing the wrong problem	0.0	0.0	0.0	2.0	0.0000000000	False
out what s happening	0.0	0.0	0.0	0.0	0.0000000000	False
happening in an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ve described are sort	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
learning algorithm is working	0.0	0.0	0.0	2.0	0.0000000000	False
good idea to run	0.0	0.0	0.0	2.0	0.0000000000	False
idea to run diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
understand your application problem	0.0	0.0	0.0	2.0	0.0000000000	False
high-paying job to apply	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms to some application	0.0	0.0	0.0	2.0	0.0000000000	False
specific important machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
important machine learning application	0.0	0.0	0.0	2.0	0.0000000000	False
application for many months	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of what works	0.0	0.0	0.0	2.0	0.0000000000	False
nt work your problem	0.0	0.0	0.0	0.0	0.0000000000	False
work your problem sort	0.0	0.0	0.0	2.0	0.0000000000	False
problem sort of right	0.0	0.0	0.0	2.0	0.0000000000	False
companies with important machine	0.0	0.0	0.0	2.0	0.0000000000	False
important machine learning problems	0.0	0.0	0.0	2.0	0.0000000000	False
months or for years	0.0	0.0	0.0	2.0	0.0000000000	False
important problem using learning	0.0	0.0	0.0	2.0	0.0000000000	False
problem using learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of the problem	0.0	0.0	0.0	4.0	0.0000000000	False
understanding of these problems	0.0	0.0	0.0	2.0	0.0000000000	False
valley companies that outsource	0.0	0.0	0.0	2.0	0.0000000000	False
outsource their machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
company in silicon valley	0.0	0.0	0.0	2.0	0.0000000000	False
firm in new york	0.0	0.0	0.0	2.0	0.0000000000	False
run all their learning	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of your data	0.0	0.0	0.0	2.0	0.0000000000	False
nt maintain that expertise	0.0	0.0	0.0	0.0	0.0000000000	False
problem you really care	0.0	0.0	0.0	2.0	0.0000000000	False
problem that you build	0.0	0.0	0.0	2.0	0.0000000000	False
build up over months	0.0	0.0	0.0	2.0	0.0000000000	False
ll be really valuable	0.0	0.0	0.0	2.0	0.0000000000	False
reason for running diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
right ? so diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics and error analyses	0.0	0.0	0.0	2.0	0.0000000000	False
insight about the problem	0.0	0.0	0.0	2.0	0.0000000000	False
justify your research claims	0.0	0.0	0.0	2.0	0.0000000000	False
writing a research paper	0.0	0.0	0.0	4.0	0.0000000000	False
helicopter and it flies,or	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on error analysis	0.0	0.0	0.0	2.0	0.0000000000	False
good machine learning practice	0.0	0.0	0.0	2.0	0.0000000000	False
understanding what your sources	0.0	0.0	0.0	2.0	0.0000000000	False
wrong with the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
flown so many times	0.0	0.0	0.0	2.0	0.0000000000	False
helicopter is actually building	0.0	0.0	0.0	2.0	0.0000000000	False
building an accurate simulator	0.0	0.0	0.0	2.0	0.0000000000	False
simulator of a helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
helicopter is very hard	0.0	0.0	0.0	2.0	0.0000000000	False
out what is working	0.0	0.0	0.0	2.0	0.0000000000	False
working in your algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
working and we re	0.0	0.0	0.0	0.0	0.0000000000	False
re gon na talk	0.0	0.0	0.0	2.0	0.0000000000	False
sort of ia systems	0.0	0.0	0.0	2.0	0.0000000000	False
combine many different components	0.0	0.0	0.0	2.0	0.0000000000	False
components into a pipeline	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a contrived	0.0	0.0	0.0	2.0	0.0000000000	False
dissimilar in many ways	0.0	0.0	0.0	2.0	0.0000000000	False
actual machine learning systems	0.0	0.0	0.0	2.0	0.0000000000	False
recognize people from images	0.0	0.0	0.0	2.0	0.0000000000	False
input in camera image	0.0	0.0	0.0	2.0	0.0000000000	False
run a face detection	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to detect	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm to detect people	0.0	0.0	0.0	2.0	0.0000000000	False
detect people s faces	0.0	0.0	0.0	0.0	0.0000000000	False
people s faces right	0.0	0.0	0.0	0.0	0.0000000000	False
identity of the person	0.0	0.0	0.0	2.0	0.0000000000	False
segment of the eyes	0.0	0.0	0.0	2.0	0.0000000000	False
segment of the nose	0.0	0.0	0.0	2.0	0.0000000000	False
friend after she sees	0.0	0.0	0.0	2.0	0.0000000000	False
found all these features	0.0	0.0	0.0	2.0	0.0000000000	False
feed all the features	0.0	0.0	0.0	2.0	0.0000000000	False
regression or soft match	0.0	0.0	0.0	2.0	0.0000000000	False
identity of this person	0.0	0.0	0.0	2.0	0.0000000000	False
long complicated pipeline combining	0.0	0.0	0.0	2.0	0.0000000000	False
pipeline combining many machine	0.0	0.0	0.0	2.0	0.0000000000	False
combining many machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
error can be attributed	0.0	0.0	0.0	2.0	0.0000000000	False
typical error analysis procedure	0.0	0.0	0.0	2.0	0.0000000000	False
ground-truth for each component	0.0	0.0	0.0	2.0	0.0000000000	False
figure on the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
accuracy of the system	0.0	0.0	0.0	2.0	0.0000000000	False
implement my correct background	0.0	0.0	0.0	2.0	0.0000000000	False
correct background versus foreground	0.0	0.0	0.0	2.0	0.0000000000	False
giving that ground-truth data	0.0	0.0	0.0	2.0	0.0000000000	False
data in the test	0.0	0.0	0.0	2.0	0.0000000000	False
assume our accuracy increases	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm where the face	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm s accuracy increases	0.0	0.0	0.0	0.0	0.0000000000	False
components and just give	0.0	0.0	0.0	2.0	0.0000000000	False
out where the nose	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to figure	0.0	0.0	0.0	0.0	0.0000000000	False
giving it the correct	0.0	0.0	0.0	2.0	0.0000000000	False
output label and end	0.0	0.0	0.0	2.0	0.0000000000	False
giving the ground-truth labels	0.0	0.0	0.0	2.0	0.0000000000	False
components could help boost	0.0	0.0	0.0	2.0	0.0000000000	False
boost your final performance	0.0	0.0	0.0	2.0	0.0000000000	False
added the face detection	0.0	0.0	0.0	2.0	0.0000000000	False
percent whereas in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to improve	0.0	0.0	0.0	2.0	0.0000000000	False
improve your background subtraction	0.0	0.0	0.0	2.0	0.0000000000	False
larger potential for gains	0.0	0.0	0.0	2.0	0.0000000000	False
easily choose to spend	0.0	0.0	0.0	2.0	0.0000000000	False
right ? and choosing	0.0	0.0	0.0	2.0	0.0000000000	False
choosing the right piece	0.0	0.0	0.0	2.0	0.0000000000	False
sort of diagnostic tells	0.0	0.0	0.0	2.0	0.0000000000	False
sort of another type	0.0	0.0	0.0	2.0	0.0000000000	False
analyses that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
talked about the error	0.0	0.0	0.0	2.0	0.0000000000	False
analysis i just talked	0.0	0.0	0.0	2.0	0.0000000000	False
current performance and perfect	0.0	0.0	0.0	2.0	0.0000000000	False
performance and perfect performance	0.0	0.0	0.0	2.0	0.0000000000	False
sort of ablative analysis	0.0	0.0	0.0	2.0	0.0000000000	False
analysis tries to explain	0.0	0.0	0.0	2.0	0.0000000000	False
difference between some baselines	0.0	0.0	0.0	2.0	0.0000000000	False
suppose you ve built	0.0	0.0	0.0	0.0	0.0000000000	False
anti-spam classifier for adding	0.0	0.0	0.0	2.0	0.0000000000	False
classifier for adding lots	0.0	0.0	0.0	2.0	0.0000000000	False
adding lots of clever	0.0	0.0	0.0	2.0	0.0000000000	False
lots of clever features	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression algorithm right	0.0	0.0	0.0	2.0	0.0000000000	False
added features for spam	0.0	0.0	0.0	2.0	0.0000000000	False
features for spam correction	0.0	0.0	0.0	2.0	0.0000000000	False
email text parser features	0.0	0.0	0.0	2.0	0.0000000000	False
features for embedded images	0.0	0.0	0.0	2.0	0.0000000000	False
research paper and claim	0.0	0.0	0.0	2.0	0.0000000000	False
made the big difference	0.0	0.0	0.0	2.0	0.0000000000	False
figure out what accounts	0.0	0.0	0.0	2.0	0.0000000000	False
accounts for your improvement	0.0	0.0	0.0	2.0	0.0000000000	False
ll instead remove components	0.0	0.0	0.0	2.0	0.0000000000	False
ll remove the sender	0.0	0.0	0.0	2.0	0.0000000000	False
remove the sender host	0.0	0.0	0.0	4.0	0.0000000000	False
occurred when you remove	0.0	0.0	0.0	2.0	0.0000000000	False
remove the text parser	0.0	0.0	0.0	2.0	0.0000000000	False
make a credible case	0.0	0.0	0.0	2.0	0.0000000000	False
made the biggest difference	0.0	0.0	0.0	2.0	0.0000000000	False
features on this line	0.0	0.0	0.0	2.0	0.0000000000	False
means that in case	0.0	0.0	0.0	2.0	0.0000000000	False
rid of the sender	0.0	0.0	0.0	2.0	0.0000000000	False
host features to speed	0.0	0.0	0.0	2.0	0.0000000000	False
good candidate for elimination	0.0	0.0	0.0	2.0	0.0000000000	False
shuffle around the order	0.0	0.0	0.0	2.0	0.0000000000	False
things ? the answer	0.0	0.0	0.0	2.0	0.0000000000	False
result so in practice	0.0	0.0	0.0	2.0	0.0000000000	False
fairly natural of ordering	0.0	0.0	0.0	2.0	0.0000000000	False
ordering for both types	0.0	0.0	0.0	2.0	0.0000000000	False
add things or remove	0.0	0.0	0.0	2.0	0.0000000000	False
things or remove things	0.0	0.0	0.0	2.0	0.0000000000	False
formulas that are constants	0.0	0.0	0.0	2.0	0.0000000000	False
feel free to invent	0.0	0.0	0.0	2.0	0.0000000000	False
system and just remove	0.0	0.0	0.0	2.0	0.0000000000	False
talk about is sort	0.0	0.0	0.0	2.0	0.0000000000	False
started on a learning	0.0	0.0	0.0	2.0	0.0000000000	False
broad to get started	0.0	0.0	0.0	2.0	0.0000000000	False
started on learning problem	0.0	0.0	0.0	2.0	0.0000000000	False
carefully design your system	0.0	0.0	0.0	2.0	0.0000000000	False
designing exactly the right	0.0	0.0	0.0	2.0	0.0000000000	False
collecting the right data	0.0	0.0	0.0	2.0	0.0000000000	False
implement it and hope	0.0	0.0	0.0	2.0	0.0000000000	False
right ? the benefit	0.0	0.0	0.0	2.0	0.0000000000	False
benefit of this sort	0.0	0.0	0.0	2.0	0.0000000000	False
contribute to basic research	0.0	0.0	0.0	2.0	0.0000000000	False
basic research in machine	0.0	0.0	0.0	2.0	0.0000000000	False
research in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
invent new machine learning	0.0	0.0	0.0	4.0	0.0000000000	False
slowing down and thinking	0.0	0.0	0.0	2.0	0.0000000000	False
deeply about the problem	0.0	0.0	0.0	4.0	0.0000000000	False
sort of the right	0.0	0.0	0.0	2.0	0.0000000000	False
deeply about a problem	0.0	0.0	0.0	2.0	0.0000000000	False
error analyses and diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
wrong and you fix	0.0	0.0	0.0	2.0	0.0000000000	False
working much more quickly	0.0	0.0	0.0	2.0	0.0000000000	False
working in a company	0.0	0.0	0.0	4.0	0.0000000000	False
first product to market	0.0	0.0	0.0	2.0	0.0000000000	False
hack and then fixing	0.0	0.0	0.0	2.0	0.0000000000	False
quickly and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
parts of a system	0.0	0.0	0.0	2.0	0.0000000000	False
lot of time focusing	0.0	0.0	0.0	2.0	0.0000000000	False
right ? for identifying	0.0	0.0	0.0	2.0	0.0000000000	False
big complicated learning system	0.0	0.0	0.0	2.0	0.0000000000	False
obvious at the outset	0.0	0.0	0.0	2.0	0.0000000000	False
components you should spend	0.0	0.0	0.0	2.0	0.0000000000	False
lots of time working	0.0	0.0	0.0	2.0	0.0000000000	False
nt know that preprocessing	0.0	0.0	0.0	0.0	0.0000000000	False
nt the right component	0.0	0.0	0.0	0.0	0.0000000000	False
spent three months working	0.0	0.0	0.0	2.0	0.0000000000	False
working on better background	0.0	0.0	0.0	2.0	0.0000000000	False
out what really works	0.0	0.0	0.0	2.0	0.0000000000	False
quickly and you find	0.0	0.0	0.0	2.0	0.0000000000	False
find out what parts	0.0	0.0	0.0	4.0	0.0000000000	False
hard parts to implement	0.0	0.0	0.0	2.0	0.0000000000	False
parts are hard parts	0.0	0.0	0.0	2.0	0.0000000000	False
parts that could make	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to build	0.0	0.0	0.0	4.0	0.0000000000	False
build a people recognition	0.0	0.0	0.0	2.0	0.0000000000	False
prototyped a few systems	0.0	0.0	0.0	2.0	0.0000000000	False
first system you re	0.0	0.0	0.0	0.0	0.0000000000	False
system you re designing	0.0	0.0	0.0	0.0	0.0000000000	False
concrete piece of advice	0.0	0.0	0.0	2.0	0.0000000000	False
applies to your projects	0.0	0.0	0.0	2.0	0.0000000000	False
build a working application	0.0	0.0	0.0	2.0	0.0000000000	False
system like this step	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to predict	0.0	0.0	0.0	2.0	0.0000000000	False
predict and just plot	0.0	0.0	0.0	2.0	0.0000000000	False
negative ? i thought	0.0	0.0	0.0	2.0	0.0000000000	False
wrong with this dataset	0.0	0.0	0.0	2.0	0.0000000000	False
wrong with your data	0.0	0.0	0.0	2.0	0.0000000000	False
out just by plotting	0.0	0.0	0.0	2.0	0.0000000000	False
find out be implementing	0.0	0.0	0.0	2.0	0.0000000000	False
big complicated learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms on it plotting	0.0	0.0	0.0	2.0	0.0000000000	False
plotting the data sounds	0.0	0.0	0.0	2.0	0.0000000000	False
lots of us give	0.0	0.0	0.0	2.0	0.0000000000	False
advice if your goal	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms all right	0.0	0.0	0.0	2.0	0.0000000000	False
lying around so give	0.0	0.0	0.0	2.0	0.0000000000	False
give me a learning	0.0	0.0	0.0	2.0	0.0000000000	False
complicated than logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression on it first	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to hack	0.0	0.0	0.0	0.0	0.0000000000	False
follow this specifically shoot	0.0	0.0	0.0	2.0	0.0000000000	False
premature optimization of code	0.0	0.0	0.0	2.0	0.0000000000	False
people will prematurely optimize	0.0	0.0	0.0	2.0	0.0000000000	False
prematurely optimize one component	0.0	0.0	0.0	2.0	0.0000000000	False
big complicated machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
complicated machine learning system	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon that highly influenced	0.0	0.0	0.0	2.0	0.0000000000	False
influenced my own thinking	0.0	0.0	0.0	2.0	0.0000000000	False
thinking it was based	0.0	0.0	0.0	2.0	0.0000000000	False
based on a paper	0.0	0.0	0.0	2.0	0.0000000000	False
paper written by christos	0.0	0.0	0.0	2.0	0.0000000000	False
written by christos papadimitriou	0.0	0.0	0.0	2.0	0.0000000000	False
developmental progress of research	0.0	0.0	0.0	2.0	0.0000000000	False
build a mail delivery	0.0	0.0	0.0	2.0	0.0000000000	False
ve drawn a circle	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to deliver	0.0	0.0	0.0	0.0	0.0000000000	False
wander around indoor environments	0.0	0.0	0.0	2.0	0.0000000000	False
robot to manipulate objects	0.0	0.0	0.0	2.0	0.0000000000	False
manipulate objects and pickup	0.0	0.0	0.0	2.0	0.0000000000	False
objects and pickup envelopes	0.0	0.0	0.0	2.0	0.0000000000	False
build those two components	0.0	0.0	0.0	2.0	0.0000000000	False
two components in order	0.0	0.0	0.0	2.0	0.0000000000	False
drawing those two components	0.0	0.0	0.0	2.0	0.0000000000	False
components and little arrows	0.0	0.0	0.0	2.0	0.0000000000	False
obstacle avoidance is needed	0.0	0.0	0.0	2.0	0.0000000000	False
build your mail delivery	0.0	0.0	0.0	2.0	0.0000000000	False
robot well for obstacle	0.0	0.0	0.0	2.0	0.0000000000	False
robot that can navigate	0.0	0.0	0.0	2.0	0.0000000000	False
obstacles now we re	0.0	0.0	0.0	0.0	0.0000000000	False
computer vision to detect	0.0	0.0	0.0	2.0	0.0000000000	False
evening this is lighting	0.0	0.0	0.0	2.0	0.0000000000	False
lighting causes the color	0.0	0.0	0.0	2.0	0.0000000000	False
colors of an object	0.0	0.0	0.0	2.0	0.0000000000	False
right ? because lighting	0.0	0.0	0.0	2.0	0.0000000000	False
represented by three-dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
learn when two colors	0.0	0.0	0.0	2.0	0.0000000000	False
appearance of two colors	0.0	0.0	0.0	2.0	0.0000000000	False
geometry of 3d manifolds	0.0	0.0	0.0	4.0	0.0000000000	False
manifolds because that helps	0.0	0.0	0.0	2.0	0.0000000000	False
build a sound theory	0.0	0.0	0.0	2.0	0.0000000000	False
develop our 3d similarity	0.0	0.0	0.0	2.0	0.0000000000	False
understand the fundamental aspects	0.0	0.0	0.0	2.0	0.0000000000	False
aspects of this problem	0.0	0.0	0.0	2.0	0.0000000000	False
complexity of non-riemannian geometries	0.0	0.0	0.0	2.0	0.0000000000	False
eventually you re proving	0.0	0.0	0.0	0.0	0.0000000000	False
re proving convergence bounds	0.0	0.0	0.0	2.0	0.0000000000	False
convergence bounds for sampled	0.0	0.0	5.99890789953	6.0	0.0000000000	False
sampled of non-monotonic logic	0.0	0.0	0.0	2.0	0.0000000000	False
chances are that link	0.0	0.0	0.0	2.0	0.0000000000	False
link is nt real	0.0	0.0	0.0	0.0	0.0000000000	False
nt real color variance	0.0	0.0	0.0	0.0	0.0000000000	False
variance just barely helped	0.0	0.0	0.0	2.0	0.0000000000	False
barely helped object recognition	0.0	0.0	0.0	2.0	0.0000000000	False
learning and that link	0.0	0.0	0.0	2.0	0.0000000000	False
thought in your head	0.0	0.0	0.0	2.0	0.0000000000	False
written on differential geometry	0.0	0.0	0.0	2.0	0.0000000000	False
written because some guy	0.0	0.0	0.0	2.0	0.0000000000	False
ll help 3d similarity	0.0	0.0	0.0	2.0	0.0000000000	False
friend of mine told	0.0	0.0	0.0	2.0	0.0000000000	False
told me that color	0.0	0.0	0.0	2.0	0.0000000000	False
working on color invariance	0.0	0.0	0.0	2.0	0.0000000000	False
mine that his thing	0.0	0.0	0.0	2.0	0.0000000000	False
ll tell a friend	0.0	0.0	0.0	2.0	0.0000000000	False
re working on convergence	0.0	0.0	0.0	2.0	0.0000000000	False
working on convergence bound	0.0	0.0	0.0	2.0	0.0000000000	False
day of your mail	0.0	0.0	0.0	2.0	0.0000000000	False
theory of vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
impact on many applications	0.0	0.0	0.0	2.0	0.0000000000	False
dramatically advanced data machine	0.0	0.0	0.0	2.0	0.0000000000	False
advanced data machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
mind are you working	0.0	0.0	0.0	2.0	0.0000000000	False
relevance to some application	0.0	0.0	0.0	2.0	0.0000000000	False
work on an application	0.0	0.0	0.0	2.0	0.0000000000	False
link from the theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory i m working	0.0	0.0	0.0	0.0	0.0000000000	False
back to an application	0.0	0.0	0.0	2.0	0.0000000000	False
working on will relate	0.0	0.0	0.0	2.0	0.0000000000	False
relate to an application	0.0	0.0	0.0	2.0	0.0000000000	False
personally see a link	0.0	0.0	0.0	2.0	0.0000000000	False
back just to summarize	0.0	0.0	0.0	2.0	0.0000000000	False
coming up with diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics for learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms and making	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms and making progress	0.0	0.0	0.0	2.0	0.0000000000	False
tests on your learning	0.0	0.0	0.0	2.0	0.0000000000	False
spent implementing those tests	0.0	0.0	0.0	2.0	0.0000000000	False
out what to work	0.0	0.0	0.0	2.0	0.0000000000	False
talked about error analyses	0.0	0.0	0.0	2.0	0.0000000000	False
analyses and ablative analyses	0.0	0.0	2.99890789953	6.0	0.0000000000	False
approaches and the risks	0.0	0.0	0.0	2.0	0.0000000000	False
minutes for your questions	0.0	0.0	0.0	2.0	0.0000000000	False
quick announcement of sorts	0.0	0.0	0.0	2.0	0.0000000000	False
years ago that stanford	0.0	0.0	0.0	2.0	0.0000000000	False
ago that stanford submitted	0.0	0.0	0.0	2.0	0.0000000000	False
stanford submitted an entry	0.0	0.0	0.0	2.0	0.0000000000	False
entry to the darpa	0.0	0.0	0.0	2.0	0.0000000000	False
darpa grand challenge phase	0.0	0.0	0.0	2.0	0.0000000000	False
thrun has a team	0.0	0.0	0.0	2.0	0.0000000000	False
racing another autonomous car	0.0	0.0	0.0	2.0	0.0000000000	False
tools and ai machines	0.0	0.0	0.0	2.0	0.0000000000	False
ll try to drive	0.0	0.0	0.0	2.0	0.0000000000	False
drive itself in midst	0.0	0.0	0.0	2.0	0.0000000000	False
carry out the sort	0.0	0.0	0.0	2.0	0.0000000000	False
re free this weekend	0.0	0.0	0.0	2.0	0.0000000000	False
weekend if you re	0.0	0.0	0.0	0.0	0.0000000000	False
re free on saturday	0.0	0.0	0.0	2.0	0.0000000000	False
watch tv or search	0.0	0.0	0.0	2.0	0.0000000000	False
search online for urban	0.0	0.0	0.0	2.0	0.0000000000	False
online for urban challenge	0.0	0.0	0.0	2.0	0.0000000000	False
fun thing to watch	0.0	0.0	0.0	2.0	0.0000000000	False
cool demo or instance	0.0	0.0	0.0	2.0	0.0000000000	False
died a few seconds	0.0	0.0	0.0	2.0	0.0000000000	False
seconds before class started	0.0	0.0	0.0	2.0	0.0000000000	False
show you the things	0.0	0.0	0.0	2.0	0.0000000000	False
morning and welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
today is actually begin	0.0	0.0	0.0	2.0	0.0000000000	False
begin a new chapter	0.0	0.0	0.0	2.0	0.0000000000	False
briefly talk about clustering	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm with a mixture	0.0	0.0	0.0	2.0	0.0000000000	False
describe something called jensen	0.0	0.0	0.0	4.0	0.0000000000	False
derive a general form	0.0	0.0	0.0	2.0	0.0000000000	False
place and different unsupervised	0.0	0.0	0.0	2.0	0.0000000000	False
machine or any application	0.0	0.0	0.0	2.0	0.0000000000	False
application so the cartoons	0.0	0.0	0.0	2.0	0.0000000000	False
draw for supervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative crosses	0.0	0.0	0.0	2.0	0.0000000000	False
call it the supervised	0.0	0.0	0.0	2.0	0.0000000000	False
learning because you re	0.0	0.0	0.0	0.0	0.0000000000	False
re sort of told	0.0	0.0	0.0	2.0	0.0000000000	False
told what the right	0.0	0.0	0.0	2.0	0.0000000000	False
supervision in unsupervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
study a different problem	0.0	0.0	0.0	2.0	0.0000000000	False
re given a data	0.0	0.0	0.0	2.0	0.0000000000	False
set with no labels	0.0	0.0	0.0	2.0	0.0000000000	False
labels and no indication	0.0	0.0	0.0	2.0	0.0000000000	False
job of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to discover structure	0.0	0.0	0.0	2.0	0.0000000000	False
structure in the data	0.0	0.0	0.0	2.0	0.0000000000	False
weeks we ll talk	0.0	0.0	0.0	0.0	0.0000000000	False
talk about a variety	0.0	0.0	0.0	2.0	0.0000000000	False
variety of unsupervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
first unsupervised learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ll be an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
automatically breaks the data	0.0	0.0	0.0	2.0	0.0000000000	False
breaks the data set	0.0	0.0	0.0	2.0	0.0000000000	False
set into different smaller	0.0	0.0	0.0	2.0	0.0000000000	False
applications just to rattle	0.0	0.0	0.0	2.0	0.0000000000	False
better-known ones i guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess in biology application	0.0	0.0	0.0	2.0	0.0000000000	False
application you often cross	0.0	0.0	0.0	2.0	0.0000000000	False
cross the different things	0.0	0.0	0.0	2.0	0.0000000000	False
genes and they cluster	0.0	0.0	0.0	2.0	0.0000000000	False
cluster the different genes	0.0	0.0	0.0	2.0	0.0000000000	False
genes together in order	0.0	0.0	0.0	2.0	0.0000000000	False
examine them and understand	0.0	0.0	0.0	2.0	0.0000000000	False
understand the biological function	0.0	0.0	0.0	2.0	0.0000000000	False
common application of clustering	0.0	0.0	0.0	2.0	0.0000000000	False
clustering is market research	0.0	0.0	0.0	2.0	0.0000000000	False
market research so imagine	0.0	0.0	0.0	2.0	0.0000000000	False
common practice to apply	0.0	0.0	0.0	2.0	0.0000000000	False
practice to apply clustering	0.0	0.0	0.0	2.0	0.0000000000	False
clustering algorithms to break	0.0	0.0	0.0	2.0	0.0000000000	False
customers into different market	0.0	0.0	0.0	2.0	0.0000000000	False
products towards different market	0.0	0.0	0.0	2.0	0.0000000000	False
market segments and target	0.0	0.0	0.0	2.0	0.0000000000	False
target your sales pitches	0.0	0.0	0.0	2.0	0.0000000000	False
specifically to different market	0.0	0.0	0.0	2.0	0.0000000000	False
ll do later today	0.0	0.0	0.0	2.0	0.0000000000	False
clustering algorithm to everyday	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to everyday group	0.0	0.0	0.0	2.0	0.0000000000	False
everyday group related news	0.0	0.0	0.0	2.0	0.0000000000	False
group related news articles	0.0	0.0	0.0	2.0	0.0000000000	False
articles together to display	0.0	0.0	0.0	2.0	0.0000000000	False
thousand news articles today	0.0	0.0	0.0	2.0	0.0000000000	False
top story of today	0.0	0.0	0.0	2.0	0.0000000000	False
websites on different story	0.0	0.0	0.0	2.0	0.0000000000	False
story of the day	0.0	0.0	0.0	2.0	0.0000000000	False
talks about image segmentation	0.0	0.0	0.0	2.0	0.0000000000	False
group together different subsets	0.0	0.0	0.0	2.0	0.0000000000	False
subsets of the picture	0.0	0.0	0.0	2.0	0.0000000000	False
picture into coherent pieces	0.0	0.0	0.0	2.0	0.0000000000	False
coherent pieces of pixels	0.0	0.0	0.0	2.0	0.0000000000	False
understand what s contained	0.0	0.0	0.0	0.0	0.0000000000	False
contained in the picture	0.0	0.0	0.0	2.0	0.0000000000	False
clustering the next idea	0.0	0.0	0.0	2.0	0.0000000000	False
automatically group the data	0.0	0.0	0.0	2.0	0.0000000000	False
group the data sets	0.0	0.0	0.0	2.0	0.0000000000	False
data sets into coherent	0.0	0.0	0.0	2.0	0.0000000000	False
sets into coherent clusters	0.0	0.0	0.0	2.0	0.0000000000	False
waiting for the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
nt i just start	0.0	0.0	0.0	0.0	0.0000000000	False
out the specific clustering	0.0	0.0	0.0	2.0	0.0000000000	False
show you the animation	0.0	0.0	0.0	4.0	0.0000000000	False
clustering algorithm for finding	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for finding clustering	0.0	0.0	0.0	2.0	0.0000000000	False
input to the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
set which i write	0.0	0.0	0.0	2.0	0.0000000000	False
talking about unsupervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
sense when i show	0.0	0.0	0.0	2.0	0.0000000000	False
animation on my laptop	0.0	0.0	0.0	2.0	0.0000000000	False
re of training data	0.0	0.0	0.0	2.0	0.0000000000	False
steps so the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroid j is closest	0.0	0.0	0.0	2.0	0.0000000000	False
step is called assigning	0.0	0.0	0.0	2.0	0.0000000000	False
point xi to cluster	0.0	0.0	0.0	2.0	0.0000000000	False
picking the cluster centroid	0.0	0.0	0.0	2.0	0.0000000000	False
step is you update	0.0	0.0	0.0	2.0	0.0000000000	False
update the cluster centroids	0.0	0.0	3.99789621318	6.0	0.0000000000	False
bring down the display	0.0	0.0	0.0	2.0	0.0000000000	False
display for the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
k-means algorithm and hope	0.0	0.0	0.0	2.0	0.0000000000	False
michael jordan in berkley	0.0	0.0	0.0	2.0	0.0000000000	False
berkley so these points	0.0	0.0	0.0	2.0	0.0000000000	False
green are my data	0.0	0.0	0.0	2.0	0.0000000000	False
randomly initialize a pair	0.0	0.0	0.0	2.0	0.0000000000	False
pair of cluster centroids	0.0	0.0	0.0	2.0	0.0000000000	False
blue crosses to note	0.0	0.0	0.0	2.0	0.0000000000	False
clusters in this data	0.0	0.0	0.0	2.0	0.0000000000	False
data sets of k-means	0.0	0.0	0.0	2.0	0.0000000000	False
sets of k-means algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
k-means algorithms as follow	0.0	0.0	0.0	2.0	0.0000000000	False
points in my data	0.0	0.0	0.0	2.0	0.0000000000	False
denote that by painting	0.0	0.0	0.0	2.0	0.0000000000	False
blue or red depending	0.0	0.0	0.0	2.0	0.0000000000	False
cross points are painted	0.0	0.0	0.0	2.0	0.0000000000	False
points that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
red dots and compute	0.0	0.0	0.0	2.0	0.0000000000	False
move the cluster centroids	0.0	0.0	0.0	2.0	0.0000000000	False
repeat the same process	0.0	0.0	0.0	2.0	0.0000000000	False
assign all the points	0.0	0.0	0.0	2.0	0.0000000000	False
cross to the color	0.0	0.0	0.0	2.0	0.0000000000	False
blue and similarly red	0.0	0.0	0.0	2.0	0.0000000000	False
points to the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
blue points and compute	0.0	0.0	0.0	2.0	0.0000000000	False
red points and update	0.0	0.0	0.0	2.0	0.0000000000	False
running these two sets	0.0	0.0	0.0	2.0	0.0000000000	False
two sets of k-means	0.0	0.0	0.0	2.0	0.0000000000	False
centroids and the assignment	0.0	0.0	0.0	2.0	0.0000000000	False
assignment of the points	0.0	0.0	0.0	2.0	0.0000000000	False
closest to the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroids will actually remain	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you understand	0.0	0.0	0.0	2.0	0.0000000000	False
understand how the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
maps onto the animation	0.0	0.0	0.0	2.0	0.0000000000	False
two steps this step	0.0	0.0	0.0	2.0	0.0000000000	False
shifting the cluster centroid	0.0	0.0	0.0	2.0	0.0000000000	False
assigned to that cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroid okay okay questions	0.0	0.0	0.0	2.0	0.0000000000	False
converge ? the answer	0.0	0.0	0.0	2.0	0.0000000000	False
define the distortion function	0.0	0.0	0.0	4.0	0.0000000000	False
squared you can define	0.0	0.0	0.0	2.0	0.0000000000	False
function of the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroids and square distances	0.0	0.0	0.0	2.0	0.0000000000	False
points and the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroids that they re	0.0	0.0	0.0	0.0	0.0000000000	False
sense as an authorization	0.0	0.0	0.0	2.0	0.0000000000	False
sense is the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ll repeatedly with respect	0.0	0.0	0.0	2.0	0.0000000000	False
prove is that k-means	0.0	0.0	0.0	2.0	0.0000000000	False
k-means the two steps	0.0	0.0	0.0	2.0	0.0000000000	False
two steps of k-means	0.0	0.0	0.0	2.0	0.0000000000	False
respect a new alternately	0.0	0.0	0.0	2.0	0.0000000000	False
converge in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
clustering s they give	0.0	0.0	0.0	0.0	0.0000000000	False
give the same value	0.0	0.0	0.0	2.0	0.0000000000	False
k-means may actually switch	0.0	0.0	0.0	2.0	0.0000000000	False
value for this objective	0.0	0.0	0.0	2.0	0.0000000000	False
ll just never happen	0.0	0.0	0.0	2.0	0.0000000000	False
randomly pick a number	0.0	0.0	0.0	2.0	0.0000000000	False
work best the number	0.0	0.0	0.0	2.0	0.0000000000	False
clusters in this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
hard to choose automatically	0.0	0.0	0.0	2.0	0.0000000000	False
automatic ways of choosing	0.0	0.0	0.0	2.0	0.0000000000	False
pick of the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of clusters randomly	0.0	0.0	0.0	2.0	0.0000000000	False
randomly and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
problems the true number	0.0	0.0	0.0	2.0	0.0000000000	False
true number of clusters	0.0	0.0	0.0	2.0	0.0000000000	False
actual number of clusters	0.0	0.0	0.0	2.0	0.0000000000	False
right so yes k-means	0.0	0.0	0.0	2.0	0.0000000000	False
function and so k-means	0.0	0.0	0.0	2.0	0.0000000000	False
function is not guaranteed	0.0	0.0	0.0	2.0	0.0000000000	False
initializations and then run	0.0	0.0	0.0	2.0	0.0000000000	False
run clustering a bunch	0.0	0.0	0.0	2.0	0.0000000000	False
value for the distortion	0.0	0.0	0.0	2.0	0.0000000000	False
centroid has no points	0.0	0.0	0.0	2.0	0.0000000000	False
vast majority of applications	0.0	0.0	0.0	2.0	0.0000000000	False
ve seen for k-means	0.0	0.0	0.0	2.0	0.0000000000	False
norm and one norm	0.0	0.0	0.0	2.0	0.0000000000	False
variations on this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
describe is actually talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about density estimation	0.0	0.0	0.0	2.0	0.0000000000	False
estimation as another k-means	0.0	0.0	0.0	2.0	0.0000000000	False
building off an assembly	0.0	0.0	0.0	2.0	0.0000000000	False
work for an aircraft	0.0	0.0	0.0	2.0	0.0000000000	False
re building aircraft engines	0.0	0.0	0.0	2.0	0.0000000000	False
engines off the assembly	0.0	0.0	0.0	2.0	0.0000000000	False
test these aircraft engines	0.0	0.0	0.0	2.0	0.0000000000	False
aircraft engines and measure	0.0	0.0	0.0	2.0	0.0000000000	False
measure various different properties	0.0	0.0	0.0	2.0	0.0000000000	False
heat and vibrations right	0.0	0.0	0.0	2.0	0.0000000000	False
vibrations right in reality	0.0	0.0	0.0	2.0	0.0000000000	False
amount of heat produced	0.0	0.0	0.0	4.0	0.0000000000	False
heat produced and vibrations	0.0	0.0	0.0	2.0	0.0000000000	False
produced and vibrations produced	0.0	0.0	0.0	2.0	0.0000000000	False
produced and the amount	0.0	0.0	0.0	2.0	0.0000000000	False
rolls off the assembly	0.0	0.0	0.0	4.0	0.0000000000	False
measure the same heat	0.0	0.0	0.0	2.0	0.0000000000	False
heat and vibration properties	0.0	0.0	0.0	2.0	0.0000000000	False
flaw in this aircraft	0.0	0.0	0.0	2.0	0.0000000000	False
typical distribution of features	0.0	0.0	0.0	2.0	0.0000000000	False
raise a red flag	0.0	0.0	0.0	2.0	0.0000000000	False
fly with the engine	0.0	0.0	0.0	2.0	0.0000000000	False
engine so this problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem i just described	0.0	0.0	0.0	2.0	0.0000000000	False
described is an instance	0.0	0.0	0.0	2.0	0.0000000000	False
typical data you re	0.0	0.0	0.0	0.0	0.0000000000	False
unusual transactions to start	0.0	0.0	0.0	2.0	0.0000000000	False
stolen my credit card	0.0	0.0	0.0	2.0	0.0000000000	False
talk about specific algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
specific algorithm for density	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for density estimation	0.0	0.0	0.0	2.0	0.0000000000	False
works with data sets	0.0	0.0	0.0	2.0	0.0000000000	False
standard text book distributions	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian or a explanation	0.0	0.0	0.0	2.0	0.0000000000	False
model to estimate densities	0.0	0.0	0.0	2.0	0.0000000000	False
imagine maybe a data	0.0	0.0	0.0	2.0	0.0000000000	False
axis and these dots	0.0	0.0	0.0	2.0	0.0000000000	False
dots represent the positions	0.0	0.0	0.0	2.0	0.0000000000	False
positions of the data	0.0	0.0	0.0	2.0	0.0000000000	False
coming from a density	0.0	0.0	0.0	2.0	0.0000000000	False
clear that the picture	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian s that generated	0.0	0.0	0.0	0.0	0.0000000000	False
generated this data set	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian to my crosses	0.0	0.0	0.0	2.0	0.0000000000	False
nt actually have access	0.0	0.0	0.0	0.0	0.0000000000	False
access to these labels	0.0	0.0	0.0	2.0	0.0000000000	False
idea in this model	0.0	0.0	0.0	2.0	0.0000000000	False
re gon na imagine	0.0	0.0	0.0	2.0	0.0000000000	False
distributed multinomial with parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameter are the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
distribution and the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution of xi conditioned	0.0	0.0	0.0	2.0	0.0000000000	False
equations that i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant analysis algorithm	0.0	0.0	0.0	2.0	0.0000000000	True
analysis with these latent	0.0	0.0	0.0	2.0	0.0000000000	False
explicit if we knew	0.0	0.0	0.0	2.0	0.0000000000	False
suppose for the sake	0.0	0.0	0.0	2.0	0.0000000000	False
estimation you can write	0.0	0.0	0.0	2.0	0.0000000000	False
write down the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
write down the law	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood and do maximum	0.0	0.0	0.0	2.0	0.0000000000	False
estimate all the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of your model	0.0	0.0	0.0	4.0	0.0000000000	False
model does this make	0.0	0.0	0.0	2.0	0.0000000000	False
make sense ? raise	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	2.99789621318	6.0	0.0000000000	False
nt raise your hands	0.0	0.0	0.0	0.0	0.0000000000	False
basically any other questions	0.0	0.0	0.0	2.0	0.0000000000	False
playing a similar role	0.0	0.0	0.0	2.0	0.0000000000	False
role to the cross	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian s discriminant analysis	0.0	0.0	0.0	0.0	0.0000000000	False
maximum likeliness estimation parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters but in reality	0.0	0.0	0.0	2.0	0.0000000000	False
guess what the values	0.0	0.0	0.0	2.0	0.0000000000	False
guess at the values	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the model	0.0	0.0	0.0	4.0	0.0000000000	False
estimate for the parameters	0.0	0.0	5.99719495091	8.0	0.4233576642	False
parameters for the rest	0.0	0.0	0.0	2.0	0.0000000000	False
likeliness estimation to set	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the model	0.0	0.0	0.0	2.0	0.0000000000	False
model so the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm and it proceeds	0.0	0.0	0.0	2.0	0.0000000000	False
proceeds as follows repeat	0.0	0.0	0.0	2.0	0.0000000000	False
re going to guess	0.0	0.0	0.0	2.0	0.0000000000	False
values of the unknown	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters in my model	0.0	0.0	0.0	2.0	0.0000000000	False
sum from o equals	0.0	0.0	0.0	4.0	0.0000000000	False
essentially the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian and the numerator	0.0	0.0	0.0	2.0	0.0000000000	False
numerator and the sum	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the denominator	0.0	0.0	0.0	2.0	0.0000000000	False
estimates of the parameters	0.0	0.0	0.0	4.0	0.0000000000	False
lay down the formulas	0.0	0.0	0.0	2.0	0.0000000000	False
remember was the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability that we computed	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to call	0.0	0.0	0.0	0.0	0.0000000000	False
commonly use different covariant	0.0	0.0	0.0	2.0	0.0000000000	False
sort of by convention	0.0	0.0	0.0	2.0	0.0000000000	False
sigma i just wrote	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down a lot	0.0	0.0	0.0	2.0	0.0000000000	False
values for the zis	0.0	0.0	0.0	2.0	0.0000000000	False
give you labeled data	0.0	0.0	0.0	2.0	0.0000000000	False
values of the zis	0.0	0.0	0.0	4.0	0.0000000000	False
giving you a data	0.0	0.0	0.0	2.0	0.0000000000	False
set that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
discriminant analysis we figured	0.0	0.0	0.0	2.0	0.0000000000	False
figured out the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out the maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
estimation and the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
probability that zi equals	0.0	0.0	0.0	4.0	0.0000000000	False
estimate that as sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum of i equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals j and divide	0.0	0.0	0.0	2.0	0.0000000000	False
knew the cross labels	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for the chance	0.0	0.0	0.0	2.0	0.0000000000	False
chance that the labels	0.0	0.0	0.0	2.0	0.0000000000	False
examples your maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
likeliness estimate for probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability of getting examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples in your training	0.0	0.0	0.0	2.0	0.0000000000	False
draw the same data	0.0	0.0	0.0	2.0	0.0000000000	False
cross label is unknown	0.0	0.0	0.0	2.0	0.0000000000	False
guess for the values	0.0	0.0	0.0	2.0	0.0000000000	False
step we computed wij	0.0	0.0	0.0	2.0	0.0000000000	False
guess for the probability	0.0	0.0	0.0	4.0	0.0000000000	False
probability that the point	0.0	0.0	0.0	2.0	0.0000000000	False
probability that this point	0.0	0.0	0.0	4.0	0.0000000000	False
point was a cross	0.0	0.0	0.0	2.0	0.0000000000	False
sum from i equals	0.0	0.0	0.0	2.0	0.0000000000	False
formula for the estimate	0.0	0.0	0.0	2.0	0.0000000000	False
back to the formula	0.0	0.0	0.0	2.0	0.0000000000	False
convey an intuitive sense	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm s make sense	0.0	0.0	0.0	0.0	0.0000000000	False
sense can you raise	0.0	0.0	0.0	2.0	0.0000000000	False
sense now ? cool	0.0	0.0	0.0	2.0	0.0000000000	False
present a broader view	0.0	0.0	0.0	2.0	0.0000000000	False
hour i have today	0.0	0.0	0.0	2.0	0.0000000000	False
describe a general description	0.0	0.0	0.0	2.0	0.0000000000	False
pre-cursor to actually deriving	0.0	0.0	0.0	2.0	0.0000000000	False
jensen s and equality	0.0	0.0	0.0	0.0	0.0000000000	False
function so a function	0.0	0.0	0.0	2.0	0.0000000000	False
function is a convex	0.0	0.0	0.0	2.0	0.0000000000	False
ve written f prime	0.0	0.0	0.0	2.0	0.0000000000	False
written f prime prime	0.0	0.0	0.0	2.0	0.0000000000	False
differentiatable to be convex	0.0	0.0	0.0	2.0	0.0000000000	False
prime should be creating	0.0	0.0	0.0	2.0	0.0000000000	False
applied to the expectation	0.0	0.0	0.0	2.0	0.0000000000	False
equal of 2d expectation	0.0	0.0	0.0	2.0	0.0000000000	False
remember i often drop	0.0	0.0	0.0	2.0	0.0000000000	False
drop the square back	0.0	0.0	0.0	2.0	0.0000000000	False
drop the square brackets	0.0	0.0	0.0	2.0	0.0000000000	False
picture that would explain	0.0	0.0	0.0	2.0	0.0000000000	False
equality is by drawing	0.0	0.0	0.0	2.0	0.0000000000	False
drawing the following picture	0.0	0.0	0.0	2.0	0.0000000000	False
ll illustrate this inequality	0.0	0.0	0.0	2.0	0.0000000000	False
vertical axis we re	0.0	0.0	0.0	0.0	0.0000000000	False
value in the middle	0.0	0.0	0.0	2.0	0.0000000000	False
prime of x makes	0.0	0.0	0.0	2.0	0.0000000000	False
makes than z row	0.0	0.0	0.0	2.0	0.0000000000	False
convex then the inequality	0.0	0.0	0.0	2.0	0.0000000000	False
inequality holds an equality	0.0	0.0	0.0	2.0	0.0000000000	False
variable x always takes	0.0	0.0	0.0	2.0	0.0000000000	False
value okay any questions	0.0	0.0	0.0	2.0	0.0000000000	False
definition for strictly convex	0.0	0.0	0.0	2.0	0.0000000000	False
part of this function	0.0	0.0	0.0	2.0	0.0000000000	False
strictly convexed just means	0.0	0.0	0.0	2.0	0.0000000000	False
nt have a convex	0.0	0.0	0.0	0.0	0.0000000000	False
nt any straight line	0.0	0.0	0.0	0.0	0.0000000000	False
goal is to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of model right	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to find	0.0	0.0	0.0	2.0	0.0000000000	False
find the maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
data where the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
defined as something equals	0.0	0.0	0.0	2.0	0.0000000000	False
values of zi parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
performing this maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
maximum likeliness estimation problem	0.0	0.0	0.0	2.0	0.0000000000	False
complicated by the fact	0.0	0.0	0.0	2.0	0.0000000000	False
zis in our model	0.0	0.0	0.0	2.0	0.0000000000	False
model that are unobserved	0.0	0.0	0.0	2.0	0.0000000000	False
axis in this cartoon	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon is the axis	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
construct a lower bound	0.0	0.0	5.99719495091	8.0	0.2974358974	False
bound for this law	0.0	0.0	0.0	2.0	0.0000000000	False
law of likelihood function	0.0	0.0	0.0	4.0	0.0000000000	False
bound will be tight	0.0	0.0	0.0	2.0	0.0000000000	False
equality after current guessing	0.0	0.0	0.0	2.0	0.0000000000	False
current guessing the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters and they maximize	0.0	0.0	0.0	2.0	0.0000000000	False
maximize this lower boundary	0.0	0.0	0.0	2.0	0.0000000000	False
lower boundary with respect	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm look at theta	0.0	0.0	0.0	2.0	0.0000000000	False
construct a new lower	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound of theta	0.0	0.0	0.0	2.0	0.0000000000	False
converge to local optimum	0.0	0.0	0.0	2.0	0.0000000000	False
local optimum on theta	0.0	0.0	0.0	2.0	0.0000000000	False
optimum on theta function	0.0	0.0	0.0	2.0	0.0000000000	False
respect to theta sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum over all values	0.0	0.0	0.0	2.0	0.0000000000	False
construct the probability distribution	0.0	0.0	0.0	2.0	0.0000000000	False
ll later go describe	0.0	0.0	0.0	2.0	0.0000000000	False
describe the specific choice	0.0	0.0	0.0	2.0	0.0000000000	False
choice of this distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over the random	0.0	0.0	0.0	2.0	0.0000000000	False
function so that tells	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the expected	0.0	0.0	0.0	4.0	0.0000000000	False
expected value of log	0.0	0.0	0.0	2.0	0.0000000000	False
function form of jensen	0.0	0.0	0.0	2.0	0.0000000000	False
equality and so continuing	0.0	0.0	0.0	2.0	0.0000000000	False
summary of a log	0.0	0.0	0.0	2.0	0.0000000000	False
log and an expectation	0.0	0.0	0.0	2.0	0.0000000000	False
value of the log	0.0	0.0	0.0	2.0	0.0000000000	False
lastly just to expand	0.0	0.0	0.0	2.0	0.0000000000	False
expand out this formula	0.0	0.0	0.0	2.0	0.0000000000	False
distribution let s denote	0.0	0.0	0.0	0.0	0.0000000000	False
probability of that value	0.0	0.0	0.0	2.0	0.0000000000	False
value of z times	0.0	0.0	0.0	2.0	0.0000000000	False
right that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
sort of the definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of a random	0.0	0.0	0.0	2.0	0.0000000000	False
step to this step	0.0	0.0	0.0	2.0	0.0000000000	False
ve been using distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution qi to denote	0.0	0.0	0.0	2.0	0.0000000000	False
expected value with respect	0.0	0.0	0.0	2.0	0.0000000000	False
respect to a random	0.0	0.0	0.0	2.0	0.0000000000	False
random variable z joined	0.0	0.0	0.0	2.0	0.0000000000	False
joined from the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
general when you re	0.0	0.0	0.0	0.0	0.0000000000	False
re doing maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the data	0.0	0.0	0.0	2.0	0.0000000000	False
previously we said probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability of the data	0.0	0.0	0.0	4.0	0.0000000000	False
bound on the law	0.0	0.0	0.0	4.0	0.0000000000	False
theta are the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
function of your parameters	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of your parameters	0.0	0.0	0.0	2.0	0.0000000000	False
theta is lower bounded	0.0	0.0	0.0	2.0	0.0000000000	False
bounded by this thing	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon of repeatedly constructing	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound and optimizing	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing the lower bound	0.0	0.0	0.0	4.0	0.0000000000	False
bound for the law	0.0	0.0	0.0	2.0	0.0000000000	False
current value for theta	0.0	0.0	0.0	4.0	0.0000000000	False
theta so just refrain	0.0	0.0	0.0	2.0	0.0000000000	False
construct some lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound to be tight	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the law	0.0	0.0	0.0	2.0	0.0000000000	False
optimize my lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
nt think i ve	0.0	0.0	0.0	0.0	0.0000000000	False
bound is a concave	0.0	0.0	0.0	2.0	0.0000000000	False
concave function of theta	0.0	0.0	0.0	4.0	0.0000000000	False
equality if the random	0.0	0.0	0.0	2.0	0.0000000000	False
inside is a constant	0.0	0.0	0.0	2.0	0.0000000000	False
right if you re	0.0	0.0	0.0	0.0	0.0000000000	False
re taking an expectation	0.0	0.0	0.0	2.0	0.0000000000	False
respect to constant valued	0.0	0.0	0.0	2.0	0.0000000000	False
theta and just normalize	0.0	0.0	0.0	2.0	0.0000000000	False
skipping here to show	0.0	0.0	0.0	2.0	0.0000000000	False
ll just be convinced	0.0	0.0	0.0	2.0	0.0000000000	False
convinced it s true	0.0	0.0	0.0	0.0	0.0000000000	False
steps that i skipped	0.0	0.0	0.0	2.0	0.0000000000	False
out in the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
definition of conditional probability	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has two steps	0.0	0.0	0.0	2.0	0.0000000000	False
formula we just worked	0.0	0.0	0.0	2.0	0.0000000000	False
created a lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
current value of theta	0.0	0.0	0.0	4.0	0.0000000000	False
optimize that lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound with respect	0.0	0.0	0.0	4.0	0.0000000000	False
respect to our parameters	0.0	0.0	0.0	2.0	0.0000000000	False
step that i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
constructs this lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound and makes	0.0	0.0	0.0	2.0	0.0000000000	False
data okay so lots	0.0	0.0	0.0	2.0	0.0000000000	False
lecture let s check	0.0	0.0	0.0	0.0	0.0000000000	False
questions before we close	0.0	0.0	0.0	2.0	0.0000000000	False
close no okay cool	0.0	0.0	0.0	2.0	0.0000000000	False
wrap up for today	0.0	0.0	0.0	2.0	0.0000000000	False
