keyphrase	tfidf	cuewords	localspan	cscore	dispersion	keyword
d	c	c	c	c	c	d
m						class
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t.delhi	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t.delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
i.i.t.delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
high level programming languages	0.0	1.0	0.0	2.0	0.0000000000	True
imperative and functional languages	0.0	0.0	0.0	2.0	0.0000000000	False
respects so imperative language	0.0	0.0	0.0	2.0	0.0000000000	False
based languages where state	0.0	0.0	0.0	2.0	0.0000000000	False
languages where state updation	0.0	0.0	0.0	2.0	0.0000000000	False
languages are really value	0.0	0.0	0.0	2.0	0.0000000000	False
languages in the notion	0.0	0.0	0.0	2.0	0.0000000000	False
variables in functional languages	0.0	0.0	0.0	2.0	0.0000000000	False
mathematics whereas the notion	0.0	0.0	0.0	2.0	0.0000000000	False
notion of the variables	0.0	0.0	0.0	4.0	0.0000000000	False
physics which can change	0.0	0.0	0.0	2.0	0.0000000000	False
quantities like acceleration velocity	0.0	0.0	0.0	2.0	0.0000000000	False
state based languages means	0.0	0.0	0.0	2.0	0.0000000000	False
trimaxes though unlike physics	0.0	0.0	0.0	2.0	0.0000000000	False
case of functional languages	0.0	0.0	0.0	2.0	0.0000000000	False
functional languages the notion	0.0	0.0	0.0	2.0	0.0000000000	False
execution of a program	0.0	0.0	0.0	2.0	0.0000000000	False
languages is really concentrated	0.0	0.0	0.0	2.0	0.0000000000	False
hundreds of programming languages	0.0	0.0	0.0	4.0	0.0000000000	False
history you will find	0.0	0.0	0.0	2.0	0.0000000000	False
sixties a large portion	0.0	0.0	0.0	2.0	0.0000000000	False
features so which means	0.0	0.0	0.0	2.0	0.0000000000	False
means these these represent	0.0	0.0	0.0	2.0	0.0000000000	False
represent the basic control	0.0	0.0	0.0	2.0	0.0000000000	False
control structures the exploration	0.0	0.0	0.0	2.0	0.0000000000	False
data structures in order	0.0	0.0	0.0	2.0	0.0000000000	False
obtain clean readable programs	0.0	0.0	0.0	2.0	0.0000000000	False
efficiently implement able programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs um efficient running	0.0	0.0	0.0	2.0	0.0000000000	False
fixed in the seventies	0.0	0.0	0.0	2.0	0.0000000000	False
exploration of programming languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages was in terms	0.0	0.0	0.0	2.0	0.0000000000	False
pascal most important feature	0.0	0.0	0.0	2.0	0.0000000000	False
combines the module features	0.0	0.0	0.0	2.0	0.0000000000	False
module features of modula	0.0	0.0	0.0	2.0	0.0000000000	False
important feature exception handling	0.0	0.0	0.0	2.0	0.0000000000	False
feature exception handling generics	0.0	0.0	0.0	2.0	0.0000000000	False
handling generics or polymorphism	0.0	0.0	0.0	2.0	0.0000000000	False
clu is a module	0.0	0.0	0.0	2.0	0.0000000000	False
sense the basic control	0.0	0.0	0.0	2.0	0.0000000000	False
basic control structure remain	0.0	0.0	0.0	2.0	0.0000000000	False
structures in these languages	0.0	0.0	0.0	2.0	0.0000000000	False
mark denote the decendency	0.0	0.0	0.0	2.0	0.0000000000	False
structures so from simula	0.0	0.0	0.0	2.0	0.0000000000	False
small talk eighty control	0.0	0.0	0.0	2.0	0.0000000000	False
talk eighty control structures	0.0	0.0	0.0	2.0	0.0000000000	False
control structures or syntax	0.0	0.0	0.0	2.0	0.0000000000	False
simula which was extended	0.0	0.0	0.0	2.0	0.0000000000	False
features are these kinds	0.0	0.0	0.0	2.0	0.0000000000	False
nowadays biolarge their exploration	0.0	0.0	0.0	2.0	0.0000000000	False
terms of new features	0.0	0.0	0.0	2.0	0.0000000000	False
kind of new features	0.0	0.0	0.0	2.0	0.0000000000	False
current state of art	0.0	0.0	0.0	2.0	0.0000000000	False
large amount of work	0.0	0.0	0.0	2.0	0.0000000000	False
efficient trying to make	0.0	0.0	0.0	2.0	0.0000000000	False
data structures and controls	0.0	0.0	0.0	2.0	0.0000000000	False
controls and control structures	0.0	0.0	0.0	2.0	0.0000000000	False
control structures then languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages like ml caml	0.0	0.0	0.0	2.0	0.0000000000	False
addition of new features	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of ml expressions	0.0	0.0	0.0	2.0	0.0000000000	False
lisp in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
features like the introduction	0.0	0.0	0.0	2.0	0.0000000000	False
introduction of modules introduction	0.0	0.0	0.0	2.0	0.0000000000	False
introduction of exceptional handling	0.0	0.0	0.0	2.0	0.0000000000	False
exceptional handling the introduction	0.0	0.0	0.0	2.0	0.0000000000	False
powerful data abstraction mechanisms	0.0	0.0	0.0	2.0	0.0000000000	False
mechanisms and a type	0.0	0.0	0.0	2.0	0.0000000000	False
checking ok so lisp	0.0	0.0	0.0	2.0	0.0000000000	False
lisp has no type	0.0	0.0	0.0	2.0	0.0000000000	False
checking at all right	0.0	0.0	0.0	2.0	0.0000000000	False
study the basic features	0.0	0.0	0.0	2.0	0.0000000000	False
basic features of languages	0.0	0.0	0.0	2.0	0.0000000000	True
thing like language design	0.0	0.0	0.0	2.0	0.0000000000	False
issue that the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
implementation that the language	0.0	0.0	0.0	2.0	0.0000000000	False
language pascal has taught	0.0	0.0	0.0	2.0	0.0000000000	False
idea for a language	0.0	0.0	0.0	2.0	0.0000000000	False
unified primitives for expressing	0.0	0.0	0.0	2.0	0.0000000000	False
basically all your algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms and data structures	0.0	0.0	0.0	2.0	0.0000000000	False
algol sixty like languages	0.0	0.0	0.0	2.0	0.0000000000	False
variations of the dialect	0.0	0.0	0.0	2.0	0.0000000000	False
pascal or algol system	0.0	0.0	0.0	2.0	0.0000000000	False
set of primitive operations	0.0	0.0	0.0	2.0	0.0000000000	False
read the source code	0.0	0.0	5.9978021978	6.0	0.0000000000	False
code of the program	0.0	0.0	0.0	2.0	0.0000000000	False
program like a book	0.0	0.0	0.0	2.0	0.0000000000	False
software that you write	0.0	0.0	0.0	2.0	0.0000000000	False
permanently fixed what hsppens	0.0	0.0	0.0	2.0	0.0000000000	False
bugs might be detected	0.0	0.0	0.0	2.0	0.0000000000	False
detected years and years	0.0	0.0	0.0	2.0	0.0000000000	False
years after their software	0.0	0.0	0.0	2.0	0.0000000000	False
software is been commissioned	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms of the source	0.0	0.0	0.0	2.0	0.0000000000	False
contained so in fact	0.0	0.0	0.0	2.0	0.0000000000	False
efficiency and such consideration	0.0	0.0	0.0	2.0	0.0000000000	False
thing because it includes	0.0	0.0	0.0	2.0	0.0000000000	False
maintainability of the software	0.0	0.0	0.0	2.0	0.0000000000	False
persons who have written	0.0	0.0	0.0	2.0	0.0000000000	False
software so the software	0.0	0.0	0.0	2.0	0.0000000000	False
means that the source	0.0	0.0	0.0	2.0	0.0000000000	False
thing the second thing	0.0	0.0	0.0	2.0	0.0000000000	False
users use their piece	0.0	0.0	0.0	2.0	0.0000000000	False
adding some more conveniences	0.0	0.0	0.0	2.0	0.0000000000	False
part of the maintainability	0.0	0.0	0.0	2.0	0.0000000000	False
maintainability of a piece	0.0	0.0	0.0	2.0	0.0000000000	False
extensibility of the software	0.0	0.0	0.0	2.0	0.0000000000	False
original team that wrote	0.0	0.0	0.0	2.0	0.0000000000	False
abstraction the basic abstraction	0.0	0.0	0.0	2.0	0.0000000000	False
aware of the control	0.0	0.0	0.0	2.0	0.0000000000	False
control abstractions or things	0.0	0.0	0.0	2.0	0.0000000000	False
things like procedures functions	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of control abstractions	0.0	0.0	0.0	2.0	0.0000000000	False
primitive kind of data	0.0	0.0	0.0	2.0	0.0000000000	False
kind of data abstraction	0.0	0.0	0.0	2.0	0.0000000000	False
arrays are one data	0.0	0.0	0.0	2.0	0.0000000000	False
data abstraction that means	0.0	0.0	0.0	2.0	0.0000000000	False
logical unit um records	0.0	0.0	0.0	2.0	0.0000000000	False
unit um records variant	0.0	0.0	0.0	2.0	0.0000000000	False
ability to take sets	0.0	0.0	0.0	2.0	0.0000000000	False
single unit so combinations	0.0	0.0	0.0	2.0	0.0000000000	False
operations and data abstractions	0.0	0.0	0.0	2.0	0.0000000000	False
languages like ml ada	0.0	0.0	0.0	2.0	0.0000000000	False
ada provide the notion	0.0	0.0	0.0	2.0	0.0000000000	False
variables and change types	0.0	0.0	0.0	2.0	0.0000000000	False
change types and instantiate	0.0	0.0	0.0	2.0	0.0000000000	False
instantiate the same kinds	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms for example stacks	0.0	0.0	0.0	2.0	0.0000000000	False
talking of a stack	0.0	0.0	0.0	2.0	0.0000000000	False
stack of some record	0.0	0.0	0.0	2.0	0.0000000000	False
things the basic operation	0.0	0.0	0.0	2.0	0.0000000000	False
basic operation on stacks	0.0	0.0	0.0	2.0	0.0000000000	False
stacks are like pop	0.0	0.0	0.0	2.0	0.0000000000	False
push checking for emptiness	0.0	0.0	0.0	2.0	0.0000000000	False
repeat the code depending	0.0	0.0	0.0	2.0	0.0000000000	False
depending on the type	0.0	0.0	0.0	2.0	0.0000000000	False
type of the element	0.0	0.0	0.0	2.0	0.0000000000	False
element of the stack	0.0	0.0	0.0	2.0	0.0000000000	False
code carefully written verified	0.0	0.0	0.0	2.0	0.0000000000	False
right so the support	0.0	0.0	0.0	2.0	0.0000000000	False
important modern language design	0.0	0.0	0.0	2.0	0.0000000000	False
modern language design issue	0.0	0.0	0.0	2.0	0.0000000000	False
programs so the language	0.0	0.0	0.0	2.0	0.0000000000	False
language should also provide	0.0	0.0	0.0	2.0	0.0000000000	False
provide support for verification	0.0	0.0	0.0	2.0	0.0000000000	False
support for verification provability	0.0	0.0	0.0	2.0	0.0000000000	False
verification provability of programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs not necessarily machine	0.0	0.0	0.0	2.0	0.0000000000	False
necessarily machine based provability	0.0	0.0	0.0	2.0	0.0000000000	False
provability but possibly hand	0.0	0.0	0.0	2.0	0.0000000000	False
possibly hand based provability	0.0	0.0	0.0	2.0	0.0000000000	False
provability or a mixture	0.0	0.0	0.0	2.0	0.0000000000	False
mixture or a user	0.0	0.0	0.0	2.0	0.0000000000	False
interactive provability of programs	0.0	0.0	0.0	2.0	0.0000000000	False
sixties where a lot	0.0	0.0	0.0	2.0	0.0000000000	False
expended in the case	0.0	0.0	0.0	2.0	0.0000000000	False
fortan and cobol compilers	0.0	0.0	0.0	2.0	0.0000000000	False
cobol compilers was portability	0.0	0.0	0.0	2.0	0.0000000000	False
means what it means	0.0	0.0	0.0	2.0	0.0000000000	False
oriented towards an end	0.0	0.0	0.0	2.0	0.0000000000	False
architecture or machine independent	0.0	0.0	0.0	4.0	0.0000000000	False
machine independent or machine	0.0	0.0	0.0	2.0	0.0000000000	False
kind of assembly instruction	0.0	0.0	0.0	2.0	0.0000000000	False
related to the machine	0.0	0.0	0.0	2.0	0.0000000000	False
machines if you ensure	0.0	0.0	0.0	2.0	0.0000000000	False
ensure that you language	0.0	0.0	0.0	2.0	0.0000000000	False
language is really architecture	0.0	0.0	0.0	2.0	0.0000000000	False
independent in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that your main	0.0	0.0	0.0	2.0	0.0000000000	False
convenience the abstractions required	0.0	0.0	0.0	2.0	0.0000000000	False
required for the user	0.0	0.0	0.0	2.0	0.0000000000	False
specific to particular machine	0.0	0.0	0.0	2.0	0.0000000000	False
sets of particular architecture	0.0	0.0	0.0	2.0	0.0000000000	False
based architectures or stack	0.0	0.0	0.0	2.0	0.0000000000	False
architectures or stack based	0.0	0.0	0.0	2.0	0.0000000000	False
architecture specific or machine	0.0	0.0	0.0	2.0	0.0000000000	False
move the entire language	0.0	0.0	0.0	2.0	0.0000000000	False
language to another machine	0.0	0.0	0.0	2.0	0.0000000000	False
minimum amount of effort	0.0	0.0	0.0	2.0	0.0000000000	False
changed when i move	0.0	0.0	0.0	2.0	0.0000000000	False
move an entire language	0.0	0.0	0.0	2.0	0.0000000000	False
implementation from one machine	0.0	0.0	0.0	2.0	0.0000000000	False
idea of the language	0.0	0.0	0.0	2.0	0.0000000000	False
design or the design	0.0	0.0	0.0	2.0	0.0000000000	False
design of its implementation	0.0	0.0	0.0	2.0	0.0000000000	False
ease of the implementation	0.0	0.0	0.0	4.0	0.0000000000	False
availability of ready algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
ready algorithms for implementing	0.0	0.0	0.0	2.0	0.0000000000	False
reason for the success	0.0	0.0	0.0	2.0	0.0000000000	False
reason c c programs	0.0	0.0	0.0	2.0	0.0000000000	False
implementers trying to implement	0.0	0.0	0.0	2.0	0.0000000000	False
syntax common clear semantics	0.0	0.0	0.0	2.0	0.0000000000	False
semantics or the specification	0.0	0.0	0.0	2.0	0.0000000000	False
effects of each language	0.0	0.0	0.0	2.0	0.0000000000	False
language construct each construct	0.0	0.0	0.0	2.0	0.0000000000	False
construct in the language	0.0	0.0	0.0	2.0	0.0000000000	False
programs have to run	0.0	0.0	0.0	2.0	0.0000000000	False
efficiency of the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
means compile time efficiency	0.0	0.0	0.0	2.0	0.0000000000	False
fast can you compile	0.0	0.0	0.0	2.0	0.0000000000	False
written in the language	0.0	0.0	3.99633699634	10.0	0.3824362606	False
language whereas this runtime	0.0	0.0	0.0	2.0	0.0000000000	False
support and the program	0.0	0.0	0.0	2.0	0.0000000000	False
fast as the programs	0.0	0.0	0.0	2.0	0.0000000000	False
run fast yeah ease	0.0	0.0	0.0	2.0	0.0000000000	False
talking about the maintenance	0.0	0.0	0.0	2.0	0.0000000000	False
maintenance of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language by an implementation	0.0	0.0	0.0	2.0	0.0000000000	False
maintenance of the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
implementation of the language	0.0	0.0	0.0	4.0	0.0000000000	False
bugs in the language	0.0	0.0	0.0	2.0	0.0000000000	False
compilation translation and support	0.0	0.0	0.0	2.0	0.0000000000	False
language should support subsets	0.0	0.0	0.0	2.0	0.0000000000	False
subsets of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
smaller set of operations	0.0	0.0	0.0	2.0	0.0000000000	False
features of the language	0.0	0.0	0.0	2.0	0.0000000000	False
divide up the language	0.0	0.0	0.0	2.0	0.0000000000	False
large sort of extensions	0.0	0.0	0.0	2.0	0.0000000000	False
kernel any way run	0.0	0.0	0.0	2.0	0.0000000000	False
run on all machines	0.0	0.0	0.0	2.0	0.0000000000	False
subsets and their reasons	0.0	0.0	0.0	2.0	0.0000000000	False
portability of programs written	0.0	0.0	0.0	2.0	0.0000000000	False
important language for embedded	0.0	0.0	0.0	2.0	0.0000000000	False
language for embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
systems that control sensors	0.0	0.0	0.0	2.0	0.0000000000	False
control sensors various kinds	0.0	0.0	0.0	2.0	0.0000000000	False
affects it could affect	0.0	0.0	0.0	2.0	0.0000000000	False
program to another implementation	0.0	0.0	0.0	2.0	0.0000000000	False
feature like your programs	0.0	0.0	0.0	2.0	0.0000000000	False
right so the portability	0.0	0.0	0.0	2.0	0.0000000000	False
portability of actually programs	0.0	0.0	0.0	2.0	0.0000000000	False
divide up the study	0.0	0.0	0.0	2.0	0.0000000000	False
study of programming languages	0.0	0.0	0.0	2.0	0.0000000000	False
theory of programming languages	0.0	0.0	0.0	4.0	0.0000000000	False
general theory of programming	0.0	0.0	0.0	2.0	0.0000000000	False
programming languages is based	0.0	0.0	0.0	2.0	0.0000000000	False
based on three things	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of the language	0.0	0.0	0.0	2.0	0.0000000000	True
highly simplified natural language	0.0	0.0	0.0	2.0	0.0000000000	False
right so which means	0.0	0.0	0.0	2.0	0.0000000000	False
sentences of the language	0.0	0.0	2.99633699634	10.0	0.4251968504	False
written in that language	0.0	0.0	0.0	2.0	0.0000000000	False
languageit has various parts	0.0	0.0	0.0	2.0	0.0000000000	False
languages all natural languages	0.0	0.0	0.0	2.0	0.0000000000	False
natural languages one thing	0.0	0.0	0.0	2.0	0.0000000000	False
syntactic category called predicates	0.0	0.0	0.0	2.0	0.0000000000	False
clause or a phrase	0.0	0.0	0.0	2.0	0.0000000000	False
subject too in addition	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in natural language	0.0	0.0	0.0	2.0	0.0000000000	False
predicate no complete sentence	0.0	0.0	0.0	2.0	0.0000000000	False
predicate ok so run	0.0	0.0	0.0	2.0	0.0000000000	False
subject well subject phrases	0.0	0.0	0.0	2.0	0.0000000000	False
phrases may be noun	0.0	0.0	0.0	2.0	0.0000000000	False
noun phrases which means	0.0	0.0	0.0	2.0	0.0000000000	False
nouns qualified by object	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of this programming	0.0	0.0	0.0	2.0	0.0000000000	False
programming language and parse	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of these things	0.0	0.0	0.0	2.0	0.0000000000	False
similarities with natural language	0.0	0.0	0.0	2.0	0.0000000000	False
lot of the theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory of the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
syntax was actually inspired	0.0	0.0	0.0	2.0	0.0000000000	False
inspired by natural languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages where the construction	0.0	0.0	0.0	2.0	0.0000000000	False
construction of artificial languages	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of a programming	0.0	0.0	0.0	2.0	0.0000000000	False
study of pascal programming	0.0	0.0	0.0	2.0	0.0000000000	False
iso standard pascal reference	0.0	0.0	0.0	2.0	0.0000000000	False
reference manual by janson	0.0	0.0	0.0	2.0	0.0000000000	False
manual by janson edward	0.0	0.0	0.0	2.0	0.0000000000	False
reference manual really specifies	0.0	0.0	0.0	2.0	0.0000000000	False
effect to be expected	0.0	0.0	0.0	2.0	0.0000000000	False
executing that syntactic entity	0.0	0.0	0.0	2.0	0.0000000000	False
natural language the notion	0.0	0.0	0.0	2.0	0.0000000000	False
mathematically in a machine	0.0	0.0	0.0	2.0	0.0000000000	False
talking about this semantics	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of this programming	0.0	0.0	0.0	2.0	0.0000000000	False
language we are talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking about a pure	0.0	0.0	0.0	2.0	0.0000000000	False
general we are talking	0.0	0.0	0.0	2.0	0.0000000000	False
meanings in a abstract	0.0	0.0	0.0	2.0	0.0000000000	False
settings in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that you assume	0.0	0.0	0.0	2.0	0.0000000000	False
restrictions on the word	0.0	0.0	0.0	2.0	0.0000000000	False
restrictions on computational power	0.0	0.0	0.0	2.0	0.0000000000	False
finite number of operations	0.0	0.0	5.9978021978	6.0	0.0000000000	False
operations at any instance	0.0	0.0	0.0	2.0	0.0000000000	False
right so you assume	0.0	0.0	0.0	2.0	0.0000000000	False
semantic the programming language	0.0	0.0	0.0	2.0	0.0000000000	False
thinking of some kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of an ideal	0.0	0.0	0.0	2.0	0.0000000000	False
restrictions except one restriction	0.0	0.0	0.0	2.0	0.0000000000	False
operations can be performed	0.0	0.0	0.0	2.0	0.0000000000	False
infinite number of operations	0.0	0.0	0.0	2.0	0.0000000000	False
entity in some ideal	0.0	0.0	0.0	2.0	0.0000000000	False
constructs of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language in that ideal	0.0	0.0	0.0	2.0	0.0000000000	False
independent of any machine	0.0	0.0	0.0	2.0	0.0000000000	False
language as an entity	0.0	0.0	0.0	2.0	0.0000000000	False
devoid of any machine	0.0	0.0	0.0	2.0	0.0000000000	False
general the semantics follow	0.0	0.0	0.0	2.0	0.0000000000	False
semantics follow the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
semantics so the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
elements and some compound	0.0	0.0	0.0	2.0	0.0000000000	False
operations they are connectives	0.0	0.0	0.0	2.0	0.0000000000	False
meanings of the connectives	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of programs	0.0	0.0	0.0	2.0	0.0000000000	False
discipline that you express	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the effect	0.0	0.0	0.0	2.0	0.0000000000	False
elements of the language	0.0	0.0	0.0	4.0	0.0000000000	False
general possible to predict	0.0	0.0	0.0	2.0	0.0000000000	False
behavior of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language of a program	0.0	0.0	0.0	2.0	0.0000000000	False
language unless you follow	0.0	0.0	0.0	2.0	0.0000000000	False
feature of any kind	0.0	0.0	0.0	2.0	0.0000000000	False
derivation of the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
infinite number of programs	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of the program	0.0	0.0	0.0	4.0	0.0000000000	False
complex elements are formed	0.0	0.0	0.0	2.0	0.0000000000	False
formed so the meaning	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
elements and the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
formed a complex element	0.0	0.0	0.0	2.0	0.0000000000	False
means is that semantics	0.0	0.0	0.0	2.0	0.0000000000	False
related to the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
set of allowable objects	0.0	0.0	0.0	4.0	0.0000000000	False
objects are the programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language or the sentences	0.0	0.0	0.0	2.0	0.0000000000	False
language and the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
syntax gives you finitary	0.0	0.0	0.0	2.0	0.0000000000	False
notation right the set	0.0	0.0	0.0	2.0	0.0000000000	False
right the set builder	0.0	0.0	0.0	2.0	0.0000000000	False
give a finitary specification	0.0	0.0	0.0	2.0	0.0000000000	False
program is its structure	0.0	0.0	0.0	2.0	0.0000000000	False
terms of its syntax	0.0	0.0	0.0	2.0	0.0000000000	False
syntax the finitary specification	0.0	0.0	0.0	2.0	0.0000000000	False
specification so the meaning	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of a language	0.0	0.0	0.0	2.0	0.0000000000	False
sort of an ideal	0.0	0.0	0.0	2.0	0.0000000000	False
worry about machine constraints	0.0	0.0	0.0	2.0	0.0000000000	False
worry about word lengths	0.0	0.0	0.0	2.0	0.0000000000	False
worry about limits don	0.0	0.0	0.0	2.0	0.0000000000	False
worry about memory constraints	0.0	0.0	0.0	2.0	0.0000000000	False
constraints assume infinite amount	0.0	0.0	0.0	2.0	0.0000000000	False
infinite amount of memory	0.0	0.0	0.0	2.0	0.0000000000	False
features are really pragmatics	0.0	0.0	0.0	2.0	0.0000000000	False
associate a disc file	0.0	0.0	0.0	2.0	0.0000000000	False
file variable in side	0.0	0.0	0.0	2.0	0.0000000000	False
feature which will vary	0.0	0.0	0.0	2.0	0.0000000000	False
depending upon the operating	0.0	0.0	0.0	2.0	0.0000000000	False
firstly um firstly involves	0.0	0.0	0.0	2.0	0.0000000000	False
machine and architectural constraints	0.0	0.0	0.0	2.0	0.0000000000	False
maxint the maximum integer	0.0	0.0	0.0	2.0	0.0000000000	False
typically implementation dependant feature	0.0	0.0	0.0	2.0	0.0000000000	False
depends upon word length	0.0	0.0	0.0	2.0	0.0000000000	False
word length or byte	0.0	0.0	0.0	2.0	0.0000000000	False
length or byte length	0.0	0.0	0.0	2.0	0.0000000000	False
length or um byte	0.0	0.0	0.0	2.0	0.0000000000	False
two bytes for representing	0.0	0.0	0.0	2.0	0.0000000000	False
right so the value	0.0	0.0	0.0	2.0	0.0000000000	False
value of the maxint	0.0	0.0	0.0	2.0	0.0000000000	False
machine or a register	0.0	0.0	0.0	2.0	0.0000000000	False
machine um those things	0.0	0.0	0.0	2.0	0.0000000000	False
implement um those things	0.0	0.0	0.0	2.0	0.0000000000	False
things are implementation dependent	0.0	0.0	0.0	2.0	0.0000000000	False
portable we will separate	0.0	0.0	0.0	2.0	0.0000000000	False
out the basic algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
basic algorithms of implementation	0.0	0.0	0.0	2.0	0.0000000000	False
nature of the implementation	0.0	0.0	0.0	2.0	0.0000000000	False
features the actual code	0.0	0.0	0.0	2.0	0.0000000000	False
nature of the input	0.0	0.0	0.0	2.0	0.0000000000	False
file based terminal based	0.0	0.0	0.0	2.0	0.0000000000	False
based terminal based sensor	0.0	0.0	0.0	2.0	0.0000000000	False
terminal based sensor based	0.0	0.0	0.0	2.0	0.0000000000	False
includes the file server	0.0	0.0	0.0	2.0	0.0000000000	False
server how the language	0.0	0.0	0.0	2.0	0.0000000000	False
language has to interact	0.0	0.0	0.0	4.0	0.0000000000	False
interact with the file	0.0	0.0	0.0	2.0	0.0000000000	False
general with the directory	0.0	0.0	0.0	2.0	0.0000000000	False
service of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
errors and by errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors i mean errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors written by errors	0.0	0.0	0.0	2.0	0.0000000000	False
written by errors introduced	0.0	0.0	0.0	2.0	0.0000000000	False
errors introduced by users	0.0	0.0	0.0	2.0	0.0000000000	False
users in their programs	0.0	0.0	0.0	2.0	0.0000000000	False
errors as a blanket	0.0	0.0	0.0	2.0	0.0000000000	False
nature of the error	0.0	0.0	0.0	2.0	0.0000000000	False
throw out the program	0.0	0.0	0.0	2.0	0.0000000000	False
out all the errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors in the program	0.0	0.0	0.0	2.0	0.0000000000	False
things that are errors	0.0	0.0	0.0	2.0	0.0000000000	False
amount of compilation effort	0.0	0.0	0.0	2.0	0.0000000000	False
decent error reporting mechanism	0.0	0.0	0.0	2.0	0.0000000000	False
reporting mechanism some error	0.0	0.0	0.0	2.0	0.0000000000	False
mechanism some error handling	0.0	0.0	0.0	2.0	0.0000000000	False
policy and different languages	0.0	0.0	0.0	2.0	0.0000000000	False
implementations take different attitudes	0.0	0.0	0.0	2.0	0.0000000000	False
study all three issues	0.0	0.0	0.0	2.0	0.0000000000	False
semantic and pragmatic issues	0.0	0.0	0.0	2.0	0.0000000000	False
issues will closely depend	0.0	0.0	0.0	2.0	0.0000000000	False
depend upon the syntax	0.0	0.0	0.0	4.0	0.0000000000	False
preferable that they depend	0.0	0.0	0.0	2.0	0.0000000000	False
possibly an abstract object	0.0	0.0	0.0	2.0	0.0000000000	False
century attitude towards numbers	0.0	0.0	0.0	2.0	0.0000000000	False
conception of the mind	0.0	0.0	0.0	2.0	0.0000000000	False
representation in the form	0.0	0.0	0.0	2.0	0.0000000000	False
representing the same number	0.0	0.0	0.0	2.0	0.0000000000	False
hexadecimal and i hope	0.0	0.0	0.0	2.0	0.0000000000	False
representations of the number	0.0	0.0	0.0	2.0	0.0000000000	False
differs from the theonagri	0.0	0.0	0.0	2.0	0.0000000000	False
representation in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that the characters	0.0	0.0	0.0	2.0	0.0000000000	False
positional representation of numbers	0.0	0.0	0.0	2.0	0.0000000000	False
unified by the fact	0.0	0.0	0.0	2.0	0.0000000000	False
representations yeah positional representations	0.0	0.0	0.0	2.0	0.0000000000	False
positional representations i hope	0.0	0.0	0.0	2.0	0.0000000000	False
numerals which is non	0.0	0.0	0.0	2.0	0.0000000000	False
alphabet you could represent	0.0	0.0	0.0	2.0	0.0000000000	False
difference about this representation	0.0	0.0	0.0	2.0	0.0000000000	False
change in character set	0.0	0.0	0.0	2.0	0.0000000000	False
character set what makes	0.0	0.0	0.0	2.0	0.0000000000	False
two ok what make	0.0	0.0	0.0	2.0	0.0000000000	False
makes these two classes	0.0	0.0	0.0	2.0	0.0000000000	False
numeral of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language used for representing	0.0	0.0	0.0	2.0	0.0000000000	False
identical the character sets	0.0	0.0	0.0	2.0	0.0000000000	False
sets but the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
compound forms from simpler	0.0	0.0	0.0	2.0	0.0000000000	False
forms from simpler forms	0.0	0.0	0.0	2.0	0.0000000000	False
roman and arabic case	0.0	0.0	0.0	2.0	0.0000000000	False
setting of the programming	0.0	0.0	0.0	2.0	0.0000000000	False
call a complete dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
complete dictionary of words	0.0	0.0	0.0	2.0	0.0000000000	False
words of the language	0.0	0.0	0.0	4.0	0.0000000000	False
language and a word	0.0	0.0	0.0	2.0	0.0000000000	False
word of a language	0.0	0.0	0.0	2.0	0.0000000000	False
formed from a character	0.0	0.0	0.0	2.0	0.0000000000	False
set from a fixed	0.0	0.0	0.0	2.0	0.0000000000	False
words as allowable words	0.0	0.0	0.0	2.0	0.0000000000	False
allowable words as part	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary of the language	0.0	0.0	0.0	4.0	0.0000000000	False
dictionary of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language is what constitutes	0.0	0.0	0.0	4.0	0.0000000000	False
natural languages like konkani	0.0	0.0	0.0	2.0	0.0000000000	False
written by different people	0.0	0.0	0.0	2.0	0.0000000000	False
people some people write	0.0	0.0	0.0	2.0	0.0000000000	False
people write in devanagri	0.0	0.0	0.0	2.0	0.0000000000	False
devanagri some people write	0.0	0.0	0.0	2.0	0.0000000000	False
script the arabic script	0.0	0.0	0.0	2.0	0.0000000000	False
collection of the words	0.0	0.0	0.0	2.0	0.0000000000	False
person who knows devanagri	0.0	0.0	0.0	2.0	0.0000000000	False
communicate with the person	0.0	0.0	0.0	2.0	0.0000000000	False
urdu script by speech	0.0	0.0	0.0	2.0	0.0000000000	False
speech because the words	0.0	0.0	0.0	2.0	0.0000000000	False
fixed collection of words	0.0	0.0	0.0	2.0	0.0000000000	False
words whose actual form	0.0	0.0	0.0	2.0	0.0000000000	False
actual form might depend	0.0	0.0	0.0	2.0	0.0000000000	False
depend on the character	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary there are ways	0.0	0.0	0.0	2.0	0.0000000000	False
ways of combining words	0.0	0.0	0.0	2.0	0.0000000000	False
language to form sentences	0.0	0.0	0.0	2.0	0.0000000000	False
finite set of formation	0.0	0.0	0.0	2.0	0.0000000000	False
set of formation rules	0.0	0.0	0.0	2.0	0.0000000000	False
rules are called productions	0.0	0.0	0.0	2.0	0.0000000000	False
generate all possible sentences	0.0	0.0	0.0	2.0	0.0000000000	False
sentences in the language	0.0	0.0	0.0	2.0	0.0000000000	False
character set really depends	0.0	0.0	0.0	2.0	0.0000000000	False
depends upon the kind	0.0	0.0	0.0	2.0	0.0000000000	False
codes you use nowadays	0.0	0.0	0.0	2.0	0.0000000000	False
pcs and seven bit	0.0	0.0	0.0	2.0	0.0000000000	False
main frame the character	0.0	0.0	0.0	2.0	0.0000000000	False
frame the character sets	0.0	0.0	0.0	2.0	0.0000000000	False
constitutes the a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
four tuple of objects	0.0	0.0	0.0	2.0	0.0000000000	False
set of non terminals	0.0	0.0	3.9978021978	6.0	0.0000000000	False
terminals and this set	0.0	0.0	0.0	2.0	0.0000000000	False
non terminals really specifies	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of grammatical categories	0.0	0.0	0.0	2.0	0.0000000000	False
categories of the language	0.0	0.0	0.0	2.0	0.0000000000	False
parts of speech noun	0.0	0.0	0.0	2.0	0.0000000000	False
speech noun phrase verb	0.0	0.0	0.0	2.0	0.0000000000	False
noun phrase verb phrase	0.0	0.0	0.0	2.0	0.0000000000	False
phrase verb phrase adjectival	0.0	0.0	0.0	2.0	0.0000000000	False
verb phrase adjectival phrase	0.0	0.0	0.0	2.0	0.0000000000	False
phrase adjectival phrase noun	0.0	0.0	0.0	2.0	0.0000000000	False
adjectival phrase noun clause	0.0	0.0	0.0	2.0	0.0000000000	False
phrase noun clause subject	0.0	0.0	0.0	2.0	0.0000000000	False
noun clause subject clauses	0.0	0.0	0.0	2.0	0.0000000000	False
clause subject clauses subject	0.0	0.0	0.0	2.0	0.0000000000	False
subject clauses subject phrases	0.0	0.0	0.0	2.0	0.0000000000	False
clauses subject phrases object	0.0	0.0	0.0	2.0	0.0000000000	False
subject phrases object clauses	0.0	0.0	0.0	2.0	0.0000000000	False
phrases object clauses predicates	0.0	0.0	0.0	2.0	0.0000000000	False
symbols or terminal words	0.0	0.0	0.0	2.0	0.0000000000	False
collection of formation rules	0.0	0.0	0.0	2.0	0.0000000000	False
represents a grammatical category	0.0	0.0	0.0	2.0	0.0000000000	False
grammar specifying boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
symbol s every grammar	0.0	0.0	0.0	2.0	0.0000000000	False
categories the grammatical categories	0.0	0.0	0.0	2.0	0.0000000000	False
stand for an add	0.0	0.0	0.0	2.0	0.0000000000	False
expression or a complement	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary of this language	0.0	0.0	0.0	2.0	0.0000000000	False
left and right parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
productions from the start	0.0	0.0	0.0	2.0	0.0000000000	False
belonging to this set	0.0	0.0	0.0	2.0	0.0000000000	False
set of boolean variables	0.0	0.0	0.0	2.0	0.0000000000	False
expression so the sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of this languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages are boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
fully parenthesized boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions an and clause	0.0	0.0	0.0	2.0	0.0000000000	False
two boolean expressions enclosed	0.0	0.0	0.0	4.0	0.0000000000	False
expressions enclosed in parenthesis	0.0	0.0	0.0	4.0	0.0000000000	False
separated by the word	0.0	0.0	0.0	2.0	0.0000000000	False
variables whenever you find	0.0	0.0	0.0	2.0	0.0000000000	False
sentence generation you start	0.0	0.0	0.0	2.0	0.0000000000	False
replacing i have circled	0.0	0.0	0.0	2.0	0.0000000000	False
replacing this s leaving	0.0	0.0	0.0	2.0	0.0000000000	False
leaving everything else intact	0.0	0.0	0.0	2.0	0.0000000000	False
chosen here to replace	0.0	0.0	0.0	2.0	0.0000000000	False
possibility is to replace	0.0	0.0	0.0	2.0	0.0000000000	False
chosen it to replace	0.0	0.0	0.0	2.0	0.0000000000	False
two and i proceed	0.0	0.0	0.0	2.0	0.0000000000	False
proceed in this fashion	0.0	0.0	0.0	2.0	0.0000000000	False
generated by this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
talk of a language	0.0	0.0	0.0	2.0	0.0000000000	False
language as being generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated from a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar as a set	0.0	0.0	0.0	2.0	0.0000000000	False
generated from the start	0.0	0.0	0.0	4.0	0.0000000000	False
symbol s important warnings	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and the set	0.0	0.0	0.0	2.0	0.0000000000	False
set of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
disjoint and a production	0.0	0.0	0.0	2.0	0.0000000000	False
terminal by a string	0.0	0.0	0.0	2.0	0.0000000000	False
string consisting of terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals or non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals yeah and sentence	0.0	0.0	0.0	2.0	0.0000000000	False
string of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t.delhi	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
technology i.i.t.delhi presents	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
presents a video	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
comp.sc & engg	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
high level programming	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
level programming languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds imperative functional	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
important and logic	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
imperative and functional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
respects so imperative	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
state based languages	0.00495804014246	1.0	3.9978021978	3.16992500144	0.0000000000	True
languages where state	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
value based languages	0.0	0.0	0.0	1.58496250072	0.0000000000	False
languages much closer	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
notion of variables	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
variables in functional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
variables in mathematics	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
quantities in physics	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
quantities like acceleration	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
based languages means	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
trimaxes though unlike	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
talking of continuous	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
talking of discrete	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
case of functional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
languages the notion	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
mathematics which means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
history of languages	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	True
high level languages	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
hundreds and hundreds	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
hundreds of programming	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
impossible to study	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
fifties and sixties	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sixties a large	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
represent the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
basic control structures	0.00826340023744	0.0	4.99633699634	6.33985000288	0.2928416486	True
structures the exploration	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
basic data structures	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
structures in order	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
order to obtain	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
obtain clean readable	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
clean readable programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
programs efficiently implement	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implement able programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
programs um efficient	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
efficient running programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things were fixed	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
seventies and eighties	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
exploration of programming	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
extension of pascal	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
pascal most important	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
ada it combines	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
combines the module	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
features of modula	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
modula and adds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
adds more features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features like concurrency	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
important feature exception	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
feature exception handling	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
exception handling generics	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
generics or polymorphism	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
module based language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sense the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
control structure remain	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
extend the language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
arrow mark denote	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
denote the decendency	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
decendency in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
terms of similarity	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
small talk eighty	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
talk eighty control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
eighty control structures	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
structures or syntax	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
simula the basic	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
basic extensional feature	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
feature of simula	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
notion of class	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
class or objects	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of features	0.00268840666323	0.0	0.0	3.16992500144	0.0000000000	False
language of sequential	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sixties were sequential	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
biolarge their exploration	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
features what kind	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
state of art	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
art large amount	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
amount of work	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
basic functional languages	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
early functional languages	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
structures and controls	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
controls and control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
structures then languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
caml actually signify	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
signify the addition	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features in fact	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fact the syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
lisp like language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
introduction of modules	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
introduction of exceptional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
handling the introduction	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
powerful data abstraction	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
data abstraction mechanisms	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
lisp is lisp	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
study the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
features of languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
thing like language	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
design a language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language what kinds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of issues	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
pascal has taught	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of unified	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
unified unified primitives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
primitives for expressing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms and data	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
thing about pascal	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
sixty like languages	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms are written	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
dialect of pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
pascal or algol	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language easily learnable	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
people are taught	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
set of primitive	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
absolutely clear syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
highly readable programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
readability that means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
means by readability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
readability it means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
read the source	0.00495804014246	0.0	5.9978021978	0.0	0.0000000000	False
piece of software	0.00465502408195	0.0	3.99706959707	6.33985000288	0.3506493506	False
fixed what hsppens	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
software have bugs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
years and years	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
years after means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
bug is detected	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
understand the algorithms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
source code contained	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
write the person	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
person or persons	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
written this software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
maintain the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
software in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
years the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
extend the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
adding new features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features by adding	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
reason so part	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
detection and correction	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
correction of bugs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
software as years	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
team that wrote	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
wrote the software	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language should provide	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support for abstraction	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
abstraction the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
basic abstraction mechanisms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
abstractions or things	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
things like procedures	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
functions in pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
loops loop statements	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kind of data	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
abstraction that pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
abstraction that means	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
sequence of elements	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
single logical unit	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
unit um records	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
records variant records	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
abstraction data abstraction	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sets of data	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
unit so combinations	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
combinations of operations	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
operations and data	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
provide the notion	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
variables and change	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
types and instantiate	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds of algorithms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stacks it doesn	0.0	0.0	0.0	1.58496250072	0.0000000000	False
stack of integers	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
integers a stack	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stack of characters	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
characters a stack	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stack of reals	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
reals a stack	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
complicated data element	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
record of things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things or stacks	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stacks of arrays	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
arrays of things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
operation on stacks	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
pop push checking	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
checking for emptiness	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
repeat the code	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
piece of code	0.00093641929429	0.0	0.0	1.58496250072	0.0000000000	False
code carefully written	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
carefully written verified	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
tested and instantiate	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
instantiate the types	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of stacks	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of operations	0.00103572661575	0.0	0.0	1.58496250072	0.0000000000	False
important modern language	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
modern language design	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language design issue	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
verify your programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support for verification	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
provability of programs	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
necessarily machine based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
machine based provability	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
possibly hand based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
hand based provability	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
user interactive provability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
effort was expended	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
case of fortan	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fortan and cobol	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
compilers was portability	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
portability ok nowadays	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portability what means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
architecture or machine	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
independent or machine	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language other machines	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine independence means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
basic instruction set	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
users um convenience	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
convenience the abstractions	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
machine instructions sets	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
register based architectures	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
architectures or stack	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
stack based architectures	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
design the language	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
specific or machine	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
move the entire	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
amount of effort	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
archi certain machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine specific details	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
move an entire	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
entire language implementation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
alter of portability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portability um ease	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implementation the availability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
availability of ready	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms for implementing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
implementing the language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
low level primitives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
run very fast	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
common clear syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
clear syntax common	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
syntax common clear	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
common clear semantics	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
construct each construct	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
notion of semantics	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
run time efficient	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
efficient by run	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implementation which means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
compile time efficiency	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
efficiency how fast	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
compile programs written	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
excellent runtime support	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
program should run	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
run as fast	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language should run	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fast yeah ease	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
ease of maintenance	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
maintenance of programs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
translation and support	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
support for extensibility	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language of pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
add new features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support for subsets	0.00661072018995	0.0	2.99706959707	6.33985000288	0.2983425414	False
programming languages books	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language should support	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of operations	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
operations or features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kernel and larger	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
larger large sort	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sort of extensions	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
language of ada	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
affects the portability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portability of programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language for embedded	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
real time things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things with systems	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
systems that control	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
sensors various kinds	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds of hardware	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
hardware ballistic missiles	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
affect their portability	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
move the program	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
support that feature	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language gets affected	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
study of programming	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
theory of programming	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
languages is based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
highly simplified natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
simplified natural language	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
grammar certain things	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things can occur	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
arbitrarily form sentences	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
languages all natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
languages one thing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
category called predicates	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
words a predicate	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sentence in natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
predicate no complete	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
subject well subject	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrases which means	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
qualified by object	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
object um adjectives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
grammatically correct sentence	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
firstly various clauses	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
clauses each clause	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
greatly simplified form	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
parts of speech	0.00495804014246	0.0	2.9978021978	3.16992500144	0.0000000000	False
specifies various parts	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language and parse	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
similarities with natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
inspired by natural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
construction of artificial	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
lot of problems	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
study of pascal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
iso standard pascal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
standard pascal reference	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
pascal reference manual	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
manual by janson	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
manual really specifies	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
expected by executing	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
executing that syntactic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
notion of meanings	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
unlike natural language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine independent fashion	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language is implemented	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
implemented in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
talking about meanings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
restrictions on memory	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
restrictions on computational	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
number of operations	0.00403260999485	0.0	5.9978021978	1.58496250072	0.0000000000	False
assume a sort	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
semantic the programming	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
entity quite independent	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
ideal environment form	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
actual reference manual	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
manual of pascal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
manual is independent	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
specific machine paragraphs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
implementation dependent features	0.00826340023744	0.0	3.99633699634	6.33985000288	0.2372583480	False
general the semantics	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
follow the syntax	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
syntax the syntax	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
compound forming operations	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
compound um connective	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
form um compound	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sentences from simpler	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
meanings in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
gave the meanings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
give the meanings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
connectives in terms	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
set of programs	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
express the effects	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
effects of connectives	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
predict the behavior	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
follow this discipline	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kind of semantics	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
number of programs	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
programs which means	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
derive the meaning	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
elements are formed	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
derivable in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
connectives which formed	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
formed a complex	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of allowable	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
set theory notation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
right the set	0.0	0.0	0.0	0.0	0.0000000000	False
set builder notation	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
give a finitary	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
structure in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
syntax the finitary	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
expressed in terms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
ideal environment don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about machine	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
machine constraints don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about architecture	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
portable ok don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about word	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
word lengths don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
worry about limits	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
worry about memory	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
memory constraints assume	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
constraints assume infinite	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
assume infinite amount	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
amount of memory	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
associate a disc	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
variable in side	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
side the program	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
operating system interface	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language all kinds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of machine	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
machine and architectural	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
maxint the maximum	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
maximum integer allowable	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
typically implementation dependant	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
depends upon word	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
length or byte	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
bytes for representing	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
representing a integers	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine to machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine the amount	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
program can vary	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
stack based machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
register based machine	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
things are implement	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
implementation in order	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
order to make	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
make the language	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
out the basic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
algorithms of implementation	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
architectural specific nature	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
machine dependant features	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
features the actual	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
input and output	0.00116375602049	0.0	0.0	1.58496250072	0.0000000000	False
file based terminal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
based terminal based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
terminal based sensor	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
based sensor based	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
interface also includes	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
includes the file	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
interact in general	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
written by errors	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
introduced by users	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
programs so errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
syntactic nature errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
recovering from errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
out the program	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
reduces the amount	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
amount of compilation	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
decent error reporting	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
error reporting mechanism	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
mechanism some error	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
error handling mechanism	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
thing but errors	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
attitudes different implementations	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
notion of syntax	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
separately the semantic	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
semantic and pragmatic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
possibly an abstract	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
numbers um numbers	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
twentieth century attitude	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
attitude towards numbers	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
form of numerals	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
ways of representing	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
hundred and twenty	0.00537681332647	0.0	5.99706959707	6.33985000288	0.2983425414	False
twenty six written	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
written in hexadecimal	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
roman representation differs	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
representation of numbers	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
base the character	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
representations yeah positional	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
representations i hope	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
hope everybody understands	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
units tens hundreds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
roman same number	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
thing fundamental difference	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
disregard the change	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
change in character	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set what makes	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
cases the grammar	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
identical the character	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
enlarge the grammar	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sense the form	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
form of representation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
represent compound forms	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
forms from simpler	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
roman and arabic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
call a complete	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
dictionary of words	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language is formed	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
fixed character set	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
identify certain strings	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
strings of characters	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
characters as words	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
words as allowable	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
words as part	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
constitutes that states	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
languages like konkani	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
konkani or sindi	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
collection of words	0.00330536009497	0.0	0.0	1.58496250072	0.0000000000	False
words ok sindi	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
people some people	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
write in devanagri	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
devanagri some people	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
script the arabic	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
devanagri can communicate	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
person who doesn	0.0	0.0	0.0	1.58496250072	0.0000000000	False
script by speech	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
communicate by letter	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
words whose actual	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
form might depend	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
ways of combining	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
language to form	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of formation	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
set really depends	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kind of codes	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
frame the character	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
kinds of differences	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
tuple of objects	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of non	0.0	0.0	3.9978021978	0.0	0.0000000000	False
terminals really specifies	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
specifies various kinds	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
kinds of grammatical	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
speech noun phrase	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
noun phrase verb	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrase verb phrase	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
verb phrase adjectival	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrase adjectival phrase	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
adjectival phrase noun	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrase noun clause	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
noun clause subject	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
clause subject clauses	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
subject clauses subject	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
clauses subject phrases	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
subject phrases object	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
phrases object clauses	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
object clauses predicates	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set n consists	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
basic grammatical categories	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
sets are finite	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
symbols or terminal	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
collection of formation	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
represents a grammatical	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
constitutes a sentence	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
grammar specifying boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
categories the grammatical	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
add boolean expression	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
symbol any boolean	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
set of boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
languages are boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
fully parenthesized boolean	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
parenthesized boolean expressions	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
two boolean expression	0.0	0.0	5.9978021978	1.58496250072	0.0000000000	False
form which consists	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
boolean expressions enclosed	0.00330536009497	0.0	0.0	0.0	0.0000000000	False
enclosed in parenthesis	0.00268840666323	0.0	0.0	0.0	0.0000000000	False
parenthesis and separated	0.00330536009497	0.0	0.0	3.16992500144	0.0000000000	False
simple sentence generation	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
generation you start	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
circled in orange	0.00134420333162	0.0	0.0	1.58496250072	0.0000000000	False
chosen to replace	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
language which consists	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
symbol s important	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
set of terminal	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
symbols are disjoint	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
replacement it replaces	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
replaces a non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
consisting of terminals	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
terminals or non	0.0	0.0	0.0	0.0	0.0000000000	False
string of terminal	0.00116375602049	0.0	0.0	0.0	0.0000000000	False
terminal symbols generated	0.00165268004749	0.0	0.0	1.58496250072	0.0000000000	False
v.srinivasa rajkumar	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
educational technology	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
technology i.i.t.delhi	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
i.i.t.delhi presents	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
programming languages	0.0110134698919	0.0	17.9846153846	20.0	0.3641618497	True
dr.s.arun kumar	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
kumar deptt	0.001380968821	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
delhi lecture	0.000524450947233	0.0	0.0	0.0	0.0000000000	False
last lecture	0.0	0.0	0.0	1.0	0.0000000000	False
high level	0.000780701257324	0.0	0.0	1.0	0.0000000000	False
level programming	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
imperative functional	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
main concern	0.00220357339665	0.0	0.0	2.0	0.0000000000	False
functional languages	0.00627294888088	0.0	9.99487179487	6.0	0.2319018405	True
imperative language	0.00232751204098	0.0	2.9978021978	2.0	0.0000000000	True
state based	0.00330536009497	0.0	3.9978021978	1.0	0.0000000000	False
based languages	0.00550893349162	0.0	5.99633699634	4.0	0.3316953317	False
state updation	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
main action	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
value based	0.0	0.0	0.0	0.0	0.0000000000	False
mathematical languages	0.000775837346992	0.0	0.0	1.0	0.0000000000	False
acceleration velocity	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
languages means	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
state change	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
unlike physics	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
level languages	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
large portion	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
basic features	0.00232751204098	0.0	2.9978021978	2.0	0.0000000000	False
basic control	0.00550893349162	0.0	4.99633699634	3.0	0.2928416486	False
control structures	0.00627294888088	0.0	7.99487179487	6.0	0.2673267327	False
basic data	0.00220357339665	0.0	0.0	0.0	0.0000000000	False
data structures	0.0010936051775	0.0	4.9978021978	2.0	0.0000000000	False
clean readable	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
readable programs	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
efficient running	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
running programs	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
important feature	0.00232751204098	0.0	2.9978021978	2.0	0.0000000000	False
module features	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
feature exception	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
exception handling	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
handling generics	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
module based	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
structure remain	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
arrow mark	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
mark denote	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
small talk	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
talk eighty	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
eighty control	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
basic extensional	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
extensional feature	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
early sixties	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
nowadays biolarge	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
current state	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
large amount	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
readable comprehend	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
basic functional	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
early functional	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
modules introduction	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
powerful data	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
data abstraction	0.00661072018995	0.0	4.9956043956	5.0	0.1956521739	False
abstraction mechanisms	0.00155167469398	0.0	0.0	1.0	0.0000000000	False
type checking	0.00179227110882	0.0	0.0	2.0	0.0000000000	False
language design	0.00358454221765	0.0	3.99706959707	3.0	0.4251968504	False
major issue	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
good idea	0.00124855905905	0.0	0.0	2.0	0.0000000000	False
simple clear	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
small set	0.001380968821	0.0	0.0	2.0	0.0000000000	False
unified unified	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
unified primitives	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
nicest thing	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
algol sixty	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
crude variations	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
algol system	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
nice thing	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
small language	0.00220357339665	0.0	0.0	2.0	0.0000000000	False
primitive operations	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
clear syntax	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
source code	0.00448067777206	0.0	9.99633699634	3.0	0.2372583480	False
good reason	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
detected years	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
code contained	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
fact efficiency	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
important thing	0.000899775991318	0.0	0.0	2.0	0.0000000000	False
includes maintainability	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
first thing	0.000298330178194	0.0	0.0	1.0	0.0000000000	False
users feel	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
original programmer	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
original team	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
basic abstraction	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
control abstractions	0.00179227110882	0.0	0.0	1.0	0.0000000000	False
procedures functions	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
loops loop	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
loop statements	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
primitive kind	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
record structures	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
early languages	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
single unit	0.00268840666323	0.0	2.9978021978	2.0	0.0000000000	False
single logical	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
logical unit	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
records variant	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
variant records	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
abstraction data	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
module basis	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
ada provide	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
change types	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
complicated data	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
data element	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
basic operation	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
pop push	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
push checking	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
code depending	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
basic element	0.0080652199897	0.0	5.99340659341	9.0	0.2432432432	False
important modern	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
modern language	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
design issue	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
provide support	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
verification provability	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
necessarily machine	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
machine based	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
based provability	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
user interactive	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
interactive provability	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
cobol compilers	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
end user	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
machine independent	0.00550893349162	0.0	4.99633699634	4.0	0.3316953317	False
assembly instruction	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
independence means	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
abstract form	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
basic instruction	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
instruction set	0.00155167469398	0.0	0.0	1.0	0.0000000000	False
abstractions required	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
machine instructions	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
based architectures	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
entire language	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
minimum amount	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
specific details	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
language implementation	0.00179227110882	0.0	0.0	1.0	0.0000000000	False
ready algorithms	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
important reason	0.00550893349162	0.0	7.99633699634	5.0	0.3316953317	False
low level	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
level primitives	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
programs run	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
clear definition	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
common clear	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
clear semantics	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
language construct	0.00179227110882	0.0	0.0	1.0	0.0000000000	False
wide applicability	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
compile programs	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
programs written	0.00627294888088	0.0	3.99487179487	6.0	0.3467889908	False
runtime efficient	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
excellent runtime	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
runtime support	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
implementation maintenance	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
compilation translation	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
basic support	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
basic language	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
newer languages	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
controversial feature	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
languages books	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
support subsets	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
smaller set	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
small kernel	0.00220357339665	0.0	0.0	2.0	0.0000000000	False
larger large	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
large sort	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
subset supported	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
controversial thing	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
important language	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
embedded systems	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
control sensors	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
ballistic missiles	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
programs don	0.0	0.0	0.0	1.0	0.0000000000	False
run right	0.0	0.0	0.0	1.0	0.0000000000	False
arbitrary subsets	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
small parts	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
general theory	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
basic thing	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
natural language	0.0068670748248	0.0	14.9912087912	11.0	0.2649420161	False
arbitrarily form	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
form sentences	0.00179227110882	0.0	0.0	1.0	0.0000000000	False
natural languageit	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
full sentence	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
syntactic category	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
complete sentence	0.0044071467933	0.0	2.99706959707	3.0	0.2571428571	False
object clause	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
subject clause	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
grammatical form	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
subject phrases	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
noun phrases	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
nouns qualified	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
correct sentence	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
grammatical properties	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
similar manner	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
simplified form	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
artificial languages	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
pascal programming	0.00155167469398	0.0	0.0	1.0	0.0000000000	False
important references	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
iso standard	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
pascal reference	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
janson edward	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
syntactic entity	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
unlike natural	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
independent fashion	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
pure meaning	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
abstract settings	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
practical purposes	0.000690484410498	0.0	0.0	1.0	0.0000000000	False
word lengths	0.00330536009497	0.0	1.9978021978	2.0	0.0000000000	False
computational power	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
finite number	0.00124855905905	0.0	5.99706959707	1.0	0.0000000000	False
mathematical entity	0.00220357339665	0.0	0.0	2.0	0.0000000000	False
ideal machine	0.00179227110882	0.0	0.0	2.0	0.0000000000	False
infinite number	0.001380968821	0.0	0.0	1.0	0.0000000000	False
ideal environment	0.00330536009497	0.0	3.9978021978	2.0	0.0000000000	False
environment form	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
actual reference	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
specific machine	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
machine paragraphs	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
implementation dependent	0.00448067777206	0.0	3.99633699634	3.0	0.2372583480	False
dependent features	0.00661072018995	0.0	4.9956043956	4.0	0.2647058824	False
entity devoid	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
semantics follow	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
compound forming	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
forming operations	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
finitary object	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
infinite set	0.00276193764199	0.0	2.99706959707	3.0	0.2983425414	False
basic discipline	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
finitary elements	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
complex elements	0.00330536009497	0.0	2.9978021978	2.0	0.0000000000	False
allowable objects	0.00220357339665	0.0	0.0	0.0	0.0000000000	False
finitary mechanism	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
allowable programs	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
set theory	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
theory notation	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
set builder	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
builder notation	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
finitary specification	0.00358454221765	0.0	3.99706959707	3.0	0.2061068702	False
infinitary set	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
arbitrary program	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
environment don	0.0	0.0	0.0	0.0	0.0000000000	False
machine constraints	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
constraints don	0.0	0.0	0.0	0.0	0.0000000000	False
lengths don	0.0	0.0	0.0	0.0	0.0000000000	False
limits don	0.0	0.0	0.0	0.0	0.0000000000	False
memory constraints	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
constraints assume	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
infinite amount	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
pragmatic considerations	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
disc file	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
file variable	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
operating system	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
system interface	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
simple implementation	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
architectural constraints	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
maximum integer	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
typically implementation	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
byte length	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
stack based	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
based machine	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
register based	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
basic algorithms	0.00179227110882	0.0	0.0	1.0	0.0000000000	False
architectural specific	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
specific nature	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
small compiler	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
machine dependant	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
actual code	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
based sensor	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
sensor based	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
file server	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
file saver	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
directory service	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
errors written	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
errors introduced	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
syntactic nature	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
nature errors	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
runtime nature	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
blanket policy	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
error reporting	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
error correction	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
first error	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
compilation effort	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
decent error	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
reporting mechanism	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
error handling	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
handling mechanism	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
dicey object	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
dicey policy	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
pragmatic feature	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
issues sort	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
pragmatic issues	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
constitutes syntax	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
physical representation	0.00220357339665	0.0	0.0	2.0	0.0000000000	False
abstract object	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
twentieth century	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
century attitude	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
numeral right	0.0	0.0	0.0	1.0	0.0000000000	False
positional representation	0.00550893349162	0.0	9.99633699634	4.0	0.1719745223	False
basic form	0.00155167469398	0.0	0.0	2.0	0.0000000000	False
roman representation	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
representation differs	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
theonagri representation	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
basic alphabet	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
character set	0.0143232270782	0.0	10.9904761905	12.0	0.2512526843	False
units tens	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
tens hundreds	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
units sixteen	0.0	0.0	0.0	1.0	0.0000000000	False
roman numerals	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
thing fundamental	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
fundamental difference	0.000896135554412	0.0	2.9978021978	2.0	0.0000000000	False
simpler forms	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
arabic case	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
general setting	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
complete dictionary	0.00220357339665	1.0	0.0	1.0	0.0000000000	False
fixed character	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
allowable words	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
people write	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
urdu script	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
arabic script	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
fixed collection	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
actual form	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
formation rules	0.00310334938797	0.0	4.99706959707	3.0	0.2983425414	True
combining words	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
finite set	0.000570186203079	0.0	2.99633699634	4.0	0.0000000000	False
ascii codes	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
bit ascii	0.0	0.0	0.0	2.0	0.0000000000	False
main frame	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
grammar grammar	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
non terminals	0.0	0.0	7.99633699634	4.0	0.3417721519	False
grammatical categories	0.00448067777206	0.0	8.99633699634	4.0	0.2928416486	False
speech noun	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
phrase verb	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
verb phrase	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
phrase adjectival	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
adjectival phrase	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
phrase noun	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
noun clause	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
clause subject	0.00220357339665	0.0	0.0	1.0	0.0000000000	False
phrases object	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
clauses predicates	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
basic grammatical	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
terminal symbols	0.00276193764199	0.0	7.99706959707	3.0	0.5094339623	False
terminal words	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
complete vocabulary	0.00110178669832	0.0	0.0	1.0	0.0000000000	False
start symbol	0.00414290646299	0.0	11.9956043956	6.0	0.2061068702	False
simple grammar	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
boolean expressions	0.00749135435432	0.0	23.9912087912	11.0	0.1241379310	False
add boolean	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
complement expression	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
language consists	0.000775837346992	0.0	0.0	1.0	0.0000000000	False
boolean variables	0.00448067777206	0.0	9.99633699634	4.0	0.2928416486	False
expressions enclosed	0.00179227110882	0.0	0.0	0.0	0.0000000000	False
replacement rules	0.000896135554412	0.0	0.0	1.0	0.0000000000	False
simple sentence	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
sentence generation	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
language generated	0.000775837346992	0.0	0.0	1.0	0.0000000000	False
important warnings	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
string consisting	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
symbols generated	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
transcriptor	0.000209314192807	0.0	0.0	0.0	0.0000000000	False
v.srinivasa	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
rajkumar	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
educational	0.000224943997829	0.0	0.0	0.0	0.0000000000	False
technology	0.000209314192807	0.0	0.0	0.0	0.0000000000	False
i.i.t.delhi	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
presents	0.0002129772417	0.0	0.0	0.0	0.0000000000	False
video	0.000224943997829	0.0	0.0	0.0	0.0000000000	False
programming	0.0043297846415	0.0	0.0	0.0	0.3222739227	False
languages	0.022475386134	0.0	0.0	0.0	0.2670967742	False
dr.s.arun	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
kumar	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
deptt	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
comp.sc	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
engg	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
i.i.t	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
delhi	0.000242416633292	0.0	0.0	0.0	0.0000000000	False
lecture	0.000154106024352	0.0	0.0	0.0	0.0000000000	False
syntax	0.00655493506003	0.0	0.0	0.0	0.3103448276	False
briefly	0.000391792933978	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.0000000000	False
concerned	0.000342293318886	0.0	0.0	0.0	0.0000000000	False
high	0.000184699484749	0.0	0.0	0.0	0.0000000000	False
level	0.000257266511248	0.0	0.0	0.0	0.0000000000	False
kinds	0.000289338217941	0.0	0.0	0.0	0.3907083016	False
imperative	0.00193959336748	0.0	0.0	0.0	0.2372583480	False
functional	0.000249948654323	0.0	0.0	0.0	0.2195121951	False
important	0.00105347847677	0.0	0.0	0.0	0.4381338742	False
logic	0.000298330178194	0.0	0.0	0.0	0.0000000000	False
main	0.000681574074614	0.0	0.0	0.0	0.4251968504	False
similar	0.000256843373919	0.0	0.0	0.0	0.3824362606	False
respects	0.000122118425873	0.0	0.0	0.0	0.0000000000	False
state	0.00111579931162	0.0	0.0	0.0	0.2894333844	False
based	0.00145784356374	0.0	0.0	0.0	0.3594361785	False
updation	0.000139591061336	0.0	0.0	0.0	0.0000000000	False
action	0.000285093101539	0.0	0.0	0.0	0.0000000000	False
value	0.0	0.0	0.0	0.0	0.0000000000	False
closer	0.000449887995659	0.0	0.0	0.0	0.0000000000	False
mathematical	0.00102236111192	0.0	0.0	0.0	0.3214285714	False
notion	0.000857555037495	0.0	0.0	0.0	0.3300733496	False
variables	0.00119162936439	0.0	0.0	0.0	0.2795031056	False
quantities	0.000261195289319	0.0	0.0	0.0	0.0000000000	False
physics	0.0010936051775	0.0	0.0	0.0	0.2432432432	False
change	0.000220592936275	0.0	0.0	0.0	0.4934725849	False
acceleration	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
velocity	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
means	0.000128206711269	0.0	0.0	0.0	0.3004769475	False
trimaxes	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
unlike	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
talking	6.67695868821e-05	0.0	0.0	0.0	0.3698630137	False
continuous	5.13686747838e-05	0.0	0.0	0.0	0.0000000000	False
discrete	0.000285093101539	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.4515050167	False
execution	0.000390350628662	0.0	0.0	0.0	0.0000000000	False
history	0.000484833266585	0.0	0.0	0.0	0.0000000000	False
work	5.55441454052e-05	0.0	0.0	0.0	0.0000000000	False
concentrated	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
hundreds	0.00117537880193	0.0	0.0	0.0	0.2903225806	False
firstly	0.00112471998915	0.0	0.0	0.0	0.4515050167	False
impossible	0.000570186203079	0.0	0.0	0.0	0.0000000000	False
study	0.00117537880193	0.0	0.0	0.0	0.4736842105	False
find	4.56849817802e-05	0.0	0.0	0.0	0.0000000000	False
large	0.000205474699135	0.0	0.0	0.0	0.4251968504	False
portion	0.000484833266585	0.0	0.0	0.0	0.0000000000	False
fifties	0.000182267529583	0.0	0.0	0.0	0.0000000000	False
sixties	0.00104657096403	0.0	0.0	0.0	0.5510204082	False
basic	0.000532991454102	0.0	0.0	0.0	0.3163709407	False
features	0.00304754149836	1.0	0.0	0.0	0.2234762980	False
represent	0.000472975626877	0.0	0.0	0.0	0.3849287169	False
control	0.00143657409125	0.0	0.0	0.0	0.3096976017	False
structures	0.000878383307058	0.0	0.0	0.0	0.3271202237	False
exploration	0.00155167469398	0.0	0.0	0.0	0.4251968504	False
data	0.000456228079574	0.0	0.0	0.0	0.2221391174	False
order	3.38166030164e-05	0.0	0.0	0.0	0.0000000000	False
obtain	0.000122118425873	0.0	0.0	0.0	0.0000000000	False
clean	0.000285093101539	0.0	0.0	0.0	0.0000000000	False
readable	0.00276193764199	0.0	0.0	0.0	0.3121387283	True
efficiently	0.00136917327555	0.0	0.0	0.0	0.2278481013	False
implement	0.0029775239385	0.0	0.0	0.0	0.2102803738	False
running	0.000386407663975	0.0	0.0	0.0	0.2812500000	False
things	0.0	0.0	0.0	0.0	0.4310148233	False
fixed	0.000522390578637	0.0	0.0	0.0	0.4251968504	False
seventies	0.000285093101539	0.0	0.0	0.0	0.0000000000	False
eighties	0.000727249899877	0.0	0.0	0.0	0.0000000000	False
terms	0.000154342831329	0.0	0.0	0.0	0.3385579937	False
modula	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
extension	0.00134966398698	0.0	0.0	0.0	0.4736842105	False
pascal	0.00499423623621	0.0	0.0	0.0	0.4153846154	False
module	0.00156069882382	0.0	0.0	0.0	0.4515050167	False
ada	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
combines	0.00029775239385	0.0	0.0	0.0	0.0000000000	False
adds	0.000317767830504	0.0	0.0	0.0	0.4251968504	False
concurrency	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
exception	0.000449887995659	0.0	0.0	0.0	0.4736842105	False
handling	0.000585525942993	0.0	0.0	0.0	0.0000000000	False
generics	0.00022544402011	0.0	0.0	0.0	0.5242718447	False
polymorphism	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
similarly	0.000231697585701	0.0	0.0	0.0	0.3316953317	False
clu	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
sense	0.000225404470652	0.0	0.0	0.0	0.5744680851	False
remain	0.00015939990166	0.0	0.0	0.0	0.0000000000	False
extend	0.000780701257324	0.0	0.0	0.0	0.3506493506	False
arrow	0.000182267529583	0.0	0.0	0.0	0.0000000000	False
mark	0.000195175314331	0.0	0.0	0.0	0.0000000000	False
denote	0.000130597644659	0.0	0.0	0.0	0.0000000000	False
decendency	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
simula	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
small	0.000211247002957	0.0	0.0	0.0	0.3103448276	False
extensional	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
class	8.29505599226e-05	0.0	0.0	0.0	0.0000000000	False
objects	0.0011910095754	0.0	0.0	0.0	0.3673469388	False
sequential	0.000690484410498	0.0	0.0	0.0	0.0000000000	False
early	0.000585525942993	0.0	0.0	0.0	0.0000000000	False
modular	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
distributed	0.000149165089097	0.0	0.0	0.0	0.0000000000	False
parallel	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
oriented	0.000570186203079	0.0	0.0	0.0	0.0000000000	False
clear	0.00051370326255	0.0	0.0	0.0	0.3467889908	False
noise	0.000798684410735	0.0	0.0	0.0	0.0000000000	False
nowadays	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
biolarge	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
listed	9.23497423744e-05	0.0	0.0	0.0	0.0000000000	False
current	0.00015939990166	0.0	0.0	0.0	0.0000000000	False
art	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
amount	0.0006389317251	0.0	0.0	0.0	0.4736842105	False
make	6.67695868821e-05	0.0	0.0	0.0	0.2432432432	False
comprehend	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
caml	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
signify	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
addition	0.000277049227123	0.0	0.0	0.0	0.0000000000	False
fact	0.000138860363513	0.0	0.0	0.0	0.5510204082	False
expressions	0.00265223016538	0.0	0.0	0.0	0.1168298793	False
lisp	0.00224033888603	0.0	0.0	0.0	0.1719745223	False
philosiscally	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
applicative	0.000146772360729	0.0	0.0	0.0	0.0000000000	False
introduction	0.00078667642085	0.0	0.0	0.0	0.0000000000	False
powerful	0.000171511007499	0.0	0.0	0.0	0.0000000000	False
abstraction	0.00286919822988	0.0	0.0	0.0	0.1304347826	False
mechanisms	0.000796999508299	0.0	0.0	0.0	0.4515050167	False
type	0.000556093703381	0.0	0.0	0.0	0.3155258765	False
checking	0.000257266511248	0.0	0.0	0.0	0.0000000000	False
right	0.0	0.0	0.0	0.0	0.4554216867	False
first	0.0	0.0	0.0	0.0	0.5400000000	False
constitutes	0.00172621102625	0.0	0.0	0.0	0.5510204082	False
issues	0.0010648862085	0.0	0.0	0.0	0.3096330275	False
design	0.00074542034595	0.0	0.0	0.0	0.3849287169	False
major	0.000195175314331	0.0	0.0	0.0	0.0000000000	False
taught	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
good	8.33162181078e-05	0.0	0.0	0.0	0.0000000000	False
idea	0.000110296468137	0.0	0.0	0.0	0.0000000000	False
simple	0.00011108829081	0.0	0.0	0.0	0.5400000000	False
set	0.000450888040219	0.0	0.0	0.0	0.2135071596	False
unified	0.00179227110882	0.0	0.0	0.0	0.4251968504	False
primitives	0.000899775991318	0.0	0.0	0.0	0.4251968504	False
algorithms	0.000370716137122	0.0	0.0	0.0	0.4537815126	False
nicest	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
algol	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
written	0.000954020344737	0.0	0.0	0.0	0.4686248331	False
crude	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
variations	0.000209314192807	0.0	0.0	0.0	0.0000000000	False
dialect	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
system	0.0004259544834	0.0	0.0	0.0	0.4251968504	False
nice	0.00010648862085	0.0	0.0	0.0	0.0000000000	False
easily	0.000279182122672	0.0	0.0	0.0	0.0000000000	False
learnable	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
people	0.000317767830504	0.0	0.0	0.0	0.2983425414	False
initially	7.94419576259e-05	0.0	0.0	0.0	0.0000000000	False
start	0.0	0.0	0.0	0.0	0.2647058824	False
operations	0.000565055422622	0.0	0.0	0.0	0.3997308210	False
build	0.000122118425873	0.0	0.0	0.0	0.0000000000	False
absolutely	0.000149165089097	0.0	0.0	0.0	0.0000000000	False
ambiguity	0.000242416633292	0.0	0.0	0.0	0.0000000000	False
highly	0.000570186203079	0.0	0.0	0.0	0.0000000000	False
read	0.000270271786787	0.0	0.0	0.0	0.4251968504	False
source	0.00104657096403	0.0	0.0	0.0	0.2372583480	False
code	0.000923497423744	0.0	0.0	0.0	0.3096330275	False
book	0.000228195545924	0.0	0.0	0.0	0.0000000000	False
reason	0.000463395171402	0.0	0.0	0.0	0.3534031414	False
piece	0.000461748711872	0.0	0.0	0.0	0.3824362606	False
software	0.00221511574249	0.0	0.0	0.0	0.1123200000	False
write	0.000117359446087	0.0	0.0	0.0	0.4515050167	False
permanently	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
hsppens	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
bugs	0.00224033888603	0.0	0.0	0.0	0.3316953317	False
detected	0.00078667642085	0.0	0.0	0.0	0.0000000000	False
years	0.000798684410735	0.0	0.0	0.0	0.2673267327	False
commissioned	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
modify	0.000130597644659	0.0	0.0	0.0	0.0000000000	False
understand	3.85857078321e-05	0.0	0.0	0.0	0.0000000000	False
contained	0.000224943997829	0.0	0.0	0.0	0.0000000000	False
consideration	0.000727249899877	0.0	0.0	0.0	0.0000000000	False
includes	0.0002129772417	0.0	0.0	0.0	0.0000000000	False
maintainability	0.00104890189447	0.0	0.0	0.0	0.2061068702	False
person	0.000796999508299	0.0	0.0	0.0	0.2928416486	False
users	0.00111672849069	0.0	0.0	0.0	0.3698630137	False
feel	0.000224943997829	0.0	0.0	0.0	0.0000000000	False
adding	0.000244236851745	0.0	0.0	0.0	0.0000000000	False
conveniences	0.000524450947233	0.0	0.0	0.0	0.0000000000	False
part	5.19319009083e-05	0.0	0.0	0.0	0.4324942792	False
correction	0.000369398969498	0.0	0.0	0.0	0.5400000000	False
felt	0.00116375602049	0.0	0.0	0.0	0.0000000000	False
original	0.000171511007499	0.0	0.0	0.0	0.0000000000	False
programmer	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
team	0.000242416633292	0.0	0.0	0.0	0.0000000000	False
wrote	0.000139591061336	0.0	0.0	0.0	0.0000000000	False
provide	0.000522390578637	0.0	0.0	0.0	0.3316953317	False
support	0.00181468379737	0.0	0.0	0.0	0.2105578884	False
aware	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
procedures	0.000122118425873	0.0	0.0	0.0	0.0000000000	False
loops	0.000364535059165	0.0	0.0	0.0	0.0000000000	False
statements	0.000114097772962	0.0	0.0	0.0	0.0000000000	False
record	0.00096966653317	0.0	0.0	0.0	0.2983425414	False
arrays	0.000447495267291	0.0	0.0	0.0	0.0000000000	False
sequence	8.57555037495e-05	0.0	0.0	0.0	0.0000000000	False
elements	0.00127107132201	0.0	0.0	0.0	0.1767594108	False
single	0.000293544721457	0.0	0.0	0.0	0.2061068702	False
unit	0.000956399409959	0.0	0.0	0.0	0.2432432432	False
variant	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
ability	0.000262225473617	0.0	0.0	0.0	0.0000000000	False
basis	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
require	0.000135135893394	0.0	0.0	0.0	0.0000000000	False
instantiate	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
stacks	0.00342111721847	0.0	0.0	0.0	0.2045454545	False
doesn	0.0	0.0	0.0	0.0	0.0000000000	False
matter	9.925079795e-05	0.0	0.0	0.0	0.0000000000	False
integers	0.00047819970498	0.0	0.0	0.0	0.0000000000	False
characters	0.0038240479631	0.0	0.0	0.0	0.2319353209	False
reals	0.000123938644326	0.0	0.0	0.0	0.0000000000	False
complicated	0.000114097772962	0.0	0.0	0.0	0.0000000000	False
pop	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
push	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
emptiness	0.00015939990166	0.0	0.0	0.0	0.0000000000	False
form	0.000539853452002	0.0	0.0	0.0	0.4388692580	False
repeat	0.000114097772962	0.0	0.0	0.0	0.0000000000	False
depending	0.000418608302639	0.0	0.0	0.0	0.2512526843	False
carefully	7.33861803644e-05	0.0	0.0	0.0	0.0000000000	False
verified	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
tested	0.000139591061336	0.0	0.0	0.0	0.0000000000	False
modern	0.000262225473617	0.0	0.0	0.0	0.0000000000	False
verification	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
provability	0.00220357339665	0.0	0.0	0.0	0.2061068702	False
necessarily	0.000139591061336	0.0	0.0	0.0	0.0000000000	False
machine	0.0031760255344	0.0	0.0	0.0	0.1390856407	False
possibly	0.000558364245343	0.0	0.0	0.0	0.5050359712	False
hand	5.65743297032e-05	0.0	0.0	0.0	0.0000000000	False
mixture	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
interactive	0.00078667642085	0.0	0.0	0.0	0.0000000000	False
lot	0.000154106024352	0.0	0.0	0.0	0.0000000000	False
effort	0.00093641929429	0.0	0.0	0.0	0.0000000000	False
expended	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
fortan	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
cobol	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
compilers	0.00145449979975	0.0	0.0	0.0	0.3600000000	False
portability	0.0044071467933	0.0	0.0	0.0	0.3698630137	False
end	1.52283272601e-05	0.0	0.0	0.0	0.0000000000	False
architecture	0.00313602411693	0.0	0.0	0.0	0.1496221662	False
independent	0.000854828981109	0.0	0.0	0.0	0.3467889908	False
specific	0.000497703359536	0.0	0.0	0.0	0.2368421053	False
simply	0.000170393518653	0.0	0.0	0.0	0.0000000000	False
assembly	0.000262225473617	0.0	0.0	0.0	0.0000000000	False
instruction	0.00103572661575	0.0	0.0	0.0	0.0000000000	False
related	0.0001985015959	0.0	0.0	0.0	0.0000000000	False
ensure	0.000242416633292	0.0	0.0	0.0	0.0000000000	False
register	0.000570186203079	0.0	0.0	0.0	0.0000000000	False
fashion	0.00047819970498	0.0	0.0	0.0	0.0000000000	False
move	0.000154106024352	0.0	0.0	0.0	0.0000000000	False
entire	8.29505599226e-05	0.0	0.0	0.0	0.0000000000	False
minimum	0.000364535059165	0.0	0.0	0.0	0.0000000000	False
archi	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
details	5.65743297032e-05	0.0	0.0	0.0	0.0000000000	False
made	7.94419576259e-05	0.0	0.0	0.0	0.0000000000	False
compromise	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
alter	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
ease	0.00116375602049	0.0	0.0	0.0	0.0000000000	False
availability	0.000387918673496	0.0	0.0	0.0	0.4090909091	False
ready	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
low	0.000170393518653	0.0	0.0	0.0	0.0000000000	False
success	0.000209314192807	0.0	0.0	0.0	0.0000000000	False
fast	0.00112471998915	0.0	0.0	0.0	0.2372583480	False
acceptable	0.000524450947233	0.0	0.0	0.0	0.0000000000	False
definition	6.19693221629e-05	0.0	0.0	0.0	0.0000000000	False
constructs	0.000854828981109	0.0	0.0	0.0	0.3467889908	False
widely	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
common	0.000261195289319	0.0	0.0	0.0	0.0000000000	False
semantics	0.00269932797395	0.0	0.0	0.0	0.3673469388	False
effects	0.0003970031918	0.0	0.0	0.0	0.4251968504	False
expect	0.000298330178194	0.0	0.0	0.0	0.0000000000	False
runtime	0.00134420333162	0.0	0.0	0.0	0.0000000000	False
excellent	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
maintenance	0.00220357339665	0.0	0.0	0.0	0.2061068702	False
translation	0.000182267529583	0.0	0.0	0.0	0.0000000000	False
newer	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
controversial	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
subsets	0.00169691643305	0.0	0.0	0.0	0.2047670639	False
smaller	9.23497423744e-05	0.0	0.0	0.0	0.0000000000	False
divide	0.00029775239385	0.0	0.0	0.0	0.0000000000	False
kernel	0.000524450947233	0.0	0.0	0.0	0.0000000000	False
larger	7.33861803644e-05	0.0	0.0	0.0	0.0000000000	False
sort	0.000165901119845	0.0	0.0	0.0	0.5400000000	False
affects	0.00096966653317	0.0	0.0	0.0	0.2061068702	False
desirable	0.000242416633292	0.0	0.0	0.0	0.0000000000	False
embedded	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
sensors	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
hardware	0.000224943997829	0.0	0.0	0.0	0.0000000000	False
ballistic	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
missiles	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
don	0.0	0.0	0.0	0.0	0.2174913694	False
arbitrary	0.000340787037307	0.0	0.0	0.0	0.0000000000	False
finally	8.57555037495e-05	0.0	0.0	0.0	0.0000000000	False
theory	0.000637599606639	0.0	0.0	0.0	0.4251968504	False
simplified	0.000340787037307	0.0	0.0	0.0	0.0000000000	False
natural	0.00145784356374	0.0	0.0	0.0	0.2319353209	False
grammar	0.00517863307874	0.0	0.0	0.0	0.2251443233	False
occur	0.000139591061336	0.0	0.0	0.0	0.0000000000	False
ways	0.000154106024352	0.0	0.0	0.0	0.5635673624	False
arbitrarily	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
sentences	0.00603118589318	0.0	0.0	0.0	0.2356453836	False
languageit	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
full	0.000130597644659	0.0	0.0	0.0	0.0000000000	False
predicate	0.00271543071447	1.0	0.0	0.0	0.2894333844	False
syntactic	0.00124855905905	0.0	0.0	0.0	0.4251968504	False
category	0.00171055860924	0.0	0.0	0.0	0.3214285714	False
words	0.000961763604954	0.0	0.0	0.0	0.1747240198	False
clause	0.00349126806146	0.0	0.0	0.0	0.2195121951	False
phrase	0.00349126806146	0.0	0.0	0.0	0.1914893617	False
subject	0.00146519934965	0.0	0.0	0.0	0.2047670639	False
complete	0.000194404508918	0.0	0.0	0.0	0.3600000000	False
optionally	0.000209314192807	0.0	0.0	0.0	0.0000000000	False
grammatical	0.00310334938797	0.0	0.0	0.0	0.2895442359	False
noun	0.00220357339665	0.0	0.0	0.0	0.3506493506	False
qualified	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
adjectives	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
article	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
properties	6.75679466968e-05	0.0	0.0	0.0	0.0000000000	False
manner	0.000122118425873	0.0	0.0	0.0	0.0000000000	False
greatly	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
speech	0.00179227110882	0.0	0.0	0.0	0.4251968504	False
specifies	0.000674831993488	0.0	0.0	0.0	0.4115853659	False
vocabulary	0.00358454221765	1.0	0.0	0.0	0.3698630137	False
parse	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
inspired	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
artificial	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
problems	7.4188429869e-06	0.0	0.0	0.0	0.0000000000	False
reference	0.000540543573574	0.0	0.0	0.0	0.2529274005	False
manual	0.00313647444044	0.0	0.0	0.0	0.2894333844	False
iso	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
standard	9.925079795e-05	0.0	0.0	0.0	0.0000000000	False
janson	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
edward	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
entity	0.00112471998915	0.0	0.0	0.0	0.2928416486	False
pure	0.000285093101539	0.0	0.0	0.0	0.0000000000	False
assume	0.000226297318813	0.0	0.0	0.0	0.5400000000	False
practical	0.00010648862085	0.0	0.0	0.0	0.0000000000	False
purposes	8.57555037495e-05	0.0	0.0	0.0	0.0000000000	False
restrictions	0.000975876571655	0.0	0.0	0.0	0.2928416486	False
lengths	0.000697955306679	0.0	0.0	0.0	0.3316953317	False
memory	0.00072907011833	0.0	0.0	0.0	0.2983425414	False
computational	1.92928539161e-05	0.0	0.0	0.0	0.0000000000	False
finite	0.000681574074614	0.0	0.0	0.0	0.4251968504	False
number	4.76196356141e-05	0.0	0.0	0.0	0.2512526843	False
instance	5.13686747838e-05	0.0	0.0	0.0	0.0000000000	False
thought	0.000170393518653	0.0	0.0	0.0	0.0000000000	False
thinking	0.000182267529583	0.0	0.0	0.0	0.4736842105	False
ideal	0.0014254655077	0.0	0.0	0.0	0.2372583480	False
instant	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
performed	6.75679466968e-05	0.0	0.0	0.0	0.0000000000	False
infinite	0.00111579931162	0.0	0.0	0.0	0.3467889908	False
environment	0.00078667642085	0.0	0.0	0.0	0.0000000000	False
actual	0.00031946586255	0.0	0.0	0.0	0.5111876076	False
paragraphs	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
capable	0.000242416633292	0.0	0.0	0.0	0.0000000000	False
devoid	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.3461538462	False
follow	0.000158883915252	0.0	0.0	0.0	0.0000000000	False
compound	0.001380968821	0.0	0.0	0.0	0.2983425414	False
connectives	0.000697955306679	0.0	0.0	0.0	0.2372583480	False
simpler	0.000364535059165	0.0	0.0	0.0	0.0000000000	False
gave	0.000209314192807	0.0	0.0	0.0	0.0000000000	False
give	7.32609778679e-06	0.0	0.0	0.0	0.0000000000	False
finitary	0.00310334938797	0.0	0.0	0.0	0.1753246753	False
discipline	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
predict	0.000170393518653	0.0	0.0	0.0	0.0000000000	False
behavior	0.000182267529583	0.0	0.0	0.0	0.0000000000	False
derivation	0.000522390578637	0.0	0.0	0.0	0.2983425414	False
complex	0.000391792933978	0.0	0.0	0.0	0.0000000000	False
intimately	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
allowable	0.00121208316646	0.0	0.0	0.0	0.3103448276	False
notation	0.000228195545924	0.0	0.0	0.0	0.0000000000	False
builder	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
infinitary	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
analyzable	0.000195175314331	0.0	0.0	0.0	0.0000000000	False
lastly	0.00062794257842	0.0	0.0	0.0	0.0000000000	False
worry	0.000600288526246	0.0	0.0	0.0	0.2174913694	False
constraints	0.000674831993488	0.0	0.0	0.0	0.0000000000	False
limits	0.000149165089097	0.0	0.0	0.0	0.0000000000	False
pragmatic	0.00224033888603	0.0	0.0	0.0	0.2928416486	False
associate	0.000139591061336	0.0	0.0	0.0	0.4251968504	False
disc	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
file	0.00104657096403	0.0	0.0	0.0	0.2928416486	False
side	6.75679466968e-05	0.0	0.0	0.0	0.0000000000	False
vary	0.000418628385613	0.0	0.0	0.0	0.0000000000	False
interface	0.00062794257842	0.0	0.0	0.0	0.0000000000	False
involves	0.000149165089097	0.0	0.0	0.0	0.0000000000	False
maxint	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
maximum	0.00010648862085	0.0	0.0	0.0	0.0000000000	False
typically	0.00010648862085	0.0	0.0	0.0	0.0000000000	False
byte	0.00116375602049	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.2931885489	False
separate	0.000369398969498	0.0	0.0	0.0	0.4251968504	False
out	0.0	0.0	0.0	0.0	0.4251968504	False
happening	3.67654893791e-05	0.0	0.0	0.0	0.0000000000	False
input	6.75679466968e-05	0.0	0.0	0.0	0.0000000000	False
output	9.23497423744e-05	0.0	0.0	0.0	0.0000000000	False
terminal	0.0025372790863	0.0	0.0	0.0	0.1956521739	False
signal	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
server	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
saver	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
directory	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
service	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
errors	0.00331798034363	0.0	0.0	0.0	0.1041052393	False
introduced	0.000139591061336	0.0	0.0	0.0	0.0000000000	False
blanket	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
policy	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
abort	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
reporting	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
recovering	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
throw	0.000182267529583	0.0	0.0	0.0	0.0000000000	False
point	3.66304889339e-06	0.0	0.0	0.0	0.0000000000	False
reduces	0.000149165089097	0.0	0.0	0.0	0.0000000000	False
decent	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
dicey	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
attitudes	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
stop	0.000122118425873	0.0	0.0	0.0	0.0000000000	False
closely	3.67654893791e-05	0.0	0.0	0.0	0.0000000000	False
preferable	0.000242416633292	0.0	0.0	0.0	0.0000000000	False
representation	0.00136917327555	0.0	0.0	0.0	0.1525423729	False
twentieth	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
century	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
conception	0.000149165089097	0.0	0.0	0.0	0.0000000000	False
mind	0.000114097772962	0.0	0.0	0.0	0.0000000000	False
numerals	0.000780701257324	0.0	0.0	0.0	0.4251968504	False
twenty	0.00072907011833	0.0	0.0	0.0	0.2983425414	False
positional	0.000308212048703	0.0	0.0	0.0	0.1475409836	False
hexadecimal	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
hope	0.000364535059165	0.0	0.0	0.0	0.0000000000	False
roman	0.00179227110882	0.0	0.0	0.0	0.3506493506	False
differs	2.22565289607e-05	0.0	0.0	0.0	0.1819169746	False
theonagri	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
alphabet	0.000524450947233	0.0	0.0	0.0	0.0000000000	False
incidental	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
tens	7.33861803644e-05	0.0	0.0	0.0	0.0000000000	False
sixteen	0.0	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
non	0.0	0.0	0.0	0.0	0.3913043478	False
fundamental	0.000674831993488	0.0	0.0	0.0	0.0000000000	False
disregard	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
identical	0.000170393518653	0.0	0.0	0.0	0.0000000000	False
enlarge	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
arabic	0.000896135554412	0.0	0.0	0.0	0.0000000000	False
call	3.66304889339e-06	0.0	0.0	0.0	0.4405594406	False
dictionary	0.000524450947233	0.0	0.0	0.0	0.0000000000	False
identify	0.000149165089097	0.0	0.0	0.0	0.0000000000	False
strings	0.000585525942993	0.0	0.0	0.0	0.0000000000	False
konkani	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
sindi	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
collection	0.000522390578637	0.0	0.0	0.0	0.2983425414	False
devanagri	0.00165268004749	0.0	0.0	0.0	0.0000000000	False
urdu	0.00110178669832	0.0	0.0	0.0	0.0000000000	False
script	0.00078667642085	0.0	0.0	0.0	0.0000000000	False
communicate	0.000390350628662	0.0	0.0	0.0	0.0000000000	False
letter	0.000262225473617	0.0	0.0	0.0	0.0000000000	False
formation	0.00096966653317	0.0	0.0	0.0	0.2983425414	False
rules	0.000610592129364	0.0	0.0	0.0	0.3316953317	False
productions	0.000652988223296	1.0	0.0	0.0	0.4251968504	False
quickly	0.000171511007499	0.0	0.0	0.0	0.0000000000	False
ascii	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
bit	6.44012773291e-05	0.0	0.0	0.0	0.0000000000	False
pcs	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
frame	0.000262225473617	0.0	0.0	0.0	0.0000000000	False
tuple	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
verb	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
adjectival	0.000550893349162	0.0	0.0	0.0	0.0000000000	False
consists	0.000745825445484	0.0	0.0	0.0	0.3913043478	False
symbols	0.00209314192807	0.0	0.0	0.0	0.2372583480	False
boolean	0.00484658272617	0.0	0.0	0.0	0.0969786605	False
chosen	0.000637599606639	0.0	0.0	0.0	0.2983425414	False
stand	0.000182267529583	0.0	0.0	0.0	0.0000000000	False
complement	0.000775837346992	0.0	0.0	0.0	0.0000000000	False
left	4.63395171402e-05	0.0	0.0	0.0	0.0000000000	False
parenthesis	0.00093641929429	0.0	0.0	0.0	0.0000000000	False
connectors	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
belonging	0.000195175314331	0.0	0.0	0.0	0.0000000000	False
fully	0.000285093101539	0.0	0.0	0.0	0.0000000000	False
parenthesized	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
enclosed	0.000624279529527	0.0	0.0	0.0	0.0000000000	False
replacement	0.00237304804271	0.0	0.0	0.0	0.0647482014	False
circled	0.000182267529583	0.0	0.0	0.0	0.0000000000	False
orange	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
leaving	0.000114097772962	0.0	0.0	0.0	0.0000000000	False
intact	0.000448067777206	0.0	0.0	0.0	0.0000000000	False
proceed	0.000345242205249	0.0	0.0	0.0	0.0000000000	False
warnings	0.000312139764763	0.0	0.0	0.0	0.0000000000	False
disjoint	0.000387918673496	0.0	0.0	0.0	0.0000000000	False
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t.delhi	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t.delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
i.i.t.delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
today we will continue	0.0	0.0	0.0	2.0	0.0000000000	False
grammar on last lecture	0.0	0.0	0.0	2.0	0.0000000000	False
symbols or grammatical categories	0.0	0.0	0.0	2.0	0.0000000000	False
set of terminal symbols	0.0	0.0	2.99261311173	16.0	0.3793103448	False
symbols which usually constitutes	0.0	0.0	0.0	2.0	0.0000000000	False
vocabulary of programming language	0.0	0.0	0.0	2.0	0.0000000000	False
finite collection of formation	0.0	0.0	0.0	2.0	0.0000000000	False
collection of formation rules	0.0	0.0	0.0	2.0	0.0000000000	False
formation rules or productions	0.0	0.0	0.0	2.0	0.0000000000	False
replacement and a start	0.0	0.0	0.0	2.0	0.0000000000	False
symbol which really signifies	0.0	0.0	0.0	2.0	0.0000000000	False
signifies the grammatical category	0.0	0.0	0.0	2.0	0.0000000000	False
category called a sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of the language	0.0	0.0	0.0	4.0	0.0000000000	False
language of a language	0.0	0.0	0.0	2.0	0.0000000000	False
generation of boolean expression	0.0	0.0	0.0	2.0	0.0000000000	False
set of non terminals	0.0	0.0	2.9972299169	6.0	0.0000000000	False
essentially the and expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions the v stands	0.0	0.0	0.0	2.0	0.0000000000	False
stands for or expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions the c stand	0.0	0.0	0.0	2.0	0.0000000000	False
stand for conditional exp	0.0	0.0	0.0	2.0	0.0000000000	False
conditional exp um complement	0.0	0.0	0.0	2.0	0.0000000000	False
exp um complement expressions	0.0	0.0	0.0	2.0	0.0000000000	False
symbol the terminal set	0.0	0.0	0.0	2.0	0.0000000000	False
open and close parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis and the connectives	0.0	0.0	0.0	2.0	0.0000000000	False
black for terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
categories are a level	0.0	0.0	0.0	2.0	0.0000000000	False
green um light green	0.0	0.0	0.0	2.0	0.0000000000	False
green for some things	0.0	0.0	0.0	2.0	0.0000000000	False
string of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
symbols can be generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated from this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
cases i have circled	0.0	0.0	0.0	2.0	0.0000000000	False
number of other sentences	0.0	0.0	0.0	4.0	0.0000000000	False
sentences you will generate	0.0	0.0	0.0	2.0	0.0000000000	False
generate a large number	0.0	0.0	0.0	2.0	0.0000000000	False
case of this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
generate an infinite set	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of sentences	0.0	0.0	0.0	2.0	0.0000000000	False
set a large part	0.0	0.0	0.0	2.0	0.0000000000	False
large part of computer	0.0	0.0	0.0	2.0	0.0000000000	False
part of computer science	0.0	0.0	0.0	2.0	0.0000000000	False
science mathematics and logic	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and the set	0.0	0.0	0.0	2.0	0.0000000000	False
symbols should be disjoint	0.0	0.0	0.0	2.0	0.0000000000	False
binary relation from non	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols to strings	0.0	0.0	0.0	2.0	0.0000000000	False
right so the replacement	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbol and replace	0.0	0.0	0.0	2.0	0.0000000000	False
replace that this set	0.0	0.0	0.0	2.0	0.0000000000	False
generated from this set	0.0	0.0	0.0	2.0	0.0000000000	False
general for any set	0.0	0.0	0.0	2.0	0.0000000000	False
set a a star	0.0	0.0	0.0	2.0	0.0000000000	False
star is the set	0.0	0.0	0.0	2.0	0.0000000000	False
strings of finite length	0.0	0.0	0.0	4.0	0.0000000000	False
letter epsilon to denote	0.0	0.0	0.0	2.0	0.0000000000	False
set of all non	0.0	0.0	5.9972299169	6.0	0.0000000000	False
non empty strings generated	0.0	0.0	0.0	2.0	0.0000000000	False
string of zero length	0.0	0.0	0.0	2.0	0.0000000000	False
equal to a star	0.0	0.0	0.0	2.0	0.0000000000	False
star with epsilon removed	0.0	0.0	0.0	2.0	0.0000000000	False
side of the arrow	0.0	0.0	0.0	2.0	0.0000000000	False
single non terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and non terminals	0.0	0.0	5.99630655586	8.0	0.4313725490	False
grammar right a context	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive grammar has production	0.0	0.0	0.0	2.0	0.0000000000	False
grammar has production rules	0.0	0.0	0.0	2.0	0.0000000000	False
symbols you are allowed	0.0	0.0	0.0	2.0	0.0000000000	False
string of non terminals	0.0	0.0	4.9972299169	6.0	0.0000000000	False
assume we are choosing	0.0	0.0	0.0	2.0	0.0000000000	False
choosing this arbitrary string	0.0	0.0	0.0	2.0	0.0000000000	False
appears in a context	0.0	0.0	1.99630655586	8.0	0.4313725490	False
context and the rest	0.0	0.0	0.0	2.0	0.0000000000	False
appears in this context	0.0	0.0	0.0	2.0	0.0000000000	False
calling this grammar context	0.0	0.0	0.0	2.0	0.0000000000	False
non terminals and terminals	0.0	0.0	4.9972299169	6.0	0.0000000000	False
context that s appears	0.0	0.0	0.0	2.0	0.0000000000	False
uniform rule the production	0.0	0.0	0.0	2.0	0.0000000000	False
rule the production rule	0.0	0.0	0.0	2.0	0.0000000000	False
rule says that uniform	0.0	0.0	0.0	2.0	0.0000000000	False
uniform in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
replacement ok as suppose	0.0	0.0	0.0	2.0	0.0000000000	False
terminal can be replaced	0.0	0.0	0.0	2.0	0.0000000000	False
replaced by a string	0.0	0.0	0.0	2.0	0.0000000000	False
general than a context	0.0	0.0	0.0	2.0	0.0000000000	False
context free grammar production	0.0	0.0	0.0	2.0	0.0000000000	False
consists of the empty	0.0	0.0	0.0	4.0	0.0000000000	False
worry about some simpler	0.0	0.0	0.0	2.0	0.0000000000	False
rules in its context	0.0	0.0	0.0	2.0	0.0000000000	False
languages the language generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated by any grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar is a set	0.0	0.0	0.0	2.0	0.0000000000	False
generated from the start	0.0	0.0	0.0	4.0	0.0000000000	False
located in some context	0.0	0.0	0.0	2.0	0.0000000000	False
general we would call	0.0	0.0	0.0	2.0	0.0000000000	False
call it a language	0.0	0.0	0.0	2.0	0.0000000000	False
language on the set	0.0	0.0	0.0	2.0	0.0000000000	False
symbols and a language	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of strings	0.0	0.0	0.0	2.0	0.0000000000	False
subset of t star	0.0	0.0	0.0	4.0	0.0000000000	False
star is a language	0.0	0.0	0.0	2.0	0.0000000000	False
define on any set	0.0	0.0	0.0	2.0	0.0000000000	False
empty set for strings	0.0	0.0	0.0	2.0	0.0000000000	False
single element the empty	0.0	0.0	0.0	2.0	0.0000000000	False
element the empty string	0.0	0.0	0.0	2.0	0.0000000000	False
lot of other languages	0.0	0.0	0.0	2.0	0.0000000000	False
star as two extreme	0.0	0.0	0.0	2.0	0.0000000000	False
extreme as one extreme	0.0	0.0	0.0	2.0	0.0000000000	False
language and the language	0.0	0.0	0.0	2.0	0.0000000000	False
language containing the empty	0.0	0.0	0.0	2.0	0.0000000000	False
set of possible programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs and the problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem is of defining	0.0	0.0	0.0	2.0	0.0000000000	False
defining exactly what grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammars called regular grammars	0.0	0.0	0.0	2.0	0.0000000000	False
regular grammar every production	0.0	0.0	0.0	2.0	0.0000000000	False
form where this capital	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbol this capital	0.0	0.0	0.0	2.0	0.0000000000	False
denotes a terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbol in fact	0.0	0.0	0.0	2.0	0.0000000000	False
form then we call	0.0	0.0	0.0	2.0	0.0000000000	False
call this a right	0.0	0.0	0.0	2.0	0.0000000000	False
right linear regular grammar	0.0	0.0	4.9944598338	12.0	0.3666666667	True
first thing to realize	0.0	0.0	0.0	2.0	0.0000000000	False
difference ok a context	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar allows productions	0.0	0.0	0.0	2.0	0.0000000000	False
linear regular grammar means	0.0	0.0	0.0	2.0	0.0000000000	False
appearing in this order	0.0	0.0	0.0	2.0	0.0000000000	False
order the terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
symbol in a context	0.0	0.0	0.0	2.0	0.0000000000	False
terminal to be generated	0.0	0.0	0.0	2.0	0.0000000000	False
strings of the language	0.0	0.0	0.0	2.0	0.0000000000	False
form the terminal set	0.0	0.0	0.0	2.0	0.0000000000	False
non terminal symbols appearing	0.0	0.0	0.0	2.0	0.0000000000	False
appearing on the right	0.0	0.0	0.0	4.0	0.0000000000	False
generate a full sentence	0.0	0.0	0.0	2.0	0.0000000000	False
language so a right	0.0	0.0	0.0	2.0	0.0000000000	False
similarly you might define	0.0	0.0	0.0	2.0	0.0000000000	False
define a left linear	0.0	0.0	0.0	4.0	0.0000000000	False
left linear regular grammar	0.0	0.0	3.9972299169	6.0	0.0000000000	True
defined for example designed	0.0	0.0	0.0	2.0	0.0000000000	False
designed some hard ware	0.0	0.0	0.0	2.0	0.0000000000	False
hard ware using finite	0.0	0.0	0.0	2.0	0.0000000000	False
ware using finite state	0.0	0.0	0.0	2.0	0.0000000000	False
state machines it turns	0.0	0.0	0.0	2.0	0.0000000000	False
linear grammars actually represents	0.0	0.0	0.0	2.0	0.0000000000	False
represents finite state machines	0.0	0.0	0.0	2.0	0.0000000000	False
machines you know machines	0.0	0.0	0.0	2.0	0.0000000000	False
output i am talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking of those kinds	0.0	0.0	0.0	2.0	0.0000000000	False
right so in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact you can represent	0.0	0.0	0.0	2.0	0.0000000000	False
diagram of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
state as a non	0.0	0.0	0.0	2.0	0.0000000000	False
input symbol the input	0.0	0.0	0.0	2.0	0.0000000000	False
input into that state	0.0	0.0	0.0	2.0	0.0000000000	False
state machine automatically defines	0.0	0.0	0.0	2.0	0.0000000000	False
automatically defines a right	0.0	0.0	0.0	2.0	0.0000000000	False
defines a right linear	0.0	0.0	0.0	2.0	0.0000000000	False
machines have a start	0.0	0.0	0.0	2.0	0.0000000000	False
start symbol the start	0.0	0.0	0.0	2.0	0.0000000000	False
symbol the start symbol	0.0	0.0	0.0	2.0	0.0000000000	False
symbol is the start	0.0	0.0	0.0	2.0	0.0000000000	False
suma let us summarize	0.0	0.0	0.0	2.0	0.0000000000	False
general properties of grammars	0.0	0.0	0.0	2.0	0.0000000000	True
firstly every regular grammar	0.0	0.0	0.0	2.0	0.0000000000	False
regular grammar whether right	0.0	0.0	0.0	2.0	0.0000000000	False
grammar whether right linear	0.0	0.0	0.0	2.0	0.0000000000	False
right linear or left	0.0	0.0	0.0	4.0	0.0000000000	False
left linear every regular	0.0	0.0	0.0	2.0	0.0000000000	False
linear every regular grammar	0.0	0.0	0.0	2.0	0.0000000000	False
context free every context	0.0	0.0	0.0	4.0	0.0000000000	False
productions of the context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar can be considered	0.0	0.0	0.0	2.0	0.0000000000	False
considered in the context	0.0	0.0	0.0	2.0	0.0000000000	False
context of empty strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings on both sides	0.0	0.0	0.0	2.0	0.0000000000	False
sides of the non	0.0	0.0	0.0	2.0	0.0000000000	False
symbol then an empty	0.0	0.0	0.0	2.0	0.0000000000	False
bracket then an empty	0.0	0.0	0.0	2.0	0.0000000000	False
production as being padded	0.0	0.0	0.0	2.0	0.0000000000	False
context which contains empty	0.0	0.0	0.0	2.0	0.0000000000	False
string and the empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty string implicitly appears	0.0	0.0	0.0	2.0	0.0000000000	False
ultimately in generating languages	0.0	0.0	0.0	2.0	0.0000000000	False
language supposing that language	0.0	0.0	0.0	2.0	0.0000000000	False
language can be generated	0.0	0.0	0.0	4.0	0.0000000000	False
generated by a right	0.0	0.0	3.99630655586	8.0	0.3548387097	False
grammar which will generate	0.0	0.0	0.0	2.0	0.0000000000	False
generated by a left	0.0	0.0	3.9972299169	6.0	0.0000000000	False
left linear grammar left	0.0	0.0	0.0	2.0	0.0000000000	False
general kind of production	0.0	0.0	0.0	2.0	0.0000000000	False
star for any set	0.0	0.0	0.0	2.0	0.0000000000	False
set of all strings	0.0	0.0	0.0	4.0	0.0000000000	False
terminal symbol ok obtained	0.0	0.0	0.0	2.0	0.0000000000	False
symbol ok obtained form	0.0	0.0	0.0	2.0	0.0000000000	False
string ok the set	0.0	0.0	0.0	2.0	0.0000000000	False
cross t the set	0.0	0.0	0.0	2.0	0.0000000000	False
right so t star	0.0	0.0	0.0	2.0	0.0000000000	False
set which is obtained	0.0	0.0	0.0	2.0	0.0000000000	False
obtained as the union	0.0	0.0	0.0	2.0	0.0000000000	False
union of cartesian products	0.0	0.0	0.0	2.0	0.0000000000	False
equal to zero right	0.0	0.0	0.0	2.0	0.0000000000	False
define a binary operation	0.0	0.0	0.0	2.0	0.0000000000	False
binary operation called catenation	0.0	0.0	0.0	2.0	0.0000000000	False
catenation ok the effect	0.0	0.0	0.0	2.0	0.0000000000	False
two strings and put	0.0	0.0	0.0	2.0	0.0000000000	False
simplicity let us assume	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the set	0.0	0.0	0.0	2.0	0.0000000000	False
call those two symbols	0.0	0.0	0.0	2.0	0.0000000000	False
string in t star	0.0	0.0	0.0	4.0	0.0000000000	False
string in the set	0.0	0.0	0.0	2.0	0.0000000000	False
dot for the moment	0.0	0.0	0.0	2.0	0.0000000000	False
produce the string ababbbab	0.0	0.0	0.0	2.0	0.0000000000	False
juxtapose the two strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings the two strings	0.0	0.0	0.0	2.0	0.0000000000	False
binary operation on strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings it just puts	0.0	0.0	0.0	2.0	0.0000000000	False
puts the two strings	0.0	0.0	0.0	2.0	0.0000000000	False
string is of length	0.0	0.0	0.0	4.0	0.0000000000	False
belongs to the set	0.0	0.0	2.9972299169	6.0	0.0000000000	False
length three this belongs	0.0	0.0	0.0	2.0	0.0000000000	False
cube and this string	0.0	0.0	0.0	2.0	0.0000000000	False
star and so catenation	0.0	0.0	0.0	2.0	0.0000000000	False
operation from t star	0.0	0.0	0.0	2.0	0.0000000000	False
star cross t star	0.0	0.0	0.0	2.0	0.0000000000	False
star to t star	0.0	0.0	0.0	2.0	0.0000000000	False
finite length and juxtapose	0.0	0.0	0.0	2.0	0.0000000000	False
juxtapose an empty string	0.0	0.0	0.0	2.0	0.0000000000	False
back the same string	0.0	0.0	0.0	2.0	0.0000000000	False
juxtapose some other string	0.0	0.0	0.0	2.0	0.0000000000	False
back the other string	0.0	0.0	0.0	2.0	0.0000000000	False
string so the empty	0.0	0.0	0.0	2.0	0.0000000000	False
string satisfies these conditions	0.0	0.0	0.0	2.0	0.0000000000	False
belonging to t star	0.0	0.0	0.0	2.0	0.0000000000	False
concatenated with the empty	0.0	0.0	0.0	2.0	0.0000000000	False
catenation is juxtaposition operation	0.0	0.0	0.0	2.0	0.0000000000	False
rid of the dot	0.0	0.0	0.0	2.0	0.0000000000	False
dot in between right	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon is in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact the identity element	0.0	0.0	0.0	2.0	0.0000000000	False
identity element for catenation	0.0	0.0	0.0	2.0	0.0000000000	False
addition right secondly catenation	0.0	0.0	0.0	2.0	0.0000000000	False
associative in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
catenation and under catenation	0.0	0.0	0.0	2.0	0.0000000000	False
monoid because this operation	0.0	0.0	0.0	2.0	0.0000000000	False
arbitrary context sensitive grammar	0.0	0.0	0.0	2.0	0.0000000000	False
production of a context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar what it specifies	0.0	0.0	0.0	2.0	0.0000000000	False
appears in some context	0.0	0.0	0.0	2.0	0.0000000000	False
string so which means	0.0	0.0	0.0	2.0	0.0000000000	False
means that the context	0.0	0.0	0.0	2.0	0.0000000000	False
rewriting i can replace	0.0	0.0	0.0	2.0	0.0000000000	False
drew what this production	0.0	0.0	0.0	2.0	0.0000000000	False
large in the generation	0.0	0.0	0.0	2.0	0.0000000000	False
arbitrary string and turns	0.0	0.0	0.0	2.0	0.0000000000	False
minimal a minimal shell	0.0	0.0	0.0	2.0	0.0000000000	False
case of our context	0.0	0.0	2.9972299169	6.0	0.0000000000	False
epsilon on both sides	0.0	0.0	0.0	2.0	0.0000000000	False
appears in an empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty context which means	0.0	0.0	0.0	2.0	0.0000000000	False
means that you don	0.0	0.0	0.0	2.0	0.0000000000	False
appears on either side	0.0	0.0	0.0	2.0	0.0000000000	False
specifies the smallest kernel	0.0	0.0	0.0	2.0	0.0000000000	False
string in the generation	0.0	0.0	0.0	2.0	0.0000000000	False
occurs in the string	0.0	0.0	0.0	2.0	0.0000000000	False
replacing by this rule	0.0	0.0	0.0	2.0	0.0000000000	False
sense that this padding	0.0	0.0	0.0	2.0	0.0000000000	False
inclusive meaning of context	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of context sensitiveness	0.0	0.0	0.0	2.0	0.0000000000	False
padding around that non	0.0	0.0	0.0	2.0	0.0000000000	False
symbol which will enable	0.0	0.0	0.0	2.0	0.0000000000	False
case of a context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar the minimal padding	0.0	0.0	0.0	2.0	0.0000000000	False
rules can be thought	0.0	0.0	0.0	2.0	0.0000000000	False
thought of as rules	0.0	0.0	0.0	2.0	0.0000000000	False
rules in the context	0.0	0.0	0.0	2.0	0.0000000000	False
sides of the padding	0.0	0.0	0.0	2.0	0.0000000000	False
padding the minimal padding	0.0	0.0	0.0	2.0	0.0000000000	False
padding that you require	0.0	0.0	0.0	2.0	0.0000000000	False
require is the empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty string which means	0.0	0.0	0.0	2.0	0.0000000000	False
care what the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the string	0.0	0.0	0.0	4.0	0.0000000000	False
out that the context	0.0	0.0	0.0	2.0	0.0000000000	False
context sensitivity into account	0.0	0.0	0.0	2.0	0.0000000000	False
deal with the programming	0.0	0.0	0.0	2.0	0.0000000000	False
language as a context	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar as generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated by a context	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar and deal	0.0	0.0	0.0	2.0	0.0000000000	False
deal with a context	0.0	0.0	0.0	2.0	0.0000000000	False
typical context sensitive feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature even in languages	0.0	0.0	0.0	2.0	0.0000000000	False
check on these context	0.0	0.0	0.0	2.0	0.0000000000	False
issues ok so undeclared	0.0	0.0	0.0	2.0	0.0000000000	False
efficient algorithms to recognize	0.0	0.0	0.0	4.0	0.0000000000	False
pause context sensitive languages	0.0	0.0	0.0	2.0	0.0000000000	False
context sensitive languages represented	0.0	0.0	0.0	2.0	0.0000000000	False
pause context free grammars	0.0	0.0	0.0	2.0	0.0000000000	False
linear algorithms available linear	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms available for phrasing	0.0	0.0	0.0	2.0	0.0000000000	False
phrasing context sensitive grammars	0.0	0.0	0.0	2.0	0.0000000000	False
part of the semantics	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive aspects many people	0.0	0.0	0.0	2.0	0.0000000000	False
synonymous with the semantics	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of the language	0.0	0.0	0.0	4.0	0.0000000000	False
context sensitive every language	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive every language generated	0.0	0.0	0.0	2.0	0.0000000000	False
regular one every language	0.0	0.0	0.0	2.0	0.0000000000	False
rules may be left	0.0	0.0	0.0	2.0	0.0000000000	False
left linear such grammars	0.0	0.0	0.0	2.0	0.0000000000	False
conversion is what helps	0.0	0.0	0.0	2.0	0.0000000000	False
helps us to design	0.0	0.0	0.0	2.0	0.0000000000	False
design machines for recognizing	0.0	0.0	0.0	2.0	0.0000000000	False
machines for recognizing languages	0.0	0.0	0.0	2.0	0.0000000000	False
languages of this grammars	0.0	0.0	0.0	2.0	0.0000000000	False
subject of the theory	0.0	0.0	0.0	2.0	0.0000000000	False
regular if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
exists a regular grammar	0.0	0.0	0.0	2.0	0.0000000000	False
regular grammar which generates	0.0	0.0	0.0	2.0	0.0000000000	False
free it there exists	0.0	0.0	0.0	2.0	0.0000000000	False
free grammar that generates	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
sensitive grammar that generates	0.0	0.0	0.0	2.0	0.0000000000	False
language you have generated	0.0	0.0	0.0	2.0	0.0000000000	False
free but the language	0.0	0.0	0.0	2.0	0.0000000000	False
generate you have written	0.0	0.0	0.0	2.0	0.0000000000	False
written context sensitive grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar for a language	0.0	0.0	0.0	2.0	0.0000000000	False
free in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
out with a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
purely which is context	0.0	0.0	0.0	2.0	0.0000000000	False
generated by the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
long before any grammar	0.0	0.0	0.0	2.0	0.0000000000	False
large number of numerals	0.0	0.0	0.0	2.0	0.0000000000	False
notion of the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar in natural language	0.0	0.0	0.0	2.0	0.0000000000	False
language and um sanskrit	0.0	0.0	0.0	2.0	0.0000000000	False
rigorous um art form	0.0	0.0	0.0	2.0	0.0000000000	False
neat we have evolved	0.0	0.0	0.0	2.0	0.0000000000	False
evolved such neat notation	0.0	0.0	0.0	2.0	0.0000000000	False
neat notation for numbers	0.0	0.0	0.0	2.0	0.0000000000	False
numerals the terminal set	0.0	0.0	0.0	2.0	0.0000000000	False
set is the set	0.0	0.0	0.0	2.0	0.0000000000	False
require just one non	0.0	0.0	0.0	2.0	0.0000000000	False
replaced on a digit	0.0	0.0	0.0	2.0	0.0000000000	False
replaced by a digit	0.0	0.0	0.0	2.0	0.0000000000	False
nice and simple grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar which is equivalent	0.0	0.0	0.0	2.0	0.0000000000	False
sense that the romans	0.0	0.0	0.0	2.0	0.0000000000	False
romans had a pattern	0.0	0.0	0.0	2.0	0.0000000000	False
pattern in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
fifty hundred five hundred	0.0	0.0	0.0	2.0	0.0000000000	False
hundred five hundred thousand	0.0	0.0	0.0	2.0	0.0000000000	False
thousand they had symbols	0.0	0.0	0.0	2.0	0.0000000000	False
symbols also for ten	0.0	0.0	0.0	2.0	0.0000000000	False
ten thousand fifty thousand	0.0	0.0	0.0	2.0	0.0000000000	False
fifty thousand um hundred	0.0	0.0	0.0	2.0	0.0000000000	False
thousand um hundred thousand	0.0	0.0	0.0	2.0	0.0000000000	False
thousand five hundred thousand	0.0	0.0	0.0	2.0	0.0000000000	False
require if you continue	0.0	0.0	0.0	2.0	0.0000000000	False
require an infinite set	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols ok supposing	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols which means	0.0	0.0	0.0	2.0	0.0000000000	False
grammar already is violated	0.0	0.0	0.0	2.0	0.0000000000	False
ten can not precede	0.0	0.0	0.0	2.0	0.0000000000	False
sense the roman numerals	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent after all remember	0.0	0.0	0.0	2.0	0.0000000000	False
aim is to represent	0.0	0.0	0.0	2.0	0.0000000000	False
set but the language	0.0	0.0	0.0	2.0	0.0000000000	False
right so the language	0.0	0.0	0.0	2.0	0.0000000000	False
previewed for the context	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent context free grammar	0.0	0.0	0.0	2.0	0.0000000000	False
introduce a new non	0.0	0.0	0.0	2.0	0.0000000000	False
rid of the non	0.0	0.0	0.0	2.0	0.0000000000	False
quickly see that grammar	0.0	0.0	0.0	2.0	0.0000000000	False
common occurrence of left	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of left parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent way of writing	0.0	0.0	0.0	2.0	0.0000000000	False
make a grammar smaller	0.0	0.0	0.0	2.0	0.0000000000	False
grammar smaller to reduce	0.0	0.0	0.0	2.0	0.0000000000	False
number of non terminals	0.0	0.0	5.9972299169	6.0	0.0000000000	False
important thing to reduce	0.0	0.0	0.0	2.0	0.0000000000	False
parsing of the language	0.0	0.0	0.0	2.0	0.0000000000	False
depends how many non	0.0	0.0	0.0	2.0	0.0000000000	False
idea so which means	0.0	0.0	0.0	2.0	0.0000000000	False
matter of decision making	0.0	0.0	0.0	2.0	0.0000000000	False
decision making to choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose the right kind	0.0	0.0	0.0	2.0	0.0000000000	False
right kind of grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar right correct kind	0.0	0.0	0.0	2.0	0.0000000000	False
correct kind of grammar	0.0	0.0	0.0	2.0	0.0000000000	False
facilitate an easy explanation	0.0	0.0	0.0	2.0	0.0000000000	False
explanation of the semantics	0.0	0.0	0.0	2.0	0.0000000000	False
fact the arabic numerals	0.0	0.0	0.0	2.0	0.0000000000	False
numerals um the left	0.0	0.0	0.0	2.0	0.0000000000	False
linear and the right	0.0	0.0	0.0	2.0	0.0000000000	False
difference they both equivalent	0.0	0.0	0.0	2.0	0.0000000000	False
terms of actual generation	0.0	0.0	0.0	2.0	0.0000000000	False
generation but the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact of the matter	0.0	0.0	0.0	2.0	0.0000000000	False
semantics for the left	0.0	0.0	0.0	2.0	0.0000000000	False
thatn the right linear	0.0	0.0	0.0	2.0	0.0000000000	False
semantics for the right	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms actually will choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose the right linear	0.0	0.0	0.0	2.0	0.0000000000	False
linear over the left	0.0	0.0	0.0	2.0	0.0000000000	False
constraint in those parsing	0.0	0.0	0.0	2.0	0.0000000000	False
calls in this case	0.0	0.0	0.0	2.0	0.0000000000	False
case will could lead	0.0	0.0	0.0	2.0	0.0000000000	False
case they would lead	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t.delhi	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
technology i.i.t.delhi presents	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
presents a video	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.0013006395523	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
comp.sc & engg	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
lecture so today	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
started on grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar on last	0.0	0.0	0.0	0.0	0.0000000000	False
set a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
four tuple consisting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
finite a set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set of non	0.0	0.0	2.9972299169	0.0	0.0000000000	False
non terminal symbols	0.0	0.0	11.9787626962	34.8691750159	0.4426946632	True
symbols or grammatical	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set of terminal	0.0135041351094	0.0	2.99261311173	0.0	0.3793103448	False
constitutes the vocabulary	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
vocabulary of programming	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
collection of formation	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
rules or productions	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
rules of replacement	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
signifies the grammatical	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
simple um grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generation of boolean	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammatical categories consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
stand for conditional	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
exp um complement	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbol the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
terminal set consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
consists of open	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
open and close	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
dealing with grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
black for terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
level of abstraction	0.00146141567327	0.0	0.0	1.58496250072	0.0000000000	False
green um light	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
things and dark	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string of terminal	0.00438424701981	0.0	4.9972299169	3.16992500144	0.0000000000	False
grammar by applying	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
applying the rules	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
circled in orange	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
orange the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choices for replacing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
choose different choices	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
generate a large	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
sentences in fact	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
absolutely no restriction	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generate an infinite	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
set of sentences	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set a large	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
part of computer	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
computer science mathematics	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
mathematics and logic	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
represent infintary object	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
warnings and cautions	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
relation from non	0.0	0.0	0.0	0.0	0.0000000000	False
symbols to strings	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
strings of non	0.0	0.0	4.9972299169	0.0	0.0000000000	False
terminal and terminal	0.00622618267517	0.0	4.9972299169	0.0	0.0000000000	False
terminal terminal symbols	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
choose any non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
symbol and replace	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
consisting of terminal	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
terminal and non	0.0	0.0	5.99630655586	0.0	0.4313725490	False
set n union	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
strings of finite	0.00415078845012	0.0	0.0	0.0	0.0000000000	False
greek letter epsilon	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
epsilon to denote	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
non empty strings	0.0	0.0	5.9972299169	3.16992500144	0.0000000000	False
empty strings generated	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
star with epsilon	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
kind of grammar	0.00830157690023	0.0	3.99630655586	4.75488750216	0.4313725490	False
context free grammar	0.0365353918317	1.0	16.9769159741	38.0391000173	0.3698722260	True
allowed to replace	0.00622618267517	0.0	5.9972299169	4.75488750216	0.0000000000	False
replace a single	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
single the rules	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
left hand side	0.0013006395523	0.0	0.0	1.58496250072	0.0000000000	False
single non terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
free as suppose	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context sensitive grammar	0.0269801249258	0.0	11.9879963066	19.0195500087	0.4022503516	True
right a context	0.0	0.0	0.0	0.0	0.0000000000	False
grammar has production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
replace the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
meaning of context	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
choosing this arbitrary	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
calling this grammar	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar context free	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
allowing this replacement	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rule the production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
contexts the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non terminal appears	0.0	0.0	0.0	1.58496250072	0.0000000000	False
kind of context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
define that context	0.0	0.0	0.0	1.58496250072	0.0000000000	False
general a context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
context a context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
free grammar production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context which consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
languages the language	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
start symbol located	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context and generate	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generate a string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string that string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
call a language	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
language on set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
possibly infinite set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set of strings	0.00622618267517	0.0	1.9972299169	3.16992500144	0.0000000000	False
set for strings	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
element the empty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
lots of subsets	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
languages the problem	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar can generate	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
generate that language	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
defined um grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammars called regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar every production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
capital a denotes	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
denotes a non	0.0	0.0	0.0	3.16992500144	0.0000000000	False
symbol this capital	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
capital b denotes	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
small a denotes	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
denotes a terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbol in fact	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
made it black	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
right linear regular	0.0	0.0	4.9944598338	0.0	0.3666666667	False
linear regular grammar	0.0186785480255	0.0	8.99168975069	9.50977500433	0.3178170144	False
thing to realize	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
grammar allows productions	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
regular grammar means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right hand side	0.0	0.0	0.0	3.16992500144	0.0000000000	False
terminal symbol appearing	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
order the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
linear or regular	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
form the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
generate a full	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
define a left	0.0	0.0	0.0	0.0	0.0000000000	False
left linear regular	0.00830157690023	0.0	3.99630655586	1.58496250072	0.4313725490	False
terminal generation rule	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
out for completion	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
completion all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
left linear grammar	0.00622618267517	1.0	1.9972299169	3.16992500144	0.0000000000	True
designed some hard	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
ware using finite	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
finite state machines	0.00830157690023	0.0	7.99630655586	4.75488750216	0.3548387097	False
machines it turns	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right linear grammars	0.0	0.0	3.99630655586	6.33985000288	0.5500000000	True
grammars actually represents	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
represents finite state	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
machines without output	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
kinds of machines	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
state transition diagram	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
symbol the input	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
machine automatically defines	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
defines a right	0.0	0.0	0.0	0.0	0.0000000000	False
symbol the start	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
properties of grammars	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
firstly every regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar whether right	0.0	0.0	0.0	0.0	0.0000000000	False
linear or left	0.00415078845012	0.0	0.0	0.0	0.0000000000	False
linear every regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
free every context	0.00415078845012	0.0	0.0	0.0	0.0000000000	False
context of empty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
top most string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
empty string symbol	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context free production	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string implicitly appears	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbols between terminal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
reason every context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
interest in grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
ultimately in generating	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
supposing that language	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
linear grammar left	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar left linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
kind of production	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set t star	0.00622618267517	0.0	3.9972299169	4.75488750216	0.0000000000	False
symbol ok obtained	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
star as consisting	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
strings of length	0.00622618267517	0.0	2.9972299169	4.75488750216	0.0000000000	False
union of cartesian	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
define a binary	0.0	0.0	0.0	0.0	0.0000000000	False
operation called catenation	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
effect of catenation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
strings and put	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
set t consists	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
bab the operation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
operation of catenation	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
produce the string	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
catenation just juxtapose	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
operation on strings	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
string this string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set t cube	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
set t raised	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
sets are subsets	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
cross t star	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
length and juxtapose	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
string and juxtapose	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
juxtapose an empty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
empty string satisfies	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
satisfies these conditions	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
star s concatenated	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
empty string equals	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
empty string concatenated	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
catenation is juxtaposition	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
fact the identity	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
element for catenation	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right secondly catenation	0.0	0.0	0.0	0.0	0.0000000000	False
catenation is associative	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
set the set	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
star under catenation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
operation is associative	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
associative so catenation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
arbitrary context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
replace this non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
small b appearing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
sense this production	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
production is context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
string and turns	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
minimal a minimal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context which means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
care what appears	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context really specifies	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
specifies the smallest	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
candidate for replacing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rule ok context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
enable a rule	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rule to applied	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar the minimal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
padding the minimal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
string which means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
means you don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
apply the production	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
sensitivity into account	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
simpler to deal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar as generated	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar and deal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context sensitive aspects	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
process of compilation	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
typical context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context sensitive feature	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
languages like pascal	0.00146141567327	0.0	0.0	1.58496250072	0.0000000000	False
grammar for pascal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
fail to check	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context sensitive issues	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
algorithms to recognize	0.00337603377736	0.0	0.0	0.0	0.0000000000	False
recognize or pause	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
pause context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
context sensitive languages	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
sensitive languages represented	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
represented as context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
recognize and pause	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
pause context free	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
algorithms available linear	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
linear time algorithms	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
phrasing context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
aspects many people	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
people in fact	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
fact consider context	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammar is context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
sensitive every language	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
fact go supposing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
necessarily right linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
linear such grammars	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
purely right linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
purely left linear	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
machines for recognizing	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
theory of computation	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
language is regular	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
exists a regular	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar which generates	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
similarly a language	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
language is context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
exists a context	0.00415078845012	0.0	0.0	3.16992500144	0.0000000000	False
grammar that generates	0.00415078845012	0.0	0.0	1.58496250072	0.0000000000	False
written context sensitive	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
remember one thing	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
thing to design	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
design a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
define a grammar	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of numerals	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
grammar in natural	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
neat um rigorous	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
rigorous um art	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
evolved such neat	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
notation for numbers	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
numerals the terminal	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
representation in decimal	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
nice and simple	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
romans never considered	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
considered a things	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
tens of thousands	0.00146141567327	0.0	0.0	1.58496250072	0.0000000000	False
thousands the romans	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
ten fifty hundred	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
hundred five hundred	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
ten thousand fifty	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
thousand fifty thousand	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
thousand um hundred	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
continue that pattern	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
require an infinite	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbols ok supposing	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
symbols which means	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
means your condition	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
violated but supposing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
numerals are written	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
sense the roman	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
language it generates	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
easy to construct	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
construct a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
grammars are equivalent	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
non terminal set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language they generate	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
context free language	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
equivalent context free	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
occurrence of left	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
writing this grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
produce this string	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
make a grammar	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
smaller to reduce	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
reduce the number	0.00292283134654	0.0	0.0	3.16992500144	0.0000000000	False
number of non	0.0	0.0	5.9972299169	0.0	0.0000000000	False
thing to reduce	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
language really depends	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
variety of grammars	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
matter of decision	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
making to choose	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
choose the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
grammar right correct	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
right correct kind	0.0	0.0	0.0	0.0	0.0000000000	False
criteria for choosing	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
choosing a grammar	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
firstly the grammar	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
impossible to parse	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
parse the language	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
non terminals low	0.0	0.0	0.0	1.58496250072	0.0000000000	False
facilitate an easy	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
language in fact	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
fact the arabic	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
equivalent in terms	0.00168801688868	0.0	0.0	1.58496250072	0.0000000000	False
terms of actual	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
thatn the right	0.0	0.0	0.0	0.0	0.0000000000	False
interest inherent constraint	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
finite recursion based	0.00207539422506	0.0	0.0	1.58496250072	0.0000000000	False
v.srinivasa rajkumar	0.000867093034868	0.0	0.0	0.0	0.0000000000	False
educational technology	0.000867093034868	0.0	0.0	0.0	0.0000000000	False
technology i.i.t.delhi	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
i.i.t.delhi presents	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
programming languages	0.00329296184361	0.0	1.99538319483	4.0	0.4602510460	False
dr.s.arun kumar	0.000867093034868	0.0	0.0	0.0	0.0000000000	False
kumar deptt	0.00173418606974	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi	0.000867093034868	0.0	0.0	0.0	0.0000000000	False
delhi lecture	0.000658592368722	0.0	0.0	0.0	0.0000000000	False
last lecture	0.0	0.0	0.0	1.0	0.0000000000	False
tuple consisting	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
terminal symbols	0.0346837213947	0.0	20.9630655586	38.0	0.3410852713	True
grammatical categories	0.00450137836981	0.0	3.99630655586	3.0	0.3013698630	False
finite set	0.000716025557927	0.0	2.99261311173	8.0	0.0000000000	False
finite collection	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
formation rules	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
start symbol	0.00606965124407	0.0	6.99353647276	6.0	0.3938618926	False
boolean expression	0.000783954602932	0.0	0.0	0.0	0.0000000000	False
syntactic categories	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
non terminals	0.0	0.0	24.9667590028	33.0	0.3785850860	False
categories consists	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
conditional exp	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
complement expressions	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
terminal set	0.00968517305027	0.0	3.99353647276	6.0	0.5082508251	False
set consists	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
close parenthesis	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
color black	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
light green	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
production rules	0.00562672296227	0.0	8.99538319483	4.0	0.3363914373	True
large number	0.00120102243341	0.0	1.9972299169	2.0	0.0000000000	False
infinite set	0.00606965124407	0.0	2.99353647276	6.0	0.3215031315	False
finitary representation	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
large part	0.000867093034868	0.0	0.0	0.0	0.0000000000	False
computer science	0.000608841477282	0.0	0.0	0.0	0.0000000000	False
science mathematics	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
infintary object	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
finite manner	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
production set	0.00276719230008	0.0	0.0	2.0	0.0000000000	False
binary relation	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
terminal terminal	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
replacement rule	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
string consisting	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
finite strings	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
finite length	0.00337603377736	0.0	3.9972299169	2.0	0.0000000000	False
length string	0.00276719230008	0.0	0.0	2.0	0.0000000000	False
empty string	0.0270082702189	0.0	19.9778393352	23.0	0.2225969646	False
greek letter	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
letter epsilon	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
non empty	0.0	0.0	5.9972299169	1.0	0.0000000000	False
strings generated	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
epsilon removed	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
free grammar	0.0243569278878	0.0	16.9769159741	22.0	0.3698722260	False
left hand	0.000783954602932	0.0	0.0	0.0	0.0000000000	False
hand side	0.00214807667378	0.0	3.9972299169	2.0	0.0000000000	False
arrow mark	0.000974277115513	0.0	0.0	1.0	0.0000000000	False
single non	0.0	0.0	0.0	0.0	0.0000000000	False
right side	0.0	0.0	0.0	1.0	0.0000000000	False
sensitive grammar	0.0179867499505	0.0	11.9879963066	10.0	0.4022503516	False
arbitrary string	0.00415078845012	0.0	3.9972299169	2.0	0.0000000000	False
grammar context	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
uniform rule	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
terminal appears	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
empty context	0.00276719230008	0.0	0.0	1.0	0.0000000000	False
grammar production	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
simpler grammars	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
language generated	0.00487138557756	0.0	5.99538319483	4.0	0.4602510460	False
symbol located	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
trivial languages	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
empty set	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
empty language	0.00276719230008	0.0	0.0	2.0	0.0000000000	False
language consisting	0.000974277115513	0.0	0.0	1.0	0.0000000000	False
single element	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
define languages	0.0	0.0	0.0	1.0	0.0000000000	False
similar fashion	0.000783954602932	0.0	0.0	1.0	0.0000000000	False
regular grammars	0.0207539422506	1.0	14.9861495845	13.0	0.2689486553	True
form supposing	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
right linear	0.0	0.0	12.9806094183	19.0	0.2764811490	False
linear regular	0.0138359615004	0.0	8.99076638966	6.0	0.3179190751	False
first thing	0.000374635568406	0.0	0.0	0.0	0.0000000000	False
grammar means	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
right hand	0.0	0.0	0.0	0.0	0.0000000000	False
symbol appearing	0.00415078845012	0.0	3.9972299169	2.0	0.0000000000	False
generate strings	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
language form	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
full sentence	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
left linear	0.0221375384006	0.0	9.98522622345	15.0	0.2485875706	False
terminal generation	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
generation rule	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
linear grammar	0.0110687692003	0.0	5.99261311173	6.0	0.3464566929	False
hard ware	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
finite state	0.00553438460016	0.0	7.99630655586	3.0	0.3548387097	False
state machines	0.00553438460016	0.0	7.99630655586	3.0	0.3548387097	False
state transition	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
transition diagram	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
input symbol	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
start state	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
powerful language	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
general properties	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
context free	0.0370225303895	1.0	29.9639889197	36.0	0.3157099698	False
context sensitive	0.034885682366	1.0	26.9713758079	30.0	0.2437223043	False
string symbol	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
open bracket	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
close bracket	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
free production	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
generating languages	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
language supposing	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
grammar left	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
general kind	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
strings obtained	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
obtained form	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
cartesian products	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
binary operation	0.00225068918491	0.0	0.0	1.0	0.0000000000	False
string ababbbab	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
star cross	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
string satisfies	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
string equals	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
juxtaposition operation	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
dot symbol	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
obvious property	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
identity element	0.00276719230008	0.0	0.0	1.0	0.0000000000	False
ebleion monoid	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
arbitrary context	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
conditional rewriting	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
production drew	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
string xbcy	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
generation process	0.00337603377736	0.0	1.9972299169	3.0	0.0000000000	False
large string	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
context specifies	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
minimal shell	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
smallest kernel	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
inclusive meaning	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
minimal padding	0.00415078845012	0.0	2.9972299169	2.0	0.0000000000	False
practical reasons	0.00225068918491	0.0	0.0	2.0	0.0000000000	False
sensitive aspects	0.00276719230008	0.0	0.0	1.0	0.0000000000	False
typical context	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
sensitive feature	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
sensitive issues	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
undeclared variables	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
context freeness	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
efficient algorithms	0.00173418606974	0.0	0.0	0.0	0.0000000000	False
sensitive languages	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
languages represented	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
linear algorithm	0.00194855423103	0.0	0.0	1.0	0.0000000000	False
phrasing context	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
design machines	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
recognizing languages	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
small examples	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
regular languages	0.00276719230008	0.0	0.0	2.0	0.0000000000	False
arabic numerals	0.00415078845012	0.0	2.9972299169	2.0	0.0000000000	False
existing language	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
natural language	0.000783954602932	0.0	0.0	0.0	0.0000000000	False
sanskrit grammar	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
art form	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
neat notation	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
simple grammar	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
roman numerals	0.00225068918491	0.0	0.0	1.0	0.0000000000	False
ten fifty	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
fifty hundred	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
hundred thousand	0.00415078845012	0.0	2.9972299169	2.0	0.0000000000	False
ten thousand	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
thousand fifty	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
fifty thousand	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
simple object	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
ultimate aim	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
represent languages	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
finitary fashion	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
free language	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
equivalent context	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
open parenthesis	0.00112534459245	0.0	0.0	1.0	0.0000000000	False
original grammar	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
equivalent grammar	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
common occurrence	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
left parenthesis	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
grammar smaller	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
important constraint	0.00225068918491	0.0	0.0	2.0	0.0000000000	False
important thing	0.000564958080987	0.0	0.0	0.0	0.0000000000	False
good idea	0.000783954602932	0.0	0.0	1.0	0.0000000000	False
decision making	0.00112534459245	0.0	0.0	0.0	0.0000000000	False
right kind	0.0	0.0	0.0	0.0	0.0000000000	False
correct kind	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
easy explanation	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
actual generation	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
parsing algorithms	0.00276719230008	0.0	0.0	2.0	0.0000000000	False
interest inherent	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
inherent constraint	0.00276719230008	0.0	0.0	1.0	0.0000000000	False
recursive calls	0.00194855423103	0.0	0.0	2.0	0.0000000000	False
infinite recursion	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
finite recursion	0.00138359615004	0.0	0.0	1.0	0.0000000000	False
recursion based	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
transcriptor	0.000262851522673	0.0	0.0	0.0	0.0000000000	False
v.srinivasa	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
rajkumar	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
educational	0.000282479040493	0.0	0.0	0.0	0.0000000000	False
technology	0.000262851522673	0.0	0.0	0.0	0.0000000000	False
i.i.t.delhi	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
presents	0.00013372574388	0.0	0.0	0.0	0.0000000000	False
video	0.000282479040493	0.0	0.0	0.0	0.0000000000	False
programming	0.000737252223303	0.0	0.0	0.0	0.3464566929	False
languages	0.0126107355508	1.0	0.0	0.0	0.1659681475	False
dr.s.arun	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
kumar	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
deptt	0.000867093034868	0.0	0.0	0.0	0.0000000000	False
comp.sc	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
engg	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
i.i.t	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
delhi	0.000304420738641	0.0	0.0	0.0	0.0000000000	False
lecture	0.000258029982651	0.0	0.0	0.0	0.2075471698	False
grammars	0.0468230238828	0.0	0.0	0.0	0.3196986006	True
today	2.42274829076e-05	0.0	0.0	0.0	0.0000000000	False
continue	0.000193522486988	0.0	0.0	0.0	0.0000000000	False
started	0.0	0.0	0.0	0.0	0.3178170144	False
last	0.0	0.0	0.0	0.0	0.0000000000	False
detail	7.10446267752e-05	0.0	0.0	0.0	0.0000000000	False
briefly	0.000164001252356	0.0	0.0	0.0	0.0000000000	False
summarize	0.000490192546165	0.0	0.0	0.0	0.0000000000	False
set	0.000750233433277	0.0	0.0	0.0	0.1946252712	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
tuple	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
consisting	0.00149854227362	0.0	0.0	0.0	0.4190476190	False
finite	0.002781686889	0.0	0.0	0.0	0.3788079470	False
non	0.0	0.0	0.0	0.0	0.3074166965	False
terminal	0.0166665465696	0.0	0.0	0.0	0.3038180341	False
symbols	0.0155082398377	0.0	0.0	0.0	0.3836831215	False
grammatical	0.00194855423103	0.0	0.0	0.0	0.3013698630	False
categories	0.00179006389482	0.0	0.0	0.0	0.2396514161	False
constitutes	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
vocabulary	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
collection	0.000164001252356	0.0	0.0	0.0	0.0000000000	False
formation	0.000304420738641	0.0	0.0	0.0	0.0000000000	False
rules	0.00337377175741	0.0	0.0	0.0	0.3793103448	False
productions	0.00475603631833	0.0	0.0	0.0	0.3728813559	False
replacement	0.00368119415681	0.0	0.0	0.0	0.3389581805	False
signifies	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
sentence	0.00230507329053	1.0	0.0	0.0	0.2944550669	False
simple	0.000139501894253	0.0	0.0	0.0	0.4313725490	False
generation	0.000651145998693	0.0	0.0	0.0	0.3598862020	False
boolean	0.000358012778964	0.0	0.0	0.0	0.0000000000	False
expression	0.000701179839392	0.0	0.0	0.0	0.2075471698	False
syntactic	0.000391977301466	0.0	0.0	0.0	0.0000000000	False
essentially	4.04367558193e-05	0.0	0.0	0.0	0.0000000000	False
stands	0.000457774000341	0.0	0.0	0.0	0.0000000000	False
conditional	0.000534902975522	0.0	0.0	0.0	0.5500000000	False
exp	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
complement	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
open	0.000735288819247	0.0	0.0	0.0	0.0000000000	False
close	9.23383621105e-05	0.0	0.0	0.0	0.0000000000	False
parenthesis	0.0011759319044	0.0	0.0	0.0	0.0000000000	False
connectives	0.000175294959848	0.0	0.0	0.0	0.0000000000	False
dealing	0.000641927743616	0.0	0.0	0.0	0.0000000000	False
color	0.000200170405568	0.0	0.0	0.0	0.0000000000	False
black	0.000608841477282	0.0	0.0	0.0	0.0000000000	False
level	0.000107689614526	0.0	0.0	0.0	0.0000000000	False
abstraction	0.000200170405568	0.0	0.0	0.0	0.0000000000	False
higher	0.000187317784203	0.0	0.0	0.0	0.0000000000	False
green	0.000735288819247	0.0	0.0	0.0	0.0000000000	False
light	0.000282479040493	0.0	0.0	0.0	0.0000000000	False
things	0.0	0.0	0.0	0.0	0.4032586558	False
dark	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
string	0.0210782794851	0.0	0.0	0.0	0.1463037427	False
applying	0.000339400542983	0.0	0.0	0.0	0.4313725490	False
right	0.0	0.0	0.0	0.0	0.3116147309	False
cases	0.0	0.0	0.0	0.0	0.3179190751	False
circled	0.000228887000171	0.0	0.0	0.0	0.0000000000	False
orange	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
choices	0.000231940988579	0.0	0.0	0.0	0.0000000000	False
choose	0.000872456669684	0.0	0.0	0.0	0.4438040346	False
large	0.000387044973977	0.0	0.0	0.0	0.3267326733	False
number	3.21997556134e-05	0.0	0.0	0.0	0.3938618926	False
fact	0.00041850568276	0.0	0.0	0.0	0.4714285714	False
absolutely	0.000374635568406	0.0	0.0	0.0	0.0000000000	False
restriction	0.000490192546165	0.0	0.0	0.0	0.0000000000	False
long	0.000267451487761	0.0	0.0	0.0	0.0000000000	False
infinite	0.00160136324454	0.0	0.0	0.0	0.3464566929	False
finitary	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
representation	0.000286562253181	0.0	0.0	0.0	0.0000000000	False
part	1.86327945509e-05	0.0	0.0	0.0	0.0000000000	False
computer	4.84549658153e-05	0.0	0.0	0.0	0.0000000000	False
science	0.000262851522673	0.0	0.0	0.0	0.0000000000	False
mathematics	0.000213975914539	0.0	0.0	0.0	0.0000000000	False
logic	0.000187317784203	0.0	0.0	0.0	0.0000000000	False
represent	0.000424250678728	0.0	0.0	0.0	0.4602510460	False
infintary	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
object	0.000249273334196	0.0	0.0	0.0	0.0000000000	False
manner	0.0001533532617	0.0	0.0	0.0	0.0000000000	False
warnings	0.000391977301466	0.0	0.0	0.0	0.0000000000	False
cautions	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
mind	0.000143281126591	0.0	0.0	0.0	0.0000000000	False
disjoint	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
binary	0.000429843379772	0.0	0.0	0.0	0.0000000000	False
relation	0.000124636667098	0.0	0.0	0.0	0.0000000000	False
star	0.00473132740812	0.0	0.0	0.0	0.2161572052	False
denote	0.000984007514137	0.0	0.0	0.0	0.3267326733	False
union	0.000783954602932	0.0	0.0	0.0	0.0000000000	False
explain	0.000228887000171	0.0	0.0	0.0	0.0000000000	False
length	0.00227883447803	0.0	0.0	0.0	0.2155237378	False
empty	0.00600511216704	0.0	0.0	0.0	0.2220726783	False
greek	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
letter	0.000329296184361	0.0	0.0	0.0	0.0000000000	False
epsilon	0.00143205111585	0.0	0.0	0.0	0.4313725490	False
equal	0.000258029982651	0.0	0.0	0.0	0.4313725490	False
removed	0.000228887000171	0.0	0.0	0.0	0.0000000000	False
kind	0.000133863464683	0.0	0.0	0.0	0.5082508251	False
context	0.0232841459428	0.0	0.0	0.0	0.1537782356	False
free	0.0107342035387	0.0	0.0	0.0	0.3157099698	False
allowed	0.0015221036932	0.0	0.0	0.0	0.3700934579	False
single	0.000276469583739	0.0	0.0	0.0	0.0000000000	False
left	0.00110564810279	0.0	0.0	0.0	0.2896742897	False
hand	0.000213133880326	0.0	0.0	0.0	0.0000000000	False
side	0.000933351493203	0.0	0.0	0.0	0.3606557377	False
arrow	0.000457774000341	0.0	0.0	0.0	0.0000000000	False
mark	0.000245096273082	0.0	0.0	0.0	0.0000000000	False
suppose	0.000404367558193	0.0	0.0	0.0	0.5140186916	False
sensitive	0.017442841183	0.0	0.0	0.0	0.2437223043	False
meaning	4.13996857886e-05	0.0	0.0	0.0	0.4590690209	False
obtain	0.000613413046802	0.0	0.0	0.0	0.4313725490	False
arbitrary	0.000855903658154	0.0	0.0	0.0	0.4313725490	False
assume	0.000213133880326	0.0	0.0	0.0	0.0000000000	False
appears	0.0041666366424	0.0	0.0	0.0	0.2739577694	False
rest	0.000492003757069	0.0	0.0	0.0	0.0000000000	False
similarly	0.000290960027051	0.0	0.0	0.0	0.5641025641	False
calling	3.21997556134e-05	0.0	0.0	0.0	0.4656084656	False
uniform	0.000564958080987	0.0	0.0	0.0	0.0000000000	False
sense	0.000323494046554	0.0	0.0	0.0	0.5301204819	False
define	0.000184676724221	0.0	0.0	0.0	0.4888888889	False
first	0.0	0.0	0.0	0.0	0.0000000000	False
worry	0.000215379229052	0.0	0.0	0.0	0.0000000000	False
simpler	0.000457774000341	0.0	0.0	0.0	0.0000000000	False
noise	0.000429843379772	0.0	0.0	0.0	0.0000000000	False
located	0.0001533532617	0.0	0.0	0.0	0.0000000000	False
possibly	0.000175294959848	0.0	0.0	0.0	0.3793103448	False
subset	0.000913262215923	0.0	0.0	0.0	0.0000000000	False
trivial	0.000329296184361	0.0	0.0	0.0	0.0000000000	False
element	0.000299283664134	0.0	0.0	0.0	0.0000000000	False
lot	0.000129014991326	0.0	0.0	0.0	0.0000000000	False
regard	0.000391977301466	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.2583559169	False
extreme	0.000460059785101	0.0	0.0	0.0	0.0000000000	False
problem	1.86327945509e-05	0.0	0.0	0.0	0.0000000000	False
similar	6.45074956628e-05	0.0	0.0	0.0	0.0000000000	False
fashion	0.000400340811136	0.0	0.0	0.0	0.0000000000	False
regular	0.00700167698874	0.0	0.0	0.0	0.2170742171	False
form	0.000353704929691	0.0	0.0	0.0	0.2640000000	False
capital	0.000608841477282	0.0	0.0	0.0	0.0000000000	False
small	0.000265278697268	0.0	0.0	0.0	0.3700934579	False
made	9.97612213779e-05	0.0	0.0	0.0	0.0000000000	False
linear	0.00587452619021	0.0	0.0	0.0	0.1801477931	False
realize	0.000200170405568	0.0	0.0	0.0	0.0000000000	False
difference	1.86327945509e-05	0.0	0.0	0.0	0.0000000000	False
order	2.83106955954e-05	0.0	0.0	0.0	0.0000000000	False
full	0.000164001252356	0.0	0.0	0.0	0.0000000000	False
out	0.0	0.0	0.0	0.0	0.5082508251	False
completion	3.48754735634e-05	0.0	0.0	0.0	0.0000000000	False
hardware	0.000282479040493	0.0	0.0	0.0	0.0000000000	False
designed	0.000401177231641	0.0	0.0	0.0	0.0000000000	False
hard	0.000400340811136	0.0	0.0	0.0	0.0000000000	False
ware	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
state	0.00160136324454	0.0	0.0	0.0	0.2156862745	False
machines	0.000997093336782	0.0	0.0	0.0	0.2279792746	False
turns	0.000193522486988	0.0	0.0	0.0	0.0000000000	False
output	0.000115970494289	0.0	0.0	0.0	0.0000000000	False
talking	1.86327945509e-05	0.0	0.0	0.0	0.0000000000	False
transition	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
diagram	0.000282479040493	0.0	0.0	0.0	0.0000000000	False
input	0.000169700271491	0.0	0.0	0.0	0.0000000000	False
automatically	0.000228887000171	0.0	0.0	0.0	0.0000000000	False
powerful	0.000107689614526	0.0	0.0	0.0	0.0000000000	False
suma	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
looked	0.00013372574388	0.0	0.0	0.0	0.3586956522	False
properties	0.000169700271491	0.0	0.0	0.0	0.0000000000	False
firstly	0.00084743712148	0.0	0.0	0.0	0.0000000000	False
considered	0.000608841477282	0.0	0.0	0.0	0.4852941176	False
top	9.21565279128e-05	0.0	0.0	0.0	0.0000000000	False
bracket	0.000525703045347	0.0	0.0	0.0	0.0000000000	False
padded	0.00393870607359	0.0	0.0	0.0	0.2203147353	False
implicitly	0.00156790920586	0.0	0.0	0.0	0.4313725490	False
reason	0.000290960027051	0.0	0.0	0.0	0.5641025641	False
true	0.000184313055826	0.0	0.0	0.0	0.0000000000	False
interest	0.000169700271491	0.0	0.0	0.0	0.0000000000	False
ultimately	0.000658592368722	0.0	0.0	0.0	0.0000000000	False
student	0.000429843379772	0.0	0.0	0.0	0.0000000000	False
rewrite	0.000608841477282	0.0	0.0	0.0	0.0000000000	False
cross	0.000328002504712	0.0	0.0	0.0	0.0000000000	False
cartesian	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
greater	0.000124636667098	0.0	0.0	0.0	0.0000000000	False
operation	0.00045155246964	0.0	0.0	0.0	0.2716049383	False
catenation	0.00899337497525	1.0	0.0	0.0	0.1506055819	True
effect	0.000124636667098	0.0	0.0	0.0	0.0000000000	False
put	5.89508216151e-05	0.0	0.0	0.0	0.0000000000	False
simplicity	0.000391977301466	0.0	0.0	0.0	0.0000000000	False
ababb	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
bab	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
dot	0.000525884879544	0.0	0.0	0.0	0.0000000000	False
moment	0.000245096273082	0.0	0.0	0.0	0.0000000000	False
produce	0.000400340811136	0.0	0.0	0.0	0.0000000000	False
ababbbab	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
juxtapose	0.00276719230008	0.0	0.0	0.0	0.3013698630	False
belongs	0.000980385092329	0.0	0.0	0.0	0.3013698630	False
raised	0.000306706523401	0.0	0.0	0.0	0.0000000000	False
cube	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
functionality	3.48754735634e-05	0.0	0.0	0.0	0.0000000000	False
back	0.000138507543166	0.0	0.0	0.0	0.0000000000	False
satisfies	0.000400340811136	0.0	0.0	0.0	0.0000000000	False
concatenated	0.00138359615004	0.0	0.0	0.0	0.0000000000	False
juxtaposition	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
rid	0.00143205111585	0.0	0.0	0.0	0.4313725490	False
obvious	0.000245096273082	0.0	0.0	0.0	0.0000000000	False
identity	0.000427951829077	0.0	0.0	0.0	0.0000000000	False
addition	0.000115970494289	0.0	0.0	0.0	0.0000000000	False
associative	0.000525884879544	0.0	0.0	0.0	0.0000000000	False
monoid	0.00207539422506	0.0	0.0	0.0	0.0000000000	False
communicative	0.000245096273082	0.0	0.0	0.0	0.0000000000	False
ebleion	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
specifies	0.00084743712148	0.0	0.0	0.0	0.3224351747	False
preserved	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
xyz	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
don	0.0	0.0	0.0	0.0	0.0000000000	False
drew	0.000304420738641	0.0	0.0	0.0	0.0000000000	False
xbcy	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
process	0.000208334472593	0.0	0.0	0.0	0.4313725490	False
minimal	0.000820006261781	0.0	0.0	0.0	0.2964959569	False
shell	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
care	0.000184313055826	0.0	0.0	0.0	0.0000000000	False
smallest	0.000187317784203	0.0	0.0	0.0	0.0000000000	False
kernel	0.000329296184361	0.0	0.0	0.0	0.0000000000	False
occurs	0.000175294959848	0.0	0.0	0.0	0.0000000000	False
candidate	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
inclusive	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
enable	0.000391977301466	0.0	0.0	0.0	0.0000000000	False
thought	0.000213975914539	0.0	0.0	0.0	0.0000000000	False
require	0.000339400542983	0.0	0.0	0.0	0.3013698630	False
practical	0.000267451487761	0.0	0.0	0.0	0.0000000000	False
account	0.000200170405568	0.0	0.0	0.0	0.0000000000	False
aspects	0.000400340811136	0.0	0.0	0.0	0.0000000000	False
compilation	0.000304420738641	0.0	0.0	0.0	0.0000000000	False
typical	0.00013372574388	0.0	0.0	0.0	0.0000000000	False
feature	0.000115970494289	0.0	0.0	0.0	0.0000000000	False
pascal	0.000783954602932	0.0	0.0	0.0	0.0000000000	False
variable	0.000299283664134	0.0	0.0	0.0	0.0000000000	False
statement	0.000143281126591	0.0	0.0	0.0	0.0000000000	False
declaration	0.000213975914539	0.0	0.0	0.0	0.0000000000	False
fail	0.000329296184361	0.0	0.0	0.0	0.0000000000	False
check	0.000107689614526	0.0	0.0	0.0	0.0000000000	False
issues	0.00013372574388	0.0	0.0	0.0	0.0000000000	False
undeclared	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
freeness	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
efficient	0.000286562253181	0.0	0.0	0.0	0.0000000000	False
algorithms	0.000407344037872	0.0	0.0	0.0	0.2072678331	False
recognize	0.000913262215923	0.0	0.0	0.0	0.0000000000	False
pause	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
phrasing	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
people	0.000199522442756	0.0	0.0	0.0	0.0000000000	False
semantics	0.00141239520247	0.0	0.0	0.0	0.2964959569	False
synonymous	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
coming	0.00013372574388	0.0	0.0	0.0	0.4313725490	False
necessarily	0.000175294959848	0.0	0.0	0.0	0.0000000000	False
converted	0.000282479040493	0.0	0.0	0.0	0.0000000000	False
purely	0.00107403833689	0.0	0.0	0.0	0.0000000000	False
conversion	0.000200170405568	0.0	0.0	0.0	0.0000000000	False
helps	0.000228887000171	0.0	0.0	0.0	0.0000000000	False
give	4.59996508763e-06	0.0	0.0	0.0	0.0000000000	False
important	0.000311278092921	0.0	0.0	0.0	0.4313725490	False
subject	0.000262851522673	0.0	0.0	0.0	0.0000000000	False
theory	0.000200170405568	0.0	0.0	0.0	0.0000000000	False
exists	0.000573124506362	0.0	0.0	0.0	0.3013698630	False
written	0.000184313055826	0.0	0.0	0.0	0.0000000000	False
work	3.48754735634e-05	0.0	0.0	0.0	0.0000000000	False
examples	9.21565279128e-05	0.0	0.0	0.0	0.3596304193	False
arabic	0.00168801688868	0.0	0.0	0.0	0.0000000000	False
numerals	0.00171567391158	0.0	0.0	0.0	0.3540229885	False
remember	0.000129014991326	0.0	0.0	0.0	0.0000000000	False
notion	0.000107689614526	0.0	0.0	0.0	0.0000000000	False
natural	0.000107689614526	0.0	0.0	0.0	0.0000000000	False
sanskrit	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
neat	0.00146141567327	0.0	0.0	0.0	0.0000000000	False
rigorous	0.000433546517434	0.0	0.0	0.0	0.0000000000	False
art	0.000391977301466	0.0	0.0	0.0	0.0000000000	False
evolved	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
notation	0.000143281126591	0.0	0.0	0.0	0.0000000000	False
digits	0.000600511216704	0.0	0.0	0.0	0.0000000000	False
decimal	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
nice	0.00013372574388	0.0	0.0	0.0	0.0000000000	False
equivalent	0.00197735328345	0.0	0.0	0.0	0.3540229885	False
roman	0.00225068918491	0.0	0.0	0.0	0.3013698630	False
fully	0.000358012778964	0.0	0.0	0.0	0.0000000000	False
clear	9.21565279128e-05	0.0	0.0	0.0	0.0000000000	False
tens	0.000368626111651	0.0	0.0	0.0	0.3013698630	False
thousands	0.00120102243341	0.0	0.0	0.0	0.1486486486	False
pattern	0.000525703045347	0.0	0.0	0.0	0.0000000000	False
fifty	0.000457774000341	0.0	0.0	0.0	0.0000000000	False
hundred	0.000820006261781	0.0	0.0	0.0	0.2396514161	False
violated	0.000262851522673	0.0	0.0	0.0	0.0000000000	False
precede	0.000987888553083	0.0	0.0	0.0	0.0000000000	False
easy	0.000492003757069	0.0	0.0	0.0	0.0000000000	False
construct	0.0001533532617	0.0	0.0	0.0	0.0000000000	False
aim	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
criterion	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
previewed	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
previously	0.000164001252356	0.0	0.0	0.0	0.0000000000	False
factor	0.000427951829077	0.0	0.0	0.0	0.0000000000	False
introduce	0.000175294959848	0.0	0.0	0.0	0.0000000000	False
directly	0.000213975914539	0.0	0.0	0.0	0.0000000000	False
wrote	0.000175294959848	0.0	0.0	0.0	0.0000000000	False
wanted	0.000164001252356	0.0	0.0	0.0	0.0000000000	False
quickly	0.000215379229052	0.0	0.0	0.0	0.0000000000	False
original	0.000107689614526	0.0	0.0	0.0	0.0000000000	False
common	0.000164001252356	0.0	0.0	0.0	0.0000000000	False
occurrence	0.000487138557756	0.0	0.0	0.0	0.0000000000	False
writing	2.94754108075e-05	0.0	0.0	0.0	0.0000000000	False
elimination	0.000329296184361	0.0	0.0	0.0	0.0000000000	False
make	1.86327945509e-05	0.0	0.0	0.0	0.0000000000	False
smaller	0.000115970494289	0.0	0.0	0.0	0.0000000000	False
reduce	0.000374635568406	0.0	0.0	0.0	0.0000000000	False
constraint	0.00112991616197	0.0	0.0	0.0	0.3013698630	False
parsing	0.00173418606974	0.0	0.0	0.0	0.3013698630	False
depends	4.04367558193e-05	0.0	0.0	0.0	0.0000000000	False
good	3.48754735634e-05	0.0	0.0	0.0	0.0000000000	False
idea	4.61691810552e-05	0.0	0.0	0.0	0.0000000000	False
variety	0.000358012778964	0.0	0.0	0.0	0.0000000000	False
matter	0.000249273334196	0.0	0.0	0.0	0.0000000000	False
decision	0.000200170405568	0.0	0.0	0.0	0.0000000000	False
correct	0.000115970494289	0.0	0.0	0.0	0.0000000000	False
criteria	0.000329296184361	0.0	0.0	0.0	0.0000000000	False
complicated	0.000143281126591	0.0	0.0	0.0	0.0000000000	False
impossible	0.000358012778964	0.0	0.0	0.0	0.0000000000	False
preferably	0.000304420738641	0.0	0.0	0.0	0.0000000000	False
low	0.000213975914539	0.0	0.0	0.0	0.0000000000	False
facilitate	0.000562672296227	0.0	0.0	0.0	0.0000000000	False
explanation	0.000391977301466	0.0	0.0	0.0	0.0000000000	False
terms	2.42274829076e-05	0.0	0.0	0.0	0.0000000000	False
actual	0.00013372574388	0.0	0.0	0.0	0.3859649123	False
easier	0.000427951829077	0.0	0.0	0.0	0.0000000000	False
thatn	0.000691798075019	0.0	0.0	0.0	0.0000000000	False
inherent	0.000974277115513	0.0	0.0	0.0	0.0000000000	False
recursive	0.00121768295456	0.0	0.0	0.0	0.2075471698	False
lead	0.000525703045347	0.0	0.0	0.0	0.0000000000	False
based	0.000107689614526	0.0	0.0	0.0	0.0000000000	False
basically	1.91233520976e-05	0.0	0.0	0.0	0.0000000000	False
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t delhi	0.0	0.0	0.0	2.0	0.0000000000	False
technology i.i.t delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
kumar deptt of comp.sc	0.0	0.0	0.0	2.0	0.0000000000	False
today we will talk	0.0	0.0	0.0	2.0	0.0000000000	False
grammar our favorite context	0.0	0.0	0.0	2.0	0.0000000000	False
favorite context free grammar	0.0	0.0	0.0	2.0	0.0000000000	False
sentence that we generated	0.0	0.0	0.0	2.0	0.0000000000	False
generated using this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
aim is to generate	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
out of three possibilities	0.0	0.0	0.0	2.0	0.0000000000	False
chose one in fact	0.0	0.0	0.0	2.0	0.0000000000	False
possibility will not give	0.0	0.0	0.0	2.0	0.0000000000	False
give you this sentence	0.0	0.0	0.0	4.0	0.0000000000	False
sentence ok so out	0.0	0.0	0.0	2.0	0.0000000000	False
possibility a this possibility	0.0	0.0	0.0	2.0	0.0000000000	False
generate this ultimate sentence	0.0	0.0	0.0	2.0	0.0000000000	False
essential in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
chosen this um chosen	0.0	0.0	0.0	2.0	0.0000000000	False
open bracket open bracket	0.0	0.0	0.0	2.0	0.0000000000	False
possibility of either firing	0.0	0.0	0.0	2.0	0.0000000000	False
supposing you had chosen	0.0	0.0	0.0	2.0	0.0000000000	False
derivation of a sentence	0.0	0.0	0.0	4.0	0.0000000000	False
sentence this particular order	0.0	0.0	0.0	2.0	0.0000000000	False
derivations after same sentence	0.0	0.0	0.0	2.0	0.0000000000	False
depending upon the order	0.0	0.0	0.0	2.0	0.0000000000	False
chose to apply productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions in a sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in other words	0.0	0.0	0.0	2.0	0.0000000000	False
give you various orders	0.0	0.0	0.0	2.0	0.0000000000	False
chosen any particular order	0.0	0.0	0.0	2.0	0.0000000000	False
leftmost non terminal symbol	0.0	0.0	0.0	2.0	0.0000000000	False
derivations of this sentence	0.0	0.0	0.0	2.0	0.0000000000	False
talking about a context	0.0	0.0	0.0	2.0	0.0000000000	False
grammar and the replacement	0.0	0.0	0.0	2.0	0.0000000000	False
replacement of non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals by their right	0.0	0.0	0.0	2.0	0.0000000000	False
sides in the production	0.0	0.0	0.0	2.0	0.0000000000	False
non terminal is chosen	0.0	0.0	0.0	2.0	0.0000000000	False
chosen first for replacement	0.0	0.0	0.0	2.0	0.0000000000	False
first for replacement provided	0.0	0.0	0.0	2.0	0.0000000000	False
steps in this derivation	0.0	0.0	0.0	2.0	0.0000000000	False
production you have applied	0.0	0.0	0.0	2.0	0.0000000000	False
justification which just tells	0.0	0.0	0.0	2.0	0.0000000000	False
tells you which production	0.0	0.0	0.0	2.0	0.0000000000	False
production number you applied	0.0	0.0	0.0	2.0	0.0000000000	False
essentially you could permute	0.0	0.0	0.0	2.0	0.0000000000	False
order of the productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions of these applications	0.0	0.0	0.0	2.0	0.0000000000	False
choices either an application	0.0	0.0	0.0	2.0	0.0000000000	False
productions but your intermediate	0.0	0.0	0.0	2.0	0.0000000000	False
intermediate sentences your intermediate	0.0	0.0	0.0	2.0	0.0000000000	False
sentences your intermediate sentences	0.0	0.0	0.0	2.0	0.0000000000	False
application of these productions	0.0	0.0	0.0	2.0	0.0000000000	False
derived the same sentence	0.0	0.0	0.0	2.0	0.0000000000	False
productions for the derivation	0.0	0.0	0.0	2.0	0.0000000000	False
sentences in a context	0.0	0.0	0.0	2.0	0.0000000000	False
freeness of the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
derivation by just applying	0.0	0.0	0.0	2.0	0.0000000000	False
applying the same productions	0.0	0.0	0.0	2.0	0.0000000000	False
apply is still place	0.0	0.0	0.0	2.0	0.0000000000	False
alternative but to replace	0.0	0.0	0.0	2.0	0.0000000000	False
ordering on the application	0.0	0.0	0.0	2.0	0.0000000000	False
application of the productions	0.0	0.0	0.0	4.0	0.0000000000	False
order but other productions	0.0	0.0	0.0	2.0	0.0000000000	False
collapse them to give	0.0	0.0	0.0	2.0	0.0000000000	False
independence look for independence	0.0	0.0	0.0	2.0	0.0000000000	False
draw draw a tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree of exact dependences	0.0	0.0	0.0	2.0	0.0000000000	False
dependencies in the applications	0.0	0.0	0.0	2.0	0.0000000000	False
applications of various productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions so the root	0.0	0.0	0.0	2.0	0.0000000000	False
root of the parse	0.0	0.0	0.0	2.0	0.0000000000	False
generation of this sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence the first production	0.0	0.0	0.0	2.0	0.0000000000	False
production that was applied	0.0	0.0	0.0	2.0	0.0000000000	False
symbol ok open parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
single symbol um remember	0.0	0.0	0.0	2.0	0.0000000000	False
convention that black denotes	0.0	0.0	0.0	2.0	0.0000000000	False
black denotes terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
symbols the eventual strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings that you generate	0.0	0.0	0.0	2.0	0.0000000000	False
strings in black strings	0.0	0.0	0.0	2.0	0.0000000000	False
strings of the language	0.0	0.0	0.0	2.0	0.0000000000	False
language the colors denote	0.0	0.0	0.0	2.0	0.0000000000	False
colors denote um denote	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis s close parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
generated then the right	0.0	0.0	0.0	2.0	0.0000000000	False
hand s be expanded	0.0	0.0	0.0	2.0	0.0000000000	False
expanded into open parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
matter in which order	0.0	0.0	0.0	4.0	0.0000000000	False
perform these two productions	0.0	0.0	0.0	2.0	0.0000000000	False
first s should produce	0.0	0.0	0.0	2.0	0.0000000000	False
color for the productions	0.0	0.0	0.0	2.0	0.0000000000	False
call the parse tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree and the branches	0.0	0.0	0.0	2.0	0.0000000000	False
leaves of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
read if you read	0.0	0.0	0.0	2.0	0.0000000000	False
tree if you read	0.0	0.0	0.0	2.0	0.0000000000	False
sentence that you generated	0.0	0.0	0.0	2.0	0.0000000000	False
open parenthesis open parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
close parenthesis close parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree for generating	0.0	0.0	0.0	2.0	0.0000000000	False
defined for every sentence	0.0	0.0	0.0	2.0	0.0000000000	False
important from the point	0.0	0.0	0.0	2.0	0.0000000000	False
view of compiling language	0.0	0.0	0.0	2.0	0.0000000000	False
implementation from the point	0.0	0.0	0.0	2.0	0.0000000000	False
view of specifying semantics	0.0	0.0	0.0	2.0	0.0000000000	False
sacrocite and the fact	0.0	0.0	0.0	2.0	0.0000000000	False
traversing this parse parse	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree as presenting	0.0	0.0	0.0	2.0	0.0000000000	False
presenting the partial order	0.0	0.0	0.0	2.0	0.0000000000	False
order in the firing	0.0	0.0	0.0	2.0	0.0000000000	False
traversals of the parse	0.0	0.0	0.0	2.0	0.0000000000	False
tree of the sentence	0.0	0.0	0.0	2.0	0.0000000000	False
necessarily a unique derivation	0.0	0.0	0.0	2.0	0.0000000000	False
traversal of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
topological sort just takes	0.0	0.0	0.0	2.0	0.0000000000	False
takes a partial order	0.0	0.0	0.0	2.0	0.0000000000	False
partial order and linearizes	0.0	0.0	0.0	2.0	0.0000000000	False
linearizes it you sort	0.0	0.0	0.0	2.0	0.0000000000	False
provide a linear order	0.0	0.0	0.0	2.0	0.0000000000	False
linear order a total	0.0	0.0	0.0	2.0	0.0000000000	False
order a total order	0.0	0.0	0.0	2.0	0.0000000000	False
partial order are maintained	0.0	0.0	0.0	2.0	0.0000000000	False
maintained but their dependencies	0.0	0.0	0.0	2.0	0.0000000000	False
dependencies do not exists	0.0	0.0	0.0	2.0	0.0000000000	False
exists you might place	0.0	0.0	0.0	2.0	0.0000000000	False
linearization of a tree	0.0	0.0	0.0	2.0	0.0000000000	False
fact for partial orders	0.0	0.0	0.0	2.0	0.0000000000	False
order is completely defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined by the set	0.0	0.0	0.0	4.0	0.0000000000	False
essentially a parsed tree	0.0	0.0	0.0	2.0	0.0000000000	False
order by the set	0.0	0.0	0.0	2.0	0.0000000000	False
traverses you can make	0.0	0.0	0.0	2.0	0.0000000000	False
property in the theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory of partial orders	0.0	0.0	0.0	2.0	0.0000000000	False
orders of that set	0.0	0.0	0.0	2.0	0.0000000000	False
syntactical in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
compiling or language def	0.0	0.0	0.0	2.0	0.0000000000	False
def um or language	0.0	0.0	0.0	2.0	0.0000000000	False
language implementation it doesn	0.0	0.0	0.0	2.0	0.0000000000	False
symbols that are coming	0.0	0.0	0.0	2.0	0.0000000000	False
symbols but any kind	0.0	0.0	0.0	2.0	0.0000000000	False
type of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
make a clear distinction	0.0	0.0	0.0	2.0	0.0000000000	False
identifier and a operator	0.0	0.0	0.0	2.0	0.0000000000	False
call a concrete parse	0.0	0.0	0.0	2.0	0.0000000000	False
tree where we make	0.0	0.0	0.0	2.0	0.0000000000	False
symbols they are leaves	0.0	0.0	0.0	2.0	0.0000000000	False
leaves of the parse	0.0	0.0	0.0	2.0	0.0000000000	False
sentence you actually make	0.0	0.0	0.0	2.0	0.0000000000	False
clear that our intention	0.0	0.0	0.0	2.0	0.0000000000	False
intention was to define	0.0	0.0	0.0	2.0	0.0000000000	False
language of boolean expressions	0.0	0.0	3.9974533107	6.0	0.0000000000	False
expressions where the operations	0.0	0.0	0.0	2.0	0.0000000000	False
distinction between the operands	0.0	0.0	0.0	2.0	0.0000000000	False
operators is what leads	0.0	0.0	0.0	2.0	0.0000000000	False
call abstract syntax tree	0.0	0.0	0.0	2.0	0.0000000000	False
syntax tree actually elevates	0.0	0.0	0.0	2.0	0.0000000000	False
tree actually elevates replaces	0.0	0.0	0.0	2.0	0.0000000000	False
elevates replaces non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
easily elevate the operators	0.0	0.0	0.0	2.0	0.0000000000	False
nodes of this tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree we could talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk we can talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk of a root	0.0	0.0	0.0	2.0	0.0000000000	False
syntax tree the operators	0.0	0.0	0.0	2.0	0.0000000000	False
identifiers of the operands	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
language the ultimate programming	0.0	0.0	0.0	2.0	0.0000000000	False
interested in the non	0.0	0.0	0.0	2.0	0.0000000000	False
symbols the concrete parts	0.0	0.0	0.0	2.0	0.0000000000	False
parts of the language	0.0	0.0	0.0	2.0	0.0000000000	False
real down to earth	0.0	0.0	0.0	2.0	0.0000000000	False
symbols in any programming	0.0	0.0	0.0	2.0	0.0000000000	False
language have some meaning	0.0	0.0	0.0	2.0	0.0000000000	False
bring about this distinction	0.0	0.0	0.0	2.0	0.0000000000	False
interested in what order	0.0	0.0	0.0	2.0	0.0000000000	False
operators on the operands	0.0	0.0	0.0	2.0	0.0000000000	False
reason why we included	0.0	0.0	0.0	2.0	0.0000000000	False
essential to have parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
uniform post fix notion	0.0	0.0	0.0	2.0	0.0000000000	False
notion or a uniform	0.0	0.0	0.0	2.0	0.0000000000	False
fact every language construct	0.0	0.0	0.0	2.0	0.0000000000	False
construct can be regarded	0.0	0.0	0.0	2.0	0.0000000000	False
regarded as a operator	0.0	0.0	0.0	2.0	0.0000000000	False
interested in giving meanings	0.0	0.0	0.0	2.0	0.0000000000	False
giving meanings to languages	0.0	0.0	0.0	2.0	0.0000000000	False
interested in the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
arithmetic calculations in school	0.0	0.0	0.0	2.0	0.0000000000	False
expression you can choose	0.0	0.0	0.0	2.0	0.0000000000	False
order so the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
syntax to an abstract	0.0	0.0	0.0	2.0	0.0000000000	False
tree of the expression	0.0	0.0	0.0	2.0	0.0000000000	False
oftenly using these abstract	0.0	0.0	0.0	2.0	0.0000000000	False
mind so now keeping	0.0	0.0	0.0	2.0	0.0000000000	False
mind let us define	0.0	0.0	0.0	2.0	0.0000000000	False
define a small programming	0.0	0.0	0.0	2.0	0.0000000000	False
boolean variables and expressions	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of this programming	0.0	0.0	0.0	2.0	0.0000000000	False
programs in the language	0.0	0.0	0.0	2.0	0.0000000000	False
language i can generate	0.0	0.0	0.0	2.0	0.0000000000	False
generate from the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
programs of the language	0.0	0.0	0.0	2.0	0.0000000000	False
programs we are talking	0.0	0.0	0.0	2.0	0.0000000000	False
formalizing it and giving	0.0	0.0	0.0	2.0	0.0000000000	False
giving rules production rules	0.0	0.0	0.0	2.0	0.0000000000	False
rules for the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
compiler or a translator	0.0	0.0	0.0	2.0	0.0000000000	False
translator for this language	0.0	0.0	0.0	2.0	0.0000000000	False
require to specify things	0.0	0.0	0.0	2.0	0.0000000000	False
coding of various constructs	0.0	0.0	0.0	2.0	0.0000000000	False
part of the context	0.0	0.0	0.0	2.0	0.0000000000	False
context free grammar notation	0.0	0.0	0.0	2.0	0.0000000000	False
bark of a tree	0.0	0.0	0.0	2.0	0.0000000000	False
branches of parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
coded in this color	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of entities commands	0.0	0.0	0.0	2.0	0.0000000000	False
commands and boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
brown for boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
atomic commands the assignment	0.0	0.0	0.0	2.0	0.0000000000	False
green all other compound	0.0	0.0	0.0	2.0	0.0000000000	False
program or the sentence	0.0	0.0	0.0	2.0	0.0000000000	False
sentence of the language	0.0	0.0	2.9974533107	6.0	0.0000000000	False
change my color coding	0.0	0.0	0.0	2.0	0.0000000000	False
coding i will inform	0.0	0.0	0.0	2.0	0.0000000000	False
language and the sentences	0.0	0.0	0.0	2.0	0.0000000000	False
sentences of this language	0.0	0.0	0.0	2.0	0.0000000000	False
language are all programs	0.0	0.0	0.0	2.0	0.0000000000	False
unlike say a language	0.0	0.0	0.0	2.0	0.0000000000	False
program in this language	0.0	0.0	0.0	2.0	0.0000000000	False
language so this rule	0.0	0.0	0.0	2.0	0.0000000000	False
specifies that a program	0.0	0.0	0.0	2.0	0.0000000000	False
program is any command	0.0	0.0	0.0	2.0	0.0000000000	False
program of this language	0.0	0.0	0.0	2.0	0.0000000000	False
command of this language	0.0	0.0	0.0	2.0	0.0000000000	False
language well a command	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of two commands	0.0	0.0	0.0	2.0	0.0000000000	False
four productions c arrow	0.0	0.0	0.0	2.0	0.0000000000	False
arrow a c arrow	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon c c arrow	0.0	0.0	0.0	2.0	0.0000000000	False
right so this bar	0.0	0.0	0.0	2.0	0.0000000000	False
specifies the various alternatives	0.0	0.0	0.0	2.0	0.0000000000	False
languages are called statement	0.0	0.0	0.0	2.0	0.0000000000	False
level this the thing	0.0	0.0	0.0	2.0	0.0000000000	False
definitions of the programming	0.0	0.0	0.0	2.0	0.0000000000	False
programming language in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of several levels	0.0	0.0	0.0	2.0	0.0000000000	False
level ok this command	0.0	0.0	0.0	2.0	0.0000000000	False
command level essentially tells	0.0	0.0	0.0	2.0	0.0000000000	False
commands from simpler commands	0.0	0.0	0.0	2.0	0.0000000000	False
command is a command	0.0	0.0	0.0	4.0	0.0000000000	False
command and the sequence	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of two sequencing	0.0	0.0	0.0	2.0	0.0000000000	False
simple or compound commands	0.0	0.0	0.0	2.0	0.0000000000	False
blue this semi colon	0.0	0.0	0.0	2.0	0.0000000000	False
colon is the reserved	0.0	0.0	0.0	2.0	0.0000000000	False
word of the language	0.0	0.0	0.0	2.0	0.0000000000	False
black so the sequence	0.0	0.0	0.0	2.0	0.0000000000	False
command this conditional compound	0.0	0.0	0.0	2.0	0.0000000000	False
possibly a compound command	0.0	0.0	0.0	2.0	0.0000000000	False
level of grammar specification	0.0	0.0	0.0	2.0	0.0000000000	False
form let us assume	0.0	0.0	0.0	2.0	0.0000000000	False
expression then v assigned	0.0	0.0	0.0	2.0	0.0000000000	False
boolean so the language	0.0	0.0	0.0	2.0	0.0000000000	False
expressions i am defining	0.0	0.0	0.0	2.0	0.0000000000	False
defining a different grammar	0.0	0.0	0.0	2.0	0.0000000000	False
grammar just for variation	0.0	0.0	0.0	2.0	0.0000000000	False
defined but that grammar	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a hatch	0.0	0.0	0.0	2.0	0.0000000000	False
thing in that grammar	0.0	0.0	0.0	2.0	0.0000000000	False
constant true and false	0.0	0.0	0.0	2.0	0.0000000000	False
expression the terminal false	0.0	0.0	0.0	2.0	0.0000000000	False
symbols of the language	0.0	0.0	0.0	2.0	0.0000000000	False
make compound boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
grammar in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
designed a fully parenthesized	0.0	0.0	0.0	2.0	0.0000000000	False
atomic i have enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
enclosed a new parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
supposing instead we defined	0.0	0.0	0.0	2.0	0.0000000000	False
define such a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
generated by this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
expand this and replace	0.0	0.0	4.99575551783	10.0	0.1726618705	False
make a different derivation	0.0	0.0	0.0	2.0	0.0000000000	False
expand this and give	0.0	0.0	0.0	2.0	0.0000000000	False
two then i chose	0.0	0.0	0.0	2.0	0.0000000000	False
brackets in the language	0.0	0.0	0.0	2.0	0.0000000000	False
give you the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
derivations with different syntax	0.0	0.0	0.0	2.0	0.0000000000	False
two different syntax trees	0.0	0.0	0.0	2.0	0.0000000000	False
syntax trees actually affect	0.0	0.0	0.0	2.0	0.0000000000	False
meaning of this language	0.0	0.0	0.0	2.0	0.0000000000	False
two had the values	0.0	0.0	0.0	2.0	0.0000000000	False
false then the evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
evaluation of this syntax	0.0	0.0	0.0	4.0	0.0000000000	False
syntax tree would give	0.0	0.0	0.0	4.0	0.0000000000	False
true and the evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
give you a value	0.0	0.0	0.0	2.0	0.0000000000	False
grammar for example falls	0.0	0.0	0.0	2.0	0.0000000000	False
language with unique meanings	0.0	0.0	0.0	2.0	0.0000000000	False
call such a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous but the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
handle for the specification	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in the language	0.0	0.0	0.0	4.0	0.0000000000	False
right so so ambiguity	0.0	0.0	0.0	2.0	0.0000000000	False
constraint in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
two different parse tree	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree those parse	0.0	0.0	0.0	2.0	0.0000000000	False
tree those parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
translating which means running	0.0	0.0	0.0	2.0	0.0000000000	False
problem of executing programs	0.0	0.0	0.0	2.0	0.0000000000	False
executing programs in order	0.0	0.0	0.0	2.0	0.0000000000	False
order to get meanings	0.0	0.0	0.0	2.0	0.0000000000	False
program to be interpreted	0.0	0.0	0.0	2.0	0.0000000000	False
compiler for that program	0.0	0.0	0.0	2.0	0.0000000000	False
program and the user	0.0	0.0	0.0	2.0	0.0000000000	False
user of that programming	0.0	0.0	0.0	2.0	0.0000000000	False
interpreted right so ambiguity	0.0	0.0	0.0	2.0	0.0000000000	False
means the execution behavior	0.0	0.0	0.0	2.0	0.0000000000	False
execution behavior of programs	0.0	0.0	0.0	2.0	0.0000000000	False
lot of our programming	0.0	0.0	0.0	4.0	0.0000000000	False
unambiguous yeah this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
tree for every sentence	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguity in most languages	0.0	0.0	0.0	2.0	0.0000000000	False
implicit order of evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
expression without any parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
assumed that the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
tree for this expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression if you remove	0.0	0.0	0.0	2.0	0.0000000000	False
tree of this form	0.0	0.0	0.0	2.0	0.0000000000	False
construct a syntax tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree supposing i removed	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguity then the order	0.0	0.0	0.0	2.0	0.0000000000	False
multiplication should precede addition	0.0	0.0	0.0	2.0	0.0000000000	False
precede addition other wise	0.0	0.0	0.0	2.0	0.0000000000	False
mathematical notation most programming	0.0	0.0	0.0	2.0	0.0000000000	False
notation most programming languages	0.0	0.0	0.0	2.0	0.0000000000	False
construct has a perfect	0.0	0.0	0.0	2.0	0.0000000000	False
case of one construct	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
technology i.i.t delhi	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi presents	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
presents a video	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.00119880376318	0.0	0.0	1.58496250072	0.0000000000	False
deptt of comp.sc	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
comp.sc & engg	0.00119880376318	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.00119880376318	0.0	0.0	1.58496250072	0.0000000000	False
talk about ambiguity	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
simple programming language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar our favorite	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
favorite context free	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
context free grammar	0.00538796657562	0.0	4.99660441426	4.75488750216	0.5454545455	False
generate this sentence	0.00765159079678	0.0	3.99660441426	6.33985000288	0.4285714286	False
applied the productions	0.00311170146237	0.0	0.0	3.16992500144	0.0000000000	False
productions or fired	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
fired the productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
four possible choices	0.0	0.0	0.0	1.58496250072	0.0000000000	False
chose the possibility	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
generate this ultimate	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
chosen to fire	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
chosen to apply	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
apply a production	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
keeping in mind	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
open bracket open	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
bracket open bracket	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
possibilities of replacement	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
intermediate sentence generation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence ok depending	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
chose to apply	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
fire a production	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
leftmost non terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
non terminal symbol	0.0	0.0	1.9974533107	3.16992500144	0.0000000000	False
chosen the left	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
replacement of non	0.0	0.0	0.0	0.0	0.0000000000	False
right hand sides	0.0	0.0	0.0	1.58496250072	0.0000000000	False
independent of context	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
matter which non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
terminal is chosen	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
first for replacement	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
provided you choose	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number these productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
write a justification	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
number you applied	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
permute the order	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
two possible choices	0.0	0.0	0.0	1.58496250072	0.0000000000	False
application of production	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
apply these productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentences your intermediate	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order of application	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
derivation of sentences	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose to replace	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
amount of order	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
applying this production	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
possibilities before applying	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
interested in generating	0.00573869309759	0.0	1.9974533107	4.75488750216	0.0000000000	False
derivation this independence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
partial ordering specifies	0.0019128976992	0.0	0.0	3.16992500144	0.0000000000	False
derivations and collapse	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
partial order colas	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
independence and dependence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
dependence in fact	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
draw a tree	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
tree of exact	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
sentence the first	0.00382579539839	0.0	0.0	1.58496250072	0.0000000000	False
symbol ok open	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
symbol um remember	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
remember our convention	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
convention that black	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
black denotes terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
denotes terminal symbols	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
symbols the eventual	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
strings in black	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
language the colors	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
denote um denote	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
denote certain abstractions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
production s yields	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
yields open parenthesis	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
generating the sentence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
expanded into open	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order you perform	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
productions the first	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
obtain a tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
call the parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
terminal symbols notice	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
read the tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
read the leaves	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
leaves from left	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
open parenthesis open	0.00382579539839	0.0	0.0	0.0	0.0000000000	False
parenthesis open parenthesis	0.00382579539839	0.0	0.0	0.0	0.0000000000	False
close parenthesis close	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
parenthesis close parenthesis	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
tree for generating	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
generating any sentence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
point of view	0.00455270068076	0.0	7.99575551783	7.92481250361	0.3858520900	False
view of compiling	0.00382579539839	0.0	0.0	1.58496250072	0.0000000000	False
compiling language implementation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
orders of derivation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
ways of traversing	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
traversing this parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
parse parse tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
tree as presenting	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
presenting the partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
firing of productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
unique parse tree	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
necessarily a unique	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
tree um depending	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
decide to traverse	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
traverse the tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
familiar topological sorting	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sort just takes	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
takes a partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order and linearizes	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
provide a linear	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order a total	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
order are maintained	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
fact for partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
essentially a parsed	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
derivations or traverses	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
theory of partial	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
compiling or language	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
implementation it doesn	0.0	0.0	0.0	0.0	0.0000000000	False
stream of symbols	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
kind of language	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
implicit um type	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
type of terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
make we make	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
make a clear	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
call a concrete	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
concrete parse tree	0.00765159079678	1.0	4.99660441426	6.33985000288	0.5454545455	True
make no distinction	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
identifiers and operators	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
abstract parse tree	0.0019128976992	1.0	0.0	1.58496250072	0.0000000000	True
make a distinction	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
operators and operands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
define a language	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language of boolean	0.00573869309759	0.0	3.9974533107	0.0	0.0000000000	False
operands and operators	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
call abstract syntax	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
abstract syntax tree	0.0186702087742	1.0	13.9898132428	17.4345875079	0.2727272727	True
tree actually elevates	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
replaces non terminals	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
designed the language	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
elevate the operators	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
tree the operators	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
leaves the leaves	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
talk about distinction	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
distinction between operands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
kinds of terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
language the ultimate	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
ultimate programming language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
symbols the concrete	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
concrete syntax tree	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
apply the operators	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
operands in fact	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence the reason	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
application of operators	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
operators on operands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
uniform post fix	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
post fix notion	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
uniform prefix notion	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
fact every language	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
interested in giving	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
meanings to languages	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
calculations in school	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
ways of evaluating	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
evaluating that expression	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose to evaluate	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
evaluate one operand	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
first apply multiplication	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
keeping these things	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
things in mind	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
define a small	0.0	0.0	0.0	0.0	0.0000000000	False
small programming language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
variables and expressions	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
commands assignment sequencing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sequencing um conditional	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
simple looping command	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
syntactically valid programs	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
kinds of programs	0.00134699164391	0.0	0.0	1.58496250072	0.0000000000	False
question of formalizing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
giving rules production	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
rules production rules	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
build a compiler	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
start writing programs	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
purposes of translation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
translation and compilation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
compilation you require	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
summarize the construction	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
construction um summarize	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
summarize my coding	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
brown is part	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
free grammar notation	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
notation for productions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
tree so branches	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
branches of parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
color the actual	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
actual terminal symbols	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
two different kinds	0.0	0.0	0.0	1.58496250072	0.0000000000	False
kinds of entities	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
commands and boolean	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
brown for boolean	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
commands the assignment	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
change um change	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
change my color	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
defined the grammar	0.0019128976992	0.0	0.0	3.16992500144	0.0000000000	False
top down fashion	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
interested in sentences	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
programs ok unlike	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
language like pascal	0.00269398328781	0.0	0.0	3.16992500144	0.0000000000	False
productions c arrow	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
arrow c semicolon	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
bar actually specifies	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
language in terms	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
level essentially tells	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
point it tells	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
form compound commands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
commands from simpler	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
two well simple	0.0	0.0	0.0	1.58496250072	0.0000000000	False
simple or compound	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
blue this semi	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
command this conditional	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
conditional compound command	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
compound commands inside	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
possibly a compound	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
grammar of commands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
commands is concerned	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
level of grammar	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
grammar atomic commands	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar is sort	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
hatch patch grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
true and false	0.00382579539839	0.0	0.0	1.58496250072	0.0000000000	False
expression the terminal	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
expression any boolean	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
make compound boolean	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
compound boolean expressions	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
expressions from simpler	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
simpler boolean expressions	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
two boolean expressions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
changed the grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
fully parenthesized notion	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
boolean expression language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
defined this grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
rid of true	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar without parenthesis	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence this sentence	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sentence is generated	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
easy to give	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
give a derivation	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
two different ways	0.0	0.0	0.0	1.58496250072	0.0000000000	False
rule and derive	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
choose to expand	0.00956448849598	0.0	3.99575551783	7.92481250361	0.1726618705	False
expand this replace	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
decide to apply	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
chose to expand	0.00765159079678	0.0	3.99660441426	6.33985000288	0.2068965517	False
two different derivations	0.0	0.0	2.9974533107	4.75488750216	0.0000000000	False
two different syntax	0.0	0.0	0.0	0.0	0.0000000000	False
trees actually affect	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
tree would give	0.00382579539839	0.0	0.0	0.0	0.0000000000	False
give you value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of true	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of false	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sense this grammar	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
unique expression language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
language with unique	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
specification of semantics	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
grammar is ambiguous	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
exists a sentence	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
two different parse	0.0	0.0	0.0	0.0	0.0000000000	False
tree those parse	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
trees are important	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
view of translating	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
translating which means	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
means running programs	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
problem of compiling	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
problem of executing	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
programs in order	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
right so ambiguity	0.0	0.0	0.0	0.0	0.0000000000	False
meanings which means	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
means the execution	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
behavior of programs	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
specifies a language	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
absolutely no ambiguity	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
normal mathematical notation	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
order of evaluation	0.00466755219356	0.0	5.9974533107	3.16992500144	0.0000000000	False
remove the parenthesis	0.00382579539839	0.0	0.0	3.16992500144	0.0000000000	False
absolutely no reason	0.00573869309759	0.0	5.9974533107	4.75488750216	0.0000000000	False
reason except normal	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
normal mathematical convention	0.00311170146237	0.0	0.0	3.16992500144	0.0000000000	False
construct a syntax	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
syntax tree supposing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
supposing i removed	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
removed this parenthesis	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
precedence of operations	0.00155585073119	0.0	0.0	1.58496250072	0.0000000000	False
operations which ensures	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
ensures that multiplication	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
first and addition	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
multiplication should precede	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
addition other wise	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
wise the order	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
notation most programming	0.0019128976992	0.0	0.0	0.0	0.0000000000	False
languages actually implement	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
dangling else problem	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
conditional the conditional	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
defined and pascal	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
possibility of ambiguity	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
ambiguity the sequencing	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
sequencing is ambiguous	0.0019128976992	0.0	0.0	1.58496250072	0.0000000000	False
v.srinivasa rajkumar	0.000799202508786	0.0	0.0	0.0	0.0000000000	False
educational technology	0.000799202508786	0.0	0.0	0.0	0.0000000000	False
technology i.i.t	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi	0.00159840501757	0.0	0.0	1.0	0.0000000000	False
delhi presents	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
programming languages	0.00789134784665	0.0	9.98896434635	12.0	0.3718712753	False
dr.s.arun kumar	0.000799202508786	0.0	0.0	0.0	0.0000000000	False
kumar deptt	0.000799202508786	0.0	0.0	0.0	0.0000000000	False
delhi lecture	0.000607026757434	0.0	0.0	0.0	0.0000000000	False
ambiguity today	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
simple definition	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
simple programming	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
favorite grammar	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
favorite context	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
free grammar	0.00359197771708	0.0	4.99660441426	3.0	0.5454545455	False
sentence generation	0.00207446764158	0.0	0.0	1.0	0.0000000000	False
ultimate aim	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
replaces replaced	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
ultimate sentence	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
open bracket	0.00207446764158	0.0	0.0	1.0	0.0000000000	False
non terminals	0.0	0.0	10.9923599321	8.0	0.3977900552	False
intermediate sentence	0.00382579539839	0.0	5.9974533107	2.0	0.0000000000	False
apply productions	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
leftmost non	0.0	0.0	0.0	0.0	0.0000000000	False
terminal symbol	0.0119880376318	0.0	6.98726655348	14.0	0.3883495146	False
intermediate string	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
right hand	0.0	0.0	0.0	1.0	0.0000000000	False
hand sides	0.000659963117265	0.0	0.0	0.0	0.0000000000	False
production rule	0.00207446764158	0.0	0.0	1.0	0.0000000000	True
replacement provided	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
production number	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
context freeness	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
intermediate stage	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
actual production	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
partial ordering	0.0178537118592	0.0	22.9881154499	13.0	0.1846153846	True
ordering specifies	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
order colas	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
draw draw	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
exact dependences	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
parse tree	0.0259308455198	0.0	23.9787775891	24.0	0.3474232774	True
tree tells	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
start symbol	0.00159840501757	0.0	0.0	2.0	0.0000000000	False
first production	0.00207446764158	0.0	0.0	1.0	0.0000000000	False
single symbol	0.00207446764158	0.0	0.0	1.0	0.0000000000	False
open parenthesis	0.00726063674554	0.0	9.99405772496	6.0	0.2336578581	False
black denotes	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
eventual strings	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
black strings	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
colors denote	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
close parenthesis	0.00622340292475	0.0	8.99490662139	5.0	0.2666666667	False
original sentence	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
left hand	0.000722573541988	0.0	0.0	1.0	0.0000000000	False
brown color	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
symbols notice	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
parenthesis close	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
actual derivation	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
unique derivation	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
compiling language	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
language implementation	0.00311170146237	0.0	3.9974533107	2.0	0.0000000000	False
parse parse	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
unique parse	0.00382579539839	0.0	5.9974533107	1.0	0.0000000000	False
familiar topological	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
topological sorting	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
linear order	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
total order	0.00518616910396	0.0	7.99575551783	4.0	0.3858520900	False
fundamental property	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
set consisting	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
language def	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
clear distinction	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
concrete parse	0.00510106053119	0.0	4.99660441426	2.0	0.5454545455	False
abstract parse	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
boolean expressions	0.0158966179237	0.0	39.9813242784	21.0	0.1376433785	False
boolean variables	0.00414893528317	0.0	3.99660441426	3.0	0.4285714286	False
call abstract	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
abstract syntax	0.0124468058495	0.0	13.9898132428	8.0	0.2727272727	False
syntax tree	0.0217819102366	0.0	15.9821731749	19.0	0.2107904642	True
elevates replaces	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
intermediate nodes	0.00255053026559	0.0	0.0	2.0	0.0000000000	False
root operator	0.00414893528317	0.0	2.99660441426	4.0	0.3000000000	False
intermediate operators	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
ultimate language	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
ultimate programming	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
concrete parts	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
concrete syntax	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
included parenthesis	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
mathematical language	0.000897994429271	0.0	0.0	1.0	0.0000000000	False
infix operators	0.0012752651328	1.0	0.0	1.0	0.0000000000	False
uniform post	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
post fix	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
fix notion	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
uniform prefix	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
prefix notion	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
avoid operators	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
language construct	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
giving meanings	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
arithmetic calculations	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
arbitrary expression	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
explicit dependency	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
arithmetic expression	0.000897994429271	0.0	0.0	1.0	0.0000000000	False
normal arithmetic	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
implicit order	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
apply multiplication	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
evaluation mechanisms	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
cross syntax	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
small programming	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
commands assignment	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
assignment sequencing	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
simple looping	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
looping command	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
valid programs	0.00255053026559	0.0	0.0	0.0	0.0000000000	False
giving rules	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
rules production	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
writing programs	0.000897994429271	0.0	0.0	0.0	0.0000000000	False
grammar notation	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
actual terminal	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
entities commands	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
dark brown	0.00207446764158	0.0	0.0	2.0	0.0000000000	False
atomic commands	0.00829787056633	1.0	11.9932088285	7.0	0.2926829268	True
light green	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
compound commands	0.00622340292475	0.0	8.99490662139	5.0	0.1967213115	True
light blue	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
actual program	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
color coding	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
program heading	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
rule specifies	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
full program	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
conditional command	0.00255053026559	0.0	0.0	2.0	0.0000000000	False
brown bars	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
command level	0.00510106053119	0.0	2.99660441426	3.0	0.3000000000	False
imperative languages	0.000897994429271	0.0	0.0	1.0	0.0000000000	False
statement level	0.0012752651328	1.0	0.0	1.0	0.0000000000	False
production level	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
program level	0.00255053026559	0.0	0.0	2.0	0.0000000000	False
form compound	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
simpler commands	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
simple command	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
semi colon	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
reserved word	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
conditional compound	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
commands inside	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
grammar specification	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
complete definition	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
assignment statement	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
hatch patch	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
patch grammar	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
constant true	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
terminal true	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
terminal false	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
separate entity	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
level specifies	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
simpler boolean	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
parenthesized notion	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
expression language	0.00414893528317	0.0	4.99660441426	3.0	0.4285714286	True
grammar supposing	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
first symbol	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
student speaking	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
value true	0.0012752651328	0.0	0.0	2.0	0.0000000000	False
unique meaning	0.00255053026559	0.0	0.0	1.0	0.0000000000	False
adequate representation	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
unique expression	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
initial handle	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
important constraint	0.00103723382079	0.0	0.0	1.0	0.0000000000	False
means running	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
running programs	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
executing programs	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
execution behavior	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
normal mathematical	0.00518616910396	0.0	9.99575551783	3.0	0.2385685885	False
mathematical notation	0.00269398328781	0.0	5.9974533107	1.0	0.0000000000	False
mathematical convention	0.00311170146237	0.0	5.9974533107	1.0	0.0000000000	False
tree supposing	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
syntactic ambiguity	0.00382579539839	1.0	4.9974533107	3.0	0.0000000000	False
precede addition	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
perfect bracketing	0.00255053026559	0.0	0.0	2.0	0.0000000000	False
conditional construct	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
provide ambiguity	0.0012752651328	0.0	0.0	1.0	0.0000000000	False
transcriptor	0.000242271114991	0.0	0.0	0.0	0.0000000000	False
v.srinivasa	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
rajkumar	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
educational	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
technology	0.000242271114991	0.0	0.0	0.0	0.0000000000	False
i.i.t	0.000799202508786	0.0	0.0	0.0	0.0000000000	False
delhi	0.00056117119678	0.0	0.0	0.0	0.0000000000	False
presents	0.000369766376966	0.0	0.0	0.0	0.0000000000	False
video	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
programming	0.00288799317006	0.0	0.0	0.0	0.2331428571	False
languages	0.0101473747493	0.0	0.0	0.0	0.3022670025	False
dr.s.arun	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
kumar	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
deptt	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
comp.sc	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
engg	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
lecture	5.94567714145e-05	0.0	0.0	0.0	0.0000000000	False
ambiguity	0.00589229756619	1.0	0.0	0.0	0.1959604641	True
today	2.23305508668e-05	0.0	0.0	0.0	0.0000000000	False
talk	6.86956326575e-05	0.0	0.0	0.0	0.3750000000	False
simple	0.000225013872702	0.0	0.0	0.0	0.3187855787	False
definition	0.000215179533328	0.0	0.0	0.0	0.0000000000	False
naturally	0.000198515745459	0.0	0.0	0.0	0.0000000000	False
back	4.25542863847e-05	0.0	0.0	0.0	0.0000000000	False
favorite	0.000799202508786	0.0	0.0	0.0	0.0000000000	False
grammar	0.0127872401406	0.0	0.0	0.0	0.2400000000	True
context	0.00135543625746	0.0	0.0	0.0	0.4137931034	False
free	0.00104144745149	0.0	0.0	0.0	0.5454545455	False
times	0.0	0.0	0.0	0.0	0.0000000000	False
sentence	0.0148721555571	0.0	0.0	0.0	0.4017765630	False
generated	0.000273987645353	0.0	0.0	0.0	0.3775280899	False
noise	0.000792376120403	0.0	0.0	0.0	0.0000000000	False
carefully	8.494097559e-05	0.0	0.0	0.0	0.0000000000	False
ultimate	0.00212459365102	0.0	0.0	0.0	0.4386422977	False
aim	0.000448997214635	0.0	0.0	0.0	0.0000000000	False
applied	0.00179875294638	0.0	0.0	0.0	0.3027975864	False
productions	0.00619758029337	0.0	0.0	0.0	0.2204794981	False
fired	0.00382579539839	0.0	0.0	0.0	0.3636363636	False
initially	0.000183900493254	0.0	0.0	0.0	0.0000000000	False
alternatives	0.000788889223381	0.0	0.0	0.0	0.5454545455	False
chose	0.00193816891993	0.0	0.0	0.0	0.2926829268	False
out	0.0	0.0	0.0	0.0	0.0000000000	False
possibilities	0.0025851190782	0.0	0.0	0.0	0.2470588235	False
right	0.0	0.0	0.0	0.0	0.5212858384	False
replaces	0.00371610867491	0.0	0.0	0.0	0.2255823457	False
identifier	0.000863257096156	0.0	0.0	0.0	0.4562737643	False
four	0.0	0.0	0.0	0.0	0.4800000000	False
fact	0.00025715871166	0.0	0.0	0.0	0.6000000000	False
give	4.66378328458e-05	0.0	0.0	0.0	0.4727694090	False
choices	0.000427561547628	0.0	0.0	0.0	0.4285714286	False
choose	0.00137853632345	0.0	0.0	0.0	0.3000000000	False
chosen	0.00239847039529	0.0	0.0	0.0	0.1885196375	False
two	0.0	0.0	0.0	0.0	0.3582089552	False
essentially	0.000260894838026	0.0	0.0	0.0	0.5014925373	False
sense	0.000260894838026	0.0	0.0	0.0	0.4386422977	False
produce	0.000553493168143	0.0	0.0	0.0	0.0000000000	False
end	1.76260566724e-05	0.0	0.0	0.0	0.0000000000	False
forced	0.000329981558633	0.0	0.0	0.0	0.0000000000	False
happened	4.25542863847e-05	0.0	0.0	0.0	0.0000000000	False
step	0.00011181207344	0.0	0.0	0.0	0.0000000000	False
first	0.0	0.0	0.0	0.0	0.4580152672	False
computed	2.23305508668e-05	0.0	0.0	0.0	0.0000000000	False
keeping	0.000520723725745	0.0	0.0	0.0	0.2385685885	False
mind	0.000528250746935	0.0	0.0	0.0	0.3000000000	False
open	0.00203315438619	0.0	0.0	0.0	0.2599277978	False
bracket	0.00145362668995	0.0	0.0	0.0	0.4137931034	False
supposing	0.000186353455733	0.0	0.0	0.0	0.3342618384	False
derivation	0.00468597534377	0.0	0.0	0.0	0.3040457703	False
order	0.000587116382899	0.0	0.0	0.0	0.2324080052	False
sachrosite	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
non	0.0	0.0	0.0	0.0	0.3977900552	False
terminals	0.00519583898692	0.0	0.0	0.0	0.3712172159	False
intermediate	0.00359197771708	0.0	0.0	0.0	0.3428571429	False
depending	0.000298165529173	0.0	0.0	0.0	0.3157894737	False
words	0.000130964133423	0.0	0.0	0.0	0.0000000000	False
matter	0.000804146188679	0.0	0.0	0.0	0.5014925373	False
leftmost	0.000518616910396	0.0	0.0	0.0	0.0000000000	False
symbol	0.0055722356448	0.0	0.0	0.0	0.3712172159	False
string	0.000903624171639	0.0	0.0	0.0	0.3000000000	False
violated	0.000242271114991	0.0	0.0	0.0	0.0000000000	False
left	0.000160907289685	0.0	0.0	0.0	0.0000000000	False
hand	0.000196446200135	0.0	0.0	0.0	0.0000000000	False
sides	7.82066498425e-05	0.0	0.0	0.0	0.0000000000	False
rule	0.000706731034348	0.0	0.0	0.0	0.5581395349	False
independent	0.000989423448087	0.0	0.0	0.0	0.2921739130	False
provided	0.000604641979841	0.0	0.0	0.0	0.4285714286	False
justify	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
number	8.47960597197e-06	0.0	0.0	0.0	0.0000000000	False
write	8.1502749939e-05	0.0	0.0	0.0	0.0000000000	False
justification	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
tells	0.000493021835955	0.0	0.0	0.0	0.4285714286	False
permute	0.00119880376318	0.0	0.0	0.0	0.0000000000	False
applications	0.0008494097559	0.0	0.0	0.0	0.3141361257	False
don	0.0	0.0	0.0	0.0	0.0000000000	False
means	5.93572418038e-05	0.0	0.0	0.0	0.3340471092	False
totally	0.000694805109105	0.0	0.0	0.0	0.4137931034	False
freeness	0.000518616910396	0.0	0.0	0.0	0.0000000000	False
stage	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
sacrocite	0.0012752651328	0.0	0.0	0.0	0.0000000000	False
amount	0.000123255458989	0.0	0.0	0.0	0.0000000000	False
interested	0.0010948930978	0.0	0.0	0.0	0.3054545455	False
actual	0.000493021835955	0.0	0.0	0.0	0.6059275521	False
place	0.00025482292677	0.0	0.0	0.0	0.0000000000	False
specific	0.000144016927654	0.0	0.0	0.0	0.0000000000	False
eventually	0.000424038620609	0.0	0.0	0.0	0.0000000000	False
partial	0.00494972337949	0.0	0.0	0.0	0.1815431165	False
specifies	0.00130180931436	0.0	0.0	0.0	0.5004533092	False
collapse	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
colas	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
draw	0.000213780773814	0.0	0.0	0.0	0.0000000000	False
tree	0.0124469882552	0.0	0.0	0.0	0.2177456559	False
exact	0.000303513378717	0.0	0.0	0.0	0.0000000000	False
parse	0.0107892338686	0.0	0.0	0.0	0.3012552301	False
root	0.000922488613572	0.0	0.0	0.0	0.3342618384	False
start	0.0	0.0	0.0	0.0	0.0000000000	False
written	0.00016988195118	0.0	0.0	0.0	0.0000000000	False
single	0.00016988195118	0.0	0.0	0.0	0.0000000000	False
parenthesis	0.00830959573287	0.0	0.0	0.0	0.2054335690	False
remember	0.000118913542829	0.0	0.0	0.0	0.0000000000	False
convention	0.000690605676925	0.0	0.0	0.0	0.4285714286	False
black	0.00140292799195	0.0	0.0	0.0	0.4562737643	False
denotes	0.000453481484881	0.0	0.0	0.0	0.0000000000	False
colors	0.000737990890858	0.0	0.0	0.0	0.5454545455	False
abstractions	0.002582968118	0.0	0.0	0.0	0.2809364548	False
close	0.000255325718308	0.0	0.0	0.0	0.2666666667	False
yielded	0.00134699164391	0.0	0.0	0.0	0.0000000000	False
point	3.81582268739e-05	0.0	0.0	0.0	0.4363636364	False
position	5.94567714145e-05	0.0	0.0	0.0	0.0000000000	False
original	9.92578727293e-05	0.0	0.0	0.0	0.0000000000	False
expanded	0.00308644158229	0.0	0.0	0.0	0.1209344938	False
perform	7.82066498425e-05	0.0	0.0	0.0	0.0000000000	False
reason	0.00032181457937	0.0	0.0	0.0	0.3636363636	False
brown	0.00311170146237	0.0	0.0	0.0	0.3243243243	False
obtain	0.00014134620687	0.0	0.0	0.0	0.0000000000	False
call	2.11990149299e-05	0.0	0.0	0.0	0.4195804196	False
branches	0.000607026757434	0.0	0.0	0.0	0.0000000000	False
leaves	0.000792376120403	0.0	0.0	0.0	0.2666666667	False
notice	0.00021096590263	0.0	0.0	0.0	0.0000000000	False
read	0.000234619949528	0.0	0.0	0.0	0.0000000000	False
necessarily	0.000323139884775	0.0	0.0	0.0	0.0000000000	False
unique	0.00242810702974	0.0	0.0	0.0	0.2926829268	False
defined	0.000382988577462	0.0	0.0	0.0	0.5208681135	False
important	0.000215179533328	0.0	0.0	0.0	0.0000000000	False
view	0.000706731034348	0.0	0.0	0.0	0.3858520900	False
compiling	0.00168351359034	0.0	0.0	0.0	0.4137931034	False
implementation	0.000459512107817	0.0	0.0	0.0	0.4285714286	False
semantics	0.000781085588617	0.0	0.0	0.0	0.0000000000	False
thing	0.0	0.0	0.0	0.0	0.5217391304	False
ways	0.000178370314243	0.0	0.0	0.0	0.5042016807	False
traversing	0.00164990779316	0.0	0.0	0.0	0.2385685885	False
summarize	0.000677718128729	0.0	0.0	0.0	0.0000000000	False
briefly	0.00015116049496	0.0	0.0	0.0	0.0000000000	False
decide	0.00016988195118	0.0	0.0	0.0	0.0000000000	False
linearization	0.000528250746935	0.0	0.0	0.0	0.2068965517	False
familiar	0.00014134620687	0.0	0.0	0.0	0.0000000000	False
topological	0.000897994429271	0.0	0.0	0.0	0.0000000000	False
sorting	0.000192022570205	0.0	0.0	0.0	0.3000000000	False
takes	4.25542863847e-05	0.0	0.0	0.0	0.3750000000	False
elements	9.19502466271e-05	0.0	0.0	0.0	0.0000000000	False
maintained	0.000303513378717	0.0	0.0	0.0	0.0000000000	False
exists	0.000264125373468	0.0	0.0	0.0	0.0000000000	False
true	0.00067952780472	0.0	0.0	0.0	0.3750000000	False
completely	0.000160724194787	0.0	0.0	0.0	0.4562737643	False
set	6.52351536555e-05	0.0	0.0	0.0	0.2385685885	False
make	6.86956326575e-05	0.0	0.0	0.0	0.3157894737	False
past	0.000518616910396	0.0	0.0	0.0	0.0000000000	False
fundamental	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
property	7.82066498425e-05	0.0	0.0	0.0	0.0000000000	False
theory	0.000184497722714	0.0	0.0	0.0	0.0000000000	False
consisting	0.000172651419231	0.0	0.0	0.0	0.0000000000	False
syntactical	0.00325158093895	0.0	0.0	0.0	0.2938775510	False
def	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
doesn	0.0	0.0	0.0	0.0	0.0000000000	False
concerned	0.000396188060202	0.0	0.0	0.0	0.0000000000	False
stream	0.000659963117265	0.0	0.0	0.0	0.0000000000	False
coming	0.000123255458989	0.0	0.0	0.0	0.5454545455	False
kind	7.05042266896e-05	0.0	0.0	0.0	0.5454545455	False
implicit	0.000781085588617	0.0	0.0	0.0	0.0000000000	False
type	9.19502466271e-05	0.0	0.0	0.0	0.0000000000	False
distinguished	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
clear	0.00042470487795	0.0	0.0	0.0	0.3858520900	False
distinction	0.00319681003514	1.0	0.0	0.0	0.2727272727	False
operator	0.00118913542829	0.0	0.0	0.0	0.2097902098	False
concrete	0.00135543625746	0.0	0.0	0.0	0.4800000000	False
operands	0.00404097493172	0.0	0.0	0.0	0.2599277978	False
previously	0.00030232098992	0.0	0.0	0.0	0.0000000000	False
intention	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
boolean	0.00890950208308	0.0	0.0	0.0	0.1288014311	False
expressions	0.00549337804117	0.0	0.0	0.0	0.1829596413	False
variables	0.000367800986508	0.0	0.0	0.0	0.4285714286	False
leads	0.000242271114991	0.0	0.0	0.0	0.0000000000	False
syntax	0.00975474281684	0.0	0.0	0.0	0.1933751119	False
elevates	0.00155585073119	0.0	0.0	0.0	0.0000000000	False
designed	0.000246510917977	0.0	0.0	0.0	0.0000000000	False
easily	0.000161569942387	0.0	0.0	0.0	0.0000000000	False
nodes	0.000368995445429	0.0	0.0	0.0	0.0000000000	False
absolutely	0.00103590851539	0.0	0.0	0.0	0.3636363636	False
full	0.00030232098992	0.0	0.0	0.0	0.0000000000	False
proof	0.000197222305845	0.0	0.0	0.0	0.0000000000	False
parts	1.71739081644e-05	0.0	0.0	0.0	0.0000000000	False
real	7.17265111092e-05	0.0	0.0	0.0	0.0000000000	False
earth	0.000399601254393	0.0	0.0	0.0	0.0000000000	False
road	0.000448997214635	0.0	0.0	0.0	0.0000000000	False
bring	0.00021096590263	0.0	0.0	0.0	0.0000000000	False
included	0.000123255458989	0.0	0.0	0.0	0.0000000000	False
mathematical	0.00138055614092	0.0	0.0	0.0	0.2696629213	False
infix	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
uniform	0.000520723725745	0.0	0.0	0.0	0.0000000000	False
post	0.000197222305845	0.0	0.0	0.0	0.0000000000	False
fix	0.00015116049496	0.0	0.0	0.0	0.0000000000	False
notion	0.000297773618188	0.0	0.0	0.0	0.0000000000	False
prefix	0.000518616910396	0.0	0.0	0.0	0.0000000000	False
avoid	0.00022590604291	0.0	0.0	0.0	0.0000000000	False
construct	0.000989423448087	0.0	0.0	0.0	0.2696629213	False
regarded	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
arithmetic	0.000726813344974	0.0	0.0	0.0	0.0000000000	False
calculations	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
school	0.00028058559839	0.0	0.0	0.0	0.0000000000	False
arbitrary	0.000197222305845	0.0	0.0	0.0	0.0000000000	False
evaluating	0.00166047950443	0.0	0.0	0.0	0.2938775510	False
explicit	0.00028058559839	0.0	0.0	0.0	0.0000000000	False
multiplied	0.00042193180526	0.0	0.0	0.0	0.0000000000	False
normal	0.000595547236376	0.0	0.0	0.0	0.2666666667	False
multiplication	0.000755802474801	0.0	0.0	0.0	0.2948402948	False
addition	0.000427561547628	0.0	0.0	0.0	0.3529411765	False
mechanisms	0.000184497722714	0.0	0.0	0.0	0.0000000000	False
oftenly	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
cross	0.00015116049496	0.0	0.0	0.0	0.0000000000	False
small	2.7167583313e-05	0.0	0.0	0.0	0.0000000000	False
amazingly	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
useless	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
declarations	0.000394444611691	0.0	0.0	0.0	0.0000000000	False
commands	0.0118793361108	0.0	0.0	0.0	0.1034482759	False
assignment	0.000528250746935	0.0	0.0	0.0	0.4285714286	False
sequencing	0.000595547236376	0.0	0.0	0.0	0.3342618384	False
conditional	0.000862788212921	0.0	0.0	0.0	0.3507306889	False
looping	0.00042193180526	0.0	0.0	0.0	0.0000000000	False
valid	0.00121405351487	0.0	0.0	0.0	0.2068965517	False
question	1.76260566724e-05	0.0	0.0	0.0	0.0000000000	False
formalizing	0.000161569942387	0.0	0.0	0.0	0.0000000000	False
build	0.00014134620687	0.0	0.0	0.0	0.0000000000	False
translator	0.00063289770789	0.0	0.0	0.0	0.0000000000	False
problems	3.43478163288e-05	0.0	0.0	0.0	0.4285714286	False
purposes	9.92578727293e-05	0.0	0.0	0.0	0.0000000000	False
require	7.82066498425e-05	0.0	0.0	0.0	0.0000000000	False
great	8.494097559e-05	0.0	0.0	0.0	0.0000000000	False
detail	6.54820667117e-05	0.0	0.0	0.0	0.0000000000	False
coding	0.000320671160721	0.0	0.0	0.0	0.0000000000	False
notation	0.000660313433669	0.0	0.0	0.0	0.3858520900	False
bark	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
entities	0.000520723725745	0.0	0.0	0.0	0.0000000000	False
dark	0.000799202508786	0.0	0.0	0.0	0.0000000000	False
atomic	0.00395977870359	0.0	0.0	0.0	0.2727272727	False
light	0.000520723725745	0.0	0.0	0.0	0.0000000000	False
green	0.00022590604291	0.0	0.0	0.0	0.0000000000	False
compound	0.00279720878075	0.0	0.0	0.0	0.2190352021	False
blue	0.000368995445429	0.0	0.0	0.0	0.0000000000	False
change	0.000127662859154	0.0	0.0	0.0	0.0000000000	False
inform	0.000106890386907	0.0	0.0	0.0	0.0000000000	False
top	0.00025482292677	0.0	0.0	0.0	0.0000000000	False
fashion	0.000184497722714	0.0	0.0	0.0	0.0000000000	False
unlike	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
pascal	0.00144514708398	0.0	0.0	0.0	0.4285714286	False
heading	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
bars	0.000607026757434	0.0	0.0	0.0	0.0000000000	False
arrow	0.000843863610519	0.0	0.0	0.0	0.3000000000	False
semicolon	0.000329981558633	0.0	0.0	0.0	0.0000000000	False
level	0.00109183660002	0.0	0.0	0.0	0.1507709880	False
imperative	0.000448997214635	0.0	0.0	0.0	0.0000000000	False
statement	0.000264125373468	0.0	0.0	0.0	0.0000000000	False
terms	2.23305508668e-05	0.0	0.0	0.0	0.0000000000	False
form	8.1502749939e-05	0.0	0.0	0.0	0.0000000000	False
simpler	0.00042193180526	0.0	0.0	0.0	0.0000000000	False
semi	0.000518616910396	0.0	0.0	0.0	0.0000000000	False
colon	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
reserved	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
inside	0.000229756053908	0.0	0.0	0.0	0.0000000000	False
assume	0.000130964133423	0.0	0.0	0.0	0.0000000000	False
variation	0.000242271114991	0.0	0.0	0.0	0.0000000000	False
hatch	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
patch	0.000448997214635	0.0	0.0	0.0	0.0000000000	False
constant	0.000114878026954	0.0	0.0	0.0	0.0000000000	False
false	0.00151756689359	0.0	0.0	0.0	0.3858520900	False
separate	0.000106890386907	0.0	0.0	0.0	0.0000000000	False
fully	0.000329981558633	0.0	0.0	0.0	0.0000000000	False
parenthesized	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
enclosed	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
rid	0.000329981558633	0.0	0.0	0.0	0.0000000000	False
easy	0.00015116049496	0.0	0.0	0.0	0.0000000000	False
student	0.000660313433669	0.0	0.0	0.0	0.0000000000	False
speaking	0.000451812085819	0.0	0.0	0.0	0.0000000000	False
affect	0.00028058559839	0.0	0.0	0.0	0.0000000000	False
value	8.494097559e-05	0.0	0.0	0.0	0.2068965517	False
falls	0.000172651419231	0.0	0.0	0.0	0.0000000000	False
short	0.000242271114991	0.0	0.0	0.0	0.0000000000	False
adequate	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
representation	0.000132062686734	0.0	0.0	0.0	0.0000000000	False
media	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
handle	0.00022590604291	0.0	0.0	0.0	0.0000000000	False
constraint	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
running	3.72706911466e-05	0.0	0.0	0.0	0.0000000000	False
executing	0.000451812085819	0.0	0.0	0.0	0.0000000000	False
interpreted	0.000451812085819	0.0	0.0	0.0	0.0000000000	False
user	0.000161569942387	0.0	0.0	0.0	0.0000000000	False
agreement	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
consequences	0.00028058559839	0.0	0.0	0.0	0.0000000000	False
behavior	0.00021096590263	0.0	0.0	0.0	0.0000000000	False
lot	0.000118913542829	0.0	0.0	0.0	0.0000000000	False
unambiguous	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
implicitly	0.000361286770994	0.0	0.0	0.0	0.0000000000	False
remove	0.00063289770789	0.0	0.0	0.0	0.0000000000	False
precedence	0.000607026757434	0.0	0.0	0.0	0.0000000000	False
ensures	0.00028058559839	0.0	0.0	0.0	0.0000000000	False
wise	0.000329981558633	0.0	0.0	0.0	0.0000000000	False
dangling	0.000637632566398	0.0	0.0	0.0	0.0000000000	False
difference	8.58695408219e-06	0.0	0.0	0.0	0.3173957274	False
firstly	0.000260361862872	0.0	0.0	0.0	0.0000000000	False
perfect	0.000722573541988	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.0000000000	False
yesterday	0.00103723382079	0.0	0.0	0.0	0.0000000000	False
v.srinivasa rajkumar educational technology	0.0	0.0	0.0	2.0	0.0000000000	False
rajkumar educational technology i.i.t	0.0	0.0	0.0	2.0	0.0000000000	False
educational technology i.i.t delhi	0.0	0.0	0.0	2.0	0.0000000000	False
technology i.i.t delhi presents	0.0	0.0	0.0	2.0	0.0000000000	False
delhi presents a video	0.0	0.0	0.0	2.0	0.0000000000	False
video course on programming	0.0	0.0	0.0	2.0	0.0000000000	False
languages by dr.s.arun kumar	0.0	0.0	0.0	2.0	0.0000000000	False
kumar deptt of comp.sc	0.0	0.0	0.0	2.0	0.0000000000	False
syntax welcome to lecture	0.0	0.0	0.0	2.0	0.0000000000	False
lecture five so today	0.0	0.0	0.0	2.0	0.0000000000	False
slightly more complicated programming	0.0	0.0	0.0	2.0	0.0000000000	False
brown i will change	0.0	0.0	0.0	2.0	0.0000000000	False
change um so programs	0.0	0.0	0.0	2.0	0.0000000000	False
commands and atomic commands	0.0	0.0	0.0	2.0	0.0000000000	False
commands and a context	0.0	0.0	0.0	2.0	0.0000000000	False
context free grammar notation	0.0	0.0	0.0	4.0	0.0000000000	False
grammar notation will remain	0.0	0.0	0.0	2.0	0.0000000000	False
grammar firstly the grammar	0.0	0.0	0.0	2.0	0.0000000000	False
black are reserve words	0.0	0.0	0.0	2.0	0.0000000000	False
reserve words so including	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous if there exists	0.0	0.0	0.0	2.0	0.0000000000	False
sentence in the language	0.0	0.0	0.0	2.0	0.0000000000	False
tree the same sentence	0.0	0.0	0.0	2.0	0.0000000000	False
tree because the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
tree is just obtained	0.0	0.0	0.0	2.0	0.0000000000	False
obtained from the parse	0.0	0.0	0.0	2.0	0.0000000000	False
parse tree by elevating	0.0	0.0	0.0	2.0	0.0000000000	False
operators to the root	0.0	0.0	0.0	2.0	0.0000000000	False
root nodes and replacing	0.0	0.0	0.0	2.0	0.0000000000	False
restricted class of parse	0.0	0.0	0.0	2.0	0.0000000000	False
class of parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
conditional and the loop	0.0	0.0	0.0	2.0	0.0000000000	False
loop i have eliminated	0.0	0.0	0.0	2.0	0.0000000000	False
introducing two reserved words	0.0	0.0	0.0	2.0	0.0000000000	False
words the closing bracket	0.0	0.0	0.0	2.0	0.0000000000	False
composition or the sequencing	0.0	0.0	0.0	2.0	0.0000000000	False
binary operator on commands	0.0	0.0	0.0	2.0	0.0000000000	False
assume c one semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon c two semicolon	0.0	0.0	0.0	4.0	0.0000000000	False
semicolon c three semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
atomic or compound commands	0.0	0.0	0.0	2.0	0.0000000000	False
compound commands i don	0.0	0.0	0.0	2.0	0.0000000000	False
two different parse trees	0.0	0.0	0.0	2.0	0.0000000000	False
triangles here to denote	0.0	0.0	0.0	2.0	0.0000000000	False
denote that these seats	0.0	0.0	0.0	2.0	0.0000000000	False
commands themselves can expand	0.0	0.0	0.0	2.0	0.0000000000	False
first this first semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon is the root	0.0	0.0	0.0	4.0	0.0000000000	False
semicolon is a right	0.0	0.0	0.0	2.0	0.0000000000	False
circle is a root	0.0	0.0	0.0	2.0	0.0000000000	False
root of the right	0.0	0.0	0.0	2.0	0.0000000000	False
case in which case	0.0	0.0	0.0	2.0	0.0000000000	False
root of the left	0.0	0.0	0.0	2.0	0.0000000000	False
root of the tree	0.0	0.0	0.0	2.0	0.0000000000	False
tree so strictly speaking	0.0	0.0	0.0	2.0	0.0000000000	False
speaking there is ambiguity	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguity in this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
operation in any programming	0.0	0.0	0.0	2.0	0.0000000000	False
two trees really correspond	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to different bracketing	0.0	0.0	0.0	2.0	0.0000000000	False
tree for example corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to the bracketing	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to the case	0.0	0.0	0.0	2.0	0.0000000000	False
right so this corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
two the whole thing	0.0	0.0	0.0	2.0	0.0000000000	False
semicolon c three right	0.0	0.0	0.0	2.0	0.0000000000	False
general um sequencing operation	0.0	0.0	0.0	2.0	0.0000000000	False
operation and the function	0.0	0.0	0.0	2.0	0.0000000000	False
implementation of the language	0.0	0.0	0.0	2.0	0.0000000000	False
regard to the semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
operation so the fact	0.0	0.0	0.0	2.0	0.0000000000	False
ambiguous does not matter	0.0	0.0	0.0	2.0	0.0000000000	False
behavior or the meanings	0.0	0.0	0.0	2.0	0.0000000000	False
meanings of the programs	0.0	0.0	0.0	2.0	0.0000000000	False
case things can change	0.0	0.0	0.0	2.0	0.0000000000	False
expression of boolean expressions	0.0	0.0	0.0	2.0	0.0000000000	False
value of boolean expression	0.0	0.0	0.0	2.0	0.0000000000	False
parse the boolean expression	0.0	0.0	0.0	2.0	0.0000000000	False
languages since algol sixty	0.0	0.0	0.0	2.0	0.0000000000	False
sixty use a notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation called the backus	0.0	0.0	0.0	2.0	0.0000000000	False
created by john backus	0.0	0.0	0.0	2.0	0.0000000000	False
john backus and peter	0.0	0.0	0.0	2.0	0.0000000000	False
backus and peter naur	0.0	0.0	0.0	2.0	0.0000000000	False
naur in the definition	0.0	0.0	0.0	2.0	0.0000000000	False
algol sixty the algol	0.0	0.0	0.0	2.0	0.0000000000	False
sixty the algol sixty	0.0	0.0	0.0	2.0	0.0000000000	False
rigorous syntactic form based	0.0	0.0	0.0	2.0	0.0000000000	False
free grammars to define	0.0	0.0	0.0	2.0	0.0000000000	False
define the language abs	0.0	0.0	0.0	2.0	0.0000000000	False
involved in the creation	0.0	0.0	0.0	2.0	0.0000000000	False
fortan language every fortan	0.0	0.0	0.0	2.0	0.0000000000	False
language every fortan compiler	0.0	0.0	0.0	2.0	0.0000000000	False
written by various people	0.0	0.0	0.0	2.0	0.0000000000	False
people gave different interpretations	0.0	0.0	0.0	2.0	0.0000000000	False
interpretations to the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
fortan comp fortan programs	0.0	0.0	0.0	2.0	0.0000000000	False
treated um the fortan	0.0	0.0	0.0	2.0	0.0000000000	False
compiler and moving programs	0.0	0.0	0.0	2.0	0.0000000000	False
machine or one compiler	0.0	0.0	0.0	2.0	0.0000000000	False
compiler to another compiler	0.0	0.0	0.0	2.0	0.0000000000	False
problem in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that you required	0.0	0.0	0.0	2.0	0.0000000000	False
required a whole team	0.0	0.0	0.0	2.0	0.0000000000	False
suit the new compiler	0.0	0.0	0.0	2.0	0.0000000000	False
architecture of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
machine or it required	0.0	0.0	0.0	2.0	0.0000000000	False
patching up of programs	0.0	0.0	0.0	2.0	0.0000000000	False
form of theoretical study	0.0	0.0	0.0	2.0	0.0000000000	False
theoretical study and backus	0.0	0.0	0.0	2.0	0.0000000000	False
backus and naur define	0.0	0.0	0.0	2.0	0.0000000000	False
naur define the algol	0.0	0.0	0.0	2.0	0.0000000000	False
define the algol sixty	0.0	0.0	0.0	2.0	0.0000000000	False
language using this notation	0.0	0.0	0.0	2.0	0.0000000000	False
single symbol um single	0.0	0.0	0.0	2.0	0.0000000000	False
symbol um single character	0.0	0.0	0.0	2.0	0.0000000000	False
character non terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
words so they wrote	0.0	0.0	0.0	2.0	0.0000000000	False
statements within angle brackets	0.0	0.0	0.0	2.0	0.0000000000	False
mark on the type	0.0	0.0	0.0	2.0	0.0000000000	False
wrote all the productions	0.0	0.0	0.0	2.0	0.0000000000	False
productions in this form	0.0	0.0	0.0	2.0	0.0000000000	False
full the non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
non terminals being enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
enclosed in angle brackets	0.0	0.0	0.0	2.0	0.0000000000	False
brackets and the arrow	0.0	0.0	0.0	2.0	0.0000000000	False
double colon and equals	0.0	0.0	0.0	2.0	0.0000000000	False
extended backus naur form	0.0	0.0	3.99786019971	6.0	0.0000000000	False
convince we should remember	0.0	0.0	0.0	2.0	0.0000000000	False
means is the introduction	0.0	0.0	0.0	2.0	0.0000000000	False
introduction of new non	0.0	0.0	0.0	2.0	0.0000000000	False
terminal symbols to aloow	0.0	0.0	0.0	2.0	0.0000000000	False
aloow for those kinds	0.0	0.0	0.0	2.0	0.0000000000	False
essentially uses the backus	0.0	0.0	0.0	2.0	0.0000000000	False
backus naur form extended	0.0	0.0	0.0	2.0	0.0000000000	False
form extended to include	0.0	0.0	0.0	2.0	0.0000000000	False
extended to include iterations	0.0	0.0	0.0	2.0	0.0000000000	False
include iterations in choice	0.0	0.0	0.0	2.0	0.0000000000	False
backus naur form production	0.0	0.0	0.0	2.0	0.0000000000	False
production of this form	0.0	0.0	2.99786019971	6.0	0.0000000000	False
form ok where alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha beta and gamma	0.0	0.0	0.0	2.0	0.0000000000	False
terminals or non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
notation for the backus	0.0	0.0	0.0	2.0	0.0000000000	False
backus naur form notation	0.0	0.0	0.0	2.0	0.0000000000	False
set of non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon or to beta	0.0	0.0	0.0	2.0	0.0000000000	False
notation this extended backus	0.0	0.0	0.0	2.0	0.0000000000	False
extended backus form notation	0.0	0.0	0.0	2.0	0.0000000000	False
machine if you run	0.0	0.0	0.0	2.0	0.0000000000	False
run the man pages	0.0	0.0	0.0	2.0	0.0000000000	False
pages for some command	0.0	0.0	0.0	2.0	0.0000000000	False
command you will find	0.0	0.0	0.0	2.0	0.0000000000	False
brackets of one kind	0.0	0.0	0.0	2.0	0.0000000000	False
square brackets to represent	0.0	0.0	0.0	2.0	0.0000000000	False
represent the various options	0.0	0.0	0.0	2.0	0.0000000000	False
options the several options	0.0	0.0	0.0	2.0	0.0000000000	False
options are either separated	0.0	0.0	0.0	2.0	0.0000000000	False
equivalent to this set	0.0	0.0	0.0	2.0	0.0000000000	False
definition of a programming	0.0	0.0	0.0	2.0	0.0000000000	False
aide in writing out	0.0	0.0	0.0	2.0	0.0000000000	False
writing out a grammar	0.0	0.0	0.0	2.0	0.0000000000	False
logical significance you wouldn	0.0	0.0	0.0	2.0	0.0000000000	False
allowed both the statements	0.0	0.0	0.0	2.0	0.0000000000	False
clause is an option	0.0	0.0	0.0	2.0	0.0000000000	False
ideally could be sep	0.0	0.0	0.0	2.0	0.0000000000	False
entity so you wouldn	0.0	0.0	0.0	2.0	0.0000000000	False
put that else clause	0.0	0.0	0.0	2.0	0.0000000000	False
clause in the definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of your language	0.0	0.0	0.0	2.0	0.0000000000	False
language if your language	0.0	0.0	0.0	2.0	0.0000000000	False
allowed an else clause	0.0	0.0	0.0	2.0	0.0000000000	False
put the else clause	0.0	0.0	0.0	2.0	0.0000000000	False
amount of the number	0.0	0.0	0.0	2.0	0.0000000000	False
non terminal symbols remember	0.0	0.0	0.0	2.0	0.0000000000	False
remember that a programming	0.0	0.0	0.0	2.0	0.0000000000	False
language a real world	0.0	0.0	0.0	2.0	0.0000000000	False
real world programming language	0.0	0.0	0.0	2.0	0.0000000000	False
large piece of syntax	0.0	0.0	0.0	2.0	0.0000000000	False
adding these extra non	0.0	0.0	0.0	2.0	0.0000000000	False
significance for the compiler	0.0	0.0	0.0	2.0	0.0000000000	False
compiler which have significance	0.0	0.0	0.0	2.0	0.0000000000	False
accurately specifying the language	0.0	0.0	0.0	2.0	0.0000000000	False
language but other wise	0.0	0.0	0.0	2.0	0.0000000000	False
respect to ambiguity parsing	0.0	0.0	0.0	2.0	0.0000000000	False
significance from the non	0.0	0.0	0.0	2.0	0.0000000000	False
repetitions of some option	0.0	0.0	0.0	2.0	0.0000000000	False
alpha within braces beta	0.0	0.0	0.0	2.0	0.0000000000	False
productions of the form	0.0	0.0	0.0	2.0	0.0000000000	False
repetitions of the string	0.0	0.0	0.0	2.0	0.0000000000	False
production of the string	0.0	0.0	0.0	2.0	0.0000000000	False
denotes a zero number	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of a beta	0.0	0.0	0.0	2.0	0.0000000000	False
pascal manual the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
manual the syntax diagrams	0.0	0.0	0.0	2.0	0.0000000000	False
follow the arrow marks	0.0	0.0	0.0	2.0	0.0000000000	False
marks in the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
give you the productions	0.0	0.0	0.0	2.0	0.0000000000	False
ordinary context free notation	0.0	0.0	0.0	2.0	0.0000000000	False
reading manuals for learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning a new language	0.0	0.0	0.0	2.0	0.0000000000	False
last time we looked	0.0	0.0	0.0	2.0	0.0000000000	False
looked at a toy	0.0	0.0	0.0	2.0	0.0000000000	False
toy language which didn	0.0	0.0	0.0	2.0	0.0000000000	False
designed for the purposes	0.0	0.0	0.0	2.0	0.0000000000	False
purposes of teaching programming	0.0	0.0	0.0	2.0	0.0000000000	False
teaching programming languages compilers	0.0	0.0	0.0	2.0	0.0000000000	False
first course by nicolas	0.0	0.0	0.0	2.0	0.0000000000	False
worth himself the designer	0.0	0.0	0.0	2.0	0.0000000000	False
type the main features	0.0	0.0	0.0	2.0	0.0000000000	False
assignment sequencing bracketing looping	0.0	0.0	0.0	2.0	0.0000000000	False
arm conditional that means	0.0	0.0	0.0	2.0	0.0000000000	False
two one arm conditions	0.0	0.0	0.0	2.0	0.0000000000	False
arm conditions in sequence	0.0	0.0	0.0	2.0	0.0000000000	False
wise refinement of programs	0.0	0.0	0.0	2.0	0.0000000000	False
programs to be written	0.0	0.0	0.0	2.0	0.0000000000	False
written in a structured	0.0	0.0	0.0	2.0	0.0000000000	False
true to be nested	0.0	0.0	0.0	2.0	0.0000000000	False
refinement in the development	0.0	0.0	0.0	2.0	0.0000000000	False
equals for a production	0.0	0.0	0.0	2.0	0.0000000000	False
fashion so a program	0.0	0.0	0.0	2.0	0.0000000000	False
program my start symbol	0.0	0.0	0.0	2.0	0.0000000000	False
symbols and the non	0.0	0.0	0.0	2.0	0.0000000000	False
explicitly specify the terminals	0.0	0.0	0.0	2.0	0.0000000000	False
terminals and the non	0.0	0.0	0.0	2.0	0.0000000000	False
black and the non	0.0	0.0	0.0	2.0	0.0000000000	False
terminates with a dot	0.0	0.0	0.0	2.0	0.0000000000	False
dot with a period	0.0	0.0	0.0	2.0	0.0000000000	False
case of pascal programs	0.0	0.0	0.0	2.0	0.0000000000	False
pascal programs you terminate	0.0	0.0	0.0	2.0	0.0000000000	False
program with a dot	0.0	0.0	0.0	2.0	0.0000000000	False
dot right a block	0.0	0.0	0.0	2.0	0.0000000000	False
right a block consists	0.0	0.0	0.0	2.0	0.0000000000	False
consists of a declaration	0.0	0.0	0.0	4.0	0.0000000000	False
declaration and a statement	0.0	0.0	0.0	2.0	0.0000000000	False
names for the non	0.0	0.0	0.0	2.0	0.0000000000	False
single um single letter	0.0	0.0	0.0	2.0	0.0000000000	False
letter non terminal symbols	0.0	0.0	0.0	2.0	0.0000000000	False
enclosed in light brown	0.0	0.0	0.0	2.0	0.0000000000	False
constant declaration a constant	0.0	0.0	0.0	2.0	0.0000000000	False
declaration a constant declaration	0.0	0.0	0.0	2.0	0.0000000000	False
constant declaration which means	0.0	0.0	0.0	2.0	0.0000000000	False
means this word const	0.0	0.0	0.0	2.0	0.0000000000	False
const is a reserved	0.0	0.0	0.0	2.0	0.0000000000	False
put these in dark	0.0	0.0	0.0	2.0	0.0000000000	False
reason i have put	0.0	0.0	0.0	2.0	0.0000000000	False
put them in dark	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
infinite set of numbers	0.0	0.0	0.0	2.0	0.0000000000	False
syntax the actual limits	0.0	0.0	0.0	2.0	0.0000000000	False
limits on the numbers	0.0	0.0	0.0	2.0	0.0000000000	False
numbers and the lengths	0.0	0.0	0.0	2.0	0.0000000000	False
lengths of the identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
part of the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
definition of the language	0.0	0.0	0.0	2.0	0.0000000000	False
light um this dark	0.0	0.0	0.0	2.0	0.0000000000	False
phase value as identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of data type	0.0	0.0	0.0	4.0	0.0000000000	False
commas so the commas	0.0	0.0	0.0	2.0	0.0000000000	False
commas are reserved word	0.0	0.0	0.0	2.0	0.0000000000	False
word of this language	0.0	0.0	0.0	2.0	0.0000000000	False
moment the word const	0.0	0.0	0.0	2.0	0.0000000000	False
occurrences of the clause	0.0	0.0	0.0	2.0	0.0000000000	False
terminated by a semi	0.0	0.0	3.99714693295	8.0	0.2978723404	False
single declaration and terminate	0.0	0.0	0.0	2.0	0.0000000000	False
constants the um terminate	0.0	0.0	0.0	2.0	0.0000000000	False
terminate the entire declaration	0.0	0.0	0.0	2.0	0.0000000000	False
declaration by a semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
declarations but you don	0.0	0.0	0.0	2.0	0.0000000000	False
variables separated by commas	0.0	0.0	0.0	2.0	0.0000000000	False
commas but the moment	0.0	0.0	0.0	2.0	0.0000000000	False
moment and the moment	0.0	0.0	0.0	2.0	0.0000000000	False
reserved word var occurring	0.0	0.0	0.0	2.0	0.0000000000	False
procedures and a procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedure has a procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedure as a reserved	0.0	0.0	0.0	2.0	0.0000000000	False
entire the entire procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedures in your program	0.0	0.0	0.0	2.0	0.0000000000	False
clauses they should occur	0.0	0.0	0.0	2.0	0.0000000000	False
occur in this order	0.0	0.0	0.0	2.0	0.0000000000	False
declarations this so declarations	0.0	0.0	0.0	2.0	0.0000000000	False
implicitly allows the production	0.0	0.0	0.0	2.0	0.0000000000	False
means an empty string	0.0	0.0	0.0	2.0	0.0000000000	False
case but a statement	0.0	0.0	0.0	2.0	0.0000000000	False
assignment an assignment statement	0.0	0.0	0.0	2.0	0.0000000000	False
statement is a statement	0.0	0.0	0.0	2.0	0.0000000000	False
statement where an assignment	0.0	0.0	0.0	2.0	0.0000000000	False
identifier um colon equals	0.0	0.0	0.0	2.0	0.0000000000	False
colon equals an expression	0.0	0.0	0.0	2.0	0.0000000000	False
equals an expression note	0.0	0.0	0.0	2.0	0.0000000000	False
relation between what identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
declared in this declaration	0.0	0.0	0.0	2.0	0.0000000000	False
declaration and what identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
statement so the syntax	0.0	0.0	0.0	2.0	0.0000000000	False
free but the language	0.0	0.0	0.0	2.0	0.0000000000	False
syntax of the language	0.0	0.0	0.0	4.0	0.0000000000	False
explicit procedure called statement	0.0	0.0	0.0	2.0	0.0000000000	False
identifier and implicit meaning	0.0	0.0	0.0	2.0	0.0000000000	False
declared as a procedure	0.0	0.0	0.0	2.0	0.0000000000	False
call is a reserved	0.0	0.0	0.0	2.0	0.0000000000	False
condition then a statement	0.0	0.0	0.0	2.0	0.0000000000	False
statement this whole thing	0.0	0.0	0.0	2.0	0.0000000000	False
statements you can call	0.0	0.0	0.0	2.0	0.0000000000	False
call as a sequence	0.0	0.0	0.0	2.0	0.0000000000	False
pair of brackets begin	0.0	0.0	0.0	2.0	0.0000000000	False
separated by a semicolon	0.0	0.0	0.0	2.0	0.0000000000	False
define in the end	0.0	0.0	0.0	2.0	0.0000000000	False
defined at the expense	0.0	0.0	0.0	2.0	0.0000000000	False
introducing new non terminals	0.0	0.0	0.0	2.0	0.0000000000	False
condition well the language	0.0	0.0	0.0	2.0	0.0000000000	False
expression e um note	0.0	0.0	0.0	2.0	0.0000000000	False
type available is integers	0.0	0.0	0.0	2.0	0.0000000000	False
integers the only expressions	0.0	0.0	0.0	2.0	0.0000000000	False
unary data type applies	0.0	0.0	0.0	2.0	0.0000000000	False
applies over all expressions	0.0	0.0	0.0	2.0	0.0000000000	False
unary condition this unary	0.0	0.0	0.0	2.0	0.0000000000	False
condition this unary predicate	0.0	0.0	0.0	2.0	0.0000000000	False
applies over all condi	0.0	0.0	0.0	2.0	0.0000000000	False
condi over all expressions	0.0	0.0	0.0	2.0	0.0000000000	False
predicate some unary predicate	0.0	0.0	0.0	2.0	0.0000000000	False
reason for choosing odd	0.0	0.0	0.0	2.0	0.0000000000	False
jump on not equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals in most hardware	0.0	0.0	0.0	2.0	0.0000000000	False
programs a large number	0.0	0.0	0.0	2.0	0.0000000000	False
number of your programs	0.0	0.0	0.0	2.0	0.0000000000	False
cases you could check	0.0	0.0	0.0	2.0	0.0000000000	False
simplified the original language	0.0	0.0	0.0	2.0	0.0000000000	False
single letter relational symbols	0.0	0.0	0.0	2.0	0.0000000000	False
greater than or equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals this is equals	0.0	0.0	0.0	2.0	0.0000000000	False
compiler for example allowed	0.0	0.0	0.0	2.0	0.0000000000	False
original pl zero compiler	0.0	0.0	0.0	2.0	0.0000000000	False
case of the expression	0.0	0.0	0.0	2.0	0.0000000000	False
two diff two extremes	0.0	0.0	0.0	2.0	0.0000000000	False
addition subtraction multiplication division	0.0	0.0	0.0	4.0	0.0000000000	False
sum of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
two expressions a difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
two expressions a product	0.0	0.0	0.0	2.0	0.0000000000	False
product of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions or a quotient	0.0	0.0	0.0	2.0	0.0000000000	False
quotient of two expressions	0.0	0.0	0.0	2.0	0.0000000000	False
sequences which you understand	0.0	0.0	0.0	2.0	0.0000000000	False
priority order of evaluation	0.0	0.0	0.0	2.0	0.0000000000	False
define the expression language	0.0	0.0	0.0	4.0	0.0000000000	False
variable is an expression	0.0	0.0	0.0	2.0	0.0000000000	False
constant an integer constant	0.0	0.0	0.0	2.0	0.0000000000	False
statements of this grammar	0.0	0.0	0.0	2.0	0.0000000000	False
fully bracket every expression	0.0	0.0	0.0	2.0	0.0000000000	False
binary operator you put	0.0	0.0	0.0	2.0	0.0000000000	False
operator you put bracket	0.0	0.0	0.0	2.0	0.0000000000	False
bracket around the pair	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis and e divided	0.0	0.0	0.0	2.0	0.0000000000	False
divided by e enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesis over every thing	0.0	0.0	0.0	2.0	0.0000000000	False
key key in parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
language in our abstract	0.0	0.0	0.0	2.0	0.0000000000	False
abstract syntax in string	0.0	0.0	0.0	2.0	0.0000000000	False
syntax in string form	0.0	0.0	0.0	2.0	0.0000000000	False
syntax as in tree	0.0	0.0	0.0	2.0	0.0000000000	False
notation can be translated	0.0	0.0	0.0	2.0	0.0000000000	False
abstract tree which preserves	0.0	0.0	0.0	2.0	0.0000000000	False
evaluation of the expressions	0.0	0.0	0.0	2.0	0.0000000000	False
expressions and vice versa	0.0	0.0	0.0	2.0	0.0000000000	False
versa given any abstract	0.0	0.0	0.0	2.0	0.0000000000	False
tree you can transform	0.0	0.0	0.0	2.0	0.0000000000	False
bracketed string of symbols	0.0	0.0	0.0	2.0	0.0000000000	False
view of the compiler	0.0	0.0	0.0	2.0	0.0000000000	False
tedious for every programmer	0.0	0.0	0.0	2.0	0.0000000000	False
write fully parenthesized versions	0.0	0.0	0.0	2.0	0.0000000000	False
fully parenthesized versions makes	0.0	0.0	0.0	2.0	0.0000000000	False
versions makes it makes	0.0	0.0	0.0	2.0	0.0000000000	False
strike a reasonable compromise	0.0	0.0	0.0	2.0	0.0000000000	False
conventions of mathematical notation	0.0	0.0	0.0	2.0	0.0000000000	False
parsing let me mention	0.0	0.0	0.0	2.0	0.0000000000	False
minus are also overloaded	0.0	0.0	0.0	2.0	0.0000000000	False
minus of a non	0.0	0.0	0.0	2.0	0.0000000000	False
minus are binary operators	0.0	0.0	0.0	2.0	0.0000000000	False
programming too um addition	0.0	0.0	0.0	2.0	0.0000000000	False
division multilic and multiplication	0.0	0.0	0.0	2.0	0.0000000000	False
types and over integer	0.0	0.0	0.0	2.0	0.0000000000	False
unary operators usually bind	0.0	0.0	0.0	2.0	0.0000000000	False
tightest ok that means	0.0	0.0	0.0	2.0	0.0000000000	False
means a unary operator	0.0	0.0	0.0	2.0	0.0000000000	False
expression enclosed in parenthesis	0.0	0.0	0.0	2.0	0.0000000000	False
symbol after the expression	0.0	0.0	0.0	2.0	0.0000000000	False
multiplication and division bind	0.0	0.0	0.0	2.0	0.0000000000	False
operators plus and minus	0.0	0.0	0.0	4.0	0.0000000000	False
minus ok however multiplication	0.0	0.0	0.0	2.0	0.0000000000	False
multiplication and division looses	0.0	0.0	0.0	2.0	0.0000000000	False
expression of this form	0.0	0.0	0.0	2.0	0.0000000000	False
form minus five star	0.0	0.0	0.0	2.0	0.0000000000	False
minus five star minus	0.0	0.0	0.0	2.0	0.0000000000	False
entire expression this minus	0.0	0.0	0.0	2.0	0.0000000000	False
expression this minus refers	0.0	0.0	0.0	2.0	0.0000000000	False
bracketing is this right	0.0	0.0	0.0	2.0	0.0000000000	False
account for the purpose	0.0	0.0	0.0	2.0	0.0000000000	False
giving your friendly user	0.0	0.0	0.0	2.0	0.0000000000	False
expression language is concerned	0.0	0.0	0.0	2.0	0.0000000000	False
concerned so that people	0.0	0.0	0.0	2.0	0.0000000000	False
normal knowledge of mathematics	0.0	0.0	0.0	2.0	0.0000000000	False
mathematic notation mathematical conventions	0.0	0.0	0.0	2.0	0.0000000000	False
mathematical conventions can write	0.0	0.0	0.0	2.0	0.0000000000	False
conventions can write programs	0.0	0.0	0.0	2.0	0.0000000000	False
write programs can write	0.0	0.0	0.0	2.0	0.0000000000	False
programs can write expressions	0.0	0.0	0.0	2.0	0.0000000000	False
provision of this convenience	0.0	0.0	0.0	2.0	0.0000000000	False
means that you require	0.0	0.0	0.0	2.0	0.0000000000	False
large number of non	0.0	0.0	0.0	2.0	0.0000000000	False
number of non terminals	0.0	0.0	0.0	4.0	0.0000000000	False
account all the conventions	0.0	0.0	0.0	2.0	0.0000000000	False
right so an expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression is a term	0.0	0.0	0.0	2.0	0.0000000000	False
optionally an addition operator	0.0	0.0	0.0	2.0	0.0000000000	False
operator and a term	0.0	0.0	0.0	4.0	0.0000000000	False
right the addition operators	0.0	0.0	0.0	2.0	0.0000000000	False
binary plus and minus	0.0	0.0	0.0	2.0	0.0000000000	False
expression can be regarded	0.0	0.0	0.0	2.0	0.0000000000	False
signed or unsigned term	0.0	0.0	0.0	4.0	0.0000000000	False
term with an addition	0.0	0.0	0.0	2.0	0.0000000000	False
term um a term	0.0	0.0	0.0	2.0	0.0000000000	False
product of two factors	0.0	0.0	0.0	2.0	0.0000000000	False
factors or the quotient	0.0	0.0	0.0	2.0	0.0000000000	False
quotient of two factors	0.0	0.0	0.0	4.0	0.0000000000	False
multiplicative operator so star	0.0	0.0	0.0	2.0	0.0000000000	False
division are multiplicative operators	0.0	0.0	0.0	2.0	0.0000000000	False
factors right a factor	0.0	0.0	0.0	2.0	0.0000000000	False
factor is anything regarded	0.0	0.0	0.0	2.0	0.0000000000	False
number specified as part	0.0	0.0	0.0	2.0	0.0000000000	False
part of the expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression in itself enclosed	0.0	0.0	0.0	2.0	0.0000000000	False
mutually and circularly non	0.0	0.0	0.0	2.0	0.0000000000	False
sum of two things	0.0	0.0	0.0	2.0	0.0000000000	False
out into a term	0.0	0.0	0.0	2.0	0.0000000000	False
large expression whose root	0.0	0.0	0.0	2.0	0.0000000000	False
expression whose root operation	0.0	0.0	0.0	2.0	0.0000000000	False
operation is an addition	0.0	0.0	0.0	2.0	0.0000000000	False
addition operation that means	0.0	0.0	0.0	2.0	0.0000000000	False
grammar really takes precedence	0.0	0.0	0.0	2.0	0.0000000000	False
takes precedence of operators	0.0	0.0	0.0	2.0	0.0000000000	False
absolutely essential for writing	0.0	0.0	0.0	2.0	0.0000000000	False
kind of syntactic definition	0.0	0.0	0.0	2.0	0.0000000000	False
expression as a signed	0.0	0.0	0.0	2.0	0.0000000000	False
signed or unsigned expression	0.0	0.0	0.0	2.0	0.0000000000	False
operator just in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of abstract trees	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesized expressions or abstract	0.0	0.0	0.0	2.0	0.0000000000	False
expressions or abstract syntax	0.0	0.0	0.0	2.0	0.0000000000	False
definition of the number	0.0	0.0	0.0	2.0	0.0000000000	False
number so a number	0.0	0.0	0.0	2.0	0.0000000000	False
signed or unsigned integer	0.0	0.0	0.0	2.0	0.0000000000	False
clause and the definition	0.0	0.0	0.0	2.0	0.0000000000	False
digits ok and digit	0.0	0.0	0.0	2.0	0.0000000000	False
defined as a character	0.0	0.0	0.0	2.0	0.0000000000	False
follow normal pascal rules	0.0	0.0	0.0	2.0	0.0000000000	False
pascal rules an identifier	0.0	0.0	0.0	2.0	0.0000000000	False
start with a letter	0.0	0.0	0.0	2.0	0.0000000000	False
letter in the case	0.0	0.0	0.0	2.0	0.0000000000	False
compiler all the alphabet	0.0	0.0	0.0	2.0	0.0000000000	False
modify it to include	0.0	0.0	0.0	2.0	0.0000000000	False
include lower case letters	0.0	0.0	0.0	2.0	0.0000000000	False
number from an identifier	0.0	0.0	0.0	2.0	0.0000000000	False
identifier is the occurrence	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of a letter	0.0	0.0	0.0	2.0	0.0000000000	False
symbol or a digit	0.0	0.0	0.0	2.0	0.0000000000	False
occurrence of the letter	0.0	0.0	0.0	2.0	0.0000000000	False
begin with a letter	0.0	0.0	0.0	2.0	0.0000000000	False
right and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
rules also for recognizing	0.0	0.0	0.0	2.0	0.0000000000	False
recognizing that the word	0.0	0.0	0.0	2.0	0.0000000000	False
single word the word	0.0	0.0	0.0	2.0	0.0000000000	False
word the word begin	0.0	0.0	0.0	2.0	0.0000000000	False
begin has been recognized	0.0	0.0	0.0	2.0	0.0000000000	False
part of the process	0.0	0.0	0.0	2.0	0.0000000000	False
scanning or lexical analysis	0.0	0.0	0.0	2.0	0.0000000000	False
written in this language	0.0	0.0	0.0	2.0	0.0000000000	False
language it just consists	0.0	0.0	0.0	2.0	0.0000000000	False
divide up the program	0.0	0.0	0.0	2.0	0.0000000000	False
entity in the program	0.0	0.0	0.0	2.0	0.0000000000	False
recognize all those reserved	0.0	0.0	0.0	2.0	0.0000000000	False
words you should scan	0.0	0.0	0.0	2.0	0.0000000000	False
scan all the words	0.0	0.0	0.0	2.0	0.0000000000	False
treat them as identifiers	0.0	0.0	0.0	2.0	0.0000000000	False
out the entire constant	0.0	0.0	0.0	2.0	0.0000000000	False
constant in this case	0.0	0.0	0.0	2.0	0.0000000000	False
string of digits representing	0.0	0.0	0.0	4.0	0.0000000000	False
digits representing an integer	0.0	0.0	0.0	4.0	0.0000000000	False
unit so a scanner	0.0	0.0	0.0	2.0	0.0000000000	False
typically takes a file	0.0	0.0	0.0	2.0	0.0000000000	False
lexemes yeah the word	0.0	0.0	0.0	2.0	0.0000000000	False
desk file it means	0.0	0.0	0.0	2.0	0.0000000000	False
means any unbounded sequence	0.0	0.0	0.0	2.0	0.0000000000	False
unbounded sequence ordered sequence	0.0	0.0	0.0	2.0	0.0000000000	False
ordered sequence of object	0.0	0.0	0.0	2.0	0.0000000000	False
object so the process	0.0	0.0	0.0	2.0	0.0000000000	False
process of scanning converts	0.0	0.0	0.0	2.0	0.0000000000	False
scanning converts the file	0.0	0.0	0.0	2.0	0.0000000000	False
takes over the handling	0.0	0.0	0.0	2.0	0.0000000000	False
scanning would have created	0.0	0.0	0.0	2.0	0.0000000000	False
created a single lexeme	0.0	0.0	0.0	2.0	0.0000000000	False
scanning they would lose	0.0	0.0	0.0	2.0	0.0000000000	False
unit in the form	0.0	0.0	0.0	2.0	0.0000000000	False
form of some structured	0.0	0.0	0.0	2.0	0.0000000000	False
structured um an element	0.0	0.0	0.0	2.0	0.0000000000	False
element of some structured	0.0	0.0	0.0	2.0	0.0000000000	False
constant it is striped	0.0	0.0	0.0	2.0	0.0000000000	False
create a huge table	0.0	0.0	0.0	2.0	0.0000000000	False
table of the amount	0.0	0.0	0.0	2.0	0.0000000000	False
extract from the program	0.0	0.0	0.0	2.0	0.0000000000	False
checking for example type	0.0	0.0	0.0	2.0	0.0000000000	False
type checking runtime type	0.0	0.0	0.0	2.0	0.0000000000	False
checking runtime type checks	0.0	0.0	0.0	2.0	0.0000000000	False
runtime type checks compile	0.0	0.0	0.0	2.0	0.0000000000	False
checks compile time type	0.0	0.0	0.0	2.0	0.0000000000	False
compile time type checks	0.0	0.0	0.0	2.0	0.0000000000	False
type checks to detect	0.0	0.0	0.0	2.0	0.0000000000	False
detect un declared variables	0.0	0.0	0.0	2.0	0.0000000000	False
good way of detecting	0.0	0.0	0.0	2.0	0.0000000000	False
resident always in memory	0.0	0.0	0.0	2.0	0.0000000000	False
reference during the process	0.0	0.0	0.0	2.0	0.0000000000	False
context sensitive um issues	0.0	0.0	0.0	2.0	0.0000000000	False
assigned the right type	0.0	0.0	0.0	2.0	0.0000000000	False
expression in the right	0.0	0.0	0.0	2.0	0.0000000000	False
type so you require	0.0	0.0	0.0	2.0	0.0000000000	False
word or each lexeme	0.0	0.0	0.0	2.0	0.0000000000	False
correctly in the program	0.0	0.0	0.0	2.0	0.0000000000	False
semantics of the language	0.0	0.0	0.0	2.0	0.0000000000	True
start the next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
basic notions of semantics	0.0	0.0	0.0	2.0	0.0000000000	False
toy language new features	0.0	0.0	0.0	2.0	0.0000000000	False
defined the syntactic definitions	0.0	0.0	0.0	2.0	0.0000000000	False
long as you parenthesizes	0.0	0.0	0.0	2.0	0.0000000000	False
parenthesizes the new features	0.0	0.0	0.0	2.0	0.0000000000	False
long as you define	0.0	0.0	0.0	2.0	0.0000000000	False
important how the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
give to the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
v.srinivasa rajkumar educational	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
rajkumar educational technology	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
educational technology i.i.t	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
technology i.i.t delhi	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi presents	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
presents a video	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
languages by dr.s.arun	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
dr.s.arun kumar deptt	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
deptt of comp.sc	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
comp.sc & engg	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
i.i.t delhi lecture	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
slightly more complicated	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
complicated programming language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
answer the question	0.000833878766623	0.0	0.0	1.58496250072	0.0000000000	False
programs and commands	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
commands and atomic	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
context free grammar	0.00680782123296	0.0	6.99572039943	6.33985000288	0.4719101124	False
free grammar notation	0.00262113817137	0.0	0.0	0.0	0.0000000000	False
notation will remain	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
last times grammar	0.0	0.0	0.0	1.58496250072	0.0000000000	False
firstly the grammar	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
grammar of programs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
sequence of commands	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
words in black	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
black are reserve	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
words so including	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
define the notion	0.0	0.0	0.0	1.58496250072	0.0000000000	False
notion of ambiguity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammar was ambiguous	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammar is ambiguous	0.00524227634274	0.0	2.99714693295	6.33985000288	0.2978723404	False
exists a sentence	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
abstract sentence tree	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
abstract syntax tree	0.00655284542843	0.0	4.99643366619	7.92481250361	0.5283018868	False
tree by elevating	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
elevating the operators	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
nodes and replacing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
replacing the non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non terminal symbols	0.0	0.0	8.99215406562	15.8496250072	0.3706377858	False
class of parse	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two control structures	0.0	0.0	0.0	1.58496250072	0.0000000000	False
structures the conditional	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
eliminated the ambiguity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
ambiguity by introducing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
introducing two reserved	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two reserved words	0.0	0.0	0.0	0.0	0.0000000000	False
words the closing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
closing bracket words	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
operator on commands	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
atomic or compound	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
commands i don	0.0	0.0	0.0	0.0	0.0000000000	False
two different parse	0.0	0.0	0.0	0.0	0.0000000000	False
expand into trees	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
first this first	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
first semi colon	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
forms the root	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
left sub tree	0.000766992443296	0.0	0.0	1.58496250072	0.0000000000	False
trees really correspond	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two bracketed inside	0.0	0.0	0.0	1.58496250072	0.0000000000	False
bracketed outside right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
general um sequencing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
function composition operation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
language is concerned	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
concerned any implementation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
decision with regard	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
programs is concerned	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
things can change	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
expression of boolean	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
change the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of boolean	0.0	0.0	0.0	0.0	0.0000000000	False
boolean expression depending	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parse the boolean	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
language reference manual	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
languages since algol	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
backus naur form	0.0112792903386	0.0	5.99500713267	9.50977500433	0.2170542636	True
notation um created	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
created by john	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
backus and peter	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
definition algol sixty	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
sixty the algol	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
first um language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
rigorous syntactic form	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
syntactic form based	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
based on context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
context free languages	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
languages and context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammars to define	0.0	0.0	0.0	0.0	0.0000000000	False
define the language	0.0	0.0	0.0	0.0	0.0000000000	False
backus was involved	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
creation of fortan	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clear syntactic definition	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
language every fortan	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fortan compiler written	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
gave different interpretations	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
syntax of fortan	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
fortan comp fortan	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
comp fortan programs	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
compatible across machines	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
compiler and moving	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
team of programmers	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
rewrite that program	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
program to suit	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
required substantial rewriting	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
form of theoretical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
study and backus	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
define the algol	0.0	0.0	0.0	0.0	0.0000000000	False
algol sixty language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
symbol um single	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
single character non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
character non terminal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
statements within angle	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
double colon equal	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
form in full	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
full the non	0.0	0.0	0.0	0.0	0.0000000000	False
terminals being enclosed	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
enclosed in angle	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
arrow being replaced	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
replaced double colon	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
colon and equals	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extended backus naur	0.00483398157367	0.0	3.99786019971	0.0	0.0000000000	False
adds the power	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions within context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
firstly regular expressions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
symbols to aloow	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
kinds of iterations	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
naur form extended	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extended to include	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
iterations in choice	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
naur form production	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
beta and gamma	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
gamma are strings	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
strings of terminals	0.00113463687216	0.0	0.0	1.58496250072	0.0000000000	False
terminals or non	0.0	0.0	0.0	0.0	0.0000000000	False
light brown brackets	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
naur form notation	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
alpha b gamma	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
set of non	0.0	0.0	0.0	0.0	0.0000000000	False
notation this extended	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extended backus form	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
backus form notation	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
run the man	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
options given switches	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
enclosed in brackets	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
brackets to represent	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
separated by bars	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
separated by commas	0.00644530876489	0.0	2.99714693295	4.75488750216	0.4242424242	False
set of productions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
aide in writing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
out a grammar	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
significance you wouldn	0.0	0.0	0.0	0.0	0.0000000000	False
language like pascal	0.00113463687216	0.0	0.0	1.58496250072	0.0000000000	False
pascal you allowed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clause actually belongs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
normal one conditional	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
reduce the amount	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
number of non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
terminal symbols remember	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
language a real	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
real world programming	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
world programming language	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
piece of syntax	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
adding these extra	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
extra non terminals	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
respect to ambiguity	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
alpha within braces	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
braces beta gamma	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
epsilon which denotes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
number of iterations	0.00113463687216	0.0	0.0	1.58496250072	0.0000000000	False
iterations um number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
number of repetitions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
extended bnf notation	0.00805663595611	0.0	9.99643366619	7.92481250361	0.3814713896	True
manual the syntax	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
diagrams of pascal	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
follow the arrow	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
ordinary context free	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
context free notation	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
manuals for learning	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
language the last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language which didn	0.0	0.0	0.0	0.0	0.0000000000	False
purposes of teaching	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
teaching programming languages	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
programming languages compilers	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
designer of pascal	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
written the compiler	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
smaller than pascal	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
single data type	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
type the main	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
assignment sequencing bracketing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequencing bracketing looping	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conditional that means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
two one arm	0.0	0.0	0.0	0.0	0.0000000000	False
conditions in sequence	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
neglect the boolean	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
boolean data types	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
encode your booleans	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
control abstraction mechanism	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parameter list procedures	0.00483398157367	0.0	3.99786019971	4.75488750216	0.0000000000	False
step wise refinement	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
refinement of programs	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
abstraction complicated programs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
development of programs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
top down fashion	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
program my start	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
block which terminates	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
case of pascal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
programs you terminate	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
terminate the program	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
right a block	0.0	0.0	0.0	0.0	0.0000000000	False
brevity i don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
write full names	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
single um single	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
single letter non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
letter non terminal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sort of obvious	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clause is optional	0.00483398157367	0.0	2.99786019971	4.75488750216	0.0000000000	False
enclosed in light	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
declaration a constant	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
declaration which means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
means this word	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
stand for identifier	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifier and number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
set of identifiers	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
set of numbers	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
syntax the actual	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
value as identifiers	0.0	0.0	0.0	0.0	0.0000000000	False
identifiers um names	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
names and numbers	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
kinds of data	0.0020196219603	0.0	0.0	0.0	0.0000000000	False
number of constant	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
constant specified separated	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
commas are reserved	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
moment the word	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
word const occurs	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
clause i equals	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
const reserved word	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
define a sequence	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sequence of constants	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
declaration and terminate	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
terminate that sequence	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
terminate the entire	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
reserved word var	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
word var occurring	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
var the entire	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
entire variable declaration	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
procedure has procedure	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
entire the entire	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
optional you don	0.0	0.0	0.0	1.58496250072	0.0000000000	False
block just consists	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
definition of statements	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	True
empty a declaration	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
empty which means	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
means an empty	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
assignment an assignment	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
identifier um colon	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
equals an expression	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
absolutely no relation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifiers are declared	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
syntax is context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
variable without declaring	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
context sensitive feature	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
procedure called statement	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
call an identifier	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifier and implicit	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequence of statements	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
statements by bracketing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
begin and end	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
end and call	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
produce a epsilon	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
pair of brackets	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
brackets begin end	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
repetition um occurrences	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
previous our previous	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expense of introducing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
introducing new non	0.0	0.0	0.0	0.0	0.0000000000	False
define so condition	0.0	0.0	0.0	1.58496250072	0.0000000000	False
modified the language	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
language a bit	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
unary data type	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
data type applies	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
condition this unary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
unary predicate applies	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions and yields	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
yields the true	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
true or false	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
predicate some unary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
reason for choosing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
high level programs	0.00100981098015	0.0	0.0	1.58496250072	0.0000000000	False
programs a large	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
check for oddness	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
binary relational operators	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
simplified the original	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
single letter relational	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
letter relational symbols	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
odd looking symbols	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
original pascal compiler	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
equals the original	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
compiler has defined	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
defined by wirth	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
wirth actually assume	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
greater than equals	0.000833878766623	0.0	0.0	1.58496250072	0.0000000000	False
conditions really dependant	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
dependant upon expressions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
diff two extremes	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
addition subtraction multiplication	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
subtraction multiplication division	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
expressions a difference	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
expressions a product	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
ambiguous this grammar	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
order of evaluation	0.00393170725706	0.0	2.99786019971	3.16992500144	0.0000000000	False
define the expression	0.0	0.0	0.0	0.0	0.0000000000	False
expression every constant	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
constant an integer	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
bracket every expression	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
operator you put	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
pair of operands	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
enclosed in parenthesis	0.00786341451412	0.0	7.99572039943	7.92481250361	0.2641509434	False
parenthesis e minus	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
minus e enclosed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parenthesis e star	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
star e enclosed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
find it tedious	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
key in parenthesis	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
syntax in string	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
draw the trees	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
fully parenthesized notation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
tree which preserves	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
preserves the order	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions and vice	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fully bracketed string	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
string of symbols	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
point of view	0.000766992443296	0.0	0.0	1.58496250072	0.0000000000	False
programmer to write	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
write fully parenthesized	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fully parenthesized versions	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
parenthesized versions makes	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
makes it makes	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
strike a reasonable	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conventions of mathematical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
right in parsing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
overloaded unary operators	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
write positive numbers	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
non negative integer	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus are binary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
lot of overloading	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
multiplication division multilic	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
multilic and multiplication	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
real data types	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
integer data types	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
operators usually bind	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
bind the tightest	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
means a unary	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
first available symbol	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
large expression enclosed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
normal mathematical convention	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
multiplication and division	0.00483398157367	0.0	5.99786019971	3.16992500144	0.0000000000	False
division bind tighter	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
division looses precedence	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
minus five star	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
expression this minus	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conventions into account	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
giving your friendly	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
friendly user interface	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
knowledge of mathematics	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
mathematics mathematic notation	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
mathematic notation mathematical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
notation mathematical conventions	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
conventions can write	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
programs can write	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
trained to write	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
convenience mean means	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
fairly large number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expect to define	0.0	0.0	0.0	1.58496250072	0.0000000000	False
language of expression	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
deal with parsing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
parsing or compiling	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
wont i wont	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
optionally an addition	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
right the addition	0.0	0.0	0.0	0.0	0.0000000000	False
term a signed	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
signed or unsigned	0.00644530876489	0.0	3.99714693295	4.75488750216	0.4242424242	False
term a term	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
operator so star	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
star and division	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
division the multiplication	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
division are multiplicative	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
product or quotient	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
right a factor	0.0	0.0	0.0	0.0	0.0000000000	False
identifier which means	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
talking about variables	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
variables or constants	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
defined in terms	0.00302943294045	0.0	2.99786019971	4.75488750216	0.0000000000	False
circularly non recursive	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
account the fact	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
basically the sum	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expression whose root	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
operation that means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
left operand supposing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
grammar really takes	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
precedence of operators	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
operators into account	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
essential for writing	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
writing the compiler	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
kind of syntactic	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
terms of abstract	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
fully parenthesized expressions	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
expressions or abstract	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
identifier we follow	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
follow normal pascal	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
normal pascal rules	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
rules an identifier	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
identifier should start	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
upper case letters	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
trivial to modify	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
include lower case	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
lower case letters	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
distinguishes a number	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
integer and neglect	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
letters or digits	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
reason for removing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
part of parsing	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
write such rules	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
word the word	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
scanning or lexical	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
file of characters	0.00805663595611	0.0	7.99643366619	7.92481250361	0.2922755741	False
program into words	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
describe each entity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
file of words	0.00483398157367	0.0	3.99786019971	4.75488750216	0.0000000000	False
words and decide	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
out the entire	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
string of digits	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
representing an integer	0.00322265438245	0.0	0.0	0.0	0.0000000000	False
scanner typically takes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
takes a file	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
file of lexemes	0.00483398157367	0.0	5.99786019971	4.75488750216	0.0000000000	False
file it means	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
means any unbounded	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
unbounded sequence ordered	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequence ordered sequence	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
sequence of object	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
process of scanning	0.00322265438245	0.0	0.0	1.58496250072	0.0000000000	False
converts the file	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
process of parsing	0.00322265438245	0.0	0.0	3.16992500144	0.0000000000	False
parsing actually takes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
created a single	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
lose the status	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
string of characters	0.00131056908569	0.0	0.0	1.58496250072	0.0000000000	False
single entity unit	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
structured data type	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
create a huge	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
amount of information	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
process of compiling	0.00262113817137	0.0	0.0	3.16992500144	0.0000000000	False
type checking runtime	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
checking runtime type	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
runtime type checks	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
compile time type	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
checks to detect	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
detect un declared	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
detecting spelling mistakes	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
table is resident	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
memory for reference	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
check various context	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
sensitive um issues	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
issues like hasn	0.0	0.0	0.0	1.58496250072	0.0000000000	False
assigned the right	0.0	0.0	0.0	0.0	0.0000000000	False
require this table	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
table of information	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
identifier reserved word	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
future to defining	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
defining the semantics	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
notions of semantics	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
language new features	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
defined the syntactic	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
introducing without ambiguity	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
meaning you give	0.00161132719122	0.0	0.0	1.58496250072	0.0000000000	False
v.srinivasa rajkumar	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
educational technology	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
technology i.i.t	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
i.i.t delhi	0.0013464146402	0.0	0.0	1.0	0.0000000000	False
delhi presents	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
programming languages	0.00357929806871	0.0	4.99500713267	6.0	0.3456790123	False
dr.s.arun kumar	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
kumar deptt	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
delhi lecture	0.000511328295531	0.0	0.0	0.0	0.0000000000	False
complicated programming	0.00174742544758	0.0	0.0	1.0	0.0000000000	False
abstraction levels	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
atomic commands	0.00174742544758	0.0	0.0	1.0	0.0000000000	False
free grammar	0.00453854748864	0.0	6.99572039943	4.0	0.4719101124	False
grammar notation	0.00174742544758	0.0	0.0	1.0	0.0000000000	False
last times	0.0	0.0	1.99786019971	2.0	0.0000000000	False
times grammar	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
reserve words	0.0122319781331	0.0	10.9900142653	13.0	0.4242424242	False
closing bracket	0.00262113817137	0.0	2.99786019971	2.0	0.0000000000	False
language generated	0.000756424581439	0.0	0.0	1.0	0.0000000000	False
parse tree	0.00611598906653	0.0	6.99500713267	6.0	0.2043795620	False
abstract sentence	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
sentence tree	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
abstract syntax	0.00698970179033	0.0	4.99429386591	6.0	0.3589743590	False
syntax tree	0.00436856361895	0.0	4.99643366619	0.0	0.5283018868	True
root nodes	0.000608658997475	0.0	0.0	0.0	0.0000000000	False
terminal symbols	0.00942490248139	0.0	12.9900142653	12.0	0.2978723404	False
restricted class	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
control structures	0.00174742544758	0.0	0.0	1.0	0.0000000000	False
bracket words	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
sequential composition	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
sequencing operator	0.00262113817137	0.0	3.99786019971	2.0	0.0000000000	False
binary operator	0.00524227634274	0.0	4.99572039943	5.0	0.4719101124	False
compound commands	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
drawing triangles	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
first semicolon	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
right circle	0.0	0.0	0.0	2.0	0.0000000000	False
first semi	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
semi colon	0.00436856361895	0.0	3.99643366619	4.0	0.3309692671	False
left sub	0.0	0.0	0.0	0.0	0.0000000000	False
sub tree	0.0	0.0	0.0	0.0	0.0000000000	False
bracketed inside	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
tree corresponds	0.000873712723791	0.0	0.0	2.0	0.0000000000	False
thing semicolon	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
function composition	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
composition operation	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
semicolon operation	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
runtime behavior	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
small matter	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
case things	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
boolean expressions	0.00182597699242	0.0	5.99786019971	2.0	0.0000000000	False
introduce parenthesis	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
expression depending	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
language reference	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
algol sixty	0.00302569832576	0.0	7.99714693295	3.0	0.2978723404	False
backus naur	0.00751952689237	0.0	5.99500713267	5.0	0.2170542636	False
naur form	0.00751952689237	0.0	5.99500713267	5.0	0.2170542636	False
john backus	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
peter naur	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
definition algol	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
rigorous syntactic	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
syntactic form	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
form based	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
context free	0.00832067039583	0.0	12.9921540656	9.0	0.3706377858	False
free languages	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
language abs	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
net result	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
clear syntactic	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
syntactic definition	0.00429687250993	0.0	3.99714693295	3.0	0.3906976744	False
fortan language	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
fortan compiler	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
compiler written	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
people gave	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
fortan comp	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
comp fortan	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
fortan programs	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
compiler treated	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
fortan syntax	0.00107421812748	0.0	0.0	1.0	0.0000000000	True
moving programs	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
huge problem	0.00214843625496	0.0	0.0	2.0	0.0000000000	False
substantial rewriting	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
theoretical study	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
sixty language	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
ensure readability	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
single symbol	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
single character	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
character non	0.0	0.0	0.0	0.0	0.0000000000	False
full words	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
wrote statements	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
angle brackets	0.00151284916288	0.0	0.0	1.0	0.0000000000	False
arrow mark	0.00226927374432	0.0	3.99786019971	2.0	0.0000000000	False
type writer	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
double colon	0.00322265438245	0.0	3.99786019971	2.0	0.0000000000	False
non terminals	0.0	0.0	15.9807417974	26.0	0.3069427527	False
extended backus	0.00429687250993	0.0	3.99714693295	3.0	0.2978723404	False
regular expressions	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
convenient fashion	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
limited notation	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
form extended	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
include iterations	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
form production	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
alpha beta	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
alpha note	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
light brown	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
brown brackets	0.00214843625496	0.0	0.0	0.0	0.0000000000	False
form notation	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
backus form	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
unix machine	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
man pages	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
square brackets	0.00174742544758	0.0	0.0	1.0	0.0000000000	False
logical significance	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
grammatical entity	0.00214843625496	0.0	0.0	2.0	0.0000000000	False
language allowed	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
symbols remember	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
real world	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
world programming	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
large piece	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
extra non	0.0	0.0	0.0	0.0	0.0000000000	False
grammatical significance	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
ambiguity parsing	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
logical entity	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
separate significance	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
braces beta	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
beta gamma	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
string beta	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
extended bnf	0.00537109063741	0.0	9.99643366619	0.0	0.3814713896	False
bnf notation	0.00537109063741	0.0	9.99643366619	0.0	0.3814713896	True
practical reasons	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
pascal manual	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
syntax diagrams	0.00214843625496	0.0	0.0	1.0	0.0000000000	True
ordinary context	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
free notation	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
reading manuals	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
toy language	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
teaching programming	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
languages compilers	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
main thing	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
single data	0.00214843625496	0.0	0.0	0.0	0.0000000000	False
data type	0.00669524897222	0.0	7.99215406562	10.0	0.3974193548	False
main features	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
assignment sequencing	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
sequencing bracketing	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
bracketing looping	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
arm conditions	0.00322265438245	0.0	3.99786019971	2.0	0.0000000000	False
boolean data	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
thing greater	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
important feature	0.000756424581439	0.0	0.0	1.0	0.0000000000	False
control abstraction	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
abstraction mechanism	0.00151284916288	0.0	0.0	0.0	0.0000000000	False
parameter list	0.00322265438245	0.0	3.99786019971	0.0	0.0000000000	False
list procedures	0.00322265438245	0.0	3.99786019971	0.0	0.0000000000	False
step wise	0.00174742544758	0.0	0.0	0.0	0.0000000000	False
wise refinement	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
abstraction complicated	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
structured fashion	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
colon equals	0.00262113817137	0.0	1.99786019971	2.0	0.0000000000	False
start symbol	0.0013464146402	0.0	0.0	1.0	0.0000000000	False
pascal programs	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
block consists	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
full names	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
single letter	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
letter non	0.0	0.0	0.0	0.0	0.0000000000	False
constant declaration	0.00429687250993	0.0	3.99714693295	3.0	0.2978723404	False
dark brown	0.00262113817137	0.0	2.99786019971	3.0	0.0000000000	False
infinite set	0.0013464146402	0.0	0.0	1.0	0.0000000000	False
ideal machine	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
actual limits	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
implementation dependant	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
syntax definition	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
infinite number	0.0006732073201	0.0	0.0	1.0	0.0000000000	False
phase value	0.0	0.0	0.0	0.0	0.0000000000	False
word const	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
const occurs	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
constant definition	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
combination specifies	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
const reserved	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
single declaration	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
entire declaration	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
entire clause	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
variable declarations	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
variables separated	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
word var	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
var occurring	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
entire variable	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
procedure declarations	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
entire procedure	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
declarations end	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
entire set	0.000756424581439	0.0	0.0	1.0	0.0000000000	False
empty declaration	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
empty string	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
trivial case	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
assignment statement	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
expression note	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
language feature	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
sensitive feature	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
explicit procedure	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
implicit meaning	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
call call	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
single statement	0.00214843625496	0.0	0.0	2.0	0.0000000000	False
looping construct	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
compound statements	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
brackets begin	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
begin end	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
trivial statement	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
expressions conditions	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
unary condition	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
unary data	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
type applies	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
unary predicate	0.00429687250993	0.0	5.99714693295	3.0	0.2978723404	False
predicate applies	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
choosing odd	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
direct jump	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
high level	0.000380583394245	0.0	0.0	0.0	0.0000000000	False
level programs	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
large number	0.000621645783679	0.0	0.0	1.0	0.0000000000	False
binary relational	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
relational operators	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
original language	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
relational symbols	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
standard greater	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
original pascal	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
pascal compiler	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
equal symbol	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
key board	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
binary predicates	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
expression language	0.00611598906653	0.0	8.99500713267	6.0	0.3456790123	True
form supposing	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
addition subtraction	0.00214843625496	0.0	0.0	0.0	0.0000000000	False
subtraction multiplication	0.00214843625496	0.0	0.0	0.0	0.0000000000	False
multiplication division	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
generate sequences	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
priority order	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
integer constant	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
atomic statements	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
put bracket	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
write parenthesis	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
abstract language	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
string form	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
tree form	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
parenthesized notation	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
abstract tree	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
vice versa	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
parenthesized versions	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
versions makes	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
reasonable compromise	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
normal conventions	0.00214843625496	0.0	0.0	2.0	0.0000000000	False
mathematical notation	0.00151284916288	0.0	0.0	1.0	0.0000000000	False
unary operators	0.00751952689237	0.0	10.9950071327	6.0	0.2314049587	False
negative numbers	0.00262113817137	0.0	1.99786019971	3.0	0.0000000000	False
positive numbers	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
unary minus	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
negative integer	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
real data	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
integer data	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
pascal language	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
set operations	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
influence extends	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
takes precedence	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
large expression	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
expression enclosed	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
entire expression	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
first symbol	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
left parenthesis	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
normal mathematical	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
mathematical convention	0.00174742544758	0.0	0.0	1.0	0.0000000000	False
division bind	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
bind tighter	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
division looses	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
looses precedence	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
unparenthesized expression	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
form minus	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
star minus	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
minus refers	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
star binds	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
friendly user	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
user interface	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
normal knowledge	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
write programs	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
write expressions	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
great details	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
optional clause	0.00214843625496	0.0	0.0	2.0	0.0000000000	False
unsigned term	0.00322265438245	0.0	5.99786019971	1.0	0.0000000000	False
addition operator	0.00429687250993	0.0	5.99714693295	3.0	0.2978723404	False
multiplicative operator	0.00174742544758	0.0	0.0	1.0	0.0000000000	False
single unit	0.00436856361895	0.0	7.99643366619	5.0	0.3814713896	False
circularly non	0.0	0.0	0.0	0.0	0.0000000000	False
outermost operation	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
root operation	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
last operation	0.0	0.0	0.0	1.0	0.0000000000	False
left operand	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
operand supposing	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
pragmatic reasons	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
unsigned expression	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
parenthesized expressions	0.00214843625496	0.0	2.99786019971	2.0	0.0000000000	False
last part	0.0	0.0	0.0	1.0	0.0000000000	False
unsigned integer	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
normal pascal	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
pascal rules	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
alphabet consists	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
upper case	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
case letters	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
lower case	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
minus symbol	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
main grammar	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
lexical analysis	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
single word	0.00214843625496	0.0	0.0	1.0	0.0000000000	False
word begin	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
program written	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
entire constant	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
digits representing	0.00214843625496	0.0	0.0	0.0	0.0000000000	False
entire thing	0.000380583394245	0.0	0.0	1.0	0.0000000000	False
user program	0.000873712723791	0.0	0.0	1.0	0.0000000000	False
word file	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
general fashion	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
desk file	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
unbounded sequence	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
sequence ordered	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
ordered sequence	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
scanning converts	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
single lexeme	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
single entity	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
entity unit	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
structured data	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
complicated language	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
integer type	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
huge table	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
type checking	0.00262113817137	0.0	5.99786019971	2.0	0.0000000000	False
checking runtime	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
runtime type	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
declared variables	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
detecting spelling	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
spelling mistakes	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
right type	0.0	0.0	0.0	1.0	0.0000000000	False
basic notions	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
basic material	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
good syntax	0.00107421812748	0.0	0.0	1.0	0.0000000000	False
transcriptor	0.000204076796892	0.0	0.0	0.0	0.0000000000	False
v.srinivasa	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
rajkumar	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
educational	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
technology	0.000204076796892	0.0	0.0	0.0	0.0000000000	False
i.i.t	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
delhi	0.000472701916409	0.0	0.0	0.0	0.0000000000	False
presents	0.000207648190093	0.0	0.0	0.0	0.0000000000	False
video	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
programming	0.00257579761442	0.0	0.0	0.0	0.3539325843	False
languages	0.00761516085007	0.0	0.0	0.0	0.2978723404	False
dr.s.arun	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
kumar	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
deptt	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
comp.sc	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
engg	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
lecture	0.000150250030395	0.0	0.0	0.0	0.0000000000	False
plo	0.0	0.0	0.0	0.0	0.0000000000	False
syntax	0.00608658997475	0.0	0.0	0.0	0.4941176471	True
today	1.88101140075e-05	0.0	0.0	0.0	0.0000000000	False
slightly	6.04187446775e-05	0.0	0.0	0.0	0.0000000000	False
complicated	0.000444971413097	0.0	0.0	0.0	0.5384615385	False
compiler	0.00496337012229	0.0	0.0	0.0	0.2683706070	False
briefly	0.000127329870212	0.0	0.0	0.0	0.0000000000	False
summarize	0.000190291697123	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.4501607717	False
answer	6.04187446775e-05	0.0	0.0	0.0	0.0000000000	False
question	4.45418660949e-05	0.0	0.0	0.0	0.0000000000	False
follow	0.000309816740733	0.0	0.0	0.0	0.4516129032	False
abstraction	0.00248658313472	0.0	0.0	0.0	0.3255813953	False
levels	0.000167219511361	0.0	0.0	0.0	0.0000000000	False
brown	0.00262113817137	0.0	0.0	0.0	0.4077669903	False
change	0.000143382218053	0.0	0.0	0.0	0.4242424242	False
commands	0.00333551506649	0.0	0.0	0.0	0.2110552764	False
atomic	0.0011118383555	0.0	0.0	0.0	0.4242424242	False
context	0.00247379206259	0.0	0.0	0.0	0.3827549947	False
free	0.00241247069468	0.0	0.0	0.0	0.3706377858	False
grammar	0.00639546954095	0.0	0.0	0.0	0.3447828905	False
notation	0.00211361421221	0.0	0.0	0.0	0.3327079425	False
remain	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
noise	0.00189112850566	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.4719101124	False
firstly	0.000657946553096	0.0	0.0	0.0	0.0000000000	False
sequence	0.00108692682385	0.0	0.0	0.0	0.5006877579	False
conditioner	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
words	0.00159960357815	0.0	0.0	0.0	0.1812904666	False
black	0.000472701916409	0.0	0.0	0.0	0.0000000000	False
reserve	0.00426061298232	0.0	0.0	0.0	0.4242424242	False
including	0.000311472285139	0.0	0.0	0.0	0.0000000000	False
acts	0.000608658997475	0.0	0.0	0.0	0.0000000000	False
closing	0.00010753666354	0.0	0.0	0.0	0.0000000000	False
bracket	0.0048978431254	0.0	0.0	0.0	0.3360000000	False
similarly	4.51800238707e-05	0.0	0.0	0.0	0.0000000000	False
things	0.0	0.0	0.0	0.0	0.5753424658	False
define	0.000322609990619	0.0	0.0	0.0	0.4452296820	False
notion	0.000167219511361	0.0	0.0	0.0	0.0000000000	False
ambiguity	0.00425431724768	0.0	0.0	0.0	0.2669657880	False
exists	0.000333728559823	0.0	0.0	0.0	0.0000000000	False
sentence	0.00102265659106	0.0	0.0	0.0	0.2058823529	False
generated	5.49507571434e-05	0.0	0.0	0.0	0.5490196078	False
parse	0.00504905490075	0.0	0.0	0.0	0.3127326880	False
tree	0.00408725840166	0.0	0.0	0.0	0.1520236920	False
implicit	0.000438631035397	0.0	0.0	0.0	0.0000000000	False
obtained	0.000119062815853	0.0	0.0	0.0	0.0000000000	False
elevating	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
operators	0.00185308370821	0.0	0.0	0.0	0.2416608351	False
root	0.000932468675518	0.0	0.0	0.0	0.2641509434	False
nodes	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
replacing	0.000272196512718	0.0	0.0	0.0	0.0000000000	False
non	0.0	0.0	0.0	0.0	0.3296792529	False
terminal	0.00780195958203	0.0	0.0	0.0	0.2050366137	False
symbols	0.0048978431254	0.0	0.0	0.0	0.3181818182	False
restricted	0.000190291697123	0.0	0.0	0.0	0.0000000000	False
class	4.04374981515e-05	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.3733333333	False
two	0.0	0.0	0.0	0.0	0.2552594670	False
control	0.000381989610637	0.0	0.0	0.0	0.0000000000	False
structures	0.000329386410676	0.0	0.0	0.0	0.4501607717	False
conditional	0.00124588914056	0.0	0.0	0.0	0.2937062937	False
loop	0.000533120661086	0.0	0.0	0.0	0.0000000000	False
eliminated	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
introducing	0.000680491281794	0.0	0.0	0.0	0.5384615385	False
sequential	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
composition	0.00113463687216	0.0	0.0	0.0	0.0000000000	False
binary	0.00100118567947	0.0	0.0	0.0	0.5260960334	False
assume	0.000165476232223	0.0	0.0	0.0	0.0000000000	False
semicolon	0.00389143424424	0.0	0.0	0.0	0.2222222222	False
compound	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
don	0.0	0.0	0.0	0.0	0.3309692671	False
care	0.000143099867468	0.0	0.0	0.0	0.0000000000	False
give	1.42855728032e-05	0.0	0.0	0.0	0.4912280702	False
drawing	0.000180077990554	0.0	0.0	0.0	0.0000000000	False
triangles	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
denote	0.000381989610637	0.0	0.0	0.0	0.0000000000	False
seats	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
expand	0.000472701916409	0.0	0.0	0.0	0.0000000000	False
first	0.0	0.0	0.0	0.0	0.3456790123	False
right	0.0	0.0	0.0	0.0	0.3860667634	False
circle	0.000355413774057	0.0	0.0	0.0	0.0000000000	False
semi	0.00218428180948	0.0	0.0	0.0	0.3309692671	False
colon	0.00273896548864	0.0	0.0	0.0	0.3894899536	False
forms	0.000549229986283	0.0	0.0	0.0	0.3181818182	False
left	0.000135540071612	0.0	0.0	0.0	0.0000000000	False
sub	0.0	0.0	0.0	0.0	0.0000000000	False
strictly	0.000277959588874	0.0	0.0	0.0	0.0000000000	False
speaking	0.000190291697123	0.0	0.0	0.0	0.0000000000	False
obvious	0.000570875091368	0.0	0.0	0.0	0.0000000000	False
sense	6.2789848203e-05	0.0	0.0	0.0	0.0000000000	False
correspond	0.000952687794511	0.0	0.0	0.0	0.3320158103	False
inside	0.000193534749488	0.0	0.0	0.0	0.0000000000	False
semantics	0.000877262070794	0.0	0.0	0.0	0.5185185185	False
function	5.41543367336e-05	0.0	0.0	0.0	0.0000000000	False
associative	0.000272196512718	0.0	0.0	0.0	0.0000000000	False
means	5.35708980121e-05	0.0	0.0	0.0	0.5283018868	False
implementation	0.000290302124232	0.0	0.0	0.0	0.0000000000	False
concerned	0.000556214266371	0.0	0.0	0.0	0.4501607717	False
decision	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
regard	0.00152164749369	0.0	0.0	0.0	0.3814713896	False
fact	5.41543367336e-05	0.0	0.0	0.0	0.0000000000	False
matter	0.000193534749488	0.0	0.0	0.0	0.0000000000	False
runtime	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
behavior	0.000177706887029	0.0	0.0	0.0	0.0000000000	False
small	2.28845827618e-05	0.0	0.0	0.0	0.0000000000	False
disposed	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
expression	0.00666881456158	0.0	0.0	0.0	0.2164948454	False
boolean	0.00166775753325	0.0	0.0	0.0	0.2641509434	False
parenthesis	0.00395628348359	0.0	0.0	0.0	0.1586056645	False
value	0.0	0.0	0.0	0.0	0.0000000000	False
depending	9.41847723045e-05	0.0	0.0	0.0	0.0000000000	False
reference	0.000263509128541	0.0	0.0	0.0	0.4242424242	False
manual	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
algol	0.00151284916288	0.0	0.0	0.0	0.2978723404	False
sixty	0.000816307187567	0.0	0.0	0.0	0.2978723404	False
backus	0.00590819970115	0.0	0.0	0.0	0.2518397383	False
naur	0.00483398157367	0.0	0.0	0.0	0.2425409047	False
created	0.000290302124232	0.0	0.0	0.0	0.0000000000	False
john	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
peter	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
definition	0.00072502493613	0.0	0.0	0.0	0.4283727399	False
rigorous	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
syntactic	0.00152164749369	0.0	0.0	0.0	0.4242424242	False
based	8.36097556805e-05	0.0	0.0	0.0	0.0000000000	False
abs	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
accurately	0.000438631035397	0.0	0.0	0.0	0.0000000000	False
involved	0.000145432725716	0.0	0.0	0.0	0.0000000000	False
creation	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
fortan	0.00264748603504	0.0	0.0	0.0	0.1290322581	False
net	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
result	0.000154908370366	0.0	0.0	0.0	0.0000000000	False
clear	7.15499337339e-05	0.0	0.0	0.0	0.0000000000	False
written	0.000357749668669	0.0	0.0	0.0	0.5490196078	False
people	0.000154908370366	0.0	0.0	0.0	0.0000000000	False
gave	0.000204076796892	0.0	0.0	0.0	0.0000000000	False
interpretations	0.000190291697123	0.0	0.0	0.0	0.0000000000	False
comp	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
compatible	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
machines	0.000580604248465	0.0	0.0	0.0	0.2641509434	False
treated	0.000355413774057	0.0	0.0	0.0	0.0000000000	False
moving	5.00833434651e-05	0.0	0.0	0.0	0.0000000000	False
huge	0.000498389951942	0.0	0.0	0.0	0.0000000000	False
problem	1.44664219192e-05	0.0	0.0	0.0	0.0000000000	False
required	0.000329386410676	0.0	0.0	0.0	0.3814713896	False
team	0.000236350958204	0.0	0.0	0.0	0.0000000000	False
programmers	0.0006732073201	0.0	0.0	0.0	0.0000000000	False
rewrite	0.000472701916409	0.0	0.0	0.0	0.0000000000	False
suit	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
architecture	0.000277959588874	0.0	0.0	0.0	0.0000000000	False
substantial	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
patching	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
run	6.2789848203e-05	0.0	0.0	0.0	0.0000000000	False
correctly	0.000511328295531	0.0	0.0	0.0	0.0000000000	False
popular	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
theoretical	0.000277959588874	0.0	0.0	0.0	0.0000000000	False
study	0.000127329870212	0.0	0.0	0.0	0.0000000000	False
ensure	0.000236350958204	0.0	0.0	0.0	0.0000000000	False
readability	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
single	0.00135944874094	0.0	0.0	0.0	0.3869090909	False
character	0.00175452414159	0.0	0.0	0.0	0.2886597938	False
full	0.000381989610637	0.0	0.0	0.0	0.0000000000	False
wrote	0.000272196512718	0.0	0.0	0.0	0.0000000000	False
statements	0.00289231418513	1.0	0.0	0.0	0.1734985701	False
angle	0.000511328295531	0.0	0.0	0.0	0.0000000000	False
arrow	0.000710827548115	0.0	0.0	0.0	0.4242424242	False
mark	0.000570875091368	0.0	0.0	0.0	0.0000000000	False
type	0.00147162951848	0.0	0.0	0.0	0.2464103752	False
writer	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
double	0.000381989610637	0.0	0.0	0.0	0.0000000000	False
equal	0.000701166808512	0.0	0.0	0.0	0.2089552239	False
standard	0.000193534749488	0.0	0.0	0.0	0.0000000000	False
productions	0.00216460779361	0.0	0.0	0.0	0.4078834619	False
enclosed	0.00273896548864	0.0	0.0	0.0	0.3320158103	False
convenient	0.00127832073883	0.0	0.0	0.0	0.4501607717	False
extended	0.00209320866835	0.0	0.0	0.0	0.3266171792	False
adds	0.000154908370366	0.0	0.0	0.0	0.0000000000	False
power	8.36097556805e-05	0.0	0.0	0.0	0.0000000000	False
regular	0.000472701916409	0.0	0.0	0.0	0.0000000000	False
fashion	0.000621645783679	0.0	0.0	0.0	0.4242424242	False
convince	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
remember	0.00010016668693	0.0	0.0	0.0	0.0000000000	False
constructs	0.000238125631706	0.0	0.0	0.0	0.0000000000	False
options	0.00428561273473	0.0	0.0	0.0	0.2989323843	False
occurrences	0.00264748603504	0.0	0.0	0.0	0.4307692308	False
order	6.59409085721e-05	0.0	0.0	0.0	0.4719101124	False
limited	0.000290865451432	0.0	0.0	0.0	0.0000000000	False
introduction	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
aloow	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
kinds	7.42364434915e-05	0.0	0.0	0.0	0.5490196078	False
iterations	0.000466234337759	0.0	0.0	0.0	0.0000000000	False
essentially	6.2789848203e-05	0.0	0.0	0.0	0.0000000000	False
choice	9.00389952771e-05	0.0	0.0	0.0	0.0000000000	False
supposing	9.41847723045e-05	0.0	0.0	0.0	0.0000000000	False
alpha	0.00109657758849	0.0	0.0	0.0	0.2922755741	False
beta	0.0020196219603	0.0	0.0	0.0	0.2427745665	False
gamma	0.00102265659106	0.0	0.0	0.0	0.3500000000	False
strings	0.00209320866835	0.0	0.0	0.0	0.4283727399	False
note	0.000286199734936	0.0	0.0	0.0	0.5384615385	False
usual	0.000190291697123	0.0	0.0	0.0	0.2978723404	False
light	0.000657946553096	0.0	0.0	0.0	0.0000000000	False
equivalent	0.000877262070794	0.0	0.0	0.0	0.3500000000	False
set	6.59409085721e-05	0.0	0.0	0.0	0.4077669903	False
epsilon	0.0011118383555	0.0	0.0	0.0	0.5384615385	False
unix	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
man	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
pages	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
find	2.96945773966e-05	0.0	0.0	0.0	0.0000000000	False
switches	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
separated	0.00108046794333	0.0	0.0	0.0	0.3442622951	False
square	0.000180077990554	0.0	0.0	0.0	0.0000000000	False
represent	0.000263509128541	0.0	0.0	0.0	0.4242424242	False
typical	0.000311472285139	0.0	0.0	0.0	0.0000000000	False
examp	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
bars	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
commas	0.0026855453187	0.0	0.0	0.0	0.3206106870	False
clutter	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
significance	0.00204531318212	0.0	0.0	0.0	0.2014388489	False
aide	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
writing	0.000228845827618	0.0	0.0	0.0	0.4093567251	False
out	0.0	0.0	0.0	0.0	0.4501607717	False
systematically	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
logical	0.000436298177149	0.0	0.0	0.0	0.0000000000	False
wouldn	0.0	0.0	0.0	0.0	0.0000000000	False
pascal	0.00334762448611	0.0	0.0	0.0	0.4283727399	False
allowed	0.000709052874613	0.0	0.0	0.0	0.2772277228	False
clause	0.00453854748864	0.0	0.0	0.0	0.2675159236	False
ideally	0.000555919177748	0.0	0.0	0.0	0.0000000000	False
sep	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
belongs	0.000190291697123	0.0	0.0	0.0	0.0000000000	False
grammatical	0.00113463687216	0.0	0.0	0.0	0.0000000000	False
entity	0.00109657758849	0.0	0.0	0.0	0.5490196078	False
put	0.000114422913809	0.0	0.0	0.0	0.3814713896	False
normal	0.000919707312486	0.0	0.0	0.0	0.5074135091	False
reduce	0.000145432725716	0.0	0.0	0.0	0.0000000000	False
amount	0.000207648190093	0.0	0.0	0.0	0.0000000000	False
number	6.78564708153e-05	0.0	0.0	0.0	0.2918266594	False
real	0.000120837489355	0.0	0.0	0.0	0.0000000000	False
world	0.000166129983981	0.0	0.0	0.0	0.0000000000	False
large	0.000250416717326	0.0	0.0	0.0	0.5490196078	False
piece	9.00389952771e-05	0.0	0.0	0.0	0.0000000000	False
adding	0.000119062815853	0.0	0.0	0.0	0.0000000000	False
extra	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
wise	0.000833878766623	0.0	0.0	0.0	0.0000000000	False
respect	0.000119062815853	0.0	0.0	0.0	0.0000000000	False
repetitions	0.00174742544758	0.0	0.0	0.0	0.2978723404	False
braces	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
bnf	0.0026855453187	0.0	0.0	0.0	0.3814713896	False
practical	0.000103824095046	0.0	0.0	0.0	0.0000000000	False
reasons	0.000361440190966	0.0	0.0	0.0	0.5090909091	False
diagrams	0.000438631035397	0.0	0.0	0.0	0.0000000000	False
directly	0.000166129983981	0.0	0.0	0.0	0.0000000000	False
ordinary	0.000277959588874	0.0	0.0	0.0	0.0000000000	False
important	0.00024167497871	0.0	0.0	0.0	0.5185185185	False
reading	0.00013175456427	0.0	0.0	0.0	0.0000000000	False
learning	8.36097556805e-05	0.0	0.0	0.0	0.0000000000	False
looked	0.000103824095046	0.0	0.0	0.0	0.4000000000	False
toy	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
didn	0.0	0.0	0.0	0.0	0.0000000000	False
designed	0.000207648190093	0.0	0.0	0.0	0.0000000000	False
purposes	0.000167219511361	0.0	0.0	0.0	0.0000000000	False
teaching	0.000204076796892	0.0	0.0	0.0	0.0000000000	False
nicolas	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
worth	0.000236350958204	0.0	0.0	0.0	0.0000000000	False
main	0.000498389951942	0.0	0.0	0.0	0.0000000000	False
smaller	9.00389952771e-05	0.0	0.0	0.0	0.0000000000	False
data	0.000444812479666	0.0	0.0	0.0	0.3974193548	False
features	0.00063027296694	0.0	0.0	0.0	0.4242424242	False
integers	0.00202034879696	0.0	0.0	0.0	0.5006877579	False
assignment	0.000556214266371	0.0	0.0	0.0	0.3309692671	False
arm	0.000912988496212	0.0	0.0	0.0	0.0000000000	False
neglect	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
encode	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
false	0.000511328295531	0.0	0.0	0.0	0.0000000000	False
greater	0.000387069498977	0.0	0.0	0.0	0.2978723404	False
true	0.000214649801202	0.0	0.0	0.0	0.0000000000	False
mechanism	0.000310822891839	0.0	0.0	0.0	0.0000000000	False
parameter	0.000290302124232	0.0	0.0	0.0	0.0000000000	False
list	0.000270116985831	0.0	0.0	0.0	0.0000000000	False
procedures	0.00130969097438	0.0	0.0	0.0	0.1727425687	False
step	6.2789848203e-05	0.0	0.0	0.0	0.0000000000	False
refinement	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
nested	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
development	0.000136098256359	0.0	0.0	0.0	0.0000000000	False
top	7.15499337339e-05	0.0	0.0	0.0	0.0000000000	False
start	0.0	0.0	0.0	0.0	0.5283018868	False
explicitly	0.000766992443296	0.0	0.0	0.0	0.0000000000	False
colored	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
block	0.000945403832817	0.0	0.0	0.0	0.4242424242	False
dot	0.000272196512718	0.0	0.0	0.0	0.0000000000	False
period	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
consists	0.000581730902865	0.0	0.0	0.0	0.5384615385	False
declaration	0.00415324959952	0.0	0.0	0.0	0.1648222275	False
brevity	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
names	0.000355413774057	0.0	0.0	0.0	0.0000000000	False
letter	0.00230097732989	0.0	0.0	0.0	0.1575984991	False
sort	8.08749963029e-05	0.0	0.0	0.0	0.0000000000	False
constant	0.00145151062116	0.0	0.0	0.0	0.3411860276	False
const	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
dark	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
stand	0.000177706887029	0.0	0.0	0.0	0.0000000000	False
identifier	0.00290865451432	0.0	0.0	0.0	0.3589743590	True
infinite	0.000466234337759	0.0	0.0	0.0	0.0000000000	False
actual	0.000103824095046	0.0	0.0	0.0	0.5011933174	False
lengths	0.000136098256359	0.0	0.0	0.0	0.0000000000	False
part	4.33992657576e-05	0.0	0.0	0.0	0.3589743590	False
phase	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
moment	0.000570875091368	0.0	0.0	0.0	0.0000000000	False
occurs	0.000544393025435	0.0	0.0	0.0	0.4242424242	False
combination	9.67673747441e-05	0.0	0.0	0.0	0.0000000000	False
specifies	0.000438631035397	0.0	0.0	0.0	0.3414634146	False
entire	0.000404374981515	0.0	0.0	0.0	0.2919431280	False
variable	0.000851996037015	1.0	0.0	0.0	0.3083083083	False
var	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
erase	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
end	5.93891547932e-05	0.0	0.0	0.0	0.2978723404	False
empty	0.000932468675518	0.0	0.0	0.0	0.1953488372	False
implicitly	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
worry	0.000250829267042	0.0	0.0	0.0	0.0000000000	False
trivial	0.000766992443296	0.0	0.0	0.0	0.0000000000	False
absolutely	0.000290865451432	0.0	0.0	0.0	0.0000000000	False
relation	0.000290302124232	0.0	0.0	0.0	0.0000000000	False
sensitive	0.000873712723791	0.0	0.0	0.0	0.0000000000	False
explicit	0.000236350958204	0.0	0.0	0.0	0.0000000000	False
call	1.7856966004e-05	0.0	0.0	0.0	0.1995249406	False
begin	0.000387270925916	0.0	0.0	0.0	0.3309692671	False
produce	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
pair	0.000332259967961	0.0	0.0	0.0	0.0000000000	False
hardware	0.000438631035397	0.0	0.0	0.0	0.0000000000	False
previous	0.000120837489355	0.0	0.0	0.0	0.0000000000	False
defied	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
expense	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
somethings	0.000537109063741	0.0	0.0	0.0	0.4645550528	False
modified	0.000254659740425	0.0	0.0	0.0	0.0000000000	False
bit	3.13949241015e-05	0.0	0.0	0.0	0.0000000000	False
unary	0.00605139665152	0.0	0.0	0.0	0.2081784387	False
applies	0.00013175456427	0.0	0.0	0.0	0.0000000000	False
predicate	0.0018910614536	0.0	0.0	0.0	0.2922755741	False
condi	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
yields	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
odd	0.00121731799495	0.0	0.0	0.0	0.2978723404	False
partly	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
nice	0.000103824095046	0.0	0.0	0.0	0.0000000000	False
choosing	9.67673747441e-05	0.0	0.0	0.0	0.0000000000	False
direct	0.000145432725716	0.0	0.0	0.0	0.0000000000	False
jump	0.000472701916409	0.0	0.0	0.0	0.0000000000	False
high	9.00389952771e-05	0.0	0.0	0.0	0.0000000000	False
check	0.000501658534083	0.0	0.0	0.0	0.1953488372	False
simplified	0.000166129983981	0.0	0.0	0.0	0.0000000000	False
original	0.000250829267042	0.0	0.0	0.0	0.0000000000	False
extent	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
wirth	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
key	0.000334439022722	0.0	0.0	0.0	0.2978723404	False
board	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
comprise	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
diff	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
extremes	0.000238125631706	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
addition	0.000720311962217	0.0	0.0	0.0	0.2886597938	False
subtraction	0.000555919177748	0.0	0.0	0.0	0.0000000000	False
multiplication	0.0010186389617	0.0	0.0	0.0	0.2522522523	False
division	0.00131589310619	0.0	0.0	0.0	0.3206106870	False
sum	0.000207648190093	0.0	0.0	0.0	0.0000000000	False
difference	7.2332109596e-06	0.0	0.0	0.0	0.3814713896	False
quotient	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
doesn	0.0	0.0	0.0	0.0	0.0000000000	False
sufficiently	0.000166129983981	0.0	0.0	0.0	0.0000000000	False
understand	1.88101140075e-05	0.0	0.0	0.0	0.0000000000	False
priority	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
evaluation	0.000466234337759	0.0	0.0	0.0	0.0000000000	False
fully	0.00166775753325	0.0	0.0	0.0	0.3206106870	False
operands	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
minus	0.00108753740419	0.0	0.0	0.0	0.2485207101	False
star	0.00102038398446	0.0	0.0	0.0	0.3309692671	False
divided	0.000193534749488	0.0	0.0	0.0	0.0000000000	False
tedious	0.00161132719122	0.0	0.0	0.0	0.0000000000	False
parenthesized	0.00182597699242	0.0	0.0	0.0	0.4242424242	False
translated	0.000177706887029	0.0	0.0	0.0	0.0000000000	False
preserves	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
vice	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
versa	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
transform	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
point	7.14278640161e-06	0.0	0.0	0.0	0.0000000000	False
view	0.000119062815853	0.0	0.0	0.0	0.0000000000	False
unacceptable	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
versions	0.000136098256359	0.0	0.0	0.0	0.0000000000	False
makes	1.44664219192e-05	0.0	0.0	0.0	0.0000000000	False
strike	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
compromise	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
conventions	0.00101802908001	0.0	0.0	0.0	0.3146067416	False
mathematical	0.000996779903884	0.0	0.0	0.0	0.3206106870	False
mention	0.000136098256359	0.0	0.0	0.0	0.0000000000	False
overloaded	0.00226927374432	0.0	0.0	0.0	0.2427745665	False
negative	0.000509319480849	0.0	0.0	0.0	0.2978723404	False
positive	5.00833434651e-05	0.0	0.0	0.0	0.0000000000	False
account	0.000777057229599	0.0	0.0	0.0	0.3814713896	False
lot	5.00833434651e-05	0.0	0.0	0.0	0.0000000000	False
multilic	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
tremendously	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
bind	0.00100981098015	0.0	0.0	0.0	0.0000000000	False
tightest	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
influence	0.000277959588874	0.0	0.0	0.0	0.0000000000	False
takes	0.000143382218053	0.0	0.0	0.0	0.4338498212	False
precedence	0.00127832073883	0.0	0.0	0.0	0.4501607717	False
negation	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
tighter	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
looses	0.000277959588874	0.0	0.0	0.0	0.0000000000	False
unparenthesized	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
friendly	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
user	0.000272196512718	0.0	0.0	0.0	0.0000000000	False
interface	0.000204076796892	0.0	0.0	0.0	0.0000000000	False
knowledge	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
trained	0.00015541144592	0.0	0.0	0.0	0.0000000000	False
provision	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
fairly	6.58772821352e-05	0.0	0.0	0.0	0.0000000000	False
expect	0.000145432725716	0.0	0.0	0.0	0.0000000000	False
books	0.000111242853274	0.0	0.0	0.0	0.0000000000	False
deal	0.000166129983981	0.0	0.0	0.0	0.0000000000	False
wont	0.000555919177748	0.0	0.0	0.0	0.0000000000	False
great	7.15499337339e-05	0.0	0.0	0.0	0.0000000000	False
details	0.000110317488148	0.0	0.0	0.0	0.0000000000	False
unambiguous	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
glance	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
work	2.70771683668e-05	0.0	0.0	0.0	0.0000000000	False
term	0.000300961824121	0.0	0.0	0.0	0.0884676145	False
unsigned	0.0026855453187	0.0	0.0	0.0	0.3309692671	False
disregard	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
signed	0.000710827548115	0.0	0.0	0.0	0.4242424242	False
factor	0.000996779903884	0.0	0.0	0.0	0.1473684211	False
unit	0.00108788012144	0.0	0.0	0.0	0.2666666667	False
talking	7.2332109596e-06	0.0	0.0	0.0	0.0000000000	False
mutually	0.000756424581439	0.0	0.0	0.0	0.0000000000	False
recursive	0.000709052874613	0.0	0.0	0.0	0.0000000000	False
circularly	0.00131056908569	0.0	0.0	0.0	0.0000000000	False
basically	4.45418660949e-05	0.0	0.0	0.0	0.0000000000	False
outermost	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
revolving	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
pragmatic	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
linearly	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
lastly	0.000204076796892	0.0	0.0	0.0	0.0000000000	False
digit	0.00124329156736	0.0	0.0	0.0	0.1750000000	False
rules	0.000357188447559	0.0	0.0	0.0	0.0000000000	False
alphabet	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
upper	0.000236350958204	0.0	0.0	0.0	0.0000000000	False
lower	0.000136098256359	0.0	0.0	0.0	0.0000000000	False
distinguishes	0.000438631035397	0.0	0.0	0.0	0.0000000000	False
removing	0.000177706887029	0.0	0.0	0.0	0.0000000000	False
lexical	0.00107421812748	0.0	0.0	0.0	0.0000000000	False
analysis	0.000254659740425	0.0	0.0	0.0	0.0000000000	False
recognizing	0.000945403832817	0.0	0.0	0.0	0.2058823529	False
process	0.00028306248706	0.0	0.0	0.0	0.2886597938	False
scanning	0.00118175479102	0.0	0.0	0.0	0.2922755741	False
file	0.00265299835959	0.0	0.0	0.0	0.1477872513	False
lexemes	0.00322265438245	0.0	0.0	0.0	0.3206106870	False
describe	0.000127329870212	0.0	0.0	0.0	0.0000000000	False
decide	7.15499337339e-05	0.0	0.0	0.0	0.0000000000	False
scanner	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
desk	0.000436856361895	0.0	0.0	0.0	0.0000000000	False
unbounded	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
object	9.67673747441e-05	0.0	0.0	0.0	0.0000000000	False
converts	0.000219315517699	0.0	0.0	0.0	0.0000000000	False
handling	0.000190291697123	0.0	0.0	0.0	0.0000000000	False
lose	0.000236350958204	0.0	0.0	0.0	0.0000000000	False
status	0.00037821229072	0.0	0.0	0.0	0.0000000000	False
element	7.74541851832e-05	0.0	0.0	0.0	0.0000000000	False
identification	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
index	0.000408153593784	0.0	0.0	0.0	0.0000000000	False
table	0.000996779903884	0.0	0.0	0.0	0.1953488372	False
striped	0.000537109063741	0.0	0.0	0.0	0.0000000000	False
filled	0.000177706887029	0.0	0.0	0.0	0.0000000000	False
area	0.000119062815853	0.0	0.0	0.0	0.0000000000	False
information	0.000180077990554	0.0	0.0	0.0	0.0000000000	False
extract	0.00033660366005	0.0	0.0	0.0	0.0000000000	False
detect	0.000511328295531	0.0	0.0	0.0	0.0000000000	False
good	5.41543367336e-05	0.0	0.0	0.0	0.0000000000	False
spelling	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
mistakes	0.000277959588874	0.0	0.0	0.0	0.0000000000	False
resident	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
memory	0.000177706887029	0.0	0.0	0.0	0.0000000000	False
issues	0.000103824095046	0.0	0.0	0.0	0.0000000000	False
hasn	0.0	0.0	0.0	0.0	0.0000000000	False
future	0.000255664147765	0.0	0.0	0.0	0.0000000000	False
critical	0.000304329498737	0.0	0.0	0.0	0.0000000000	False
material	0.000177706887029	0.0	0.0	0.0	0.0000000000	False
long	0.000311472285139	0.0	0.0	0.0	0.0000000000	False
graders so i guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess sometime next week	0.0	0.0	0.0	2.0	0.0000000000	False
out the first homework	0.0	0.0	0.0	2.0	0.0000000000	False
assignment for this class	0.0	0.0	0.0	2.0	0.0000000000	False
class is this loud	0.0	0.0	0.0	2.0	0.0000000000	False
people in the back	0.0	0.0	0.0	2.0	0.0000000000	False
mic a bit louder	0.0	0.0	0.0	2.0	0.0000000000	False
out the first problem	0.0	0.0	0.0	2.0	0.0000000000	False
ll be two weeks	0.0	0.0	0.0	2.0	0.0000000000	False
problems in this class	0.0	0.0	0.0	2.0	0.0000000000	False
graders are usually members	0.0	0.0	0.0	2.0	0.0000000000	False
ll email the class	0.0	0.0	0.0	2.0	0.0000000000	False
class to solicit applications	0.0	0.0	0.0	2.0	0.0000000000	False
interested in becoming graders	0.0	0.0	0.0	2.0	0.0000000000	False
graders for this class	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a fun	0.0	0.0	0.0	2.0	0.0000000000	False
four times this quarter	0.0	0.0	0.0	2.0	0.0000000000	False
spend one evening staying	0.0	0.0	0.0	2.0	0.0000000000	False
grading all the homework	0.0	0.0	0.0	2.0	0.0000000000	False
half of the teaching	0.0	0.0	0.0	2.0	0.0000000000	False
good solution and amazing	0.0	0.0	0.0	2.0	0.0000000000	False
solution and amazing solution	0.0	0.0	0.0	2.0	0.0000000000	False
solution and to give	0.0	0.0	0.0	2.0	0.0000000000	False
solutions becoming a grader	0.0	0.0	0.0	2.0	0.0000000000	False
graders are paid positions	0.0	0.0	0.0	2.0	0.0000000000	False
sort of hang out	0.0	0.0	0.0	2.0	0.0000000000	False
out for an evening	0.0	0.0	0.0	2.0	0.0000000000	False
grade all the assignments	0.0	0.0	0.0	2.0	0.0000000000	False
grader i ll send	0.0	0.0	0.0	0.0	0.0000000000	False
details and to solicit	0.0	0.0	0.0	2.0	0.0000000000	False
talk about linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
notes have been posted	0.0	0.0	0.0	2.0	0.0000000000	False
written out and work	0.0	0.0	0.0	2.0	0.0000000000	False
work through the details	0.0	0.0	0.0	2.0	0.0000000000	False
download detailed lecture notes	0.0	0.0	0.0	2.0	0.0000000000	False
amount  some amount	0.0	0.0	0.0	2.0	0.0000000000	False
amount of linear algebra	0.0	0.0	0.0	2.0	0.0000000000	False
refresher on linear algebra	0.0	0.0	0.0	4.0	0.0000000000	False
week s discussion section	0.0	0.0	0.0	0.0	0.0000000000	False
section will be taught	0.0	0.0	0.0	2.0	0.0000000000	False
taught by the tas	0.0	0.0	0.0	2.0	0.0000000000	False
linear algebra i talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about today sort	0.0	0.0	0.0	2.0	0.0000000000	False
things i m claiming	0.0	0.0	0.0	0.0	0.0000000000	False
written out in detail	0.0	0.0	0.0	2.0	0.0000000000	False
showing you a fun	0.0	0.0	0.0	2.0	0.0000000000	False
talked about supervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
supervised learning and supervised	0.0	0.0	0.0	2.0	0.0000000000	False
learning and supervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm what the close	0.0	0.0	0.0	2.0	0.0000000000	False
lecture was the problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem of predicting housing	0.0	0.0	0.0	2.0	0.0000000000	False
right " housing price	0.0	0.0	0.0	2.0	0.0000000000	False
house in the training	0.0	0.0	0.0	4.0	0.0000000000	False
houses and the prices	0.0	0.0	0.0	4.0	0.0000000000	False
show you a video	0.0	0.0	0.0	4.0	0.0000000000	False
load the big screen	0.0	0.0	0.0	2.0	0.0000000000	False
pomerleau at some work	0.0	0.0	0.0	2.0	0.0000000000	False
mellon on applied supervised	0.0	0.0	0.0	2.0	0.0000000000	False
work on a vehicle	0.0	0.0	0.0	2.0	0.0000000000	False
vehicle known as alvin	0.0	0.0	0.0	2.0	0.0000000000	False
supervised or any algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
dean pomerleau s voice	0.0	0.0	0.0	0.0	0.0000000000	False
pomerleau s voice mention	0.0	0.0	0.0	0.0	0.0000000000	False
voice mention and algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm called neural network	0.0	0.0	0.0	2.0	0.0000000000	False
lecture let s watch	0.0	0.0	0.0	0.0	0.0000000000	False
shows that we re	0.0	0.0	0.0	0.0	0.0000000000	False
re on this segment	0.0	0.0	0.0	2.0	0.0000000000	False
segment of the road	0.0	0.0	0.0	4.0	0.0000000000	False
steer at this angle	0.0	0.0	0.0	4.0	0.0000000000	False
human provides the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of " correct	0.0	0.0	0.0	2.0	0.0000000000	False
correct " steering directions	0.0	0.0	0.0	4.0	0.0000000000	False
directions to the car	0.0	0.0	0.0	2.0	0.0000000000	False
job of the car	0.0	0.0	0.0	2.0	0.0000000000	False
car on the road	0.0	0.0	0.0	2.0	0.0000000000	False
road on the monitor	0.0	0.0	0.0	2.0	0.0000000000	False
left where the mouse	0.0	0.0	0.0	2.0	0.0000000000	False
mouse pointer is moving	0.0	0.0	0.0	2.0	0.0000000000	False
horizontal line actually shows	0.0	0.0	0.0	2.0	0.0000000000	False
shows the human steering	0.0	0.0	0.0	2.0	0.0000000000	False
area right here shows	0.0	0.0	0.0	2.0	0.0000000000	False
shows the steering direction	0.0	0.0	0.0	2.0	0.0000000000	False
moving the steering wheel	0.0	0.0	0.0	2.0	0.0000000000	False
steering a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit to the left	0.0	0.0	0.0	2.0	0.0000000000	False
region this second line	0.0	0.0	0.0	2.0	0.0000000000	False
line here where mamos	0.0	0.0	0.0	2.0	0.0000000000	False
output of the learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm currently thinks	0.0	0.0	0.0	2.0	0.0000000000	False
thinks is the right	0.0	0.0	0.0	2.0	0.0000000000	False
entire range of steering	0.0	0.0	0.0	2.0	0.0000000000	False
range of steering directions	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm collects more examples	0.0	0.0	0.0	2.0	0.0000000000	False
confidently choose a steering	0.0	0.0	0.0	2.0	0.0000000000	False
choose a steering direction	0.0	0.0	0.0	2.0	0.0000000000	False
back to the chalkboard	0.0	0.0	2.99840764331	6.0	0.0000000000	False
ago and autonomous driving	0.0	0.0	0.0	2.0	0.0000000000	False
heard of the darpa	0.0	0.0	0.0	2.0	0.0000000000	False
car across a desert	0.0	0.0	0.0	2.0	0.0000000000	False
call the regression problem	0.0	0.0	0.0	4.0	0.0000000000	False
predict a continuous value	0.0	0.0	0.0	2.0	0.0000000000	False
continuous value steering directions	0.0	0.0	0.0	2.0	0.0000000000	False
first supervised learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
re going to return	0.0	0.0	0.0	2.0	0.0000000000	False
housing prices in portland	0.0	0.0	0.0	2.0	0.0000000000	False
dataset of a number	0.0	0.0	0.0	2.0	0.0000000000	False
houses of different sizes	0.0	0.0	0.0	2.0	0.0000000000	False
make your other dataset	0.0	0.0	0.0	2.0	0.0000000000	False
call a training set	0.0	0.0	0.0	2.0	0.0000000000	False
relationship between the size	0.0	0.0	0.0	2.0	0.0000000000	False
size of the house	0.0	0.0	3.99787685775	8.0	0.0000000000	False
price of the house	0.0	0.0	0.0	4.0	0.0000000000	False
task a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
first piece of notation	0.0	0.0	0.0	2.0	0.0000000000	False
case alphabet m denote	0.0	0.0	0.0	2.0	0.0000000000	False
number of training examples	0.0	0.0	3.99734607219	10.0	0.0000000000	False
alphabet m to denote	0.0	0.0	0.0	2.0	0.0000000000	False
alphabet x to denote	0.0	0.0	0.0	2.0	0.0000000000	False
denote the input variables	0.0	0.0	0.0	2.0	0.0000000000	False
ll often also call	0.0	0.0	0.0	2.0	0.0000000000	False
denote the " output	0.0	0.0	0.0	2.0	0.0000000000	False
row on the table	0.0	0.0	0.0	2.0	0.0000000000	False
words the ith row	0.0	0.0	0.0	2.0	0.0000000000	False
row in that table	0.0	0.0	0.0	2.0	0.0000000000	False
superscript i in parentheses	0.0	0.0	0.0	2.0	0.0000000000	False
parentheses is just sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of an index	0.0	0.0	0.0	2.0	0.0000000000	False
row of my list	0.0	0.0	0.0	2.0	0.0000000000	False
list of training examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples so in supervised	0.0	0.0	0.0	2.0	0.0000000000	False
re given a training	0.0	0.0	0.0	2.0	0.0000000000	False
re going to feed	0.0	0.0	0.0	2.0	0.0000000000	False
feed our training set	0.0	0.0	0.0	2.0	0.0000000000	False
comprising our m training	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm then has output	0.0	0.0	0.0	2.0	0.0000000000	False
denoted lower case alphabet	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis do nt worry	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis has a deep	0.0	0.0	0.0	2.0	0.0000000000	False
reasons and the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
area in square feet	0.0	0.0	0.0	2.0	0.0000000000	False
feet saying and output	0.0	0.0	0.0	2.0	0.0000000000	False
output estimates the price	0.0	0.0	0.0	2.0	0.0000000000	False
price of this house	0.0	0.0	0.0	2.0	0.0000000000	False
house so the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
inputs x to outputs	0.0	0.0	0.0	2.0	0.0000000000	False
design a learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
purposes of this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
representation for the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
generally for many regression	0.0	0.0	0.0	2.0	0.0000000000	False
bedrooms in these houses	0.0	0.0	0.0	2.0	0.0000000000	False
bedrooms in the house	0.0	0.0	0.0	2.0	0.0000000000	False
size and square feet	0.0	0.0	0.0	2.0	0.0000000000	False
two denote the number	0.0	0.0	0.0	2.0	0.0000000000	False
theta rho plus theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta 1x1 plus theta	0.0	0.0	0.0	2.0	0.0000000000	False
dependent on the theta	0.0	0.0	0.0	2.0	0.0000000000	False
price that my hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis predicts a house	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis predicts this house	0.0	0.0	0.0	2.0	0.0000000000	False
cost one final piece	0.0	0.0	0.0	2.0	0.0000000000	False
final piece of notation	0.0	0.0	0.0	4.0	0.0000000000	False
write this a bit	0.0	0.0	0.0	2.0	0.0000000000	False
sum from i equals	0.0	0.0	5.99681528662	12.0	0.3973509934	False
features in my learning	0.0	0.0	0.0	2.0	0.0000000000	False
fair amount of notation	0.0	0.0	0.0	4.0	0.0000000000	False
proceed through the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
symbol and you re	0.0	0.0	0.0	0.0	0.0000000000	False
standardize notation and make	0.0	0.0	0.0	2.0	0.0000000000	False
lot of our descriptions	0.0	0.0	0.0	2.0	0.0000000000	False
descriptions of learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms a lot	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms a lot easier	0.0	0.0	0.0	2.0	0.0000000000	False
remember what it means	0.0	0.0	0.0	2.0	0.0000000000	False
class who ve forgotten	0.0	0.0	0.0	0.0	0.0000000000	False
wondering what some symbol	0.0	0.0	0.0	2.0	0.0000000000	False
symbol means any questions	0.0	0.0	0.0	2.0	0.0000000000	False
theta or the theta	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of our learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm and theta	0.0	0.0	0.0	2.0	0.0000000000	False
job of the learning	0.0	0.0	0.0	2.0	0.0000000000	False
training set to choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose or to learn	0.0	0.0	0.0	2.0	0.0000000000	False
learn appropriate parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta and theta transpose	0.0	0.0	0.0	2.0	0.0000000000	False
theta all great questions	0.0	0.0	0.0	2.0	0.0000000000	False
great questions the answer	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis or can theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta be a function	0.0	0.0	0.0	2.0	0.0000000000	False
function of other variables	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm we ll talk	0.0	0.0	0.0	0.0	0.0000000000	False
class a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
talk about higher order	0.0	0.0	0.0	2.0	0.0000000000	False
chose the parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis h will make	0.0	0.0	0.0	2.0	0.0000000000	False
predictions of the housing	0.0	0.0	0.0	2.0	0.0000000000	False
set so one thing	0.0	0.0	0.0	2.0	0.0000000000	False
predictions of a learning	0.0	0.0	0.0	2.0	0.0000000000	False
accurate on a training	0.0	0.0	0.0	2.0	0.0000000000	False
make that theta square	0.0	0.0	0.0	2.0	0.0000000000	False
difference between the prediction	0.0	0.0	0.0	2.0	0.0000000000	False
prediction of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
minimize over the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
area between the predicted	0.0	0.0	0.0	2.0	0.0000000000	False
examples so the sum	0.0	0.0	0.0	2.0	0.0000000000	False
house in my training	0.0	0.0	0.0	2.0	0.0000000000	False
actual target variable mine	0.0	0.0	0.0	2.0	0.0000000000	False
mine is actual price	0.0	0.0	0.0	2.0	0.0000000000	False
sum of the squared	0.0	0.0	0.0	4.0	0.0000000000	False
define j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
predicted by my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
minus the actual value	0.0	0.0	0.0	2.0	0.0000000000	False
minimize as a function	0.0	0.0	0.0	2.0	0.0000000000	False
function of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
quantity j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
sort of linear algebra	0.0	0.0	0.0	2.0	0.0000000000	False
show that this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
broader class of algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
ll get there eventually	0.0	0.0	0.0	2.0	0.0000000000	False
talk about a couple	0.0	0.0	0.0	2.0	0.0000000000	False
couple of different algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
theta the first algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
start with some value	0.0	0.0	0.0	2.0	0.0000000000	False
value of my parameter	0.0	0.0	0.0	2.0	0.0000000000	False
vector theta maybe initialize	0.0	0.0	0.0	2.0	0.0000000000	False
initialize my parameter vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector of all zeros	0.0	0.0	5.99787685775	8.0	0.0000000000	False
correct that i sort	0.0	0.0	0.0	2.0	0.0000000000	False
changing my parameter vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector theta to reduce	0.0	0.0	0.0	2.0	0.0000000000	False
reduce j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
lower the big screen	0.0	0.0	0.0	2.0	0.0000000000	False
show you an animation	0.0	0.0	0.0	2.0	0.0000000000	False
first algorithm for minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
minimizing j of theta	0.0	0.0	3.99734607219	10.0	0.4395604396	False
plot and the axes	0.0	0.0	0.0	2.0	0.0000000000	False
horizontal axes are theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta zero and theta	0.0	0.0	3.99787685775	8.0	0.5263157895	False
represented by the height	0.0	0.0	0.0	2.0	0.0000000000	False
height of this plot	0.0	0.0	0.0	2.0	0.0000000000	False
plot so the surface	0.0	0.0	0.0	2.0	0.0000000000	False
surface represents the function	0.0	0.0	0.0	2.0	0.0000000000	False
function j of theta	0.0	0.0	7.99734607219	10.0	0.0000000000	False
theta and the axes	0.0	0.0	0.0	2.0	0.0000000000	False
axes of this function	0.0	0.0	0.0	2.0	0.0000000000	False
inputs of this function	0.0	0.0	0.0	2.0	0.0000000000	False
function are the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
choose some initial point	0.0	0.0	0.0	2.0	0.0000000000	False
start from that point	0.0	0.0	0.0	2.0	0.0000000000	False
denoted by the star	0.0	0.0	0.0	2.0	0.0000000000	False
imagine that this display	0.0	0.0	0.0	2.0	0.0000000000	False
shows a 3d landscape	0.0	0.0	0.0	2.0	0.0000000000	False
landscape imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
hill in some park	0.0	0.0	0.0	2.0	0.0000000000	False
physically at the position	0.0	0.0	0.0	2.0	0.0000000000	False
position of that star	0.0	0.0	0.0	2.0	0.0000000000	False
imagine you can stand	0.0	0.0	0.0	2.0	0.0000000000	False
stand on that hill	0.0	0.0	0.0	2.0	0.0000000000	False
hill and you re	0.0	0.0	0.0	0.0	0.0000000000	False
direction of steepest descent	0.0	0.0	5.9957537155	16.0	0.0000000000	False
step in this direction	0.0	0.0	0.0	2.0	0.0000000000	False
direction that the gradient	0.0	0.0	0.0	2.0	0.0000000000	False
step and you end	0.0	0.0	0.0	2.0	0.0000000000	False
point on this hill	0.0	0.0	0.0	2.0	0.0000000000	False
minimum of this function	0.0	0.0	0.0	4.0	0.0000000000	False
property of gradient descent	0.0	0.0	2.99840764331	6.0	0.0000000000	False
lower left hand corner	0.0	0.0	0.0	2.0	0.0000000000	False
corner of this plot	0.0	0.0	0.0	2.0	0.0000000000	False
slightly different initial starting	0.0	0.0	0.0	4.0	0.0000000000	False
right so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out if you run	0.0	0.0	0.0	2.0	0.0000000000	False
descent from that point	0.0	0.0	0.0	2.0	0.0000000000	False
completely different local optimum	0.0	0.0	0.0	2.0	0.0000000000	False
aware that gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
descent can sometimes depend	0.0	0.0	0.0	2.0	0.0000000000	False
work out the math	0.0	0.0	0.0	2.0	0.0000000000	False
math of the gradient	0.0	0.0	0.0	2.0	0.0000000000	False
issue of local optimum	0.0	0.0	0.0	2.0	0.0000000000	False
descent algorithm we re	0.0	0.0	0.0	0.0	0.0000000000	False
repeatedly take a step	0.0	0.0	0.0	2.0	0.0000000000	False
step in the direction	0.0	0.0	0.0	2.0	0.0000000000	False
re going to update	0.0	0.0	2.99840764331	6.0	0.0000000000	False
update the parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
parameters theta as theta	0.0	0.0	0.0	2.0	0.0000000000	False
partial derivative with respect	0.0	0.0	5.99734607219	10.0	0.3252032520	False
update the i parameter	0.0	0.0	0.0	2.0	0.0000000000	False
iteration of gradient descent	0.0	0.0	4.99840764331	6.0	0.0000000000	False
descent just a point	0.0	0.0	0.0	2.0	0.0000000000	False
equals notation to denote	0.0	0.0	0.0	2.0	0.0000000000	False
notation to denote setting	0.0	0.0	0.0	2.0	0.0000000000	False
variable on the left	0.0	0.0	0.0	2.0	0.0000000000	False
variable on the right	0.0	0.0	0.0	2.0	0.0000000000	False
hand side all right	0.0	0.0	0.0	2.0	0.0000000000	False
write a colon equals	0.0	0.0	0.0	2.0	0.0000000000	False
part of a computer	0.0	0.0	0.0	2.0	0.0000000000	False
part of an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
value on the right	0.0	0.0	0.0	2.0	0.0000000000	False
value on the left	0.0	0.0	0.0	2.0	0.0000000000	False
hand side in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
truth i m claiming	0.0	0.0	0.0	0.0	0.0000000000	False
claiming that the value	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the value	0.0	0.0	0.0	2.0	0.0000000000	False
operation where we overwrite	0.0	0.0	0.0	2.0	0.0000000000	False
asserting that the values	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm sort of makes	0.0	0.0	0.0	2.0	0.0000000000	False
sort of makes sense	0.0	0.0	0.0	2.0	0.0000000000	False
problem and to work	0.0	0.0	0.0	2.0	0.0000000000	False
work out gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
first somewhat mathematical lecture	0.0	0.0	0.0	2.0	0.0000000000	False
quarter we ll work	0.0	0.0	0.0	0.0	0.0000000000	False
work through the steps	0.0	0.0	0.0	4.0	0.0000000000	False
out what this gradient	0.0	0.0	0.0	2.0	0.0000000000	False
respect to the parameter	0.0	0.0	0.0	4.0	0.0000000000	False
one-half of script theta	0.0	0.0	0.0	2.0	0.0000000000	False
two times one-half times	0.0	0.0	0.0	2.0	0.0000000000	False
times one-half times theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta of x minus	0.0	0.0	0.0	2.0	0.0000000000	False
inside the square right	0.0	0.0	0.0	2.0	0.0000000000	False
cancel so this leaves	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of this sum	0.0	0.0	0.0	2.0	0.0000000000	False
terms in the sum	0.0	0.0	0.0	2.0	0.0000000000	False
term here of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta i gets updated	0.0	0.0	3.99840764331	6.0	0.0000000000	False
theta i minus alpha	0.0	0.0	0.0	4.0	0.0000000000	False
parameter of the algorithm	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm called the learning	0.0	0.0	0.0	2.0	0.0000000000	False
standing on the hill	0.0	0.0	0.0	4.0	0.0000000000	False
hand if you choose	0.0	0.0	0.0	2.0	0.0000000000	False
small than your steepest	0.0	0.0	0.0	2.0	0.0000000000	False
long time to converge	0.0	0.0	0.0	2.0	0.0000000000	False
large then the steepest	0.0	0.0	0.0	2.0	0.0000000000	False
descent may actually end	0.0	0.0	0.0	2.0	0.0000000000	False
make lots of errors	0.0	0.0	0.0	2.0	0.0000000000	False
property into an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
generally for m training	0.0	0.0	0.0	2.0	0.0000000000	False
re going to repeat	0.0	0.0	0.0	2.0	0.0000000000	False
convergence the following step	0.0	0.0	0.0	2.0	0.0000000000	False
out the appropriate equation	0.0	0.0	0.0	2.0	0.0000000000	False
equation for m examples	0.0	0.0	0.0	2.0	0.0000000000	False
updated theta i minus	0.0	0.0	0.0	2.0	0.0000000000	False
alpha times the sum	0.0	0.0	0.0	2.0	0.0000000000	False
nt bother to show	0.0	0.0	0.0	0.0	0.0000000000	False
back to the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
specific problem of linear	0.0	0.0	0.0	2.0	0.0000000000	False
problem of linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
out for ordinary release	0.0	0.0	0.0	2.0	0.0000000000	False
contours of the function	0.0	0.0	0.0	2.0	0.0000000000	False
contours of a bow	0.0	0.0	0.0	2.0	0.0000000000	False
descent on this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
randomly at the position	0.0	0.0	0.0	2.0	0.0000000000	False
position of that cross	0.0	0.0	0.0	2.0	0.0000000000	False
result of one step	0.0	0.0	0.0	2.0	0.0000000000	False
step of gradient descent	0.0	0.0	1.99840764331	6.0	0.0000000000	False
hypothesis cost the function	0.0	0.0	0.0	2.0	0.0000000000	False
fake value of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
smaller and smaller steps	0.0	0.0	0.0	4.0	0.0000000000	False
converge and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
update theta by subtracting	0.0	0.0	0.0	2.0	0.0000000000	False
subtracting from alpha times	0.0	0.0	0.0	2.0	0.0000000000	False
alpha times the gradient	0.0	0.0	0.0	4.0	0.0000000000	False
local minimum the gradient	0.0	0.0	0.0	2.0	0.0000000000	False
steps as you approach	0.0	0.0	0.0	2.0	0.0000000000	False
approach the local minimum	0.0	0.0	9.99734607219	10.0	0.3448275862	False
local minimum make sense	0.0	0.0	0.0	2.0	0.0000000000	False
plot of the housing	0.0	0.0	0.0	2.0	0.0000000000	False
parameters to the vector	0.0	0.0	0.0	2.0	0.0000000000	False
line at the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
bottom shows the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis with the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
initialization so initially theta	0.0	0.0	0.0	2.0	0.0000000000	False
predicts that all prices	0.0	0.0	0.0	2.0	0.0000000000	False
found the least square	0.0	0.0	0.0	2.0	0.0000000000	False
fit for the data	0.0	0.0	0.0	2.0	0.0000000000	False
chalkboard are there questions	0.0	0.0	0.0	2.0	0.0000000000	False
cases the new values	0.0	0.0	0.0	2.0	0.0000000000	False
right and converged means	0.0	0.0	0.0	2.0	0.0000000000	False
means that the value	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a question	0.0	0.0	0.0	2.0	0.0000000000	False
theta has nt changed	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to minimize	0.0	0.0	0.0	2.0	0.0000000000	False
minimize is not changing	0.0	0.0	0.0	2.0	0.0000000000	False
sort of standard heuristics	0.0	0.0	0.0	2.0	0.0000000000	False
standard rules of thumb	0.0	0.0	0.0	2.0	0.0000000000	False
decide if gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent has converged	0.0	0.0	0.0	2.0	0.0000000000	False
descent so one feature	0.0	0.0	0.0	2.0	0.0000000000	False
answer the second part	0.0	0.0	0.0	2.0	0.0000000000	False
gradient of the function	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of the function	0.0	0.0	0.0	2.0	0.0000000000	False
direction of steepest ascent	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of a function	0.0	0.0	0.0	4.0	0.0000000000	False
function sort of turns	0.0	0.0	0.0	2.0	0.0000000000	False
sort of turns out	0.0	0.0	0.0	2.0	0.0000000000	False
out to just give	0.0	0.0	0.0	2.0	0.0000000000	False
give you the direction	0.0	0.0	0.0	2.0	0.0000000000	False
derivative and that turns	0.0	0.0	0.0	2.0	0.0000000000	False
nt a great term	0.0	0.0	0.0	0.0	0.0000000000	False
refers to the fact	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent you re	0.0	0.0	0.0	0.0	0.0000000000	False
training set you re	0.0	0.0	0.0	0.0	0.0000000000	False
re going to perform	0.0	0.0	0.0	2.0	0.0000000000	False
oregon in our training	0.0	0.0	0.0	2.0	0.0000000000	False
u.s census size databases	0.0	0.0	0.0	2.0	0.0000000000	False
millions of training examples	0.0	0.0	0.0	2.0	0.0000000000	False
re running batch rate	0.0	0.0	0.0	2.0	0.0000000000	False
batch rate and descent	0.0	0.0	0.0	2.0	0.0000000000	False
means that to perform	0.0	0.0	0.0	2.0	0.0000000000	False
sum from j equals	0.0	0.0	0.0	4.0	0.0000000000	False
million that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
sort of a lot	0.0	0.0	0.0	2.0	0.0000000000	False
lot of training examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples where your computer	0.0	0.0	0.0	2.0	0.0000000000	False
downhill on the function	0.0	0.0	0.0	2.0	0.0000000000	False
theta so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
write down an alternative	0.0	0.0	0.0	2.0	0.0000000000	False
call it incremental gradient	0.0	0.0	0.0	2.0	0.0000000000	False
convergence and will iterate	0.0	0.0	0.0	2.0	0.0000000000	False
iterate for j equals	0.0	0.0	0.0	2.0	0.0000000000	False
sort of gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
update all the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
data runs you perform	0.0	0.0	0.0	2.0	0.0000000000	False
update for all values	0.0	0.0	0.0	2.0	0.0000000000	False
indexes and the parameter	0.0	0.0	0.0	2.0	0.0000000000	False
simultaneously and the advantage	0.0	0.0	0.0	2.0	0.0000000000	False
advantage of this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
order to start learning	0.0	0.0	0.0	2.0	0.0000000000	False
order to start modifying	0.0	0.0	0.0	2.0	0.0000000000	False
start modifying the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
training example and perform	0.0	0.0	0.0	4.0	0.0000000000	False
derivative of the error	0.0	0.0	0.0	2.0	0.0000000000	False
update and you sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of keep adapting	0.0	0.0	0.0	2.0	0.0000000000	False
scan over your entire	0.0	0.0	0.0	2.0	0.0000000000	False
entire u.s census database	0.0	0.0	0.0	2.0	0.0000000000	False
contours of your function	0.0	0.0	0.0	2.0	0.0000000000	False
run the constant gradient	0.0	0.0	0.0	2.0	0.0000000000	False
end up going uphill	0.0	0.0	0.0	2.0	0.0000000000	False
wander to the region	0.0	0.0	0.0	2.0	0.0000000000	False
sort of keep wandering	0.0	0.0	0.0	2.0	0.0000000000	False
bit near the region	0.0	0.0	0.0	2.0	0.0000000000	False
bit the global minimum	0.0	0.0	0.0	2.0	0.0000000000	False
minimum and in practice	0.0	0.0	0.0	2.0	0.0000000000	False
ll ask what questions	0.0	0.0	0.0	2.0	0.0000000000	False
training example and update	0.0	0.0	0.0	2.0	0.0000000000	False
update all the theta	0.0	0.0	0.0	2.0	0.0000000000	False
perform the second gradient	0.0	0.0	0.0	2.0	0.0000000000	False
training example one training	0.0	0.0	0.0	2.0	0.0000000000	False
iterative algorithm for performing	0.0	0.0	0.0	2.0	0.0000000000	False
theta and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
problem of least squares	0.0	0.0	0.0	2.0	0.0000000000	False
solve for the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
theta in close form	0.0	0.0	2.99840764331	6.0	0.0000000000	False
run an iterative algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
typically done requires projections	0.0	0.0	0.0	2.0	0.0000000000	False
taking lots of derivatives	0.0	0.0	0.0	2.0	0.0000000000	False
derivatives and writing lots	0.0	0.0	0.0	2.0	0.0000000000	False
writing lots of algebra	0.0	0.0	0.0	2.0	0.0000000000	False
derive the closed form	0.0	0.0	0.0	2.0	0.0000000000	False
form solution of theta	0.0	0.0	0.0	2.0	0.0000000000	False
ll need to introduce	0.0	0.0	0.0	2.0	0.0000000000	False
introduce a new notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation for matrix derivatives	0.0	0.0	0.0	2.0	0.0000000000	False
personal work has turned	0.0	0.0	0.0	2.0	0.0000000000	False
algebra rather than writing	0.0	0.0	0.0	2.0	0.0000000000	False
out pages and pages	0.0	0.0	0.0	2.0	0.0000000000	False
re going to define	0.0	0.0	0.0	2.0	0.0000000000	False
define this new notation	0.0	0.0	0.0	2.0	0.0000000000	False
work out the minimization	0.0	0.0	0.0	2.0	0.0000000000	False
minimization given a function	0.0	0.0	0.0	2.0	0.0000000000	False
function of a vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector of parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of the gradient	0.0	0.0	0.0	2.0	0.0000000000	False
dimensional vector with indices	0.0	0.0	0.0	2.0	0.0000000000	False
vector with indices ranging	0.0	0.0	0.0	2.0	0.0000000000	False
rewrite the gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent as updating	0.0	0.0	0.0	2.0	0.0000000000	False
updating the parameter vector	0.0	0.0	0.0	4.0	0.0000000000	False
vector theta  notice	0.0	0.0	0.0	2.0	0.0000000000	False
previous parameter minus alpha	0.0	0.0	0.0	2.0	0.0000000000	False
parameter minus alpha times	0.0	0.0	0.0	2.0	0.0000000000	False
boards out of order	0.0	0.0	0.0	2.0	0.0000000000	False
function f that maps	0.0	0.0	0.0	2.0	0.0000000000	False
maps from the space	0.0	0.0	0.0	2.0	0.0000000000	False
matrices to the space	0.0	0.0	0.0	2.0	0.0000000000	False
space of real numbers	0.0	0.0	0.0	2.0	0.0000000000	False
matrix so this function	0.0	0.0	0.0	2.0	0.0000000000	False
matrices to real numbers	0.0	0.0	0.0	2.0	0.0000000000	False
matrix let me define	0.0	0.0	0.0	2.0	0.0000000000	False
respect to its input	0.0	0.0	0.0	2.0	0.0000000000	False
respect to the elements	0.0	0.0	0.0	2.0	0.0000000000	False
number of rows equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals number of columns	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the sum	0.0	0.0	0.0	2.0	0.0000000000	False
nt seen this sort	0.0	0.0	0.0	0.0	0.0000000000	False
sort of operator notation	0.0	0.0	0.0	2.0	0.0000000000	False
applied to the square	0.0	0.0	0.0	2.0	0.0000000000	False
written without the parentheses	0.0	0.0	0.0	2.0	0.0000000000	False
sum of diagonal elements	0.0	0.0	0.0	4.0	0.0000000000	False
facts about the trace	0.0	0.0	0.0	2.0	0.0000000000	False
operator and about derivatives	0.0	0.0	0.0	2.0	0.0000000000	False
write these without proof	0.0	0.0	0.0	2.0	0.0000000000	False
trace of the matrix	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the trace	0.0	0.0	5.99787685775	8.0	0.2941176471	False
trace of a product	0.0	0.0	0.0	2.0	0.0000000000	False
product of three matrices	0.0	0.0	0.0	2.0	0.0000000000	False
matrix at the end	0.0	0.0	0.0	2.0	0.0000000000	False
trace of a times	0.0	0.0	0.0	2.0	0.0000000000	False
matrix b and move	0.0	0.0	0.0	2.0	0.0000000000	False
defined as a trace	0.0	0.0	0.0	2.0	0.0000000000	False
number so the trace	0.0	0.0	0.0	2.0	0.0000000000	False
matrix a and output	0.0	0.0	0.0	2.0	0.0000000000	False
output a real number	0.0	0.0	0.0	2.0	0.0000000000	False
respect to the matrix	0.0	0.0	0.0	4.0	0.0000000000	False
referring to the definitions	0.0	0.0	0.0	2.0	0.0000000000	False
traces and matrix derivatives	0.0	0.0	0.0	4.0	0.0000000000	False
easy ones the trace	0.0	0.0	0.0	2.0	0.0000000000	False
trace of a transposed	0.0	0.0	0.0	2.0	0.0000000000	False
transposed because the trace	0.0	0.0	0.0	2.0	0.0000000000	False
matrix so the trace	0.0	0.0	0.0	2.0	0.0000000000	False
sort of just algebra	0.0	0.0	0.0	2.0	0.0000000000	False
armed with these things	0.0	0.0	0.0	2.0	0.0000000000	False
theta as a function	0.0	0.0	0.0	2.0	0.0000000000	False
iterative algorithm so work	0.0	0.0	0.0	2.0	0.0000000000	False
out let me define	0.0	0.0	0.0	2.0	0.0000000000	False
inputs from my training	0.0	0.0	0.0	2.0	0.0000000000	False
inputs to the vector	0.0	0.0	0.0	2.0	0.0000000000	False
row of this matrix	0.0	0.0	0.0	2.0	0.0000000000	False
set my second training	0.0	0.0	0.0	2.0	0.0000000000	False
defined as matrix capital	0.0	0.0	0.0	2.0	0.0000000000	False
vector theta this derivation	0.0	0.0	0.0	2.0	0.0000000000	False
two or three sets	0.0	0.0	0.0	2.0	0.0000000000	False
sets so x times	0.0	0.0	0.0	2.0	0.0000000000	False
times theta  remember	0.0	0.0	0.0	2.0	0.0000000000	False
remember how matrix vector	0.0	0.0	0.0	2.0	0.0000000000	False
rows of the matrix	0.0	0.0	0.0	2.0	0.0000000000	False
matrix so x times	0.0	0.0	0.0	2.0	0.0000000000	False
predictions of your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
defined the y vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector so x theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta minus y contained	0.0	0.0	0.0	2.0	0.0000000000	False
vector in m training	0.0	0.0	0.0	2.0	0.0000000000	False
vector than z transpose	0.0	0.0	0.0	2.0	0.0000000000	False
product of a vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector with a sum	0.0	0.0	0.0	2.0	0.0000000000	False
product of this vector	0.0	0.0	0.0	2.0	0.0000000000	False
squares of the elements	0.0	0.0	0.0	2.0	0.0000000000	False
elements of this vector	0.0	0.0	0.0	2.0	0.0000000000	False
notations at you today	0.0	0.0	0.0	2.0	0.0000000000	False
examples and the number	0.0	0.0	0.0	2.0	0.0000000000	False
feature vector that runs	0.0	0.0	0.0	2.0	0.0000000000	False
sort of theta transpose	0.0	0.0	0.0	2.0	0.0000000000	False
feature vectors that index	0.0	0.0	0.0	2.0	0.0000000000	False
cool so we re	0.0	0.0	0.0	0.0	0.0000000000	False
theta and we ve	0.0	0.0	0.0	0.0	0.0000000000	False
written j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
compactly using this matrix	0.0	0.0	0.0	2.0	0.0000000000	False
notation so in order	0.0	0.0	0.0	2.0	0.0000000000	False
fairly quickly without proof	0.0	0.0	0.0	2.0	0.0000000000	False
derivative and the one-half	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the answers	0.0	0.0	0.0	2.0	0.0000000000	False
lecture notes and make	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you understand	0.0	0.0	0.0	2.0	0.0000000000	False
work through every step	0.0	0.0	0.0	2.0	0.0000000000	False
referring to the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
taking a quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic function and expanding	0.0	0.0	0.0	2.0	0.0000000000	False
great so this quantity	0.0	0.0	0.0	2.0	0.0000000000	False
trace operator without changing	0.0	0.0	0.0	2.0	0.0000000000	False
one-half derivative with respect	0.0	0.0	0.0	2.0	0.0000000000	False
theta of the trace	0.0	0.0	7.99787685775	8.0	0.4166666667	False
permutation property of trace	0.0	0.0	0.0	2.0	0.0000000000	False
theta at the end	0.0	0.0	0.0	2.0	0.0000000000	False
trace of theta times	0.0	0.0	0.0	2.0	0.0000000000	False
theta times theta transposed	0.0	0.0	0.0	2.0	0.0000000000	False
minus derivative with respect	0.0	0.0	0.0	2.0	0.0000000000	False
number and the transpose	0.0	0.0	0.0	2.0	0.0000000000	False
real number without changing	0.0	0.0	0.0	2.0	0.0000000000	False
last term with respect	0.0	0.0	0.0	2.0	0.0000000000	False
rule that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ll find in lecture	0.0	0.0	0.0	2.0	0.0000000000	False
find in lecture notes	0.0	0.0	0.0	2.0	0.0000000000	False
equal to x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
identity which we re	0.0	0.0	0.0	0.0	0.0000000000	False
re going to ignore	0.0	0.0	0.0	2.0	0.0000000000	False
transposed and the matrix	0.0	0.0	0.0	2.0	0.0000000000	False
trace of y transpose	0.0	0.0	0.0	2.0	0.0000000000	False
rules that i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
board s really bad	0.0	0.0	0.0	0.0	0.0000000000	False
back into our formula	0.0	0.0	0.0	2.0	0.0000000000	False
one-half x transpose theta	0.0	0.0	0.0	2.0	0.0000000000	False
transpose x theta minus	0.0	0.0	0.0	2.0	0.0000000000	False
inverse times x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
fit to the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters in closed form	0.0	0.0	0.0	2.0	0.0000000000	False
out reams of algebra	0.0	0.0	0.0	2.0	0.0000000000	False
excited ? any quick	0.0	0.0	0.0	2.0	0.0000000000	False
inverse ? pseudo inverse	0.0	0.0	0.0	4.0	0.0000000000	False
pseudo inverse pseudo inverse	0.0	0.0	0.0	2.0	0.0000000000	False
pseudo inverse ? pseudo	0.0	0.0	0.0	2.0	0.0000000000	False
out that in cases	0.0	0.0	0.0	2.0	0.0000000000	False
inverse minimized to solve	0.0	0.0	0.0	2.0	0.0000000000	False
turns out x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
invertible that usually means	0.0	0.0	0.0	2.0	0.0000000000	False
dependent it usually means	0.0	0.0	0.0	2.0	0.0000000000	False
repeat the same feature	0.0	0.0	0.0	2.0	0.0000000000	False
obtained by the pseudo	0.0	0.0	0.0	2.0	0.0000000000	False
inverses of the inverse	0.0	0.0	0.0	2.0	0.0000000000	False
nt be a problem	0.0	0.0	0.0	0.0	0.0000000000	False
jump into today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s material	0.0	0.0	0.0	0.0	0.0000000000	False
out the first	0.00198690377337	0.0	0.0	1.58496250072	0.0000000000	False
first homework assignment	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
mic a bit	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first problem sets	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
grade homework problems	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
combination of tas	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
tas and graders	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
members  students	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
email the class	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
class to solicit	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times this quarter	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
spend one evening	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
staying up late	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
late and grading	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taught a class	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
students that grade	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
first time sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
makes a difference	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
solution and amazing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write amazing solutions	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
graders are paid	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of hang	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
evening and grade	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll send email	0.0	0.0	0.0	3.16992500144	0.0000000000	False
started with today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is talk	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
talk about linear	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
out and work	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
homepage and download	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
download detailed lecture	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
detailed lecture notes	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
pretty much describe	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
amount of linear	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
refresher on linear	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
algebra i talk	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
talk about today	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
out in detail	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
start by showing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
fun video remember	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
talked about supervised	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
learning and supervised	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
close right answer	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number of examples	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
algorithm to replicate	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
problem of predicting	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
predicting housing prices	0.00172017965883	0.0	0.0	3.16992500144	0.0000000000	False
right " housing	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm to learn	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
learn the relationship	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
relationship between sizes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sizes of houses	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
right " answer	0.0	0.0	0.0	1.58496250072	0.0000000000	False
video now load	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
load the big	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
mellon on applied	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
applied supervised learning	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
car to drive	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
sorts of things	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
hear dean pomerleau	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pomerleau s voice	0.0	0.0	0.0	0.0	0.0000000000	False
mention and algorithm	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithm called neural	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
essential learning algorithm	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
watch the video	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
human driver shows	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
angle this segment	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
correct " steering	0.0	0.0	0.0	0.0	0.0000000000	False
learn to produce	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
pointer is moving	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
line actually shows	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
shows the human	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
human steering direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
right here shows	0.0	0.0	0.0	0.0	0.0000000000	False
shows the steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
steering direction chosen	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
moving the steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
wheel the human	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
human is steering	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
mamos is pointing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
algorithm currently thinks	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
right steering direction	0.0	0.0	0.0	1.58496250072	0.0000000000	False
beginning of training	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
range of steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
collects more examples	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
examples and learns	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
choose a steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
right ? switch	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ago and autonomous	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
darpa grand challenge	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
team s drive	0.0	0.0	0.0	0.0	0.0000000000	False
drive a car	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
absolutely amazing work	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
call the regression	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
predict a continuous	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
continuous value variables	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
continuous value steering	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
value steering directions	0.0	0.0	0.0	0.0	0.0000000000	False
first supervised learning	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
supervised learning algorithm	0.000993451886683	0.0	0.0	0.0	0.0000000000	True
prices in portland	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
number of houses	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
prices in thousands	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
thousands of dollars	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
data and plot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
call a training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
learn to predict	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
predict the relationship	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back and modify	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
modify this task	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
introduce some notation	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
piece of notation	0.00298035566005	0.0	1.99840764331	3.16992500144	0.0000000000	False
lower case alphabet	0.00366430748825	0.0	5.99840764331	3.16992500144	0.0000000000	False
alphabet m denote	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
denote the number	0.00298035566005	0.0	3.99840764331	3.16992500144	0.0000000000	False
number of training	0.00382733971974	0.0	3.99734607219	0.0	0.3738317757	False
means the number	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
number of rows	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
denote the input	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
call the features	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
denote the size	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
output " variable	0.0	0.0	0.0	1.58496250072	0.0000000000	False
comprises one training	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
table i drew	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
call one training	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
notation they re	0.0	0.0	0.0	0.0	0.0000000000	False
list of training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
feed our training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
denoted lower case	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
hypothesis s job	0.0	0.0	0.0	0.0	0.0000000000	False
takes this input	0.00298035566005	0.0	3.99787685775	6.33985000288	0.0000000000	False
area in square	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
estimates the price	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
hypothesis h maps	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
maps from inputs	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
order to design	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
design a learning	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
represent the hypothesis	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
first learning algorithm	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
represent my hypothesis	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
house we re	0.0	0.0	0.0	0.0	0.0000000000	False
knowing the size	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number of bedrooms	0.00397380754673	0.0	3.99787685775	6.33985000288	0.0000000000	False
size and square	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
script two denote	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
write the hypothesis	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rho plus theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
1x1 plus theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
make this dependent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta is explicit	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll sometimes write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
predicts a house	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
house with features	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
features x costs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
predicts this house	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
cost one final	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
convention of defining	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
equal to sum	0.00172017965883	0.0	0.0	3.16992500144	0.0000000000	False
two of theta	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of features	0.000632105886682	0.0	0.0	1.58496250072	0.0000000000	False
equal to two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
amount of notation	0.00198690377337	0.0	0.0	0.0	0.0000000000	False
day you re	0.0	0.0	0.0	0.0	0.0000000000	False
write a symbol	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
simple lower case	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll standardize notation	0.0	0.0	0.0	1.58496250072	0.0000000000	False
notation and make	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
make a lot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descriptions of learning	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithms a lot	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write some symbol	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
nt quite remember	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00043274096938	0.0	0.0	1.58496250072	0.0000000000	False
re ever wondering	0.0	0.0	0.0	1.58496250072	0.0000000000	False
means any questions	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters the thetas	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
algorithm and theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
set to choose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
learn appropriate parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta and theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta all great	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
questions the answer	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
answer is sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
linear hypothesis class	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
complicated hypothesis classes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll actually talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talk about higher	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
higher order functions	0.00122143582942	1.0	0.0	1.58496250072	0.0000000000	True
bit later today	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
chose the parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
make accurate predictions	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
houses all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis will make	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
make some prediction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
make the predictions	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
learning algorithm accurate	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
make that theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta square difference	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
choose parameters theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
training set mine	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
actual target variable	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
target variable mine	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
mine is actual	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minimizing this sum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
put a one-half	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus the actual	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters of theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of linear	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
linear algebra classes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
basic statistics classes	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
regression or squares	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ll actually show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
class of algorithms	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
algorithms for performing	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
performing that minimization	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minimization over theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta the first	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameter vector theta	0.0073286149765	0.0	5.99681528662	9.50977500433	0.3448275862	False
theta maybe initialize	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
initialize my parameter	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of write	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
arrow on top	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
top to denote	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
denote the vector	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
changing my parameter	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta to reduce	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minimum with respect	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
respect to theta	0.0137614372707	0.0	15.991507431	25.3594000115	0.3361344538	False
theta so switch	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
switch the laptops	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lower the big	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
algorithm for minimizing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithm called grading	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
grading and descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
display a plot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
axes are theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
represents the function	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
gradient descent algorithm	0.00496725943341	0.0	3.99734607219	7.92481250361	0.0000000000	True
choose some initial	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
randomly chosen point	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
display actually shows	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
park so imagine	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
re actually standing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
physically a hill	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
direction of steepest	0.0109929224648	0.0	5.99522292994	7.92481250361	0.3217158177	False
find the minimum	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
theta one property	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
property of gradient	0.00366430748825	0.0	2.99840764331	0.0	0.0000000000	False
lower left hand	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
left hand corner	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
running gradient descent	0.00344035931767	0.0	5.99734607219	7.92481250361	0.4166666667	False
started gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rerun gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
slightly different initial	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
initial starting point	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
steepest descent direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
completely different local	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
aware that gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
initialize your parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta one switch	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out the math	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
back and revisit	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
revisit this issue	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
issue of local	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
algorithm we re	0.0	0.0	0.0	0.0	0.0000000000	False
update the parameters	0.00258026948825	0.0	3.99840764331	3.16992500144	0.0000000000	False
theta as theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta i minus	0.00366430748825	0.0	3.99840764331	3.16992500144	0.0000000000	False
minus the partial	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
derivative with respect	0.0146215271001	0.0	14.9909766454	23.7744375108	0.3974284044	False
iteration of gradient	0.00298035566005	0.0	4.99840764331	0.0	0.0000000000	False
point of notation	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
colon equals notation	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
notation to denote	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
setting a variable	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
left hand side	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
hand side equal	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
right hand side	0.0	0.0	0.0	3.16992500144	0.0000000000	False
side all right	0.0	0.0	0.0	0.0	0.0000000000	False
write a colon	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
overwrite the value	0.0	0.0	0.0	3.16992500144	0.0000000000	False
side in contrast	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write a equals	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
assertion of truth	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of makes	0.000765467943948	0.0	0.0	0.0	0.0000000000	False
work out gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out gradient descent	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first somewhat mathematical	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
step through derivations	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
gradient descent rule	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
one-half of script	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
training example comprising	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
comprising one pair	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
one-half something squared	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
times one-half times	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
one-half times theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inside the square	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inside this sum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking the partial	0.00122143582942	0.0	2.99840764331	4.75488750216	0.0000000000	False
sum with respect	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
depend on theta	0.00298035566005	0.0	1.99840764331	4.75488750216	0.0000000000	False
term that depends	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
updated as theta	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
minus alpha times	0.00298035566005	0.0	2.99840764331	3.16992500144	0.0000000000	False
greek alphabet alpha	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
parameter alpha controls	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
controls how large	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
large a step	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
hill you decided	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
decided what direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
controls how aggressive	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
set by hand	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
steepest descent algorithm	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
converge if alpha	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
end up overshooting	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
overshooting the minimum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking too aggressive	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
aggressive a step	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lots of errors	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
wrap this property	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
derived the algorithm	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
repeat until convergence	0.00172017965883	0.0	0.0	3.16992500144	0.0000000000	False
times the sum	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
bother to show	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
home and sort	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
sort of verify	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
show  switch	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
run the algorithm	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
problem of linear	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
ordinary release squares	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
re doing today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
multiple local optima	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out for ordinary	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
nice bow shape	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
bow shaped function	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
initialize the parameters	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
change the space	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
space of parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
step of gradient	0.00366430748825	0.0	1.99840764331	0.0	0.0000000000	False
property of regression	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
linear hypothesis cost	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
cost the function	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
value of alpha	0.0	0.0	0.0	0.0	0.0000000000	False
approach the local	0.00610717914709	0.0	9.99734607219	0.0	0.2877697842	False
smaller and smaller	0.00298035566005	0.0	5.99840764331	1.58496250072	0.0000000000	False
theta by subtracting	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
subtracting from alpha	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times the gradient	0.00198690377337	0.0	0.0	0.0	0.0000000000	False
minimum the gradient	0.00366430748825	0.0	0.0	0.0	0.0000000000	False
automatically take smaller	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
local minimum make	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minimum make sense	0.0	0.0	0.0	0.0	0.0000000000	False
housing prices data	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lets you initialize	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
shows the hypothesis	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters of initialization	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
prices are equal	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ve now found	0.0	0.0	0.0	1.58496250072	0.0000000000	False
run each sample	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
right and converged	0.0	0.0	0.0	0.0	0.0000000000	False
test the convergence	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ways of testing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
testing for convergence	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
two different iterations	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta has changed	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
changed a lot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
quantity you re	0.0	0.0	0.0	0.0	0.0000000000	False
changing much anymore	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of standard	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
rules of thumb	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
decide if gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
descent has converged	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
math at incline	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
choosing the direction	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
compute the gradient	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
compute the derivative	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
tas can talk	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
talk a bit	0.0015309358879	0.0	0.0	3.16992500144	0.0000000000	False
interest it turns	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of turns	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
give this algorithm	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
algorithm a specific	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
batch gradient descent	0.00244287165883	1.0	0.0	3.16992500144	0.0000000000	True
nt a great	0.0	0.0	0.0	0.0	0.0000000000	False
term batch refers	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descent you re	0.0	0.0	0.0	0.0	0.0000000000	False
entire training set	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
set you re	0.0	0.0	0.0	0.0	0.0000000000	False
perform a sum	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
examples so descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descent often works	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
large training set	0.00298035566005	0.0	2.99840764331	4.75488750216	0.0000000000	False
houses from portland	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
u.s census database	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
u.s census size	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
census size databases	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
hundreds of thousands	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
thousands or millions	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
millions of training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
re running batch	0.0	0.0	0.0	0.0	0.0000000000	False
running batch rate	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
rate and descent	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
perform every step	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lot of training	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
ll also call	0.0	0.0	0.0	1.58496250072	0.0000000000	False
call it incremental	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
incremental gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
gradient descent updates	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
parameters data runs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
runs you perform	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
perform this update	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
order to start	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
modifying the parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first training examples	0.00122143582942	0.0	5.99628450106	11.094737505	0.0000000000	False
perform an update	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
error with respect	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
perform another update	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
adapting your parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
quickly without needing	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
needing to scan	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
entire u.s census	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
start adapting parameters	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
launch data sets	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
constantly gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
constant gradient descent	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
nt actually converge	0.0	0.0	0.0	0.0	0.0000000000	False
run the constant	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of tend	0.00122143582942	0.0	0.0	3.16992500144	0.0000000000	False
tend to wander	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
parameters will sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of tender	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
tender to wander	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
parameter that wanders	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
bit the global	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
works much faster	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
clean a couple	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
couple of boards	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
cleaning the boards	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of rearranging	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rearranging the order	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theory that sort	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of supports	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theory that supports	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
performing this minimization	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
minimization in terms	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
ordinary least squares	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
squares it turns	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta in close	0.00366430748825	0.0	2.99840764331	0.0	0.0000000000	False
needing to run	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
run an iterative	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
undergraduate linear algebra	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
typically done requires	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
lots of derivatives	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
derivatives and writing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
lots of algebra	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
derive the closed	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
closed form solution	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
solution of theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
lines of algebra	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
notation for matrix	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
work has turned	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
respect to matrixes	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
writing out pages	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
pages and pages	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
pages of matrices	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrices and derivatives	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out the minimization	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector of parameters	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
define the derivative	0.0	0.0	0.0	3.16992500144	0.0000000000	False
dimensional vector theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector with indices	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
define this derivative	0.0	0.0	0.0	1.58496250072	0.0000000000	False
rewrite the gradient	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
write gradient descent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
descent as updating	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta  notice	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
previous parameter minus	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameter minus alpha	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out of order	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
space of matrices	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
space of real	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function is matched	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matched from matrices	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrices to real	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function that takes	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
input to matrix	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking the gradient	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
rows equals number	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number of columns	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
define the trace	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of operator	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
trace operator applied	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
means the sum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sum of diagonal	0.00244287165883	0.0	0.0	0.0	0.0000000000	False
home and verify	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
verify the proofs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrix a times	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
home and prove	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
front so trace	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back and move	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
input of matrix	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
output a real	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function of trace	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
back and referring	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
definitions of traces	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
work it out	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
lastly a couple	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
couple of easy	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
transpose the matrix	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
function of theta	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
algorithm so work	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
work this out	0.000765467943948	0.0	0.0	1.58496250072	0.0000000000	False
define the matrix	0.0	0.0	0.0	1.58496250072	0.0000000000	False
vector of inputs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector of features	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
defined as matrix	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta this derivation	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
theta  remember	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
remember how matrix	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
matrix vector multiplication	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus y contained	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
contained the math	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus y squared	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector and put	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
put a half	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
threw a lot	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
lot of notations	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
training examples runs	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
vector that runs	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
sort of theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
vectors that index	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inside the parentheses	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta with respect	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
matrix vector notation	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
order to minimize	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
solve for theta	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
quickly without proof	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
derivative of half	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
exchanged the derivative	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
one-half in terms	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
notes and make	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
step is correct	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
slowly by referring	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
sort of taking	0.000993451886683	0.0	0.0	3.16992500144	0.0000000000	False
taking a quadratic	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
function and expanding	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out by multiplying	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
quantity in parentheses	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
operator without changing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
equal to one-half	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
property of trace	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
end and move	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
trace of theta	0.00244287165883	0.0	0.0	1.58496250072	0.0000000000	False
theta times theta	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times theta transposed	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
transpose x minus	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
number without changing	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
real number transposed	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minus the trace	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
taking the transpose	0.00122143582942	0.0	5.99840764331	4.75488750216	0.0000000000	False
transpose x theta	0.00855005080592	0.0	11.9968152866	7.92481250361	0.3252032520	False
nt actually depend	0.0	0.0	0.0	0.0	0.0000000000	False
term with respect	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
drop that term	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
facts i wrote	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
wrote down earlier	0.00198690377337	0.0	0.0	3.16992500144	0.0000000000	False
earlier without proof	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
find in lecture	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
times the identity	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
times b transposed	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
matrix x transpose	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
transpose is equal	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
plug this back	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
derivative  wow	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
theta is equal	0.000860089829417	0.0	0.0	1.58496250072	0.0000000000	False
one-half x transpose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
minus x transpose	0.00244287165883	0.0	0.0	3.16992500144	0.0000000000	False
solve this equation	0.000993451886683	0.0	0.0	1.58496250072	0.0000000000	False
equation for theta	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
times x transpose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
parameters in closed	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
writing out reams	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
reams of algebra	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
first learning hour	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
nt you excited	0.0	0.0	0.0	0.0	0.0000000000	False
close for today	0.000993451886683	0.0	0.0	3.16992500144	0.0000000000	False
inverse ? pseudo	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pseudo inverse pseudo	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
inverse pseudo inverse	0.0	0.0	0.0	0.0	0.0000000000	False
pseudo inverse minimized	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minimized to solve	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
out x transpose	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
means your features	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
features were dependent	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
out the minimum	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
minimum is obtained	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
re other questions	0.0	0.0	0.0	3.16992500144	0.0000000000	False
end of audio	0.00122143582942	0.0	0.0	1.58496250072	0.0000000000	False
good morning	0.000288493979587	0.0	0.0	1.0	0.0000000000	False
administrative announcement	0.000573393219611	0.0	0.0	1.0	0.0000000000	False
first homework	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
homework assignment	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
back hear	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
bit louder	0.0	0.0	0.0	0.0	0.0000000000	False
first problem	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
problem sets	0.000358322667476	0.0	0.0	0.0	0.0000000000	False
grade homework	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
homework problems	0.00102062392526	0.0	0.0	1.0	0.0000000000	False
solicit applications	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
fun thing	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
evening staying	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
teaching experience	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
good solution	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
amazing solution	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
points assignments	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
full marks	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
write amazing	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
paid positions	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
free food	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
send email	0.00114678643922	0.0	0.0	0.0	0.0000000000	False
entire class	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
administrative details	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
linear regression	0.000775205314176	0.0	0.0	1.0	0.0000000000	True
gradient descent	0.0209227904679	1.0	26.9782377919	40.0	0.3197376512	True
normal equations	0.00162858110589	1.0	0.0	2.0	0.0000000000	True
lecture notes	0.00193801328544	0.0	4.99734607219	4.0	0.0000000000	False
posted online	0.000461382338399	0.0	0.0	1.0	0.0000000000	False
equation written	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
detailed lecture	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
technical contents	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
today today	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
fair amount	0.00198690377337	0.0	1.99840764331	1.0	0.0000000000	False
linear algebra	0.00397380754673	0.0	3.99681528662	5.0	0.3252032520	False
discussion section	0.00126421177336	0.0	1.99840764331	3.0	0.0000000000	False
today sort	0.000814290552945	1.0	0.0	0.0	0.0000000000	False
claiming today	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
things written	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
fun video	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
video remember	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
last lecture	0.0	0.0	0.0	1.0	0.0000000000	False
initial lecture	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
supervised learning	0.00357218373843	1.0	9.99628450106	6.0	0.4166666667	False
machine-learning problem	0.000461382338399	0.0	0.0	1.0	0.0000000000	False
first lecture	0.000510311962632	0.0	0.0	1.0	0.0000000000	False
predicting housing	0.00114678643922	0.0	0.0	1.0	0.0000000000	False
housing prices	0.0027682940304	0.0	5.99681528662	5.0	0.0000000000	False
training set	0.00576987959174	1.0	7.98938428875	19.0	0.5006954103	True
big screen	0.00114678643922	0.0	0.0	1.0	0.0000000000	False
dean pomerleau	0.000814290552945	0.0	0.0	2.0	0.0000000000	False
carnegie mellon	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
voice mention	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
neural network	0.000662301257788	1.0	0.0	0.0	0.0000000000	False
essential learning	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
learning algorithm	0.00350239018088	0.0	10.9930997877	12.0	0.3296703297	True
video plays	0.00162858110589	0.0	0.0	2.0	0.0000000000	False
human driver	0.00244287165883	0.0	3.99840764331	2.0	0.0000000000	False
driver shows	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
steering directions	0.00651432442356	0.0	15.9957537155	7.0	0.0000000000	False
monitor display	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
display means	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
upper left	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
mouse pointer	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
horizontal line	0.000573393219611	0.0	0.0	0.0	0.0000000000	False
human steering	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
white bar	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
white area	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
direction chosen	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
steering wheel	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
white region	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
right steering	0.0	0.0	0.0	0.0	0.0000000000	False
white smear	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
entire range	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
algorithm collects	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
autonomous driving	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
darpa grand	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
grand challenge	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
sebastian thrun	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
winning team	0.0	0.0	0.0	1.0	0.0000000000	False
amazing work	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
regression problem	0.0015309358879	0.0	3.99840764331	1.0	0.0000000000	False
continuous value	0.0	0.0	0.0	1.0	0.0000000000	False
value variables	0.0	0.0	0.0	0.0	0.0000000000	False
value steering	0.0	0.0	0.0	0.0	0.0000000000	False
regression task	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
dataset collected	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
dan ramage	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
square feet	0.00172017965883	0.0	3.99840764331	2.0	0.0000000000	False
first piece	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
lower case	0.00401375253728	0.0	5.99628450106	6.0	0.4172876304	False
case alphabet	0.00244287165883	0.0	5.99840764331	2.0	0.0000000000	False
training examples	0.00587846782162	0.0	17.9777070064	40.0	0.4077849861	False
input variables	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
output function	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
historical reasons	0.00162858110589	0.0	0.0	2.0	0.0000000000	False
term hypothesis	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
deep meaning	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
living area	0.000461382338399	0.0	0.0	1.0	0.0000000000	False
output estimates	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
first thing	0.000220485005066	0.0	0.0	1.0	0.0000000000	False
first learning	0.00198690377337	0.0	1.99840764331	2.0	0.0000000000	False
linear representation	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
equals theta	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
input feature	0.000922764676799	0.0	0.0	2.0	0.0000000000	False
theta rho	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
subscript theta	0.000573393219611	0.0	0.0	1.0	0.0000000000	False
hypothesis predicts	0.00198690377337	0.0	1.99840764331	2.0	0.0000000000	False
final piece	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
theta transpose	0.00255155981316	0.0	4.99734607219	4.0	0.0000000000	False
learning problem	0.000664991772555	0.0	1.99840764331	3.0	0.0000000000	False
lecture today	0.000510311962632	0.0	0.0	1.0	0.0000000000	False
future weeks	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
simple lower	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
raise hand	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
standardize notation	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
lot easier	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
symbol means	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
real numbers	0.00548138561215	0.0	23.9899150743	18.0	0.2246043900	False
parameters theta	0.00505684709346	0.0	5.99469214437	9.0	0.4505632040	False
higher orders	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
great questions	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
typical hypothesis	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
linear hypothesis	0.00132460251558	0.0	0.0	1.0	0.0000000000	False
hypothesis class	0.00114678643922	0.0	0.0	1.0	0.0000000000	False
complicated hypothesis	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
order functions	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
accurate predictions	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
reasonable thing	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
algorithm accurate	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
correct prices	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
theta square	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
square difference	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
actual price	0.00264920503115	0.0	4.99840764331	2.0	0.0000000000	False
choose parameters	0.000510311962632	0.0	0.0	0.0	0.0000000000	False
squared area	0.000573393219611	0.0	0.0	1.0	0.0000000000	False
predicted price	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
price predicted	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
set mine	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
actual target	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
target variable	0.00162858110589	1.0	0.0	1.0	0.0000000000	False
variable mine	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
one-half sum	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
value predicted	0.0	0.0	0.0	1.0	0.0000000000	False
hypothesis minus	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
actual value	0.0	0.0	0.0	0.0	0.0000000000	False
algebra classes	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
basic statistics	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
statistics classes	0.000510311962632	0.0	0.0	0.0	0.0000000000	False
special case	0.000387602657088	0.0	0.0	1.0	0.0000000000	False
broader class	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
first algorithm	0.00114678643922	0.0	0.0	1.0	0.0000000000	False
search algorithm	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
basic idea	0.000387602657088	0.0	0.0	1.0	0.0000000000	False
parameter vector	0.00458714575689	0.0	5.9957537155	6.0	0.3369434416	False
vector theta	0.00570003387061	0.0	5.99628450106	6.0	0.3448275862	False
horizontal axes	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
surface represents	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
descent algorithm	0.00397380754673	0.0	3.99681528662	4.0	0.0000000000	False
initial point	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
chosen point	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
point denoted	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
landscape imagine	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
hilly park	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
small step	0.00325716221178	0.0	7.99787685775	4.0	0.3448275862	False
steepest descent	0.00895719608239	0.0	7.99416135881	8.0	0.3973509934	False
gradient turns	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
point shown	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
local minimum	0.00570003387061	0.0	11.9962845011	5.0	0.3141361257	False
lower left	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
left hand	0.0013841470152	0.0	1.99840764331	2.0	0.0000000000	False
hand corner	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
running gradient	0.00229357287844	0.0	5.99734607219	0.0	0.4166666667	False
rerun gradient	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
initial starting	0.00132460251558	0.0	0.0	0.0	0.0000000000	False
starting point	0.00114678643922	0.0	0.0	0.0	0.0000000000	False
descent direction	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
first step	0.000309393043243	0.0	0.0	1.0	0.0000000000	False
local optimum	0.00102062392526	0.0	0.0	1.0	0.0000000000	False
partial derivative	0.00401375253728	0.0	6.99628450106	2.0	0.2825428860	False
update theta	0.00244287165883	0.0	4.99840764331	2.0	0.0000000000	False
colon equals	0.00132460251558	0.0	0.0	1.0	0.0000000000	False
equals notation	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
denote setting	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
hand side	0.00168561569782	0.0	3.99787685775	3.0	0.0000000000	False
right hand	0.0	0.0	0.0	0.0	0.0000000000	False
computer program	0.00114678643922	0.0	0.0	2.0	0.0000000000	False
computer operation	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
algorithm sort	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
makes sense	0.00041266674464	0.0	2.99681528662	5.0	0.0000000000	False
out gradient	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
mathematical lecture	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
descent rule	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
script theta	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
taking derivatives	0.000814290552945	0.0	0.0	2.0	0.0000000000	False
times theta	0.00325716221178	0.0	3.99787685775	3.0	0.4166666667	False
square right	0.0	0.0	0.0	1.0	0.0000000000	False
one-half cancel	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
leaves times	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
term theta	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
learning rule	0.000510311962632	0.0	0.0	1.0	0.0000000000	False
minus alpha	0.00172017965883	0.0	2.99840764331	2.0	0.0000000000	False
alpha times	0.00204124785053	0.0	4.99787685775	3.0	0.5263157895	False
greek alphabet	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
alphabet alpha	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
learning rate	0.000573393219611	0.0	0.0	1.0	0.0000000000	True
parameter alpha	0.00114678643922	0.0	0.0	0.0	0.0000000000	False
alpha controls	0.00162858110589	0.0	0.0	0.0	0.0000000000	False
choose alpha	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
tiny steps	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
one-half missing	0.0	0.0	0.0	1.0	0.0000000000	False
make lots	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
original definition	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
laptop display	0.000573393219611	0.0	0.0	1.0	0.0000000000	False
specific problem	0.00132460251558	0.0	0.0	1.0	0.0000000000	False
ordinary release	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
release squares	0.00162858110589	0.0	0.0	0.0	0.0000000000	False
local optima	0.00244287165883	0.0	5.99840764331	2.0	0.0000000000	False
quadratic function	0.00126421177336	0.0	3.99840764331	2.0	0.0000000000	False
nice bow	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
bow shape	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
global minimum	0.00331150628894	0.0	3.99734607219	4.0	0.4166666667	False
shaped function	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
upper right	0.0	0.0	0.0	1.0	0.0000000000	False
hypothesis cost	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
alpha changing	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
fake value	0.0	0.0	0.0	0.0	0.0000000000	False
smaller steps	0.00162858110589	0.0	0.0	0.0	0.0000000000	False
minimum make	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
prices data	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
blue line	0.000922764676799	0.0	0.0	2.0	0.0000000000	False
bottom shows	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
square fit	0.00162858110589	0.0	0.0	2.0	0.0000000000	False
sample cases	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
converged means	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
standard heuristics	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
standard rules	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
feature curve	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
opposite direction	0.00132460251558	0.0	0.0	2.0	0.0000000000	False
steepest ascent	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
function sort	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
batch gradient	0.00162858110589	0.0	0.0	0.0	0.0000000000	False
term batch	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
great term	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
batch refers	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
entire training	0.000510311962632	0.0	0.0	0.0	0.0000000000	False
large training	0.00198690377337	0.0	2.99840764331	0.0	0.0000000000	False
u.s census	0.00244287165883	0.0	2.99840764331	2.0	0.0000000000	False
census database	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
census size	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
size databases	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
running batch	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
batch rate	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
step downhill	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
alternative algorithm	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
incremental gradient	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
descent updates	0.00162858110589	0.0	0.0	0.0	0.0000000000	False
parameters data	0.000510311962632	0.0	0.0	0.0	0.0000000000	False
data runs	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
parameters simultaneously	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
start learning	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
start modifying	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
first training	0.00463610880452	0.0	5.99628450106	0.0	0.2825428860	False
entire u.s	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
adapting parameters	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
launch data	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
data sets	0.000309393043243	0.0	0.0	0.0	0.0000000000	False
constant gradient	0.00162858110589	0.0	0.0	1.0	0.0000000000	False
region closest	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
nt remember	0.0	0.0	0.0	0.0	0.0000000000	False
iterative algorithm	0.00244287165883	0.0	2.99840764331	2.0	0.0000000000	False
squares regression	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
close form	0.00255155981316	0.0	4.99734607219	4.0	0.4166666667	False
undergraduate linear	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
requires projections	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
taking lots	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
writing lots	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
form solution	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
matrix derivatives	0.00244287165883	0.0	3.99840764331	2.0	0.0000000000	False
personal work	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
out pages	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
dimensional vector	0.002306911692	0.0	5.99734607219	4.0	0.0000000000	False
indices ranging	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
write gradient	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
previous parameter	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
parameter minus	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
gradient vector	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
square matrix	0.00162858110589	0.0	0.0	2.0	0.0000000000	False
rows equals	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
equals number	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
diagonal elements	0.00244287165883	0.0	3.99840764331	1.0	0.0000000000	False
operator notation	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
trace operator	0.00244287165883	0.0	3.99840764331	2.0	0.0000000000	False
operator applied	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
write trace	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
tas prove	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
algebra work	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
key facts	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
quick derivation	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
design matrix	0.00162858110589	0.0	0.0	2.0	0.0000000000	True
first row	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
matrix capital	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
matrix vector	0.00244287165883	0.0	3.99840764331	2.0	0.0000000000	False
vector multiplication	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
transposed theta	0.00264920503115	0.0	5.99787685775	3.0	0.0000000000	False
target values	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
theta minus	0.00407145276472	0.0	6.99787685775	3.0	0.2941176471	False
previous board	0.000387602657088	0.0	0.0	1.0	0.0000000000	False
previous definition	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
examples runs	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
feature vector	0.00084280784891	0.0	0.0	1.0	0.0000000000	False
vector notation	0.00132460251558	0.0	0.0	0.0	0.0000000000	False
vector product	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
dan cool	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
one-half derivative	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
permutation property	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
theta times	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
number transposed	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
minus theta	0.000573393219611	0.0	0.0	1.0	0.0000000000	False
last quantity	0.0	0.0	0.0	1.0	0.0000000000	False
last term	0.0	0.0	0.0	0.0	0.0000000000	False
identity matrix	0.00162858110589	0.0	0.0	2.0	0.0000000000	False
inverse times	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
out reams	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
bit dazed	0.000814290552945	0.0	0.0	1.0	0.0000000000	False
learning hour	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
quick questions	0.000662301257788	0.0	0.0	1.0	0.0000000000	False
pseudo inverse	0.00325716221178	0.0	9.99734607219	4.0	0.0000000000	False
inverse pseudo	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
inverse minimized	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
machinelearning-lecture02	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
right	0.0	0.0	0.0	0.0	0.4840878530	False
good	6.15759923544e-05	0.0	0.0	0.0	0.0000000000	False
morning	0.000144246989793	0.0	0.0	0.0	0.0000000000	False
back	0.000461924655891	0.0	0.0	0.0	0.4494382022	False
jump	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
today	0.00017110377579	0.0	0.0	0.0	0.3633822502	False
material	0.000269414629299	0.0	0.0	0.0	0.0000000000	False
administrative	0.000332495886277	0.0	0.0	0.0	0.0000000000	False
announcement	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
graders	0.00331150628894	0.0	0.0	0.0	0.2877697842	False
guess	0.00010316668616	0.0	0.0	0.0	0.0000000000	False
week	0.000589033404829	0.0	0.0	0.0	0.2614379085	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
hand	0.000418120333877	0.0	0.0	0.0	0.3753910323	False
out	0.0	0.0	0.0	0.0	0.2972749794	False
first	0.0	0.0	0.0	0.0	0.4358124112	False
homework	0.000581403985632	0.0	0.0	0.0	0.0000000000	False
assignment	0.000252976566453	0.0	0.0	0.0	0.0000000000	False
class	0.000398487359812	0.0	0.0	0.0	0.2825428860	False
loud	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
people	5.87126670712e-05	0.0	0.0	0.0	0.0000000000	False
hear	0.000251863328416	0.0	0.0	0.0	0.0000000000	False
turn	0.00106301223858	0.0	0.0	0.0	0.2681992337	False
mic	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
bit	0.000333176523773	0.0	0.0	0.0	0.4501607717	False
louder	0.0	0.0	0.0	0.0	0.0000000000	False
great	0.000271185309635	0.0	0.0	0.0	0.0000000000	False
problem	8.22449631203e-05	0.0	0.0	0.0	0.4651162791	False
sets	0.000241595362609	0.0	0.0	0.0	0.5405405405	False
two	0.0	0.0	0.0	0.0	0.4169221337	False
grade	0.00089580666869	1.0	0.0	0.0	0.3738317757	False
combination	7.33526618771e-05	0.0	0.0	0.0	0.0000000000	False
tas	0.0013841470152	0.0	0.0	0.0	0.4580152672	False
members	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
students	0.000168651044302	0.0	0.0	0.0	0.0000000000	False
email	0.000673536573247	0.0	0.0	0.0	0.2941176471	False
solicit	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
applications	0.000108474123854	0.0	0.0	0.0	0.0000000000	False
interested	0.00019974806652	0.0	0.0	0.0	0.0000000000	False
sort	0.00107285058411	0.0	0.0	0.0	0.4903677758	False
fun	0.000632105886682	0.0	0.0	0.0	0.0000000000	False
thing	0.0	0.0	0.0	0.0	0.4810996564	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.4026845638	False
quarter	0.00096900664272	0.0	0.0	0.0	0.0000000000	False
spend	0.000117806680966	0.0	0.0	0.0	0.0000000000	False
evening	0.000461382338399	0.0	0.0	0.0	0.5263157895	False
staying	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
late	0.000166247943139	0.0	0.0	0.0	0.0000000000	False
taught	0.000461382338399	0.0	0.0	0.0	0.0000000000	False
half	0.000314807496174	0.0	0.0	0.0	0.4166666667	False
teaching	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
experience	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
learn	0.00202812095437	0.0	0.0	0.0	0.2845528455	False
makes	9.3210958203e-05	0.0	0.0	0.0	0.3796761586	False
difference	1.64489926241e-05	0.0	0.0	0.0	0.4255319149	False
solution	0.000421627610754	0.0	0.0	0.0	0.0000000000	False
amazing	0.000692073507599	0.0	0.0	0.0	0.0000000000	False
give	8.12167939602e-06	0.0	0.0	0.0	0.4580152672	False
points	3.79011705148e-05	0.0	0.0	0.0	0.2157920549	False
full	9.65199783629e-05	0.0	0.0	0.0	0.0000000000	False
marks	0.000144246989793	0.0	0.0	0.0	0.0000000000	False
write	0.000364291646696	0.0	0.0	0.0	0.4470463012	False
paid	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
positions	0.000189823614032	0.0	0.0	0.0	0.5263157895	False
free	0.000166247943139	0.0	0.0	0.0	0.0000000000	False
food	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
hang	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
send	0.000309393043243	0.0	0.0	0.0	0.0000000000	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
entire	0.000122611495327	0.0	0.0	0.0	0.5263157895	False
details	0.000209060166938	0.0	0.0	0.0	0.3252032520	False
apply	0.00029962209978	0.0	0.0	0.0	0.4395604396	False
questions	0.000146311150398	0.0	0.0	0.0	0.4918032787	False
started	0.0	0.0	0.0	0.0	0.4787812840	False
lecture	0.000531506119291	0.0	0.0	0.0	0.4172876304	False
talk	7.12789680376e-05	0.0	0.0	0.0	0.3849000740	False
linear	0.000927580743659	0.0	0.0	0.0	0.3551251009	False
regression	0.00139226869459	0.0	0.0	0.0	0.3508771930	False
gradient	0.00988386775574	0.0	0.0	0.0	0.2722600361	False
descent	0.0131493966444	0.0	0.0	0.0	0.2784772626	False
normal	0.000126757559648	0.0	0.0	0.0	0.0000000000	False
equations	0.00067563984854	0.0	0.0	0.0	0.5263157895	False
notes	0.000271185309635	0.0	0.0	0.0	0.0000000000	False
posted	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
online	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
math	0.000773482608108	0.0	0.0	0.0	0.5333333333	False
quickly	0.000507030238592	0.0	0.0	0.0	0.4580152672	False
written	0.000325422371562	0.0	0.0	0.0	0.5405405405	False
work	0.000389981284911	0.0	0.0	0.0	0.4421175102	False
slowly	0.000632105886682	0.0	0.0	0.0	0.0000000000	False
homepage	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
download	0.000166247943139	0.0	0.0	0.0	0.0000000000	False
pretty	0.000251863328416	0.0	0.0	0.0	0.0000000000	False
describe	9.65199783629e-05	0.0	0.0	0.0	0.0000000000	False
mathematical	0.000251863328416	0.0	0.0	0.0	0.0000000000	False
technical	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
contents	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
delve	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
fair	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
amount	0.000314807496174	0.0	0.0	0.0	0.4166666667	False
algebra	0.0025376028612	0.0	0.0	0.0	0.3141361257	False
refresher	0.000421403924455	0.0	0.0	0.0	0.0000000000	False
discussion	0.00014981104989	0.0	0.0	0.0	0.0000000000	False
section	0.000664991772555	0.0	0.0	0.0	0.0000000000	False
claiming	0.000421403924455	0.0	0.0	0.0	0.0000000000	False
proof	0.000629658321041	0.0	0.0	0.0	0.0000000000	False
showing	0.000356974846899	0.0	0.0	0.0	0.3234501348	False
video	0.00132998354511	0.0	0.0	0.0	0.2339181287	False
remember	0.000151858891226	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.0000000000	False
initial	0.000587126670712	0.0	0.0	0.0	0.4505632040	False
supervised	0.00204124785053	0.0	0.0	0.0	0.3278688525	False
machine-learning	0.000210701962227	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm	0.00178088845765	0.0	0.0	0.0	0.3076372742	False
close	0.000217376308654	0.0	0.0	0.0	0.3369434416	False
answer	0.000320594935303	0.0	0.0	0.0	0.4166666667	False
number	9.74601527523e-05	0.0	0.0	0.0	0.3097345133	False
examples	0.00124745242432	0.0	0.0	0.0	0.4421175102	False
replicate	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
predicting	0.00201490662733	0.0	0.0	0.0	0.3234501348	False
housing	0.00398995063533	0.0	0.0	0.0	0.3607214429	False
prices	0.00412071067597	0.0	0.0	0.0	0.3225806452	False
training	0.00742182090085	0.0	0.0	0.0	0.2521350142	False
relationship	0.000332495886277	0.0	0.0	0.0	0.0000000000	False
sizes	0.000488133557343	0.0	0.0	0.0	0.3571428571	False
essentially	4.75966462532e-05	0.0	0.0	0.0	0.0000000000	False
produce	0.000235613361932	0.0	0.0	0.0	0.0000000000	False
load	0.000210701962227	0.0	0.0	0.0	0.0000000000	False
big	0.000126757559648	0.0	0.0	0.0	0.0000000000	False
screen	0.000332495886277	0.0	0.0	0.0	0.0000000000	False
dean	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
pomerleau	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
carnegie	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
mellon	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
car	0.00127577990658	0.0	0.0	0.0	0.3252032520	False
drive	0.00089580666869	0.0	0.0	0.0	0.3252032520	False
vehicle	0.000510311962632	0.0	0.0	0.0	0.0000000000	False
alvin	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
years	0.000168651044302	0.0	0.0	0.0	0.0000000000	False
ago	0.000309393043243	0.0	0.0	0.0	0.0000000000	False
elegant	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
voice	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
mention	0.00020633337232	0.0	0.0	0.0	0.0000000000	False
neural	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
network	0.000134707314649	0.0	0.0	0.0	0.0000000000	False
watch	0.000387602657088	0.0	0.0	0.0	0.0000000000	False
plays	0.000269414629299	0.0	0.0	0.0	0.0000000000	False
comments	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
human	0.000928179129729	0.0	0.0	0.0	0.2597402597	False
driver	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
segment	0.000309393043243	0.0	0.0	0.0	0.0000000000	False
road	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
steer	0.00430495817563	0.0	0.0	0.0	0.1271186441	False
angle	0.000387602657088	0.0	0.0	0.0	0.0000000000	False
correct	0.000341261711077	0.0	0.0	0.0	0.4166666667	False
directions	0.00253557755826	0.0	0.0	0.0	0.2435723951	False
job	0.000581403985632	0.0	0.0	0.0	0.0000000000	False
monitor	0.000210701962227	0.0	0.0	0.0	0.0000000000	False
display	0.000721234948967	0.0	0.0	0.0	0.4166666667	False
means	2.70722646534e-05	0.0	0.0	0.0	0.4172876304	False
upper	0.000358322667476	0.0	0.0	0.0	0.0000000000	False
left	0.000205487129728	0.0	0.0	0.0	0.4580152672	False
mouse	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
pointer	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
moving	0.000227788336839	0.0	0.0	0.0	0.4395604396	False
horizontal	0.000358322667476	0.0	0.0	0.0	0.0000000000	False
line	0.000292684233714	0.0	0.0	0.0	0.3073545554	False
white	0.000922764676799	0.0	0.0	0.0	0.2040816327	False
bar	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
area	0.000270759886682	0.0	0.0	0.0	0.0000000000	False
chosen	0.000235613361932	0.0	0.0	0.0	0.0000000000	False
wheel	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
region	0.000632105886682	0.0	0.0	0.0	0.0000000000	False
mamos	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
output	0.000477766395507	0.0	0.0	0.0	0.4172876304	False
thinks	0.000134707314649	0.0	0.0	0.0	0.5006954103	False
beginning	5.87126670712e-05	0.0	0.0	0.0	0.0000000000	False
idea	8.15161157454e-05	0.0	0.0	0.0	0.0000000000	False
smear	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
range	0.000235613361932	0.0	0.0	0.0	0.0000000000	False
collects	0.000193039956726	0.0	0.0	0.0	0.0000000000	False
confidently	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
choose	0.00051346863314	0.0	0.0	0.0	0.4737732657	False
thought	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
dramatic	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
switch	0.000589033404829	0.0	0.0	0.0	0.5333333333	False
chalkboard	0.000765467943948	0.0	0.0	0.0	0.0000000000	False
autonomous	0.000461382338399	0.0	0.0	0.0	0.0000000000	False
long	0.00023610562213	0.0	0.0	0.0	0.0000000000	False
heard	0.000166247943139	0.0	0.0	0.0	0.0000000000	False
darpa	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
grand	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
challenge	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
colleagues	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
sebastian	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
thrun	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
winning	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
team	0.0	0.0	0.0	0.0	0.0000000000	False
desert	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
absolutely	0.000110242502533	0.0	0.0	0.0	0.0000000000	False
call	1.89505852574e-05	0.0	0.0	0.0	0.4224569205	False
continuous	7.59294456129e-05	0.0	0.0	0.0	0.0000000000	False
value	0.000162711185781	0.0	0.0	0.0	0.2298850575	False
variables	0.000587126670712	0.0	0.0	0.0	0.4395604396	False
task	0.000421403924455	0.0	0.0	0.0	0.0000000000	False
running	0.000333176523773	0.0	0.0	0.0	0.4545454545	False
return	9.65199783629e-05	0.0	0.0	0.0	0.0000000000	False
dataset	0.00143348304903	0.0	0.0	0.0	0.2877697842	False
dan	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
ramage	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
portland	0.000573393219611	0.0	0.0	0.0	0.0000000000	False
oregon	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
thousands	0.000235613361932	0.0	0.0	0.0	0.0000000000	False
dollars	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
200,000	0.0	0.0	0.0	0.0	0.0000000000	False
data	0.000153264369159	0.0	0.0	0.0	0.0000000000	False
plot	0.000808243887896	0.0	0.0	0.0	0.4166666667	False
square	0.00136504684431	0.0	0.0	0.0	0.4545454545	False
feet	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
modify	0.000289559935089	0.0	0.0	0.0	0.0000000000	False
introduce	0.00020633337232	0.0	0.0	0.0	0.0000000000	False
notation	0.00160218492087	0.0	0.0	0.0	0.4404404404	False
rest	0.000193039956726	0.0	0.0	0.0	0.0000000000	False
piece	0.000204757026646	0.0	0.0	0.0	0.0000000000	False
lower	0.000928500175439	0.0	0.0	0.0	0.4505632040	False
case	0.0	0.0	0.0	0.0	0.4091266719	False
alphabet	0.00096900664272	0.0	0.0	0.0	0.3252032520	False
denote	0.00106171976199	0.0	0.0	0.0	0.2684563758	False
rows	0.00135660929981	0.0	0.0	0.0	0.3141361257	False
wrote	0.00030950005848	0.0	0.0	0.0	0.0000000000	False
input	0.000599244199561	0.0	0.0	0.0	0.3145103645	False
features	0.00102378513323	0.0	0.0	0.0	0.3753910323	False
target	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
pair	0.000251863328416	0.0	0.0	0.0	0.0000000000	False
comprises	0.000498743829416	0.0	0.0	0.0	0.0000000000	False
words	8.36240667754e-05	0.0	0.0	0.0	0.0000000000	False
table	0.000251863328416	0.0	0.0	0.0	0.0000000000	False
drew	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
superscript	0.000573393219611	0.0	0.0	0.0	0.0000000000	False
exponentiation	0.000144246989793	0.0	0.0	0.0	0.0000000000	False
power	0.000126757559648	0.0	0.0	0.0	0.0000000000	False
parentheses	0.000922764676799	0.0	0.0	0.0	0.0000000000	False
index	0.000618786086486	0.0	0.0	0.0	0.4166666667	False
list	6.82523422153e-05	0.0	0.0	0.0	0.0000000000	False
feed	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
function	0.000677335915898	0.0	0.0	0.0	0.3781640744	False
tradition	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
historical	0.000461382338399	0.0	0.0	0.0	0.0000000000	False
reasons	0.000136991419819	0.0	0.0	0.0	0.0000000000	False
hypothesis	0.00270955366221	1.0	0.0	0.0	0.2575107296	False
worry	0.000126757559648	0.0	0.0	0.0	0.0000000000	False
term	0.000185362423772	0.0	0.0	0.0	0.2970297030	False
deep	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
takes	0.0002988924244	0.0	0.0	0.0	0.3333804210	False
living	0.000144246989793	0.0	0.0	0.0	0.0000000000	False
estimates	0.000166247943139	0.0	0.0	0.0	0.0000000000	False
maps	0.000270759886682	0.0	0.0	0.0	0.0000000000	False
order	5.83161220091e-05	0.0	0.0	0.0	0.5479452055	False
design	0.00023610562213	0.0	0.0	0.0	0.0000000000	False
decide	0.000162711185781	0.0	0.0	0.0	0.0000000000	False
represent	0.00019974806652	0.0	0.0	0.0	0.3448275862	False
purposes	0.000126757559648	0.0	0.0	0.0	0.0000000000	False
representation	8.43255221508e-05	0.0	0.0	0.0	0.0000000000	False
equals	0.00144265946665	0.0	0.0	0.0	0.3370530631	False
theta	0.0236685678081	0.0	0.0	0.0	0.2217498229	False
generally	3.33234982909e-05	0.0	0.0	0.0	0.0000000000	False
knowing	0.000166247943139	0.0	0.0	0.0	0.4172876304	False
bedrooms	0.00132460251558	0.0	0.0	0.0	0.0000000000	False
script	0.000581403985632	0.0	0.0	0.0	0.0000000000	False
rho	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
1x1	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
2x2	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
dependent	0.00014278993876	0.0	0.0	0.0	0.4395604396	False
explicit	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
subscript	0.000332495886277	0.0	0.0	0.0	0.0000000000	False
costs	0.000404121943948	0.0	0.0	0.0	0.0000000000	False
final	0.000126757559648	0.0	0.0	0.0	0.0000000000	False
conciseness	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
compactly	0.000461382338399	0.0	0.0	0.0	0.0000000000	False
convention	0.000220485005066	0.0	0.0	0.0	0.0000000000	False
defining	0.000108688154327	0.0	0.0	0.0	0.3268384664	False
sum	0.00173144122896	0.0	0.0	0.0	0.3044581370	False
vectors	0.0048300739196	0.0	0.0	0.0	0.1825473655	False
transpose	0.00770393735073	0.0	0.0	0.0	0.1251738526	False
realize	0.000117806680966	0.0	0.0	0.0	0.0000000000	False
proceed	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
future	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
day	0.000157403748087	0.0	0.0	0.0	0.0000000000	False
symbol	0.000464089564865	0.0	0.0	0.0	0.0000000000	False
wondering	0.000332495886277	0.0	0.0	0.0	0.0000000000	False
gee	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
simple	2.05253307848e-05	0.0	0.0	0.0	0.0000000000	False
raise	0.000180506591121	0.0	0.0	0.0	0.0000000000	False
standardize	0.000220057985631	0.0	0.0	0.0	0.0000000000	False
lot	0.000303717782452	0.0	0.0	0.0	0.4347826087	False
descriptions	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
easier	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
chances	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
forgotten	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
parameters	0.00293410647508	0.0	0.0	0.0	0.3556992724	False
real	0.000870186252966	0.0	0.0	0.0	0.2289846339	False
higher	0.000220485005066	0.0	0.0	0.0	0.0000000000	False
typical	0.000157403748087	0.0	0.0	0.0	0.0000000000	False
complicated	8.43255221508e-05	0.0	0.0	0.0	0.0000000000	False
chose	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
accurate	0.000332495886277	0.0	0.0	0.0	0.0000000000	False
actual	0.000393509370217	0.0	0.0	0.0	0.4643449420	False
minimize	0.00135127969708	0.0	0.0	0.0	0.3849000740	False
fill	0.000134707314649	0.0	0.0	0.0	0.0000000000	False
mine	0.000387602657088	0.0	0.0	0.0	0.0000000000	False
put	3.46944425425e-05	0.0	0.0	0.0	0.0000000000	False
one-half	0.00179161333738	0.0	0.0	0.0	0.3002502085	False
simplify	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
minus	0.000778587700022	0.0	0.0	0.0	0.3221222170	False
quantity	0.000579119870177	0.0	0.0	0.0	0.4166666667	False
basic	2.25094077536e-05	0.0	0.0	0.0	0.0000000000	False
statistics	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
eventually	0.000180506591121	0.0	0.0	0.0	0.0000000000	False
special	8.43255221508e-05	0.0	0.0	0.0	0.0000000000	False
broader	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
couple	0.000353420042897	0.0	0.0	0.0	0.0000000000	False
performing	0.000599244199561	0.0	0.0	0.0	0.2702702703	False
search	9.65199783629e-05	0.0	0.0	0.0	0.0000000000	False
zeros	0.000922764676799	0.0	0.0	0.0	0.3554119548	False
excuse	0.000269414629299	0.0	0.0	0.0	0.0000000000	False
arrow	0.000134707314649	0.0	0.0	0.0	0.0000000000	False
top	5.4237061927e-05	0.0	0.0	0.0	0.0000000000	False
changing	0.000244548347236	0.0	0.0	0.0	0.3571428571	False
reduce	0.000110242502533	0.0	0.0	0.0	0.0000000000	False
end	0.000123801742645	0.0	0.0	0.0	0.3389830508	False
minimum	0.00229002434904	0.0	0.0	0.0	0.3539823009	False
respect	0.00243683898014	0.0	0.0	0.0	0.3222918532	False
laptops	0.000387602657088	0.0	0.0	0.0	0.0000000000	False
animation	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
axes	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
height	0.000144246989793	0.0	0.0	0.0	0.0000000000	False
surface	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
randomly	0.000309393043243	0.0	0.0	0.0	0.0000000000	False
star	0.000309393043243	0.0	0.0	0.0	0.0000000000	False
cross	0.000386079913452	0.0	0.0	0.0	0.3448275862	False
imagine	0.000579119870177	0.0	0.0	0.0	0.1929260450	False
landscape	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
hilly	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
park	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
shape	0.000377794992625	0.0	0.0	0.0	0.0000000000	False
hill	0.00244287165883	0.0	0.0	0.0	0.3252032520	False
standing	0.000673536573247	0.0	0.0	0.0	0.3252032520	False
physically	0.000269414629299	0.0	0.0	0.0	0.0000000000	False
degrees	0.000377794992625	0.0	0.0	0.0	0.0000000000	False
small	8.67361063562e-05	0.0	0.0	0.0	0.3738317757	False
step	0.000761546340052	0.0	0.0	0.0	0.3372243839	False
downhill	0.00203572638236	0.0	0.0	0.0	0.3738317757	False
steepest	0.00488574331767	0.0	0.0	0.0	0.2970297030	False
shown	5.87126670712e-05	0.0	0.0	0.0	0.0000000000	False
find	4.50188155071e-05	0.0	0.0	0.0	0.2941176471	False
local	0.00141368017159	0.0	0.0	0.0	0.2830188679	False
property	0.00029962209978	0.0	0.0	0.0	0.4580152672	False
corner	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
rerun	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
slightly	0.000183197105888	0.0	0.0	0.0	0.4166666667	False
completely	2.05253307848e-05	0.0	0.0	0.0	0.0000000000	False
optimum	0.000510311962632	0.0	0.0	0.0	0.0000000000	False
aware	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
revisit	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
issue	7.87018740435e-05	0.0	0.0	0.0	0.0000000000	False
repeatedly	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
update	0.00216650040936	0.0	0.0	0.0	0.2816901408	False
partial	0.00147491373559	0.0	0.0	0.0	0.2825428860	False
derivative	0.00472947893978	0.0	0.0	0.0	0.3362793706	False
iteration	0.00141368017159	0.0	0.0	0.0	0.5555555556	False
colon	0.000461382338399	0.0	0.0	0.0	0.0000000000	False
side	0.00019974806652	0.0	0.0	0.0	0.0000000000	False
part	1.64489926241e-05	0.0	0.0	0.0	0.0000000000	False
computer	8.55518878949e-05	0.0	0.0	0.0	0.3973509934	False
program	0.000108474123854	0.0	0.0	0.0	0.0000000000	False
overwrite	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
contrast	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
assertion	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
truth	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
operation	0.000189823614032	0.0	0.0	0.0	0.3252032520	False
sense	4.75966462532e-05	0.0	0.0	0.0	0.0000000000	False
carefully	5.4237061927e-05	0.0	0.0	0.0	0.0000000000	False
rule	0.000451266477803	0.0	0.0	0.0	0.5333333333	False
inside	0.000220057985631	0.0	0.0	0.0	0.0000000000	False
cancel	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
leaves	8.43255221508e-05	0.0	0.0	0.0	0.0000000000	False
alpha	0.00182872737453	0.0	0.0	0.0	0.2000909504	False
greek	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
rate	0.000288493979587	0.0	0.0	0.0	0.0000000000	False
controls	0.000193039956726	0.0	0.0	0.0	0.0000000000	False
large	0.000227788336839	0.0	0.0	0.0	0.3508771930	False
aggressive	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
tiny	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
converge	0.00251941727107	0.0	0.0	0.0	0.5333333333	False
overshooting	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
missing	0.000387602657088	0.0	0.0	0.0	0.0000000000	False
errors	0.000288493979587	0.0	0.0	0.0	0.0000000000	False
wrap	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
repeat	0.000252976566453	0.0	0.0	0.0	0.0000000000	False
bother	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
home	0.000618786086486	0.0	0.0	0.0	0.4166666667	False
verify	0.000461382338399	0.0	0.0	0.0	0.0000000000	False
summation	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
original	6.3378779824e-05	0.0	0.0	0.0	0.0000000000	False
definition	0.000183197105888	0.0	0.0	0.0	0.5333333333	False
specific	9.19586214952e-05	0.0	0.0	0.0	0.0000000000	False
ordinary	0.000632105886682	0.0	0.0	0.0	0.0000000000	False
release	0.000573393219611	0.0	0.0	0.0	0.0000000000	False
nasty	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
multiple	0.000193039956726	0.0	0.0	0.0	0.0000000000	False
optima	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
quadratic	0.00043274096938	0.0	0.0	0.0	0.0000000000	False
nice	7.87018740435e-05	0.0	0.0	0.0	0.0000000000	False
bow	0.000814290552945	0.0	0.0	0.0	0.0000000000	False
global	0.00116373560197	0.0	0.0	0.0	0.2597402597	False
contours	0.000860089829417	0.0	0.0	0.0	0.0000000000	False
ellipses	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
space	0.000234850668285	0.0	0.0	0.0	0.2941176471	False
result	5.87126670712e-05	0.0	0.0	0.0	0.0000000000	False
easily	0.00010316668616	0.0	0.0	0.0	0.0000000000	False
rapidly	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
fake	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
approach	0.00089580666869	0.0	0.0	0.0	0.2877697842	False
smaller	0.000409514053292	0.0	0.0	0.0	0.2877697842	False
subtracting	0.000210701962227	0.0	0.0	0.0	0.0000000000	False
automatically	0.000134707314649	0.0	0.0	0.0	0.0000000000	False
lets	4.57992764719e-05	0.0	0.0	0.0	0.4585443882	False
blue	0.000235613361932	0.0	0.0	0.0	0.0000000000	False
bottom	0.000117806680966	0.0	0.0	0.0	0.0000000000	False
found	8.43255221508e-05	0.0	0.0	0.0	0.0000000000	False
fit	0.000269414629299	0.0	0.0	0.0	0.0000000000	False
sample	0.000309393043243	0.0	0.0	0.0	0.0000000000	False
roughly	0.000117806680966	0.0	0.0	0.0	0.0000000000	False
test	0.00020633337232	0.0	0.0	0.0	0.0000000000	False
ways	3.79647228065e-05	0.0	0.0	0.0	0.2877697842	False
anymore	0.000210701962227	0.0	0.0	0.0	0.0000000000	False
inclined	0.000662301257788	0.0	0.0	0.0	0.0000000000	False
heuristics	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
thumb	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
curve	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
opposite	0.000421403924455	0.0	0.0	0.0	0.0000000000	False
ascent	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
explicitly	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
friday	0.000210701962227	0.0	0.0	0.0	0.0000000000	False
batch	0.00165575314447	0.0	0.0	0.0	0.3252032520	False
refers	0.00014981104989	0.0	0.0	0.0	0.0000000000	False
fact	0.000102626653924	0.0	0.0	0.0	0.4395604396	False
u.s	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
census	0.00122143582942	0.0	0.0	0.0	0.0000000000	False
database	0.000581403985632	0.0	0.0	0.0	0.0000000000	False
hundreds	9.65199783629e-05	0.0	0.0	0.0	0.0000000000	False
millions	0.000537484001214	0.0	0.0	0.0	0.0000000000	False
alternative	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
incremental	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
usual	0.000144246989793	0.0	0.0	0.0	0.4255319149	False
simultaneously	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
advantage	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
adapting	0.000510311962632	0.0	0.0	0.0	0.0000000000	False
needing	0.000716645334952	0.0	0.0	0.0	0.4347826087	False
scan	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
launch	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
constantly	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
faster	0.000421403924455	0.0	0.0	0.0	0.0000000000	False
constant	0.000146705323754	0.0	0.0	0.0	0.0000000000	False
tend	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
wander	0.00114678643922	0.0	0.0	0.0	0.2040816327	False
uphill	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
occasionally	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
tender	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
closest	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
practice	7.87018740435e-05	0.0	0.0	0.0	0.0000000000	False
clean	0.000632105886682	0.0	0.0	0.0	0.0000000000	False
boards	0.000824646766761	0.0	0.0	0.0	0.4395604396	False
true	0.000108474123854	0.0	0.0	0.0	0.0000000000	False
rearranging	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
theory	0.000235613361932	0.0	0.0	0.0	0.0000000000	False
supports	0.00020633337232	0.0	0.0	0.0	0.0000000000	False
theorem	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
cool	0.000377794992625	0.0	0.0	0.0	0.0000000000	False
solve	0.000541519773364	0.0	0.0	0.0	0.3141361257	False
form	8.67361063562e-05	0.0	0.0	0.0	0.4166666667	False
undergraduate	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
requires	4.99370166301e-05	0.0	0.0	0.0	0.0000000000	False
projections	0.000125931664208	0.0	0.0	0.0	0.0000000000	False
matrix	0.00698729201578	0.0	0.0	0.0	0.1867751167	False
personal	0.000117806680966	0.0	0.0	0.0	0.0000000000	False
pages	0.000332495886277	0.0	0.0	0.0	0.0000000000	False
matrices	0.00172017965883	0.0	0.0	0.0	0.4166666667	False
dimensional	0.000673536573247	0.0	0.0	0.0	0.2877697842	False
indices	0.000136504684431	0.0	0.0	0.0	0.0000000000	False
rewrite	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
notice	0.000134707314649	0.0	0.0	0.0	0.0000000000	False
previous	0.000137397829416	0.0	0.0	0.0	0.0000000000	False
matched	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
elements	0.000293563335356	0.0	0.0	0.0	0.0000000000	False
columns	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
trace	0.00867530336475	0.0	0.0	0.0	0.1429964251	False
diagonal	0.00114678643922	0.0	0.0	0.0	0.0000000000	False
commonly	0.000210701962227	0.0	0.0	0.0	0.0000000000	False
prove	0.000541519773364	0.0	0.0	0.0	0.3141361257	False
difficulty	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
similarly	6.84957099095e-05	0.0	0.0	0.0	0.0000000000	False
product	0.000482599891815	0.0	0.0	0.0	0.3252032520	False
cyclically	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
permeate	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
front	0.000538829258597	0.0	0.0	0.0	0.0000000000	False
suppose	2.37983231266e-05	0.0	0.0	0.0	0.0000000000	False
lastly	0.000464089564865	0.0	0.0	0.0	0.0000000000	False
easy	9.65199783629e-05	0.0	0.0	0.0	0.0000000000	False
tricky	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
key	6.3378779824e-05	0.0	0.0	0.0	0.0000000000	False
ten	0.000108474123854	0.0	0.0	0.0	0.0000000000	False
minutes	0.00020633337232	0.0	0.0	0.0	0.0000000000	False
armed	0.0002306911692	0.0	0.0	0.0	0.0000000000	False
figure	5.87126670712e-05	0.0	0.0	0.0	0.0000000000	False
quick	0.000220485005066	0.0	0.0	0.0	0.0000000000	False
place	5.4237061927e-05	0.0	0.0	0.0	0.0000000000	False
capital	0.000179161333738	0.0	0.0	0.0	0.0000000000	False
multiply	0.000404121943948	0.0	0.0	0.0	0.0000000000	False
dot	0.00030950005848	0.0	0.0	0.0	0.0000000000	False
contained	0.000166247943139	0.0	0.0	0.0	0.0000000000	False
emphasis	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
threw	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
meant	0.0	0.0	0.0	0.0	0.0000000000	False
fairly	9.98740332601e-05	0.0	0.0	0.0	0.0000000000	False
exchanged	0.000193801328544	0.0	0.0	0.0	0.0000000000	False
understand	1.42586479825e-05	0.0	0.0	0.0	0.0000000000	False
expand	0.000358322667476	0.0	0.0	0.0	0.0000000000	False
permutation	0.000255155981316	0.0	0.0	0.0	0.0000000000	False
bring	0.000134707314649	0.0	0.0	0.0	0.0000000000	False
drop	0.000154696521622	0.0	0.0	0.0	0.0000000000	False
earlier	9.98740332601e-05	0.0	0.0	0.0	0.0000000000	False
identity	0.000377794992625	0.0	0.0	0.0	0.0000000000	False
previously	0.000193039956726	0.0	0.0	0.0	0.0000000000	False
ignore	0.000269414629299	0.0	0.0	0.0	0.0000000000	False
metric	0.000331150628894	0.0	0.0	0.0	0.0000000000	False
plug	0.000269414629299	0.0	0.0	0.0	0.0000000000	False
wow	0.000286696609806	0.0	0.0	0.0	0.0000000000	False
bad	0.00010316668616	0.0	0.0	0.0	0.0000000000	False
formula	0.000144246989793	0.0	0.0	0.0	0.0000000000	False
inverse	0.00126421177336	0.0	0.0	0.0	0.0000000000	False
reams	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
dazed	0.000407145276472	0.0	0.0	0.0	0.0000000000	False
hour	0.000166247943139	0.0	0.0	0.0	0.0000000000	False
excited	0.0	0.0	0.0	0.0	0.0000000000	False
pseudo	0.00089580666869	0.0	0.0	0.0	0.1702127660	False
invertible	0.000993451886683	0.0	0.0	0.0	0.0000000000	False
obtained	9.02532955606e-05	0.0	0.0	0.0	0.0000000000	False
audio	0.0	0.0	0.0	0.0	0.0000000000	False
duration	0.0	0.0	0.0	0.0	0.0000000000	False
lecture of this class	0.0	0.0	0.0	2.0	0.0000000000	False
topics i do today	0.0	0.0	0.0	2.0	0.0000000000	False
illogical flow of ideas	0.0	0.0	0.0	2.0	0.0000000000	False
talked about linear regression	0.0	0.0	2.99848561333	6.0	0.0000000000	False
linear regression and today	0.0	0.0	0.0	2.0	0.0000000000	False
sort of an adaptation	0.0	0.0	0.0	2.0	0.0000000000	False
mentors probably favorite machine	0.0	0.0	0.0	2.0	0.0000000000	False
favorite machine learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
interpretation of linear regression	0.0	0.0	0.0	4.0	0.0000000000	False
fitting logistic regression models	0.0	0.0	0.0	2.0	0.0000000000	False
recap where we re	0.0	0.0	0.0	0.0	0.0000000000	False
superscript i to denote	0.0	0.0	0.0	2.0	0.0000000000	False
denote the i training	0.0	0.0	0.0	2.0	0.0000000000	False
denote the predicted value	0.0	0.0	0.0	2.0	0.0000000000	False
franchised by the vector	0.0	0.0	0.0	2.0	0.0000000000	False
convention that x subscript	0.0	0.0	0.0	2.0	0.0000000000	False
accounts for the intercept	0.0	0.0	0.0	2.0	0.0000000000	False
regression model and lowercase	0.0	0.0	0.0	2.0	0.0000000000	False
features in my training	0.0	0.0	0.0	2.0	0.0000000000	False
size of the house	0.0	0.0	7.9964664311	14.0	0.3734061931	False
house and the number	0.0	0.0	0.0	2.0	0.0000000000	False
recapping the previous lecture	0.0	0.0	0.0	2.0	0.0000000000	False
defined this quadratic cos	0.0	0.0	0.0	2.0	0.0000000000	False
function j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta of xi minus	0.0	0.0	0.0	2.0	0.0000000000	False
examples and my training	0.0	0.0	0.0	2.0	0.0000000000	False
training set so lowercase	0.0	0.0	0.0	2.0	0.0000000000	False
number of training examples	0.0	0.0	0.0	2.0	0.0000000000	False
size of my training	0.0	0.0	0.0	2.0	0.0000000000	False
minimizes this enclosed form	0.0	0.0	0.0	2.0	0.0000000000	False
move on in today	0.0	0.0	0.0	2.0	0.0000000000	False
fair amount of notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation to all remember	0.0	0.0	0.0	2.0	0.0000000000	False
partway through this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
re having trouble remembering	0.0	0.0	0.0	2.0	0.0000000000	False
trouble remembering what lowercase	0.0	0.0	0.0	2.0	0.0000000000	False
features was the size	0.0	0.0	0.0	2.0	0.0000000000	False
houses in square feet	0.0	0.0	0.0	2.0	0.0000000000	False
area of the house	0.0	0.0	0.0	2.0	0.0000000000	False
feature was the number	0.0	0.0	0.0	2.0	0.0000000000	False
bedrooms in the house	0.0	0.0	0.0	2.0	0.0000000000	False
apply a machine-learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to some problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem that you care	0.0	0.0	0.0	2.0	0.0000000000	False
care about the choice	0.0	0.0	0.0	2.0	0.0000000000	False
choice of the features	0.0	0.0	0.0	2.0	0.0000000000	False
give the learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
idea of the feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature of the number	0.0	0.0	0.0	2.0	0.0000000000	False
price of the house	0.0	0.0	0.0	4.0	0.0000000000	False
theta zero plus theta	0.0	0.0	0.0	4.0	0.0000000000	False
model if you choose	0.0	0.0	0.0	2.0	0.0000000000	False
copy the same data	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the size	0.0	0.0	0.0	2.0	0.0000000000	False
square of the size	0.0	0.0	0.0	2.0	0.0000000000	False
house in say square	0.0	0.0	0.0	2.0	0.0000000000	False
footage of the house	0.0	0.0	0.0	2.0	0.0000000000	False
fitting a quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
function for you theta	0.0	0.0	0.0	2.0	0.0000000000	False
fit to the data	0.0	0.0	4.99848561333	6.0	0.0000000000	False
fill a model theta	0.0	0.0	0.0	2.0	0.0000000000	False
fit a six model	0.0	0.0	0.0	2.0	0.0000000000	False
find that the curve	0.0	0.0	0.0	2.0	0.0000000000	False
model in a sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that it fits	0.0	0.0	0.0	2.0	0.0000000000	False
fits your training data	0.0	0.0	0.0	2.0	0.0000000000	False
model in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
good predictor of housing	0.0	0.0	0.0	2.0	0.0000000000	False
predictor of housing prices	0.0	0.0	0.0	2.0	0.0000000000	False
prices as a function	0.0	0.0	0.0	2.0	0.0000000000	False
function of the size	0.0	0.0	0.0	4.0	0.0000000000	False
out of the models	0.0	0.0	0.0	2.0	0.0000000000	False
model fits the data	0.0	0.0	0.0	2.0	0.0000000000	False
component in this data	0.0	0.0	0.0	2.0	0.0000000000	False
data that the linear	0.0	0.0	0.0	2.0	0.0000000000	False
function is not capturing	0.0	0.0	0.0	2.0	0.0000000000	False
bit later and talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the problems	0.0	0.0	0.0	2.0	0.0000000000	False
problems associated with fitting	0.0	0.0	0.0	2.0	0.0000000000	False
two small a set	0.0	0.0	0.0	2.0	0.0000000000	False
features just to give	0.0	0.0	0.0	2.0	0.0000000000	False
call this the problem	0.0	0.0	0.0	2.0	0.0000000000	False
refers to a setting	0.0	0.0	0.0	2.0	0.0000000000	False
patterns in the data	0.0	0.0	0.0	2.0	0.0000000000	False
data that the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm is just failing	0.0	0.0	0.0	2.0	0.0000000000	False
fit and this problem	0.0	0.0	0.0	2.0	0.0000000000	False
fitting the idiosyncratic properties	0.0	0.0	0.0	2.0	0.0000000000	False
properties of this data	0.0	0.0	0.0	2.0	0.0000000000	False
trends of how housing	0.0	0.0	0.0	2.0	0.0000000000	False
vary as the function	0.0	0.0	0.0	2.0	0.0000000000	False
two very different problems	0.0	0.0	0.0	2.0	0.0000000000	False
problems we ll define	0.0	0.0	0.0	0.0	0.0000000000	False
issue of selecting features	0.0	0.0	0.0	2.0	0.0000000000	False
teach us the learning	0.0	0.0	0.0	2.0	0.0000000000	False
ll talk about feature	0.0	0.0	0.0	2.0	0.0000000000	False
talk about feature selection	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms later this quarter	0.0	0.0	0.0	2.0	0.0000000000	False
automatic algorithms for choosing	0.0	0.0	0.0	2.0	0.0000000000	False
talk about a class	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms called non-parametric learning	0.0	0.0	0.0	2.0	0.0000000000	False
choose features very carefully	0.0	0.0	0.0	4.0	0.0000000000	False
discussion of locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm parametric learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm parametric learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
defined as an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
fixed number of parameters	0.0	0.0	0.0	2.0	0.0000000000	False
fix set of parameters	0.0	0.0	0.0	2.0	0.0000000000	False
set of parameters theta	0.0	0.0	0.0	4.0	0.0000000000	False
first non-parametric learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm the formal definition	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm where the number	0.0	0.0	0.0	2.0	0.0000000000	False
size of the training	0.0	0.0	0.0	4.0	0.0000000000	False
defined as a number	0.0	0.0	0.0	2.0	0.0000000000	False
number of parameters grows	0.0	0.0	0.0	2.0	0.0000000000	False
linearly with the size	0.0	0.0	0.0	2.0	0.0000000000	False
slightly less formal definition	0.0	0.0	0.0	2.0	0.0000000000	False
stuff that your learning	0.0	0.0	0.0	2.0	0.0000000000	False
linearly with the training	0.0	0.0	0.0	2.0	0.0000000000	False
specific non-parametric learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm called locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
couple of other names	0.0	0.0	0.0	2.0	0.0000000000	False
loess for self-hysterical reasons	0.0	0.0	0.0	2.0	0.0000000000	False
loess is usually spelled	0.0	0.0	0.0	2.0	0.0000000000	False
call it locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
worry a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
fit to this data	0.0	0.0	0.0	2.0	0.0000000000	False
data you can sit	0.0	0.0	0.0	2.0	0.0000000000	False
sit around and stare	0.0	0.0	0.0	2.0	0.0000000000	False
decide whether the features	0.0	0.0	0.0	2.0	0.0000000000	False
features are used right	0.0	0.0	0.0	2.0	0.0000000000	False
sit around and fiddle	0.0	0.0	0.0	2.0	0.0000000000	False
features that the model	0.0	0.0	0.0	2.0	0.0000000000	False
talk about an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
fit theta to minimize	0.0	0.0	0.0	4.0	0.0000000000	False
theta to minimize sum	0.0	0.0	0.0	4.0	0.0000000000	False
linear regression in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
locally weighted linear regression	0.0	0.0	5.99798081777	8.0	0.5256410256	True
linear regression you re	0.0	0.0	0.0	0.0	0.0000000000	False
slightly different you re	0.0	0.0	0.0	0.0	0.0000000000	False
account only the data	0.0	0.0	0.0	2.0	0.0000000000	False
vicinity of this point	0.0	0.0	0.0	2.0	0.0000000000	False
linear regression to fit	0.0	0.0	0.0	2.0	0.0000000000	False
fit a straight line	0.0	0.0	3.99798081777	8.0	0.4162436548	False
sub-set of the data	0.0	0.0	0.0	2.0	0.0000000000	False
set and i fit	0.0	0.0	0.0	2.0	0.0000000000	False
evaluate this particular value	0.0	0.0	0.0	2.0	0.0000000000	False
value of straight line	0.0	0.0	0.0	2.0	0.0000000000	False
return for my algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
outputs in locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
re gon na fall	0.0	0.0	0.0	2.0	0.0000000000	False
re going to fit	0.0	0.0	0.0	2.0	0.0000000000	False
right ? so notice	0.0	0.0	0.0	2.0	0.0000000000	False
notice that  suppose	0.0	0.0	0.0	2.0	0.0000000000	False
conversely if xi minus	0.0	0.0	0.0	2.0	0.0000000000	False
close to zero right	0.0	0.0	0.0	2.0	0.0000000000	False
minus some large number	0.0	0.0	0.0	2.0	0.0000000000	False
give the points close	0.0	0.0	0.0	2.0	0.0000000000	False
large weight and give	0.0	0.0	0.0	2.0	0.0000000000	False
times this quadratic term	0.0	0.0	0.0	4.0	0.0000000000	False
quadratic term for points	0.0	0.0	0.0	2.0	0.0000000000	False
points plus zero times	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic term for faraway	0.0	0.0	0.0	2.0	0.0000000000	False
term for faraway points	0.0	0.0	0.0	2.0	0.0000000000	False
weighted linear regression fits	0.0	0.0	0.0	2.0	0.0000000000	False
regression fits a set	0.0	0.0	0.0	2.0	0.0000000000	False
paying much more attention	0.0	0.0	0.0	2.0	0.0000000000	False
fitting the points close	0.0	0.0	0.0	2.0	0.0000000000	False
points close by accurately	0.0	0.0	0.0	2.0	0.0000000000	False
contribution from faraway points	0.0	0.0	0.0	2.0	0.0000000000	False
choice on many problems	0.0	0.0	0.0	2.0	0.0000000000	False
plug in other functions	0.0	0.0	0.0	2.0	0.0000000000	False
formula i ve written	0.0	0.0	0.0	0.0	0.0000000000	False
cosmetically looks a bit	0.0	0.0	0.0	2.0	0.0000000000	False
associating with these points	0.0	0.0	0.0	2.0	0.0000000000	False
centered around the position	0.0	0.0	0.0	2.0	0.0000000000	False
ll give a weight	0.0	0.0	0.0	2.0	0.0000000000	False
proportional to the height	0.0	0.0	0.0	2.0	0.0000000000	False
evaluated at this point	0.0	0.0	0.0	2.0	0.0000000000	False
proportionate to that height	0.0	0.0	0.0	2.0	0.0000000000	False
parameter to this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ll denote as tow	0.0	0.0	0.0	2.0	0.0000000000	False
suspiciously like the variants	0.0	0.0	0.0	2.0	0.0000000000	False
convenient form or function	0.0	0.0	0.0	2.0	0.0000000000	False
function this parameter tow	0.0	0.0	0.0	2.0	0.0000000000	False
fast the weights fall	0.0	0.0	0.0	2.0	0.0000000000	False
fall of with distance	0.0	0.0	0.0	2.0	0.0000000000	False
guess so if tow	0.0	0.0	0.0	2.0	0.0000000000	False
narrow gaussian  excuse	0.0	0.0	0.0	2.0	0.0000000000	False
fairly narrow bell shape	0.0	0.0	0.0	2.0	0.0000000000	False
weights of the points	0.0	0.0	0.0	2.0	0.0000000000	False
rapidly whereas if tow	0.0	0.0	0.0	2.0	0.0000000000	False
choosing a weighting function	0.0	0.0	0.0	2.0	0.0000000000	False
weighting function that falls	0.0	0.0	0.0	2.0	0.0000000000	False
distance from your query	0.0	0.0	0.0	2.0	0.0000000000	False
regression to a data	0.0	0.0	0.0	2.0	0.0000000000	False
line making that prediction	0.0	0.0	0.0	2.0	0.0000000000	False
put a straight line	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to make	0.0	0.0	0.0	2.0	0.0000000000	False
run a new fitting	0.0	0.0	0.0	2.0	0.0000000000	False
procedure and then evaluate	0.0	0.0	0.0	2.0	0.0000000000	False
line that you fit	0.0	0.0	0.0	2.0	0.0000000000	False
position of the value	0.0	0.0	0.0	2.0	0.0000000000	False
position of the query	0.0	0.0	0.0	2.0	0.0000000000	False
query where you re	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to make	0.0	0.0	0.0	2.0	0.0000000000	False
point along the x-axis	0.0	0.0	0.0	2.0	0.0000000000	False
x-axis then you find	0.0	0.0	0.0	2.0	0.0000000000	False
find that locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
curve for a data	0.0	0.0	0.0	2.0	0.0000000000	False
problem set we re	0.0	0.0	0.0	0.0	0.0000000000	False
topic let me check	0.0	0.0	0.0	2.0	0.0000000000	False
weighted regression can run	0.0	0.0	0.0	2.0	0.0000000000	False
penancier for the problem	0.0	0.0	0.0	2.0	0.0000000000	False
problems with locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
things i ll leave	0.0	0.0	0.0	0.0	0.0000000000	False
leave you to discover	0.0	0.0	0.0	2.0	0.0000000000	False
mentioned yeah ? instructor	0.0	0.0	0.0	2.0	0.0000000000	False
right so the question	0.0	0.0	0.0	2.0	0.0000000000	False
write a code implementing	0.0	0.0	0.0	2.0	0.0000000000	False
code implementing locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
regression on the data	0.0	0.0	0.0	2.0	0.0000000000	False
band with parameter tow	0.0	0.0	0.0	2.0	0.0000000000	False
talk about model selection	0.0	0.0	0.0	2.0	0.0000000000	False
weights are not random	0.0	0.0	0.0	2.0	0.0000000000	False
purpose of this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
choose to define things	0.0	0.0	0.0	2.0	0.0000000000	False
lead anywhere in fact	0.0	0.0	0.0	2.0	0.0000000000	False
out that i happened	0.0	0.0	0.0	2.0	0.0000000000	False
bell-shaped function to define	0.0	0.0	0.0	2.0	0.0000000000	False
force in the definition	0.0	0.0	0.0	2.0	0.0000000000	False
huge set of houses	0.0	0.0	0.0	2.0	0.0000000000	False
linear for each house	0.0	0.0	0.0	2.0	0.0000000000	False
result for each input	0.0	0.0	0.0	2.0	0.0000000000	False
theta to your entire	0.0	0.0	0.0	2.0	0.0000000000	False
data set again turns	0.0	0.0	0.0	2.0	0.0000000000	False
out there are algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms that  turns	0.0	0.0	0.0	2.0	0.0000000000	False
out there are ways	0.0	0.0	0.0	2.0	0.0000000000	False
efficient for large data	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to talk	0.0	0.0	0.0	0.0	0.0000000000	False
work of andrew moore	0.0	0.0	0.0	2.0	0.0000000000	False
andrew moore on kd-trees	0.0	0.0	0.0	2.0	0.0000000000	False
out ways to fit	0.0	0.0	0.0	2.0	0.0000000000	False
models much more efficiently	0.0	0.0	0.0	2.0	0.0000000000	False
locally weighted regression remember	0.0	0.0	0.0	2.0	0.0000000000	False
regression remember the outline	0.0	0.0	0.0	2.0	0.0000000000	False
beginning of this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
move on to talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
put aside locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
talk about ordinary unweighted	0.0	0.0	0.0	2.0	0.0000000000	False
ordinary unweighted linear regression	0.0	1.0	0.0	2.0	0.0000000000	False
things we could optimize	0.0	0.0	0.0	2.0	0.0000000000	False
square of the area	0.0	0.0	0.0	2.0	0.0000000000	False
area between the predictions	0.0	0.0	0.0	2.0	0.0000000000	False
predictions of the hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses and the values	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the absolute value	0.0	0.0	0.0	2.0	0.0000000000	False
value of the areas	0.0	0.0	0.0	2.0	0.0000000000	False
areas or the areas	0.0	0.0	0.0	2.0	0.0000000000	False
areas to the power	0.0	0.0	0.0	2.0	0.0000000000	False
assumptions that will serve	0.0	0.0	0.0	2.0	0.0000000000	False
serve to  justify	0.0	0.0	0.0	2.0	0.0000000000	False
re minimizing the sum	0.0	0.0	0.0	2.0	0.0000000000	False
squares regression make sense	0.0	0.0	0.0	2.0	0.0000000000	False
describe do nt hold	0.0	0.0	0.0	0.0	0.0000000000	False
squares actually still makes	0.0	0.0	0.0	2.0	0.0000000000	False
sense in many circumstances	0.0	0.0	0.0	2.0	0.0000000000	False
circumstances but this sort	0.0	0.0	0.0	2.0	0.0000000000	False
endow the least squares	0.0	0.0	0.0	2.0	0.0000000000	False
model with probabilistic semantics	0.0	0.0	0.0	2.0	0.0000000000	False
house it s sold	0.0	0.0	0.0	0.0	0.0000000000	False
function of the features	0.0	0.0	0.0	2.0	0.0000000000	False
error term as capturing	0.0	0.0	0.0	2.0	0.0000000000	False
term as capturing unmodeled	0.0	0.0	0.0	2.0	0.0000000000	False
features of a house	0.0	0.0	0.0	2.0	0.0000000000	False
features that we jut	0.0	0.0	0.0	2.0	0.0000000000	False
jut fail to capture	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon as random noise	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon is our error	0.0	0.0	0.0	2.0	0.0000000000	False
error term that captures	0.0	0.0	0.0	2.0	0.0000000000	False
unmodeled effects just things	0.0	0.0	0.0	2.0	0.0000000000	False
model maybe the function	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the errors	0.0	0.0	6.99747602221	10.0	0.4389721627	False
distribution i ll assume	0.0	0.0	0.0	0.0	0.0000000000	False
epsilon i are distributed	0.0	0.0	0.0	2.0	0.0000000000	False
right ? to denote	0.0	0.0	0.0	2.0	0.0000000000	False
denote a normal distribution	0.0	0.0	0.0	2.0	0.0000000000	False
quickly raise your hand	0.0	0.0	0.0	2.0	0.0000000000	False
hand if you ve	0.0	0.0	0.0	0.0	0.0000000000	False
density of our epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
implies that the probability	0.0	0.0	0.0	2.0	0.0000000000	False
distribution of a price	0.0	0.0	0.0	2.0	0.0000000000	False
price of a house	0.0	0.0	3.99798081777	8.0	0.2039800995	False
gaussian with that density	0.0	0.0	0.0	2.0	0.0000000000	False
house given the features	0.0	0.0	0.0	2.0	0.0000000000	False
features of the house	0.0	0.0	0.0	2.0	0.0000000000	False
house and my parameters	0.0	0.0	0.0	2.0	0.0000000000	False
variable that s distributed	0.0	0.0	0.0	0.0	0.0000000000	False
gaussian with mean theta	0.0	0.0	0.0	2.0	0.0000000000	False
transpose xi and variance	0.0	0.0	0.0	2.0	0.0000000000	False
variance sigma squared right	0.0	0.0	0.0	2.0	0.0000000000	False
housing prices are generated	0.0	0.0	0.0	2.0	0.0000000000	False
equal to theta transpose	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian noise with variance	0.0	0.0	0.0	2.0	0.0000000000	False
noise with variance sigma	0.0	0.0	0.0	2.0	0.0000000000	False
squared so the price	0.0	0.0	0.0	2.0	0.0000000000	False
make sense ? raise	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian ? two reasons	0.0	0.0	0.0	2.0	0.0000000000	False
limit theorem it turns	0.0	0.0	0.0	2.0	0.0000000000	False
vast majority of problems	0.0	0.0	0.0	2.0	0.0000000000	False
apply a linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
distribution of the errors	0.0	0.0	0.0	2.0	0.0000000000	False
find that the errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors really are gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
assumption for the error	0.0	0.0	0.0	2.0	0.0000000000	False
error in regression problems	0.0	0.0	0.0	2.0	0.0000000000	False
random variables will tend	0.0	0.0	0.0	2.0	0.0000000000	False
tend towards a gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
caused by many effects	0.0	0.0	0.0	2.0	0.0000000000	False
mood of the seller	0.0	0.0	0.0	2.0	0.0000000000	False
mood of the buyer	0.0	0.0	0.0	2.0	0.0000000000	False
features that we miss	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian if in practice	0.0	0.0	0.0	2.0	0.0000000000	False
unreasonable assumption i guess	0.0	0.0	0.0	2.0	0.0000000000	False
learning all the assumptions	0.0	0.0	0.0	2.0	0.0000000000	False
true in the absence	0.0	0.0	0.0	2.0	0.0000000000	False
housing prices are priced	0.0	0.0	0.0	2.0	0.0000000000	False
prices are not continued	0.0	0.0	0.0	2.0	0.0000000000	False
continued as value random	0.0	0.0	0.0	2.0	0.0000000000	False
cents in housing prices	0.0	0.0	0.0	2.0	0.0000000000	False
hurt our learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
ll say a bit	0.0	0.0	0.0	2.0	0.0000000000	False
generative and discriminative learning	0.0	0.0	0.0	2.0	0.0000000000	False
point out one bit	0.0	0.0	0.0	2.0	0.0000000000	False
theta as a random	0.0	0.0	0.0	2.0	0.0000000000	False
variable so in statistics	0.0	0.0	0.0	2.0	0.0000000000	False
true value of theta	0.0	0.0	5.99848561333	6.0	0.0000000000	False
theta that s out	0.0	0.0	0.0	0.0	0.0000000000	False
nt know what theta	0.0	0.0	0.0	0.0	0.0000000000	False
random value of theta	0.0	0.0	0.0	2.0	0.0000000000	False
value of theta out	0.0	0.0	0.0	4.0	0.0000000000	False
condition on random variables	0.0	0.0	0.0	2.0	0.0000000000	False
part of the class	0.0	0.0	0.0	2.0	0.0000000000	False
class where we re	0.0	0.0	0.0	0.0	0.0000000000	False
taking sort of frequentist	0.0	0.0	0.0	2.0	0.0000000000	False
class we re thinking	0.0	0.0	0.0	0.0	0.0000000000	False
re thinking of theta	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to estimate	0.0	0.0	0.0	2.0	0.0000000000	False
right so we re	0.0	0.0	0.0	0.0	0.0000000000	False
re gon na make	0.0	0.0	0.0	2.0	0.0000000000	False
make one more assumption	0.0	0.0	0.0	2.0	0.0000000000	False
assumption let s assume	0.0	0.0	0.0	0.0	0.0000000000	False
independently and identically distributed	0.0	0.0	0.0	2.0	0.0000000000	False
distributed part just means	0.0	0.0	0.0	2.0	0.0000000000	False
assuming that the epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
call this the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
theta as the probability	0.0	0.0	0.0	2.0	0.0000000000	False
product over my training	0.0	0.0	0.0	2.0	0.0000000000	False
densities that i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
probability of the data	0.0	0.0	7.99798081777	8.0	0.3445378151	False
probability are often confused	0.0	0.0	0.0	2.0	0.0000000000	False
confused so the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
thing as the probability	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood and for probability	0.0	0.0	0.0	2.0	0.0000000000	False
thing as a function	0.0	0.0	0.0	2.0	0.0000000000	False
function of theta holding	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the parameters	0.0	0.0	3.99848561333	6.0	0.0000000000	False
parameters and the probability	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the data	0.0	0.0	0.0	2.0	0.0000000000	False
consistent in that terminology	0.0	0.0	0.0	2.0	0.0000000000	False
estimate the parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
choose for your model	0.0	0.0	0.0	2.0	0.0000000000	False
principle of maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
choose theta to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
words choose the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
massive likely your estimation	0.0	0.0	0.0	2.0	0.0000000000	False
case l of theta	0.0	0.0	0.0	2.0	0.0000000000	False
capital l of theta	0.0	0.0	0.0	2.0	0.0000000000	False
nt bother to write	0.0	0.0	0.0	0.0	0.0000000000	False
log and a product	0.0	0.0	0.0	2.0	0.0000000000	False
sum of over logs	0.0	0.0	0.0	2.0	0.0000000000	False
sum of the logs	0.0	0.0	0.0	2.0	0.0000000000	False
simplifies to m times	0.0	0.0	0.0	2.0	0.0000000000	False
times one over root	0.0	0.0	0.0	2.0	0.0000000000	False
root two pi sigma	0.0	0.0	0.0	2.0	0.0000000000	False
log of explanation cancel	0.0	0.0	0.0	2.0	0.0000000000	False
board okay so maximizing	0.0	0.0	0.0	2.0	0.0000000000	False
maximizing the log likelihood	0.0	0.0	0.0	4.0	0.0000000000	False
minus sign so maximizing	0.0	0.0	0.0	2.0	0.0000000000	False
ordinary least squares algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
assuming this probabilistic model	0.0	0.0	0.0	2.0	0.0000000000	False
assuming iid gaussian errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors on our data	0.0	0.0	0.0	2.0	0.0000000000	False
notice that the value	0.0	0.0	0.0	2.0	0.0000000000	False
value of sigma squared	0.0	0.0	2.99848561333	6.0	0.0000000000	False
squared does nt matter	0.0	0.0	0.0	0.0	0.0000000000	False
matter what the value	0.0	0.0	0.0	2.0	0.0000000000	False
variance of a gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
matter what sigma squared	0.0	0.0	0.0	4.0	0.0000000000	False
positive number the value	0.0	0.0	0.0	2.0	0.0000000000	False
clean up another couple	0.0	0.0	0.0	2.0	0.0000000000	False
ll see what questions	0.0	0.0	0.0	2.0	0.0000000000	False
re asking about overfitting	0.0	0.0	0.0	2.0	0.0000000000	False
thing s you re	0.0	0.0	0.0	0.0	0.0000000000	False
deeper questions about learning	0.0	0.0	0.0	2.0	0.0000000000	False
questions about learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
probabilistic interpretation in order	0.0	0.0	0.0	2.0	0.0000000000	False
derive our next learning	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to predict	0.0	0.0	0.0	4.0	0.0000000000	False
predict is continuous values	0.0	0.0	0.0	2.0	0.0000000000	False
value y you re	0.0	0.0	0.0	0.0	0.0000000000	False
predict will be discreet	0.0	0.0	0.0	2.0	0.0000000000	False
number of discrete values	0.0	0.0	0.0	2.0	0.0000000000	False
case i ll talk	0.0	0.0	0.0	0.0	0.0000000000	False
ll talk about binding	0.0	0.0	0.0	2.0	0.0000000000	False
talk about binding classification	0.0	0.0	0.0	2.0	0.0000000000	False
classification where y takes	0.0	0.0	0.0	2.0	0.0000000000	False
problems if you re	0.0	0.0	0.0	0.0	0.0000000000	False
based on some features	0.0	0.0	0.0	2.0	0.0000000000	False
features that the patient	0.0	0.0	0.0	2.0	0.0000000000	False
patient has a disease	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to decide	0.0	0.0	0.0	2.0	0.0000000000	False
decide will this house	0.0	0.0	0.0	2.0	0.0000000000	False
ll either be sold	0.0	0.0	0.0	2.0	0.0000000000	False
nt be other standing	0.0	0.0	0.0	0.0	0.0000000000	False
build a spam filter	0.0	0.0	0.0	2.0	0.0000000000	False
sit in whether predicting	0.0	0.0	0.0	2.0	0.0000000000	False
predicting whether a computer	0.0	0.0	0.0	2.0	0.0000000000	False
computer system will crash	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to predict	0.0	0.0	0.0	2.0	0.0000000000	False
predict will this computing	0.0	0.0	0.0	2.0	0.0000000000	False
classification problem y takes	0.0	0.0	0.0	2.0	0.0000000000	False
takes on two values	0.0	0.0	0.0	2.0	0.0000000000	False
set you can fit	0.0	0.0	0.0	2.0	0.0000000000	False
data set i ve	0.0	0.0	0.0	0.0	0.0000000000	False
set i ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
amazingly easy classification problem	0.0	0.0	0.0	2.0	0.0000000000	False
right ? the relationship	0.0	0.0	0.0	2.0	0.0000000000	False
regressions to this data	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis to this straight	0.0	0.0	0.0	2.0	0.0000000000	False
straight line and threshold	0.0	0.0	0.0	2.0	0.0000000000	False
right answer you predict	0.0	0.0	0.0	2.0	0.0000000000	False
linear regression to classification	0.0	0.0	3.99848561333	6.0	0.0000000000	False
regression to classification problems	0.0	0.0	0.0	4.0	0.0000000000	False
bad idea to apply	0.0	0.0	0.0	4.0	0.0000000000	False
change my training set	0.0	0.0	0.0	2.0	0.0000000000	False
training set by giving	0.0	0.0	0.0	2.0	0.0000000000	False
obvious what the relationship	0.0	0.0	0.0	2.0	0.0000000000	False
convey much new information	0.0	0.0	0.0	2.0	0.0000000000	False
surprise that this corresponds	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to y equals	0.0	0.0	0.0	2.0	0.0000000000	False
data set you end	0.0	0.0	0.0	2.0	0.0000000000	False
predictions of your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
completely if your threshold	0.0	0.0	0.0	2.0	0.0000000000	False
threshold  your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
make it even worse	0.0	0.0	0.0	2.0	0.0000000000	False
regression to classification algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm sometimes it work	0.0	0.0	0.0	2.0	0.0000000000	False
value of y lies	0.0	0.0	0.0	2.0	0.0000000000	False
form of our hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
lies in the unit	0.0	0.0	0.0	2.0	0.0000000000	False
choosing a linear function	0.0	0.0	0.0	2.0	0.0000000000	False
function for my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
theta x of theta	0.0	0.0	0.0	2.0	0.0000000000	False
large and it crosses	0.0	0.0	0.0	2.0	0.0000000000	False
crosses the vertical axis	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down this function	0.0	0.0	0.0	2.0	0.0000000000	False
function it actually turns	0.0	0.0	0.0	2.0	0.0000000000	False
out naturally as part	0.0	0.0	0.0	2.0	0.0000000000	False
broader class of models	0.0	0.0	0.0	2.0	0.0000000000	False
models and another reason	0.0	0.0	0.0	2.0	0.0000000000	False
talk about next week	0.0	0.0	0.0	2.0	0.0000000000	False
output by my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
outputs and my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the probability	0.0	0.0	0.0	2.0	0.0000000000	False
equal to h subscript	0.0	0.0	0.0	4.0	0.0000000000	False
imagine that my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
outputting all these numbers	0.0	0.0	0.0	2.0	0.0000000000	False
probability of y equals	0.0	0.0	0.0	2.0	0.0000000000	False
two equations and write	0.0	0.0	0.0	2.0	0.0000000000	False
write them more compactly	0.0	0.0	0.0	2.0	0.0000000000	False
power of y times	0.0	0.0	0.0	2.0	0.0000000000	False
power of one minus	0.0	0.0	0.0	2.0	0.0000000000	False
power of one times	0.0	0.0	0.0	2.0	0.0000000000	False
thing to the power	0.0	0.0	0.0	2.0	0.0000000000	False
times this thing power	0.0	0.0	0.0	2.0	0.0000000000	False
compact way of writing	0.0	0.0	0.0	2.0	0.0000000000	False
hope our parameter fitting	0.0	0.0	0.0	2.0	0.0000000000	False
fit the parameters theta	0.0	0.0	0.0	4.0	0.0000000000	False
theta of my model	0.0	0.0	0.0	2.0	0.0000000000	False
pfyi given xi parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
dropped this theta subscript	0.0	0.0	0.0	2.0	0.0000000000	False
write a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
find a maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
find the  setting	0.0	0.0	0.0	2.0	0.0000000000	False
setting the parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
parameters theta that maximizes	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood l of theta	0.0	0.0	0.0	4.0	0.0000000000	False
work with the derivations	0.0	0.0	0.0	2.0	0.0000000000	False
log of the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood rather than maximize	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood so the log	0.0	0.0	0.0	2.0	0.0000000000	False
theta of our model	0.0	0.0	0.0	2.0	0.0000000000	False
model we ll find	0.0	0.0	0.0	0.0	0.0000000000	False
ll find the value	0.0	0.0	0.0	2.0	0.0000000000	False
maximizes this log likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
apply the same gradient	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that we learned	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
function and you remember	0.0	0.0	0.0	2.0	0.0000000000	False
talked about least squares	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the quadratic error	0.0	0.0	0.0	4.0	0.0000000000	False
likelihood and you remember	0.0	0.0	0.0	2.0	0.0000000000	False
repeatedly take the value	0.0	0.0	0.0	2.0	0.0000000000	False
theta and you replace	0.0	0.0	0.0	2.0	0.0000000000	False
previous value of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta plus a learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning rate alpha times	0.0	0.0	0.0	2.0	0.0000000000	False
alpha times the gradient	0.0	0.0	0.0	2.0	0.0000000000	False
gradient of the cos	0.0	0.0	0.0	2.0	0.0000000000	False
cos function the log	0.0	0.0	0.0	2.0	0.0000000000	False
function the log likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
log likelihood will respect	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic error term today	0.0	0.0	0.0	2.0	0.0000000000	False
term today we re	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
maximize rather than minimize	0.0	0.0	0.0	2.0	0.0000000000	False
call this gradient ascent	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm so to figure	0.0	0.0	0.0	2.0	0.0000000000	False
out what this gradient	0.0	0.0	0.0	2.0	0.0000000000	False
order to derive gradient	0.0	0.0	0.0	2.0	0.0000000000	False
compute the partial derivatives	0.0	0.0	0.0	2.0	0.0000000000	False
derivatives of your objective	0.0	0.0	0.0	2.0	0.0000000000	False
objective function with respect	0.0	0.0	0.0	2.0	0.0000000000	False
right ? it turns	0.0	0.0	0.0	2.0	0.0000000000	False
compute this partial derivative	0.0	0.0	0.0	2.0	0.0000000000	False
lower case l theta	0.0	0.0	0.0	2.0	0.0000000000	False
log likelihood of theta	0.0	0.0	0.0	2.0	0.0000000000	False
partial derivative with respect	0.0	0.0	0.0	2.0	0.0000000000	False
theta i you find	0.0	0.0	0.0	2.0	0.0000000000	False
write down a couple	0.0	0.0	0.0	2.0	0.0000000000	False
blackboards full of math	0.0	0.0	0.0	2.0	0.0000000000	False
plug in the definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition for f subscript	0.0	0.0	0.0	2.0	0.0000000000	False
subscript theta as function	0.0	0.0	0.0	2.0	0.0000000000	False
work through the algebra	0.0	0.0	0.0	2.0	0.0000000000	False
out it ll simplify	0.0	0.0	0.0	0.0	0.0000000000	False
theta j gets updated	0.0	0.0	0.0	2.0	0.0000000000	False
theta j plus alpha	0.0	0.0	0.0	2.0	0.0000000000	False
remember seeing this formula	0.0	0.0	0.0	2.0	0.0000000000	False
last lecture ? right	0.0	0.0	0.0	2.0	0.0000000000	False
worked up bastrian descent	0.0	0.0	0.0	2.0	0.0000000000	False
descent for least squares	0.0	0.0	0.0	2.0	0.0000000000	False
making all that noise	0.0	0.0	0.0	2.0	0.0000000000	False
earlier about least squares	0.0	0.0	0.0	2.0	0.0000000000	False
bad idea for classification	0.0	0.0	0.0	2.0	0.0000000000	False
idea for classification problems	0.0	0.0	0.0	2.0	0.0000000000	False
math and i skipped	0.0	0.0	0.0	2.0	0.0000000000	False
claiming at the end	0.0	0.0	0.0	2.0	0.0000000000	False
right ? the definition	0.0	0.0	0.0	2.0	0.0000000000	False
logistic function of theta	0.0	0.0	0.0	2.0	0.0000000000	False
function of theta transpose	0.0	0.0	0.0	2.0	0.0000000000	False
similar on the surface	0.0	0.0	0.0	2.0	0.0000000000	False
descent rule i derived	0.0	0.0	0.0	2.0	0.0000000000	False
totally different learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
coincidence that you ended	0.0	0.0	0.0	2.0	0.0000000000	False
elegant generalized learning models	0.0	0.0	0.0	2.0	0.0000000000	False
cool one last comment	0.0	0.0	0.0	2.0	0.0000000000	False
last comment as part	0.0	0.0	0.0	2.0	0.0000000000	False
part of a sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of learning process	0.0	0.0	0.0	2.0	0.0000000000	False
derivatives and i ended	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to make	0.0	0.0	0.0	0.0	0.0000000000	False
wrote out the entirety	0.0	0.0	0.0	2.0	0.0000000000	False
entirety of this derivation	0.0	0.0	0.0	2.0	0.0000000000	False
follow every single step	0.0	0.0	0.0	2.0	0.0000000000	False
derivatives of this log	0.0	0.0	0.0	2.0	0.0000000000	False
interested in seriously masking	0.0	0.0	0.0	2.0	0.0000000000	False
masking machine learning material	0.0	0.0	0.0	2.0	0.0000000000	False
lecture notes and read	0.0	0.0	0.0	2.0	0.0000000000	False
read through every line	0.0	0.0	0.0	2.0	0.0000000000	False
line and go yep	0.0	0.0	0.0	2.0	0.0000000000	False
material my concrete suggestion	0.0	0.0	0.0	2.0	0.0000000000	False
read through the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
cover up the derivation	0.0	0.0	0.0	4.0	0.0000000000	False
good advice for studying	0.0	0.0	0.0	2.0	0.0000000000	False
technical material like machine	0.0	0.0	0.0	2.0	0.0000000000	False
material like machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
rederive the entire thing	0.0	0.0	0.0	2.0	0.0000000000	False
pieces of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
theory and various proofs	0.0	0.0	0.0	2.0	0.0000000000	False
great way to study	0.0	0.0	0.0	2.0	0.0000000000	False
original derivation all right	0.0	0.0	0.0	2.0	0.0000000000	False
nt get to newton	0.0	0.0	0.0	0.0	0.0000000000	False
newton s method today	0.0	0.0	0.0	0.0	0.0000000000	False
quick digression to talk	0.0	0.0	0.0	2.0	0.0000000000	False
discussion sort of alluding	0.0	0.0	0.0	2.0	0.0000000000	False
lot about the perceptron	0.0	0.0	0.0	2.0	0.0000000000	False
quarter we ll talk	0.0	0.0	0.0	0.0	0.0000000000	False
ll talk about learning	0.0	0.0	0.0	2.0	0.0000000000	False
talk about learning theory	0.0	0.0	0.0	4.0	0.0000000000	False
theta of x equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals g of theta	0.0	0.0	0.0	2.0	0.0000000000	False
step function it turns	0.0	0.0	0.0	2.0	0.0000000000	False
learning called the perceptron	0.0	0.0	0.0	2.0	0.0000000000	False
ascent for logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression and the learning	0.0	0.0	0.0	2.0	0.0000000000	False
classic gradient ascent rule	0.0	0.0	0.0	2.0	0.0000000000	False
rule for logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm than least squares	0.0	0.0	0.0	2.0	0.0000000000	False
regression and logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm with probabilistic semantics	0.0	0.0	0.0	2.0	0.0000000000	False
type of learning rule	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm than logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
simplicity of this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
talks about the perceptron	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm this particular video	0.0	0.0	0.0	2.0	0.0000000000	False
series titled the machine	0.0	0.0	0.0	2.0	0.0000000000	False
world and was produced	0.0	0.0	0.0	2.0	0.0000000000	False
wgbh television in cooperation	0.0	0.0	0.0	2.0	0.0000000000	False
cooperation with the bbc	0.0	0.0	0.0	2.0	0.0000000000	False
pbs a few years	0.0	0.0	0.0	2.0	0.0000000000	False
years ago this shows	0.0	0.0	0.0	2.0	0.0000000000	False
shows you what machine	0.0	0.0	0.0	2.0	0.0000000000	False
fun clip on perceptron	0.0	0.0	0.0	2.0	0.0000000000	False
clip on perceptron algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
built a few working	0.0	0.0	0.0	2.0	0.0000000000	False
explore the mysterious problem	0.0	0.0	0.0	2.0	0.0000000000	False
brain learns this perceptron	0.0	0.0	0.0	2.0	0.0000000000	False
perceptron is being trained	0.0	0.0	0.0	2.0	0.0000000000	False
out many complex rules	0.0	0.0	0.0	2.0	0.0000000000	False
complex rules about faces	0.0	0.0	0.0	2.0	0.0000000000	False
writing a computer program	0.0	0.0	0.0	2.0	0.0000000000	False
facial features and hair	0.0	0.0	0.0	2.0	0.0000000000	False
features and hair outline	0.0	0.0	0.0	2.0	0.0000000000	False
hair outline and takes	0.0	0.0	0.0	2.0	0.0000000000	False
outline and takes longer	0.0	0.0	0.0	2.0	0.0000000000	False
takes longer to learn	0.0	0.0	0.0	2.0	0.0000000000	False
told by dr taylor	0.0	0.0	0.0	2.0	0.0000000000	False
puts on his wig	0.0	0.0	0.0	2.0	0.0000000000	False
part searching after training	0.0	0.0	0.0	2.0	0.0000000000	False
distinguish male from female	0.0	0.0	0.0	2.0	0.0000000000	False
female it has learned	0.0	0.0	0.0	2.0	0.0000000000	False
ll see you guys	0.0	0.0	0.0	2.0	0.0000000000	False
topic to topic	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
outline for today	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
flow of ideas	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talked about linear	0.00248754233192	0.0	2.99848561333	0.0	0.0000000000	False
regression and today	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about sort	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
locally weighted regression	0.015308034098	1.0	13.9934376577	19.0195500087	0.3248811410	True
mentors probably favorite	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
favorite machine learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
machine learning algorithm	0.000737959318968	0.0	0.0	0.0	0.0000000000	True
ll then talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
probable second interpretation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
interpretation of linear	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
first classification algorithm	0.00287325060515	0.0	1.99848561333	4.75488750216	0.0000000000	False
allowing i hope	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm for fitting	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
fitting logistic regression	0.000667202458811	0.0	0.0	0.0	0.0000000000	False
logistic regression models	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
remember the notation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
notation i defined	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression or linear	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
linear least squares	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
denote the predicted	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
hypothesis was franchised	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
vector of grams	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
grams as theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
linear regression model	0.00191550040343	0.0	0.0	3.16992500144	0.0000000000	True
model and lowercase	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
number of features	0.00060938989456	0.0	0.0	1.58496250072	0.0000000000	False
predict housing prices	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
number of bedrooms	0.00287325060515	0.0	2.99848561333	4.75488750216	0.0000000000	False
equal to two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
recapping the previous	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
defined this quadratic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
quadratic cos function	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
minus yi squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set so lowercase	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
notation i ve	0.0	0.0	0.0	0.0	0.0000000000	False
denote the number	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
number of training	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
derive the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of theta	0.0	0.0	9.99444724886	15.8496250072	0.2816989382	False
theta that minimizes	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minimizes this enclosed	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
transpose x inverse	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
inverse x transpose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
amount of notation	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
lecture you forgot	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
re having trouble	0.0	0.0	0.0	0.0	0.0000000000	False
remembering what lowercase	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00125156866559	0.0	1.99848561333	3.16992500144	0.0000000000	False
linear regression last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
houses in square	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
house in general	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
apply a machine-learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choose your features	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
features to give	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
give the learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choice we made	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equal this size	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
leave this idea	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
nt have data	0.0	0.0	0.0	0.0	0.0000000000	False
data that tells	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
houses one thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
draw this out	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
define the set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of features	0.00224204027183	0.0	6.99798081777	6.33985000288	0.0000000000	False
square that number	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm will end	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
end up fitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fitting a quadratic	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
slightly better fit	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fill a model	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
model that fits	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fits your data	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
fit a line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
line that passes	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fits your training	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
training data perfectly	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
predictor of housing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
quadratic model fits	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fits the data	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
small a set	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
large a set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
problem of underfitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
failing to fit	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
algorithm is fitting	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
fitting the idiosyncrasies	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
specific data set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
houses we sampled	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
sampled in portland	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
bit more expensive	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
polynomial we re	0.0	0.0	0.0	0.0	0.0000000000	False
fitting the idiosyncratic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
true underlying trends	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
housing prices vary	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
size of house	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
issue of selecting	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about feature	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
feature selection algorithms	0.000829180777308	1.0	0.0	1.58496250072	0.0000000000	True
algorithms for choosing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choosing what features	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
today is talk	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
class of algorithms	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
algorithms called non-parametric	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
non-parametric learning algorithms	0.00588770542232	1.0	7.99747602221	6.33985000288	0.0000000000	True
features very carefully	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
define the term	0.0	0.0	0.0	1.58496250072	0.0000000000	False
parametric learning algorithm	0.00235508216893	0.0	11.9964664311	9.50977500433	0.0000000000	True
learning algorithm parametric	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algorithm parametric learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
number of parameters	0.0022138779569	0.0	5.99848561333	3.16992500144	0.0000000000	False
parameters that fit	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.00121877978912	0.0	0.0	1.58496250072	0.0000000000	False
data in contrast	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
first non-parametric learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algorithm the formal	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
slightly less formal	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
amount of stuff	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
entire training set	0.00147591863794	0.0	0.0	3.16992500144	0.0000000000	False
describe a specific	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
specific non-parametric learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
loess for self-hysterical	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
self-hysterical reasons loess	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
run linear regression	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
nt really quadratic	0.0	0.0	0.0	0.0	0.0000000000	False
function of sin	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fiddle with features	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
evaluate your hypothesis	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
query point low	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta to minimize	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
transpose xi squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
return theta transpose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression in contrast	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
locally weighted linear	0.00383100080686	0.0	5.99798081777	0.0	0.5256410256	False
weighted linear regression	0.00383100080686	0.0	5.99747602221	4.75488750216	0.5256410256	False
regression you re	0.0	0.0	0.0	0.0	0.0000000000	False
value my hypothesis	0.0	0.0	0.0	3.16992500144	0.0000000000	False
apply linear regression	0.00588770542232	0.0	4.99747602221	7.92481250361	0.4389721627	False
regression to fit	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fit a straight	0.00471016433786	0.0	3.99798081777	0.0	0.4162436548	False
value of straight	0.0	0.0	0.0	0.0	0.0000000000	False
value i return	0.0	0.0	0.0	1.58496250072	0.0000000000	False
terms w superscript	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choice for ways	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minus x squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
squared over two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus some large	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
give the points	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
weight and give	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
times this quadratic	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
term for points	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
points by points	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
term for faraway	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
linear regression fits	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fits a set	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
attention to fitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fitting the points	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
close by accurately	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
accurately whereas ignoring	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
ignoring the contribution	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
contribution from faraway	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
communities of researchers	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
researchers that tend	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
tend to choose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choose different choices	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
choices by default	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
literature on debating	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
debating what point	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
exponential decay function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
formula i ve	0.0	0.0	0.0	0.0	0.0000000000	False
remember the familiar	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
familiar bell-shaped gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
ways of associating	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
value your hypothesis	0.0	0.0	0.0	3.16992500144	0.0000000000	False
give a weight	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
gaussian  excuse	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
bell-shaped function evaluated	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
weight one last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
last small generalization	0.0	0.0	0.0	1.58496250072	0.0000000000	False
denote as tow	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
form or function	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
function this parameter	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
informally it controls	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
controls how fast	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fast the weights	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
copy my diagram	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
end up choosing	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
fairly narrow gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fairly narrow bell	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
narrow bell shape	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fall off rapidly	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
tow is large	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choosing a weighting	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
function that falls	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
slowly with distance	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
apply locally weighted	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
straight line making	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
making that prediction	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
kind of class	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
value you put	0.0	0.0	0.0	1.58496250072	0.0000000000	False
put a straight	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
predict that value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value it turns	0.0	0.0	0.0	1.58496250072	0.0000000000	False
vary your hypothesis	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to make	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.00243755957824	0.0	7.99798081777	6.33985000288	0.0000000000	False
evaluate this line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set we re	0.0	0.0	0.0	0.0	0.0000000000	False
check the questions	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression can run	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
problem of overfitting	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
overfitting or underfitting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
re not building	0.0	0.0	0.0	1.58496250072	0.0000000000	False
building a model	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
entire data set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
write a code	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
implementing locally weighted	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
building your model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
successfully to model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choose this band	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
band with parameter	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll actually talk	0.0	0.0	0.0	3.16992500144	0.0000000000	False
talk about model	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
boy the weights	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choose to define	0.0	0.0	0.0	0.0	0.0000000000	False
things as gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
happened to choose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function to define	0.0	0.0	0.0	0.0	0.0000000000	False
define my weights	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose a function	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
nt even integrate	0.0	0.0	0.0	0.0	0.0000000000	False
integrates to infinity	0.00117754108446	0.0	0.0	3.16992500144	0.0000000000	False
re weighting function	0.0	0.0	0.0	1.58496250072	0.0000000000	False
functions that integrate	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
move on assume	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set of houses	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
predict the linear	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
re actually right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
large training set	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
huge data set	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set again turns	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ways to make	0.00117754108446	0.0	0.0	3.16992500144	0.0000000000	False
efficient for large	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
large data sets	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
work of andrew	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
moore on kd-trees	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
figured out ways	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
ways to fit	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fit these models	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
weighted regression remember	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
remember the outline	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about logistic	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
ll just talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talk about ordinary	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ordinary unweighted linear	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
unweighted linear regression	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
criteria for minimizing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minimizing the square	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
values y predicted	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
minimize the absolute	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
present one set	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
set of assumptions	0.00287325060515	0.0	2.99848561333	4.75488750216	0.0000000000	False
minimizing the sum	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
sum of square	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
sufficient to justify	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
squares regression make	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
regression make sense	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assumptions i describe	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
give one rationalization	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
model with probabilistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
term as capturing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
capturing unmodeled effects	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fail to capture	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
epsilon as random	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
random noise epsilon	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
term that captures	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
effects just things	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
things we forgot	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
forgot to model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
nt quite linear	0.0	0.0	0.0	0.0	0.0000000000	False
day the seller	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
variance sigma squared	0.00353262325339	0.0	2.99848561333	3.16992500144	0.0000000000	False
stands for normal	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
denote a normal	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
covariance sigma squared	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
density for gaussian	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
density for epsilon	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
epsilon i squared	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
erase the board	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sigma squared right	0.0	0.0	0.0	0.0	0.0000000000	False
prices are generated	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
house is equal	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equal to theta	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
random gaussian noise	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
noise with variance	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
sense ? raise	0.0	0.0	0.0	0.0	0.0000000000	False
point of notation	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
error as gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
mumble about justifications	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
central limit theorem	0.00287325060515	0.0	2.99848561333	4.75488750216	0.0000000000	False
theorem it turns	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
majority of problems	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
apply a linear	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
measure the distribution	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
error in regression	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
independent random variables	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
variables will tend	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
error is caused	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
effects are independent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
two real answers	0.0	0.0	0.0	1.58496250072	0.0000000000	False
assumption i guess	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assumptions we make	0.00353262325339	0.0	5.99848561333	4.75488750216	0.0000000000	False
prices are priced	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
priced to dollars	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
dollars and cents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
errors in prices	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
continued as value	0.0	0.0	0.0	0.0	0.0000000000	False
value random variables	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of dollars	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
number of cents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fractions of cents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
cents in housing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
gaussian random variable	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
accurate enough assumption	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
back to selected	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hurt our learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about generative	0.0022138779569	0.0	1.99848561333	4.75488750216	0.0000000000	False
generative and discriminative	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
discriminative learning algorithms	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
week or two	0.0	0.0	0.0	3.16992500144	0.0000000000	False
out one bit	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
bit of notation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
thinking of theta	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
frequentist s point	0.0	0.0	0.0	0.0	0.0000000000	False
point of view	0.000560510067958	0.0	0.0	1.58496250072	0.0000000000	False
generating the data	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
condition on random	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
re taking sort	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of frequentist	0.0	0.0	0.0	0.0	0.0000000000	False
frequentist s viewpoint	0.0	0.0	0.0	0.0	0.0000000000	False
part of class	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
class we re	0.0	0.0	0.0	0.0	0.0000000000	False
parameterized by theta	0.00580426544115	0.0	7.9964664311	11.094737505	0.0000000000	False
read the semicolon	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
semicolon as parameterized	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta is distributed	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
terms are iid	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
terms are independent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
identically distributed part	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
part just means	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assuming the outcome	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fit a model	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
model the probability	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
likelihood of theta	0.00383100080686	0.0	5.99798081777	4.75488750216	0.0000000000	False
parts of notation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
define this term	0.0	0.0	0.0	1.58496250072	0.0000000000	False
prioritized by theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta to test	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
test the likelihood	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
likelihood and probability	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
taking this thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
thing and viewing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function of theta	0.00295183727587	0.0	3.99798081777	4.75488750216	0.0000000000	False
view this thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
data or probability	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
probability of parameters	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
estimate the parameters	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
principle of maximum	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
maximum likelihood estimation	0.00121877978912	0.0	0.0	3.16992500144	0.0000000000	False
choose the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta that makes	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
makes the data	0.00165836155462	0.0	0.0	3.16992500144	0.0000000000	False
data as probable	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
theta to maximize	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
maximize the likelihood	0.00331672310923	0.0	1.99798081777	6.33985000288	0.0000000000	False
choose the parameters	0.00133440491762	0.0	0.0	1.58496250072	0.0000000000	False
parameters that make	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
define lower case	0.0	0.0	0.0	1.58496250072	0.0000000000	False
log likelihood function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	True
log of capital	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
log over product	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
bother to write	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
previous board log	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
two pi sigma	0.0	0.0	0.0	0.0	0.0000000000	False
log of explanation	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
inside the exponent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
likelihood or maximizing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the log	0.00248754233192	0.0	1.99848561333	1.58496250072	0.0000000000	False
minimizing that term	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
sign so maximizing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ve just shown	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ordinary least squares	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
maximum likelihood assuming	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
assuming this probabilistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
assuming iid gaussian	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
iid gaussian errors	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll actually leave	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of sigma	0.0	0.0	2.99848561333	0.0	0.0000000000	False
matter what sigma	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
number the value	0.0	0.0	0.0	0.0	0.0000000000	False
theta we end	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
theta no matter	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
model the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt really matter	0.0	0.0	0.0	0.0	0.0000000000	False
matter just remember	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
couple of boards	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
questions about learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
endows linear regression	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
interpretation in order	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
order to derive	0.00191550040343	0.0	0.0	1.58496250072	0.0000000000	False
predict is continuous	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
first classification problem	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
number of discrete	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk about binding	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
build a spam	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
system will crash	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algorithm to predict	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
computing cluster crash	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
problem y takes	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
binding the classification	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set i ve	0.0	0.0	0.0	0.0	0.0000000000	False
amazingly easy classification	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
easy classification problem	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
linear regression hypothesis	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
line and threshold	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
answer you predict	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
regression to classification	0.00353262325339	0.0	3.99848561333	1.58496250072	0.0000000000	False
pretty bad idea	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
idea to apply	0.00235508216893	0.0	0.0	0.0	0.0000000000	False
change my training	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
set by giving	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
right ? imagine	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value as greater	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt really convey	0.0	0.0	0.0	0.0	0.0000000000	False
fit linear regression	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
set you end	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
hypothesis have changed	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
line that pulls	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
couple of problems	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
kind of fix	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fix this problem	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
start by changing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
changing the form	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis always lies	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis predict values	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
values much larger	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
choosing a linear	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
choose this function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
crosses the vertical	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
generalized linear models	0.00191550040343	1.0	0.0	3.16992500144	0.0000000000	False
naturally as part	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
class of models	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
choose logistic functions	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
endow the outputs	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis is outputting	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
numbers that lie	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
estimate the probability	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
simply it turns	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
equations and write	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
times one minus	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
makes the variation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
variation much nicer	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equals zero equals	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
equals this thing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
times this thing	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
equations to gather	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
hope our parameter	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
model by data	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
fit the parameters	0.00165836155462	0.0	0.0	0.0	0.0000000000	False
probability of theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
dropped this theta	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
find a maximum	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
setting the parameters	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
theta that maximizes	0.00165836155462	0.0	0.0	1.58496250072	0.0000000000	False
theta it turns	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
easier to maximize	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
find the value	0.0	0.0	0.0	0.0	0.0000000000	False
maximizes this log	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
maximized this function	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
gradient descent algorithm	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
minimize the quadratic	0.00248754233192	0.0	2.99848561333	3.16992500144	0.0000000000	False
quadratic error function	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function was great	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
great in descent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to maximize	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
learning rate alpha	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
rate alpha times	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
times the gradient	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
function the log	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
likelihood will respect	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
respect the theta	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
quadratic error term	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
error term today	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
today we re	0.0	0.0	0.0	0.0	0.0000000000	False
great in ascents	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
call this gradient	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
derive gradient descent	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
compute the partial	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
function with respect	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
compute this partial	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
case l theta	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
derivative with respect	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
respect to theta	0.000829180777308	0.0	0.0	1.58496250072	0.0000000000	False
nt terribly complicated	0.0	0.0	0.0	0.0	0.0000000000	False
interest of saving	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
saving you watching	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
couple of blackboards	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
full of math	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta as function	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
algebra it turns	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
updated as theta	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
lecture ? right	0.0	0.0	0.0	0.0	0.0000000000	False
worked up bastrian	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
learning rule last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea for classification	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
bunch of math	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
skipped some steps	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
end they re	0.0	0.0	0.0	0.0	0.0000000000	False
longer theta transpose	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
linear function anymore	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
bastrian descent rule	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
rule i derived	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
totally different learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
talk a bit	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
elegant generalized learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
generalized learning models	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
cool one last	0.0	0.0	0.0	0.0	0.0000000000	False
comment as part	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
sort of learning	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
make you sit	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
long algebraic derivation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
out the entirety	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
derivation in full	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
follow every single	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
masking machine learning	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
machine learning material	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
notes and read	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
understand the material	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
material my concrete	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
check every line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
advice for studying	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
studying technical material	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
material like machine	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
understood every line	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
rederive the entire	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
study various pieces	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
pieces of machine	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
machine learning theory	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
study because cover	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
derivation all right	0.0	0.0	0.0	0.0	0.0000000000	False
digression to talk	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
sort of alluding	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
talk about learning	0.00147591863794	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis output values	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
perceptron algorithm defines	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
function it turns	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
perceptron learning rule	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	True
classic gradient ascent	0.00235508216893	0.0	0.0	1.58496250072	0.0000000000	False
ascent for logistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
gradient ascent rule	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
rule for logistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
flavor of algorithm	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
regression and logistic	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
outputs only values	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
difficult to endow	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
endow this algorithm	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
algorithm with probabilistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
excuse me right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
cosmetically very similar	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
type of learning	0.000957750201716	0.0	0.0	0.0	0.0000000000	False
simple learning algorithm	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
computes theta transpose	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
algorithm than logistic	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
ll do today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is show	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
video series titled	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
titled the machine	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
machine that changed	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
changed the world	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
produced wgbh television	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
television in cooperation	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
british broadcasting corporation	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
aired on pbs	0.000957750201716	0.0	0.0	1.58496250072	0.0000000000	False
ago this shows	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
clip on perceptron	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
explore the mysterious	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
learns this perceptron	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
trained to recognize	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
recognize the difference	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
difference between males	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
males and females	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
out many complex	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
rules about faces	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
faces and writing	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
writing a computer	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
simply given lots	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
lots and lots	0.000737959318968	0.0	0.0	1.58496250072	0.0000000000	False
lots of examples	0.00235508216893	0.0	0.0	3.16992500144	0.0000000000	False
beetle the computer	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
features and hair	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
outline and takes	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
longer to learn	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
taylor andrew puts	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
searching after training	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
training on lots	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
successfully distinguish male	0.00117754108446	0.0	0.0	1.58496250072	0.0000000000	False
male from female	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
learned all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt that great	0.0	0.0	0.0	0.0	0.0000000000	False
illogical flow	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
last lecture	0.0	0.0	1.99848561333	2.0	0.0000000000	False
linear regression	0.0100891812232	1.0	12.9863705199	26.0	0.4324894515	True
weighted regression	0.0102053560654	0.0	13.9934376577	9.0	0.3248811410	False
popular algorithm	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
favorite machine	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
machine learning	0.00224204027183	0.0	7.99697122665	5.0	0.5324675325	False
learning algorithm	0.00545438616536	0.0	16.9883897022	22.0	0.4346289753	False
first classification	0.00221114873949	0.0	1.99798081777	2.0	0.4162436548	False
classification algorithm	0.00177920655683	0.0	2.99798081777	2.0	0.0000000000	False
logistic regression	0.00310901061732	1.0	12.9949520444	9.0	0.5256410256	True
perceptron algorithm	0.00383100080686	0.0	9.99697122665	5.0	0.4162436548	True
regression models	0.00133440491762	0.0	1.99848561333	2.0	0.0000000000	False
previous lecture	0.00138178249659	0.0	1.99798081777	3.0	0.0000000000	False
predicted value	0.000785027389643	0.0	2.99798081777	3.0	0.5256410256	False
theta transpose	0.00590367455174	0.0	5.99444724886	10.0	0.3786733837	False
intercept term	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
training set	0.00361564281171	0.0	10.9934376577	12.0	0.3914081146	False
predict housing	0.00110557436974	0.0	0.0	0.0	0.0000000000	False
housing prices	0.00311361147445	0.0	5.9964664311	6.0	0.5256410256	False
finish recapping	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
quadratic cos	0.00157005477929	0.0	2.99848561333	2.0	0.0000000000	False
cos function	0.00235508216893	0.0	0.998485613327	2.0	0.0000000000	False
theta equals	0.000552787184872	0.0	0.0	1.0	0.0000000000	False
training examples	0.00119309753617	0.0	3.99495204442	9.0	0.3914081146	False
enclosed form	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
fair amount	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
trouble remembering	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
square feet	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
living area	0.000444801639207	0.0	0.0	1.0	0.0000000000	False
machine-learning algorithm	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
large impact	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
linear model	0.00255400053791	0.0	2.99798081777	2.0	0.0000000000	False
data set	0.00477239014467	0.0	14.9919232711	16.0	0.4346289753	False
square footage	0.00127700026895	0.0	0.0	2.0	0.0000000000	False
quadratic function	0.00121877978912	0.0	2.99848561333	2.0	0.0000000000	False
model theta	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
data points	0.00133440491762	0.0	1.99848561333	3.0	0.0000000000	False
points perfectly	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
great model	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
training data	0.000373673378638	0.0	0.0	0.0	0.0000000000	False
data perfectly	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
good model	0.00127700026895	0.0	0.0	2.0	0.0000000000	False
good predictor	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
quadratic model	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
model fits	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
quadratic component	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
linear function	0.00186836689319	0.0	3.99747602221	4.0	0.5324675325	False
fitting models	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
obvious patterns	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
specific data	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
collect data	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
house happened	0.000785027389643	0.0	0.0	2.0	0.0000000000	False
idiosyncratic properties	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
true underlying	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
underlying trends	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
selecting features	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
learning problems	0.000320546980101	0.0	0.0	1.0	0.0000000000	False
feature selection	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
selection algorithms	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
automatic algorithms	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
regression problem	0.00147591863794	0.0	1.99848561333	2.0	0.0000000000	False
non-parametric learning	0.00392513694821	0.0	7.99747602221	4.0	0.4389721627	False
choose features	0.00157005477929	0.0	0.0	0.0	0.0000000000	False
parametric learning	0.00157005477929	0.0	11.9964664311	5.0	0.0000000000	False
fixed number	0.000444801639207	0.0	0.0	0.0	0.0000000000	False
fix set	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
parameters theta	0.00406259929706	0.0	5.99444724886	10.0	0.4244306418	False
first non-parametric	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
formal definition	0.00196789151725	0.0	7.99798081777	3.0	0.0000000000	False
parameters grows	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
entire training	0.000983945758624	0.0	0.0	0.0	0.0000000000	False
specific non-parametric	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
self-hysterical reasons	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
reasons loess	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
training site	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
straight line	0.00379990186561	0.0	9.99444724886	10.0	0.3328413284	False
good fit	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
query point	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
fit theta	0.00235508216893	0.0	2.99848561333	1.0	0.0000000000	False
minimize sum	0.00157005477929	0.0	0.0	0.0	0.0000000000	False
minus theta	0.000552787184872	0.0	0.0	1.0	0.0000000000	False
return theta	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
sub-term sub-set	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
hypothesis outputs	0.00165836155462	0.0	2.99848561333	2.0	0.0000000000	False
right close	0.0	0.0	0.0	1.0	0.0000000000	False
large number	0.000454292246946	0.0	0.0	1.0	0.0000000000	False
points close	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
large weight	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
small weight	0.00157005477929	0.0	0.0	2.0	0.0000000000	False
quadratic term	0.00127700026895	0.0	0.0	1.0	0.0000000000	False
faraway points	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
regression fits	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
weighting functions	0.00235508216893	0.0	4.99848561333	2.0	0.0000000000	False
exponential decay	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
decay function	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
reasonable choice	0.00157005477929	0.0	0.0	2.0	0.0000000000	False
normal distribution	0.00127700026895	0.0	0.0	1.0	0.0000000000	False
gaussian distribution	0.00284381950794	0.0	4.9964664311	7.0	0.0000000000	False
convenient function	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
bell-shaped function	0.00235508216893	0.0	3.99848561333	2.0	0.0000000000	False
gaussian semantics	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
familiar bell-shaped	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
bell-shaped gaussian	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
bell-shaped bump	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
function evaluated	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
last small	0.0	0.0	0.0	0.0	0.0000000000	False
small generalization	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
convenient form	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
parameter tow	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
bandwidth parameter	0.000491972879312	0.0	0.0	1.0	0.0000000000	True
weights fall	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
narrow gaussian	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
narrow bell	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
bell shape	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
line making	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
house costs	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
fitting procedure	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
non-linear curve	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
problem set	0.000345445624146	0.0	0.0	1.0	0.0000000000	False
homework problem	0.000491972879312	0.0	0.0	1.0	0.0000000000	False
entire data	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
code implementing	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
autonomous helicopter	0.000552787184872	0.0	0.0	1.0	0.0000000000	False
model selection	0.000491972879312	1.0	0.0	0.0	0.0000000000	True
last question	0.0	0.0	0.0	2.0	0.0000000000	False
random variables	0.00288492282091	0.0	13.99545684	8.0	0.5256410256	False
probable semantics	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
define things	0.0	0.0	0.0	0.0	0.0000000000	False
huge set	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
end result	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
re right	0.0	0.0	0.0	1.0	0.0000000000	False
non-parametric algorithm	0.000785027389643	0.0	0.0	1.0	0.0000000000	True
large training	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
expensive algorithm	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
huge data	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
large data	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
out ways	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
regression remember	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
probabilistic interpretation	0.00392513694821	0.0	3.99747602221	4.0	0.0000000000	False
absolute value	0.0	0.0	0.0	0.0	0.0000000000	False
squares regression	0.00446950094134	0.0	5.9964664311	6.0	0.4389721627	False
regression make	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
make sense	0.00119351021389	0.0	5.9964664311	6.0	0.0000000000	False
squares model	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
probabilistic semantics	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
term epsilon	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
error term	0.00471016433786	0.0	6.99697122665	5.0	0.4162436548	False
capturing unmodeled	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
unmodeled effects	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
additional features	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
random noise	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
noise epsilon	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
bad mood	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
reasonable price	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
probability distribution	0.00112102013592	0.0	2.99848561333	3.0	0.0000000000	False
errors epsilon	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
variance sigma	0.00235508216893	0.0	2.99848561333	2.0	0.0000000000	False
sigma squared	0.00766200161373	0.0	5.99394245331	11.0	0.1459074733	False
covariance sigma	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
bell-shaped curve	0.00127700026895	0.0	0.0	2.0	0.0000000000	False
standard deviation	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
squared right	0.0	0.0	0.0	0.0	0.0000000000	False
random gaussian	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
gaussian noise	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
central limit	0.00191550040343	0.0	2.99848561333	0.0	0.0000000000	False
limit theorem	0.00191550040343	0.0	2.99848561333	1.0	0.0000000000	False
vast majority	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
gaussian model	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
good assumption	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
independent random	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
approximately gaussian	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
real answers	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
accurate assumption	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
unreasonable assumption	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
absence sense	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
value random	0.0	0.0	0.0	0.0	0.0000000000	False
gaussian random	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
practical purposes	0.000491972879312	0.0	0.0	1.0	0.0000000000	False
discriminative learning	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
semicolon theta	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
true value	0.0	0.0	5.99848561333	0.0	0.0000000000	False
random vehicle	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
random value	0.0	0.0	0.0	0.0	0.0000000000	False
avoid writing	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
taking sort	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
dasian viewpoint	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
semicolon notation	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
identically distributed	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
distributed part	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
important part	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
gaussian densities	0.000491972879312	0.0	0.0	1.0	0.0000000000	False
term likelihood	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
theta holding	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
maximum likelihood	0.00112102013592	0.0	1.99848561333	2.0	0.0000000000	False
likelihood estimation	0.000812519859413	0.0	0.0	0.0	0.0000000000	False
words choose	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
mathematical convenience	0.00235508216893	0.0	3.99848561333	3.0	0.0000000000	False
lower case	0.00110557436974	0.0	0.0	1.0	0.0000000000	False
log likelihood	0.00355841311366	0.0	6.99596163554	7.0	0.4572490706	False
likelihood function	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
find sigma	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
previous board	0.000373673378638	0.0	0.0	0.0	0.0000000000	False
board log	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
explanation cancel	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
minus sign	0.00255400053791	0.0	1.99798081777	3.0	0.0000000000	False
squares algorithm	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
likelihood assuming	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
probabilistic model	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
assuming iid	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
iid gaussian	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
gaussian errors	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
lecture notice	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
positive number	0.000983945758624	0.0	0.0	1.0	0.0000000000	False
deeper questions	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
endows linear	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
continuous values	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
classification problem	0.00284381950794	0.0	5.9964664311	6.0	0.3967741935	True
small number	0.000406259929706	0.0	0.0	1.0	0.0000000000	False
discrete values	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
binding classification	0.000785027389643	1.0	0.0	0.0	0.0000000000	True
medical diagnosis	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
house sell	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
standing examples	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
spam filter	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
e-mail spam	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
colleagues sit	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
computer system	0.000406259929706	0.0	0.0	0.0	0.0000000000	False
computing cluster	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
cluster crash	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
easy classification	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
reasonable fit	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
regression hypothesis	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
right answer	0.0	0.0	0.0	0.0	0.0000000000	False
bad idea	0.00191550040343	0.0	2.99848561333	2.0	0.0000000000	False
additional training	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
deep meaning	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
unit interval	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
hypothesis predict	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
subscript theta	0.0038695102941	0.0	7.9964664311	6.0	0.3722438392	False
sigmoid function	0.00147591863794	0.0	3.99848561333	3.0	0.0000000000	False
logistic function	0.00196789151725	0.0	5.99798081777	3.0	0.0000000000	False
horizontal axis	0.000406259929706	0.0	0.0	1.0	0.0000000000	False
vertical axis	0.000444801639207	0.0	0.0	0.0	0.0000000000	False
broader class	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
beautiful reasons	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
values output	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
compactly write	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
thing power	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
parameter fitting	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
theta subscript	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
gradient descent	0.000983945758624	0.0	0.0	1.0	0.0000000000	False
descent algorithm	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
first algorithm	0.00110557436974	0.0	0.0	2.0	0.0000000000	False
quadratic error	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
error function	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
previous value	0.0	0.0	0.0	0.0	0.0000000000	False
learning rate	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
rate alpha	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
alpha times	0.000491972879312	0.0	0.0	0.0	0.0000000000	False
small change	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
term today	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
gradient ascent	0.00255400053791	0.0	5.99798081777	3.0	0.4162436548	False
derive gradient	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
partial derivatives	0.00221114873949	0.0	4.99798081777	3.0	0.2939068100	False
objective function	0.000444801639207	0.0	0.0	0.0	0.0000000000	False
final answer	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
rule theta	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
bastrian descent	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
learning rule	0.00295183727587	0.0	9.99697122665	5.0	0.2337514253	False
longer theta	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
function anymore	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
descent rule	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
elegant generalized	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
generalized learning	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
learning models	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
coincidence cool	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
last comment	0.0	0.0	0.0	0.0	0.0000000000	False
learning process	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
long algebraic	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
algebraic derivation	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
lecture notes	0.00149469351455	0.0	7.99798081777	3.0	0.0000000000	False
single step	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
masking machine	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
learning material	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
concrete suggestion	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
good advice	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
technical material	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
entire thing	0.000278126370131	0.0	0.0	0.0	0.0000000000	False
learning theory	0.00133440491762	1.0	5.99848561333	2.0	0.0000000000	False
original derivation	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
method today	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
quick digression	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
discussion sort	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
output values	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
low numbers	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
algorithm defines	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
step function	0.00127700026895	0.0	0.0	1.0	0.0000000000	False
perceptron learning	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
classic gradient	0.00157005477929	0.0	0.0	1.0	0.0000000000	False
ascent rule	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
simple learning	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
computes theta	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
simpler algorithm	0.000638500134477	0.0	0.0	1.0	0.0000000000	False
building block	0.000444801639207	0.0	0.0	1.0	0.0000000000	False
last thing	0.0	0.0	0.0	1.0	0.0000000000	False
historical video	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
video series	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
series titled	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
produced wgbh	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
wgbh television	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
british broadcasting	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
broadcasting corporation	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
years ago	0.000373673378638	0.0	0.0	0.0	0.0000000000	False
fun clip	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
scientists built	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
working perceptrons	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
artificial brains	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
mysterious problem	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
brain learns	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
complex rules	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
computer program	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
unusual hairstyles	0.000785027389643	0.0	0.0	1.0	0.0000000000	False
facial features	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
hair outline	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
takes longer	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
taylor andrew	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
andrew puts	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
part searching	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
distinguish male	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
good	0.000138513983154	0.0	0.0	0.0	0.4728171334	False
morning	0.000139063185066	0.0	0.0	0.0	0.0000000000	False
back	0.000288151125986	0.0	0.0	0.0	0.4391431353	False
lecture	0.000585606150247	0.0	0.0	0.0	0.3722438392	False
class	0.000236410410924	0.0	0.0	0.0	0.4572490706	False
today	0.000151208583736	0.0	0.0	0.0	0.3211488251	False
topics	0.000556252740263	0.0	0.0	0.0	0.2939068100	False
bit	0.000275316992163	0.0	0.0	0.0	0.4772486772	False
jumping	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
sort	0.000827436438234	1.0	0.0	0.0	0.5102222222	False
outline	0.00060938989456	0.0	0.0	0.0	0.0000000000	False
illogical	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
flow	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
ideas	0.000157173341447	0.0	0.0	0.0	0.4162436548	False
last	0.0	0.0	0.0	0.0	0.5023562677	False
talked	0.000163864606047	0.0	0.0	0.0	0.3581290504	False
linear	0.00317050950364	0.0	0.0	0.0	0.4290313925	False
regression	0.00879909432924	0.0	0.0	0.0	0.4829672079	False
adaptation	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
locally	0.00193074204952	0.0	0.0	0.0	0.3781877374	False
weighted	0.00711682622732	1.0	0.0	0.0	0.3014705882	False
popular	0.000160273490051	0.0	0.0	0.0	0.0000000000	False
algorithm	0.00214611082631	0.0	0.0	0.0	0.3025611344	False
mentors	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
favorite	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
machine	0.000495016108537	0.0	0.0	0.0	0.4165457184	False
learning	0.00274955113465	0.0	0.0	0.0	0.2979318055	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
probable	0.00267093326322	0.0	0.0	0.0	0.2525296964	False
interpretation	0.000973442295459	0.0	0.0	0.0	0.4162436548	False
move	0.000219602306343	0.0	0.0	0.0	0.4572490706	False
first	0.0	0.0	0.0	0.0	0.4165457184	False
classification	0.00180782140585	0.0	0.0	0.0	0.3117870722	False
logistic	0.00208792068829	0.0	0.0	0.0	0.3396449704	False
digression	0.000444801639207	0.0	0.0	0.0	0.0000000000	False
perceptron	0.00319250067239	0.0	0.0	0.0	0.3273453094	False
quarter	0.000560510067958	0.0	0.0	0.0	0.5256410256	False
allowing	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
hope	0.000519465349082	0.0	0.0	0.0	0.5324675325	False
newton	0.0	0.0	0.0	0.0	0.0000000000	False
method	0.000131599114966	0.0	0.0	0.0	0.0000000000	False
fitting	0.00480505447901	0.0	0.0	0.0	0.3548879837	False
models	0.00334984822062	0.0	0.0	0.0	0.2480553155	False
recap	0.000278126370131	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
previous	0.000264920325991	0.0	0.0	0.0	0.4572490706	False
remember	0.000329403459514	0.0	0.0	0.0	0.5394736842	False
notation	0.000812951154781	0.0	0.0	0.0	0.3722438392	False
defined	0.000157173341447	0.0	0.0	0.0	0.3894870171	False
superscript	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
denote	0.000558308036771	0.0	0.0	0.0	0.3967741935	False
training	0.00306647266689	0.0	0.0	0.0	0.3040501997	False
squares	0.00263198229932	0.0	0.0	0.0	0.2348410034	False
predicted	0.0025495272058	0.0	0.0	0.0	0.3742393509	False
value	0.000470591499474	0.0	0.0	0.0	0.3558702604	False
hypothesis	0.00238503429647	0.0	0.0	0.0	0.3742393509	False
input	9.62848596729e-05	0.0	0.0	0.0	0.0000000000	False
franchised	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
vector	0.000113573061737	0.0	0.0	0.0	0.0000000000	False
grams	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
theta	0.014168033242	0.0	0.0	0.0	0.2161595630	False
equal	0.000915009609761	0.0	0.0	0.0	0.1855203620	False
transpose	0.00241811936902	0.0	0.0	0.0	0.3396449704	False
convention	0.000106280717218	0.0	0.0	0.0	0.0000000000	False
subscript	0.00144246141045	0.0	0.0	0.0	0.4086378738	False
accounts	0.000227146123473	0.0	0.0	0.0	0.0000000000	False
intercept	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
term	0.000206193523277	0.0	0.0	0.0	0.3623385452	False
lowercase	0.00110557436974	0.0	0.0	0.0	0.3445378151	False
number	4.69788633999e-05	0.0	0.0	0.0	0.3781877374	False
features	0.001908187167	0.0	0.0	0.0	0.2768399730	False
set	0.000337322491605	0.0	0.0	0.0	0.3982730707	False
housing	0.00576984564182	0.0	0.0	0.0	0.2775628627	False
prices	0.00293628780524	0.0	0.0	0.0	0.2535335689	False
two	0.0	0.0	0.0	0.0	0.5551257253	False
size	0.000627455332632	0.0	0.0	0.0	0.3288770053	False
bedrooms	0.00127700026895	0.0	0.0	0.0	0.0000000000	False
finish	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
quadratic	0.00166875822079	0.0	0.0	0.0	0.3693693694	False
cos	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
function	0.000989385593955	0.0	0.0	0.0	0.3565217391	False
one-half	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
minus	0.000706454202642	0.0	0.0	0.0	0.3224960671	False
sum	0.000758735644383	0.0	0.0	0.0	0.4638009050	False
examples	0.000366015610702	0.0	0.0	0.0	0.3936000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
end	0.000141053165921	0.0	0.0	0.0	0.4663167104	False
derive	0.00167492411031	0.0	0.0	0.0	0.2964876033	False
minimizes	0.00139577009193	0.0	0.0	0.0	0.3837293017	False
enclosed	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
form	6.68952564063e-05	0.0	0.0	0.0	0.5256410256	False
inverse	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
continue	0.000109801153171	0.0	0.0	0.0	0.0000000000	False
realize	0.000113573061737	0.0	0.0	0.0	0.0000000000	False
fair	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
amount	0.000151747128877	0.0	0.0	0.0	0.0000000000	False
partway	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
forgot	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
trouble	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
raise	0.000261029587403	0.0	0.0	0.0	0.0000000000	False
hand	0.000201547170769	0.0	0.0	0.0	0.4389721627	False
feet	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
living	0.000139063185066	0.0	0.0	0.0	0.0000000000	False
area	0.000348039449871	0.0	0.0	0.0	0.2939068100	False
general	8.03148789535e-05	1.0	0.0	0.0	0.4866468843	False
apply	0.000481424298365	0.0	0.0	0.0	0.4244306418	False
machine-learning	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
problem	0.000148006740946	0.0	0.0	0.0	0.3654781199	False
care	0.000156863833158	0.0	0.0	0.0	0.0000000000	False
choice	0.000394797344898	0.0	0.0	0.0	0.3734061931	False
right	0.0	0.0	0.0	0.0	0.3908306854	False
choose	0.00148504832561	0.0	0.0	0.0	0.3218691589	False
give	2.34894317e-05	0.0	0.0	0.0	0.4391431353	False
large	0.000366003843904	0.0	0.0	0.0	0.3382838284	False
impact	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
made	5.66027096878e-05	0.0	0.0	0.0	0.0000000000	False
leave	0.000243885346434	0.0	0.0	0.0	0.0000000000	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
data	0.00130025726008	0.0	0.0	0.0	0.3017704396	False
tells	7.58735644383e-05	0.0	0.0	0.0	0.0000000000	False
thing	0.0	0.0	0.0	0.0	0.5091661739	False
draw	0.000131599114966	0.0	0.0	0.0	0.0000000000	False
out	0.0	0.0	0.0	0.0	0.4721948009	False
copy	0.000259732674541	0.0	0.0	0.0	0.0000000000	False
footage	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
depending	2.29430826802e-05	0.0	0.0	0.0	0.0000000000	False
slightly	0.000176613550661	0.0	0.0	0.0	0.5256410256	False
polynomial	0.000747346757277	0.0	0.0	0.0	0.0000000000	False
fill	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
power	0.000611011363255	0.0	0.0	0.0	0.2017716535	False
points	8.35179793776e-05	0.0	0.0	0.0	0.2071511854	False
find	9.76521917916e-05	0.0	0.0	0.0	0.4993234100	False
guess	0.000696214291433	0.0	0.0	0.0	0.4389721627	False
drew	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
line	0.00084649811723	0.0	0.0	0.0	0.3592989289	False
passes	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
perfectly	0.00051816843622	0.0	0.0	0.0	0.0000000000	False
curve	0.000690891248293	0.0	0.0	0.0	0.0000000000	False
great	0.000313727666316	0.0	0.0	0.0	0.3734061931	False
sense	0.000252373909483	0.0	0.0	0.0	0.0000000000	False
predictor	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
turns	0.000915009609761	0.0	0.0	0.0	0.4925516579	False
feel	0.000160273490051	0.0	0.0	0.0	0.0000000000	False
component	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
capturing	0.000485624229677	0.0	0.0	0.0	0.0000000000	False
simple	3.95754237582e-05	0.0	0.0	0.0	0.0000000000	False
small	0.000167238141016	0.0	0.0	0.0	0.3912213740	False
complex	0.000186102678924	0.0	0.0	0.0	0.0000000000	False
call	1.04397474222e-05	0.0	0.0	0.0	0.4863921842	False
underfitting	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
informally	0.000263198229932	0.0	0.0	0.0	0.0000000000	False
refers	4.81424298365e-05	0.0	0.0	0.0	0.0000000000	False
obvious	0.000417189555197	0.0	0.0	0.0	0.0000000000	False
patterns	0.000298274384042	0.0	0.0	0.0	0.0000000000	False
failing	0.000373673378638	0.0	0.0	0.0	0.0000000000	False
overfitting	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
idiosyncrasies	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
specific	5.9102602731e-05	0.0	0.0	0.0	0.0000000000	False
sampled	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
portland	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
collect	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
expensive	0.000560510067958	0.0	0.0	0.0	0.0000000000	False
happened	5.23911138156e-05	0.0	0.0	0.0	0.3137755102	False
idiosyncratic	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
properties	4.81424298365e-05	0.0	0.0	0.0	0.0000000000	False
true	0.00026143972193	0.0	0.0	0.0	0.3137755102	False
underlying	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
trends	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
vary	0.000298274384042	0.0	0.0	0.0	0.0000000000	False
formally	0.000596755106943	0.0	0.0	0.0	0.2594936709	False
address	0.000106280717218	0.0	0.0	0.0	0.0000000000	False
issue	7.58735644383e-05	0.0	0.0	0.0	0.0000000000	False
selecting	0.000519465349082	0.0	0.0	0.0	0.0000000000	False
teach	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
ways	0.000183001921952	0.0	0.0	0.0	0.4734411085	False
automatic	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
non-parametric	0.00235508216893	0.0	0.0	0.0	0.4572490706	False
alleviate	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
leads	0.000298274384042	0.0	0.0	0.0	0.0000000000	False
discussion	9.62848596729e-05	0.0	0.0	0.0	0.0000000000	False
parametric	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
fixed	0.000372205357847	0.0	0.0	0.0	0.4162436548	False
parameters	0.00176791467335	0.0	0.0	0.0	0.2470526592	False
contrast	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
definition	0.000397380488986	0.0	0.0	0.0	0.4165457184	False
intuitive	0.000227146123473	0.0	0.0	0.0	0.0000000000	False
replaced	0.000198918368981	0.0	0.0	0.0	0.0000000000	False
grows	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
linearly	0.000373673378638	0.0	0.0	0.0	0.0000000000	False
stuff	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
entire	0.000118205205462	0.0	0.0	0.0	0.5324675325	False
worry	0.000122202272651	0.0	0.0	0.0	0.0000000000	False
describe	0.000186102678924	0.0	0.0	0.0	0.0000000000	False
couple	0.000567865308683	0.0	0.0	0.0	0.5324675325	False
names	0.000259732674541	0.0	0.0	0.0	0.0000000000	False
loess	0.000785027389643	0.0	0.0	0.0	0.0000000000	True
self-hysterical	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
reasons	0.000363187985991	0.0	0.0	0.0	0.3328413284	False
spelled	0.000444801639207	0.0	0.0	0.0	0.0000000000	False
l-o-e-s-s	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
motivating	0.000121406057419	0.0	0.0	0.0	0.0000000000	False
site	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
run	9.1772330721e-05	0.0	0.0	0.0	0.2939068100	False
flat	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
straight	0.000894246270259	0.0	0.0	0.0	0.3328413284	False
sit	0.000397836737962	0.0	0.0	0.0	0.4162436548	False
stare	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
decide	0.000156863833158	0.0	0.0	0.0	0.0000000000	False
toss	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
sin	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
fiddle	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
needing	0.000172722812073	0.0	0.0	0.0	0.4494518879	False
suppose	4.58861653605e-05	0.0	0.0	0.0	0.0000000000	False
evaluate	0.000454292246946	0.0	0.0	0.0	0.5256410256	False
query	0.000889603278415	0.0	0.0	0.0	0.0000000000	False
low	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
position	0.000219602306343	0.0	0.0	0.0	0.3967741935	False
return	0.000186102678924	0.0	0.0	0.0	0.0000000000	False
vicinity	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
sub-set	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
sub-term	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
outputs	0.000526396459863	0.0	0.0	0.0	0.4866468843	False
fall	0.000531403586091	0.0	0.0	0.0	0.3248811410	False
write	0.00021740958332	0.0	0.0	0.0	0.4212328767	False
notice	0.000389599011812	0.0	0.0	0.0	0.0000000000	False
close	0.000288151125986	0.0	0.0	0.0	0.1593076651	False
words	0.000241856604923	0.0	0.0	0.0	0.0000000000	False
conversely	0.000113573061737	0.0	0.0	0.0	0.0000000000	False
picture	9.62848596729e-05	0.0	0.0	0.0	0.0000000000	False
quarrying	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
shown	0.000113205419376	0.0	0.0	0.0	0.0000000000	False
axis	0.000447411576063	0.0	0.0	0.0	0.0000000000	False
contribute	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
summation	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.4275782155	False
faraway	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
effect	0.000424299521603	0.0	0.0	0.0	0.0000000000	False
paying	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
attention	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
accurately	0.000480820470152	0.0	0.0	0.0	0.0000000000	False
ignoring	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
exponentially	0.000278126370131	0.0	0.0	0.0	0.0000000000	False
inaudible	0.00157005477929	0.0	0.0	0.0	0.0000000000	False
communities	0.000139063185066	0.0	0.0	0.0	0.0000000000	False
researchers	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
tend	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
default	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
literature	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
debating	0.000491972879312	0.0	0.0	0.0	0.0000000000	False
decay	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
common	0.000186102678924	0.0	0.0	0.0	0.0000000000	False
plug	0.000389599011812	0.0	0.0	0.0	0.0000000000	False
mention	0.000298377553471	0.0	0.0	0.0	0.0000000000	False
familiar	0.000261029587403	0.0	0.0	0.0	0.0000000000	False
normal	0.000244404545302	0.0	0.0	0.0	0.4162436548	False
distribution	0.00201933362715	0.0	0.0	0.0	0.2979651163	False
gaussian	0.00541826399026	0.0	0.0	0.0	0.2531489257	False
formula	0.000695315925328	0.0	0.0	0.0	0.4162436548	False
written	5.2287944386e-05	0.0	0.0	0.0	0.0000000000	False
cosmetically	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
absolutely	0.000318842151655	0.0	0.0	0.0	0.0000000000	False
convenient	0.000934183446596	0.0	0.0	0.0	0.5256410256	False
bell-shaped	0.00223475047067	0.0	0.0	0.0	0.3364595545	False
endow	0.00235508216893	0.0	0.0	0.0	0.5394736842	False
semantics	0.000641093960202	0.0	0.0	0.0	0.0000000000	False
fact	3.95754237582e-05	0.0	0.0	0.0	0.0000000000	False
associating	9.94591844905e-05	0.0	0.0	0.0	0.0000000000	False
imagine	0.000372205357847	0.0	0.0	0.0	0.5256410256	False
putting	6.68952564063e-05	0.0	0.0	0.0	0.5189873418	False
bump	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
centered	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
proportional	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
height	0.000417189555197	0.0	0.0	0.0	0.0000000000	False
excuse	0.000519465349082	0.0	0.0	0.0	0.4162436548	False
proportionate	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
tow	0.00196256847411	0.0	0.0	0.0	0.2939068100	False
suspiciously	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
variants	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
bandwidth	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
controls	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
fast	0.000160273490051	0.0	0.0	0.0	0.0000000000	False
distance	0.000298274384042	0.0	0.0	0.0	0.0000000000	False
diagram	0.000160273490051	0.0	0.0	0.0	0.0000000000	False
side	4.81424298365e-05	0.0	0.0	0.0	0.0000000000	False
fairly	9.62848596729e-05	0.0	0.0	0.0	0.0000000000	False
narrow	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
bell	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
shape	0.000121406057419	0.0	0.0	0.0	0.0000000000	False
rapidly	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
slowly	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
making	0.00015329269598	0.0	0.0	0.0	0.3150384193	False
kind	2.17004870648e-05	0.0	0.0	0.0	0.0000000000	False
costs	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
procedure	8.70098624678e-05	0.0	0.0	0.0	0.0000000000	False
x-axis	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
trace	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
non-linear	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
play	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
finally	0.000122202272651	0.0	0.0	0.0	0.0000000000	False
check	0.000122202272651	0.0	0.0	0.0	0.0000000000	False
questions	0.000108502435324	0.0	0.0	0.0	0.3912213740	False
penancier	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
discover	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
homework	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
instructor	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
andrew	0.000829180777308	0.0	0.0	0.0	0.0000000000	False
building	0.000435049312339	0.0	0.0	0.0	0.3248811410	False
code	0.000131599114966	0.0	0.0	0.0	0.0000000000	False
implementing	7.07165869338e-05	0.0	0.0	0.0	0.0000000000	False
successfully	0.000298274384042	0.0	0.0	0.0	0.0000000000	False
dynamics	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
autonomous	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
helicopter	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
band	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
boy	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
random	0.00139242858287	0.0	0.0	0.0	0.2733333333	False
variables	0.000566027096878	0.0	0.0	0.0	0.5324675325	False
purpose	0.000122202272651	0.0	0.0	0.0	0.0000000000	False
integrate	0.000812519859413	0.0	0.0	0.0	0.2039800995	False
infinity	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
force	0.000406259929706	0.0	0.0	0.0	0.0000000000	False
assume	0.000483713209846	0.0	0.0	0.0	0.3936000000	False
huge	0.000364218172258	0.0	0.0	0.0	0.0000000000	False
result	5.66027096878e-05	0.0	0.0	0.0	0.0000000000	False
constantly	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
efficient	0.000162590230956	0.0	0.0	0.0	0.0000000000	False
interested	0.000144427289509	0.0	0.0	0.0	0.0000000000	False
work	0.000197877118791	0.0	0.0	0.0	0.4993234100	False
moore	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
kd-trees	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
figured	0.000113205419376	0.0	0.0	0.0	0.0000000000	False
beginning	5.66027096878e-05	0.0	0.0	0.0	0.0000000000	False
probabilistic	0.00248754233192	0.0	0.0	0.0	0.4494518879	False
ordinary	0.000406259929706	0.0	0.0	0.0	0.0000000000	False
unweighted	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
optimize	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
criteria	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
hypotheses	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
present	0.000151747128877	0.0	0.0	0.0	0.0000000000	False
assumptions	0.00180782140585	0.0	0.0	0.0	0.2997562957	False
serve	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
justify	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
sufficient	0.000121406057419	0.0	0.0	0.0	0.0000000000	False
hold	0.000162590230956	0.0	0.0	0.0	0.0000000000	False
circumstances	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
rationalization	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
sold	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
epsilon	0.00203129964853	0.0	0.0	0.0	0.2017716535	False
error	0.00250313733118	0.0	0.0	0.0	0.3336524653	False
unmodeled	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
fireplaces	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
garden	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
additional	0.000131599114966	0.0	0.0	0.0	0.0000000000	False
jut	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
noise	0.000325180461912	0.0	0.0	0.0	0.0000000000	False
day	7.58735644383e-05	0.0	0.0	0.0	0.0000000000	False
seller	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
bad	0.000397836737962	0.0	0.0	0.0	0.4162436548	False
mood	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
refused	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
variance	0.00101564982427	0.0	0.0	0.0	0.4162436548	False
sigma	0.00393578303449	0.0	0.0	0.0	0.2013093290	False
scripts	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
stands	0.000389599011812	0.0	0.0	0.0	0.0000000000	False
covariance	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
quickly	6.11011363255e-05	0.0	0.0	0.0	0.0000000000	False
cool	0.000364218172258	0.0	0.0	0.0	0.0000000000	False
density	0.00122993219828	0.0	0.0	0.0	0.2939068100	False
root	0.000227146123473	0.0	0.0	0.0	0.0000000000	False
negative	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
standard	7.07165869338e-05	0.0	0.0	0.0	0.0000000000	False
deviation	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
erase	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
board	0.00034071918521	0.0	0.0	0.0	0.0000000000	False
implies	9.94591844905e-05	0.0	0.0	0.0	0.0000000000	False
lots	0.000219602306343	0.0	0.0	0.0	0.3855799373	False
mathematically	0.000485624229677	0.0	0.0	0.0	0.4162436548	False
mumble	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
justifications	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
central	0.00060938989456	0.0	0.0	0.0	0.0000000000	False
limit	0.000318842151655	0.0	0.0	0.0	0.0000000000	False
theorem	0.000447411576063	0.0	0.0	0.0	0.0000000000	False
vast	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
majority	0.000139063185066	0.0	0.0	0.0	0.0000000000	False
measure	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
heard	0.000160273490051	0.0	0.0	0.0	0.0000000000	False
independent	0.000435049312339	0.0	0.0	0.0	0.4162436548	False
caused	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
buyer	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
miss	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
place	5.2287944386e-05	0.0	0.0	0.0	0.0000000000	False
inclined	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
approximately	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
practice	0.000227620693315	0.0	0.0	0.0	0.0000000000	False
real	4.41533876651e-05	0.0	0.0	0.0	0.0000000000	False
answers	0.000220766938326	0.0	0.0	0.0	0.0000000000	False
unreasonable	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
absence	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
instance	3.66003843904e-05	0.0	0.0	0.0	0.0000000000	False
dollars	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
cents	0.00117754108446	0.0	0.0	0.0	0.0000000000	False
fractions	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
week	0.000454292246946	0.0	0.0	0.0	0.4162436548	False
hurt	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
discriminative	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
wrote	0.000596755106943	0.0	0.0	0.0	0.4572490706	False
semicolon	0.00060938989456	0.0	0.0	0.0	0.0000000000	False
thinking	0.000259732674541	0.0	0.0	0.0	0.4489051095	False
statistics	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
frequentist	0.0	0.0	0.0	0.0	0.0000000000	False
view	0.000261029587403	0.0	0.0	0.0	0.0000000000	False
vehicle	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
avoid	0.000139063185066	0.0	0.0	0.0	0.0000000000	False
conditioned	0.000151747128877	0.0	0.0	0.0	0.0000000000	False
part	4.22876402703e-05	0.0	0.0	0.0	0.3364595545	False
taking	0.000130977784539	0.0	0.0	0.0	0.3205907906	False
viewpoint	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
dasian	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
estimate	0.000961640940303	0.0	0.0	0.0	0.3504273504	False
read	0.000192569719346	0.0	0.0	0.0	0.4162436548	False
parameterized	0.00162503971883	0.0	0.0	0.0	0.3273453094	False
iid	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
identically	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
means	5.2198737111e-06	0.0	0.0	0.0	0.4066726781	False
outcome	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
important	4.41533876651e-05	0.0	0.0	0.0	0.0000000000	False
likelihood	0.00466351592598	1.0	0.0	0.0	0.2111423221	False
product	0.000465256697309	0.0	0.0	0.0	0.3734061931	False
prioritized	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
test	9.94591844905e-05	0.0	0.0	0.0	0.0000000000	False
confused	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
emphasize	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
hear	0.000121406057419	0.0	0.0	0.0	0.0000000000	False
consistent	0.000106280717218	0.0	0.0	0.0	0.0000000000	False
terminology	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
principle	0.000113573061737	0.0	0.0	0.0	0.0000000000	False
maximum	0.000227620693315	0.0	0.0	0.0	0.0000000000	False
maximize	0.00155839604725	0.0	0.0	0.0	0.2286245353	False
massive	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
lower	0.000198918368981	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.0000000000	False
log	0.00138201696313	0.0	0.0	0.0	0.1670911870	False
capital	0.000345445624146	0.0	0.0	0.0	0.0000000000	False
bother	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
exponent	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
simplifies	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
explanation	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
cancel	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
inside	7.07165869338e-05	0.0	0.0	0.0	0.0000000000	False
sign	0.000649331686353	0.0	0.0	0.0	0.0000000000	False
matter	0.000353582934669	0.0	0.0	0.0	0.2039800995	False
clean	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
deeper	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
probabil	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
order	1.60629757907e-05	0.0	0.0	0.0	0.0000000000	False
recall	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
discreet	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
discrete	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
binding	0.000491972879312	0.0	0.0	0.0	0.0000000000	False
medical	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
diagnosis	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
based	6.11011363255e-05	0.0	0.0	0.0	0.0000000000	False
patient	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
disease	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
sell	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
months	0.000298274384042	0.0	0.0	0.0	0.0000000000	False
spam	0.000406259929706	0.0	0.0	0.0	0.0000000000	False
filter	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
e-mail	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
colleagues	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
computer	0.000109969879081	0.0	0.0	0.0	0.3504273504	False
system	7.58735644383e-05	0.0	0.0	0.0	0.0000000000	False
crash	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
cluster	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
hours	0.0	0.0	0.0	0.0	0.0000000000	False
drawn	0.000106280717218	0.0	0.0	0.0	0.0000000000	False
amazingly	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
easy	0.000186102678924	0.0	0.0	0.0	0.0000000000	False
pretty	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
relationship	0.000320546980101	0.0	0.0	0.0	0.0000000000	False
left	6.60341792711e-05	0.0	0.0	0.0	0.0000000000	False
threshold	0.000667202458811	0.0	0.0	0.0	0.0000000000	False
mid-point	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
people	5.66027096878e-05	0.0	0.0	0.0	0.0000000000	False
change	0.000157173341447	0.0	0.0	0.0	0.3504273504	False
greater	7.07165869338e-05	0.0	0.0	0.0	0.0000000000	False
convey	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
surprise	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
corresponds	9.94591844905e-05	0.0	0.0	0.0	0.0000000000	False
completely	1.97877118791e-05	0.0	0.0	0.0	0.0000000000	False
worse	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
pulls	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
deep	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
lies	0.000261029587403	0.0	0.0	0.0	0.0000000000	False
start	0.0	0.0	0.0	0.0	0.0000000000	False
unit	0.000113573061737	0.0	0.0	0.0	0.0000000000	False
interval	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
larger	5.2287944386e-05	0.0	0.0	0.0	0.0000000000	False
smaller	6.57995574829e-05	0.0	0.0	0.0	0.0000000000	False
sigmoid	0.000737959318968	0.0	0.0	0.0	0.0000000000	False
horizontal	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
plot	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
ascend	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
crosses	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
vertical	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
naturally	6.11011363255e-05	0.0	0.0	0.0	0.0000000000	False
broader	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
beautiful	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
simply	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
equations	0.000279154018385	0.0	0.0	0.0	0.0000000000	False
compactly	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
bizarre	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
variation	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
nicer	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
disappears	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
compact	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
gather	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
pfyi	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
dropped	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
easier	0.000121406057419	0.0	0.0	0.0	0.0000000000	False
gradient	0.00149469351455	0.0	0.0	0.0	0.2195448461	False
descent	0.00111200409802	0.0	0.0	0.0	0.4162436548	False
repeatedly	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
rate	0.000139063185066	0.0	0.0	0.0	0.0000000000	False
alpha	0.000320546980101	0.0	0.0	0.0	0.0000000000	False
respect	0.000261029587403	0.0	0.0	0.0	0.0000000000	False
previously	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
ascents	0.00122993219828	0.0	0.0	0.0	0.4162436548	False
partial	0.000812519859413	0.0	0.0	0.0	0.2939068100	False
objective	7.07165869338e-05	0.0	0.0	0.0	0.0000000000	False
wrong	0.000106280717218	0.0	0.0	0.0	0.0000000000	False
terribly	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
complicated	8.12951154781e-05	0.0	0.0	0.0	0.0000000000	False
saving	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
watching	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
blackboards	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
full	0.000186102678924	0.0	0.0	0.0	0.0000000000	False
math	0.000298274384042	0.0	0.0	0.0	0.0000000000	False
algebra	0.000444801639207	0.0	0.0	0.0	0.0000000000	False
rule	0.000870098624678	0.0	0.0	0.0	0.2011212334	False
updated	9.94591844905e-05	0.0	0.0	0.0	0.0000000000	False
bastrian	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
earlier	0.000144427289509	0.0	0.0	0.0	0.0000000000	False
bunch	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
skipped	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
steps	9.1772330721e-05	0.0	0.0	0.0	0.0000000000	False
claiming	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
longer	0.000278126370131	0.0	0.0	0.0	0.0000000000	False
anymore	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
similar	0.000109801153171	0.0	0.0	0.0	0.0000000000	False
surface	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
totally	6.11011363255e-05	0.0	0.0	0.0	0.0000000000	False
coincidence	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
elegant	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
comment	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
process	2.95513013655e-05	0.0	0.0	0.0	0.0000000000	False
long	7.58735644383e-05	0.0	0.0	0.0	0.0000000000	False
home	0.000447411576063	0.0	0.0	0.0	0.0000000000	False
notes	0.000209151777544	0.0	0.0	0.0	0.0000000000	False
entirety	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
follow	5.66027096878e-05	0.0	0.0	0.0	0.0000000000	False
single	5.2287944386e-05	0.0	0.0	0.0	0.0000000000	False
masking	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
material	0.000389599011812	0.0	0.0	0.0	0.0000000000	False
yep	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
understand	1.37462348851e-05	0.0	0.0	0.0	0.0000000000	False
concrete	0.000139063185066	0.0	0.0	0.0	0.0000000000	False
suggestion	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
cover	0.000364218172258	0.0	0.0	0.0	0.0000000000	False
advice	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
studying	0.000279154018385	0.0	0.0	0.0	0.0000000000	False
technical	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
proof	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
understood	0.000259732674541	0.0	0.0	0.0	0.0000000000	False
rederive	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
pieces	6.57995574829e-05	0.0	0.0	0.0	0.0000000000	False
theory	0.00034071918521	0.0	0.0	0.0	0.0000000000	False
original	6.11011363255e-05	0.0	0.0	0.0	0.0000000000	False
quick	0.000106280717218	0.0	0.0	0.0	0.0000000000	False
alluding	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
cartoon	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
classic	0.000638500134477	0.0	0.0	0.0	0.0000000000	False
flavor	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
difficult	0.000113573061737	0.0	0.0	0.0	0.0000000000	False
type	5.66027096878e-05	0.0	0.0	0.0	0.0000000000	False
simpler	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
simplicity	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
block	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
fun	0.000406259929706	0.0	0.0	0.0	0.0000000000	False
show	4.58861653605e-05	0.0	0.0	0.0	0.0000000000	False
historical	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
video	0.000480820470152	0.0	0.0	0.0	0.0000000000	False
series	0.000203129964853	0.0	0.0	0.0	0.0000000000	False
titled	0.000245986439656	0.0	0.0	0.0	0.0000000000	False
world	0.000121406057419	0.0	0.0	0.0	0.0000000000	False
produced	0.000113573061737	0.0	0.0	0.0	0.0000000000	False
wgbh	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
television	0.000222400819604	0.0	0.0	0.0	0.0000000000	False
cooperation	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
bbc	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
british	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
broadcasting	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
corporation	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
aired	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
pbs	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
years	8.12951154781e-05	0.0	0.0	0.0	0.0000000000	False
ago	0.000149137192021	0.0	0.0	0.0	0.0000000000	False
clip	0.000186836689319	0.0	0.0	0.0	0.0000000000	False
scientists	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
built	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
artificial	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
brains	0.000552787184872	0.0	0.0	0.0	0.0000000000	False
explore	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
mysterious	0.000319250067239	0.0	0.0	0.0	0.0000000000	False
recognize	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
difference	5.28595503379e-06	0.0	0.0	0.0	0.4086378738	False
males	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
females	0.000785027389643	0.0	0.0	0.0	0.0000000000	False
easily	9.94591844905e-05	0.0	0.0	0.0	0.0000000000	False
explain	0.000129866337271	0.0	0.0	0.0	0.0000000000	False
involve	0.000106280717218	0.0	0.0	0.0	0.0000000000	False
faces	0.000242812114838	0.0	0.0	0.0	0.0000000000	False
program	5.2287944386e-05	0.0	0.0	0.0	0.0000000000	False
including	7.58735644383e-05	0.0	0.0	0.0	0.0000000000	False
unusual	0.000276393592436	0.0	0.0	0.0	0.0000000000	False
hairstyles	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
beetle	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
facial	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
hair	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
told	0.000172722812073	0.0	0.0	0.0	0.0000000000	False
taylor	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
wig	0.000392513694821	0.0	0.0	0.0	0.0000000000	False
searching	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
distinguish	0.000160273490051	0.0	0.0	0.0	0.0000000000	False
guys	9.30513394618e-05	0.0	0.0	0.0	0.0000000000	False
announcements before we jump	0.0	0.0	0.0	2.0	0.0000000000	False
today s technical material	0.0	0.0	0.0	0.0	0.0000000000	False
handout with the sort	0.0	0.0	0.0	2.0	0.0000000000	False
choosing and proposing class	0.0	0.0	0.0	2.0	0.0000000000	False
class projects so project	0.0	0.0	0.0	2.0	0.0000000000	False
projects so project proposals	0.0	0.0	0.0	2.0	0.0000000000	False
project for this class	0.0	0.0	0.0	2.0	0.0000000000	False
class due on friday	0.0	0.0	0.0	2.0	0.0000000000	False
19th of this month	0.0	0.0	0.0	2.0	0.0000000000	False
two and a half	0.0	0.0	0.0	2.0	0.0000000000	False
nt yet formed teams	0.0	0.0	0.0	0.0	0.0000000000	False
formed teams or started	0.0	0.0	0.0	2.0	0.0000000000	False
teams or started thinking	0.0	0.0	0.0	2.0	0.0000000000	False
started thinking about project	0.0	0.0	0.0	2.0	0.0000000000	False
thinking about project ideas	0.0	0.0	0.0	2.0	0.0000000000	False
handout with the guidelines	0.0	0.0	0.0	2.0	0.0000000000	False
send me your proposals	0.0	0.0	0.0	2.0	0.0000000000	False
sort of just fishing	0.0	0.0	0.0	2.0	0.0000000000	False
fishing around for ideas	0.0	0.0	0.0	2.0	0.0000000000	False
office hours on friday	0.0	0.0	0.0	2.0	0.0000000000	False
hours on friday mornings	0.0	0.0	0.0	2.0	0.0000000000	False
list of project ideas	0.0	0.0	0.0	2.0	0.0000000000	False
ideas that i sort	0.0	0.0	0.0	2.0	0.0000000000	False
collected from my colleagues	0.0	0.0	0.0	2.0	0.0000000000	False
senior phd students working	0.0	0.0	0.0	2.0	0.0000000000	False
ideas and a variety	0.0	0.0	0.0	2.0	0.0000000000	False
re having trouble coming	0.0	0.0	0.0	2.0	0.0000000000	False
previous class i mentioned	0.0	0.0	0.0	2.0	0.0000000000	False
fun and educational thing	0.0	0.0	0.0	2.0	0.0000000000	False
registered in this class	0.0	0.0	0.0	2.0	0.0000000000	False
logistical details about applying	0.0	0.0	0.0	2.0	0.0000000000	False
encourage you to sort	0.0	0.0	0.0	2.0	0.0000000000	False
respond to that email	0.0	0.0	0.0	2.0	0.0000000000	False
ll get later today	0.0	0.0	0.0	2.0	0.0000000000	False
due in two weeks	0.0	0.0	0.0	2.0	0.0000000000	False
late days for problem	0.0	0.0	0.0	2.0	0.0000000000	False
days for problem set	0.0	0.0	0.0	2.0	0.0000000000	False
based on problem set	0.0	0.0	0.0	2.0	0.0000000000	False
problem set one solutions	0.0	0.0	0.0	2.0	0.0000000000	False
set one solutions questions	0.0	0.0	0.0	2.0	0.0000000000	False
talk about new test	0.0	0.0	0.0	2.0	0.0000000000	False
test methods for fitting	0.0	0.0	0.0	2.0	0.0000000000	False
methods for fitting models	0.0	0.0	0.0	2.0	0.0000000000	False
models like logistic regression	0.0	0.0	0.0	4.0	0.0000000000	False
talk about exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
family distributions and generalized	0.0	0.0	0.0	2.0	0.0000000000	False
nice class of ideas	0.0	0.0	0.0	2.0	0.0000000000	False
ideas that will tie	0.0	0.0	0.0	2.0	0.0000000000	False
ordinary v squares models	0.0	0.0	0.0	2.0	0.0000000000	False
lecture and this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
large amounts of material	0.0	0.0	0.0	2.0	0.0000000000	False
sort of the foundations	0.0	0.0	0.0	2.0	0.0000000000	False
prerequisites for this class	0.0	0.0	0.0	2.0	0.0000000000	False
terms of a background	0.0	0.0	0.0	2.0	0.0000000000	False
section taught this week	0.0	0.0	0.0	2.0	0.0000000000	False
briefly go over sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of octave notation	0.0	0.0	0.0	2.0	0.0000000000	False
review of the probability	0.0	0.0	0.0	2.0	0.0000000000	False
discussion section all right	0.0	0.0	0.0	2.0	0.0000000000	False
last lecture i talked	0.0	0.0	0.0	2.0	0.0000000000	False
theta under this model	0.0	0.0	0.0	2.0	0.0000000000	False
write down the log	0.0	0.0	0.0	4.0	0.0000000000	False
log like we heard	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a gradient	0.0	0.0	0.0	2.0	0.0000000000	False
ascent interval for finding	0.0	0.0	0.0	2.0	0.0000000000	False
finding the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of the parameter	0.0	0.0	0.0	4.0	0.0000000000	False
last time i wrote	0.0	0.0	0.0	4.0	0.0000000000	False
wrote down the learning	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down gradient ascent	0.0	0.0	0.0	2.0	0.0000000000	False
favor a logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
meaning find the value	0.0	0.0	0.0	2.0	0.0000000000	False
maximizes this log likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
gradient ascent or gradient	0.0	0.0	0.0	2.0	0.0000000000	False
ascent or gradient ascent	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for fitting models	0.0	0.0	0.0	2.0	0.0000000000	False
faster than gradient ascent	0.0	0.0	0.0	2.0	0.0000000000	False
ascent and this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm is called newton	0.0	0.0	0.0	2.0	0.0000000000	False
describe newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
function f of theta	0.0	0.0	0.0	2.0	0.0000000000	False
sort of slowly change	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for fitting mass	0.0	0.0	0.0	2.0	0.0000000000	False
fitting mass and likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
mass and likelihood models	0.0	0.0	0.0	2.0	0.0000000000	False
axis of of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta as some value	0.0	0.0	0.0	2.0	0.0000000000	False
value we ll call	0.0	0.0	0.0	0.0	0.0000000000	False
ll call theta superscript	0.0	0.0	0.0	2.0	0.0000000000	False
method does we re	0.0	0.0	0.0	0.0	0.0000000000	False
re going to evaluate	0.0	0.0	0.0	2.0	0.0000000000	False
ll use the linear	0.0	0.0	0.0	2.0	0.0000000000	False
consummation to the function	0.0	0.0	0.0	2.0	0.0000000000	False
tangents to my function	0.0	0.0	0.0	4.0	0.0000000000	False
hope that makes sense	0.0	0.0	0.0	2.0	0.0000000000	False
makes sense  starting	0.0	0.0	0.0	2.0	0.0000000000	False
starting the function work	0.0	0.0	0.0	2.0	0.0000000000	False
function work out nicely	0.0	0.0	0.0	2.0	0.0000000000	False
function at that point	0.0	0.0	0.0	2.0	0.0000000000	False
intercepts the horizontal axis	0.0	0.0	0.0	2.0	0.0000000000	False
thing with the dec	0.0	0.0	0.0	2.0	0.0000000000	False
point take the tangent	0.0	0.0	0.0	2.0	0.0000000000	False
iterations of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
theta zero to theta	0.0	0.0	0.0	2.0	0.0000000000	False
call that capital delta	0.0	0.0	0.0	2.0	0.0000000000	False
capital delta so capital	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of f evaluated	0.0	0.0	0.0	2.0	0.0000000000	False
horizontal length a gradient	0.0	0.0	0.0	2.0	0.0000000000	False
slope of this function	0.0	0.0	0.0	2.0	0.0000000000	False
defined as the ratio	0.0	0.0	0.0	2.0	0.0000000000	False
height and this width	0.0	0.0	0.0	2.0	0.0000000000	False
theta zero minus delta	0.0	0.0	0.0	2.0	0.0000000000	False
newton s method precedes	0.0	0.0	0.0	0.0	0.0000000000	False
equals theta t minus	0.0	0.0	0.0	4.0	0.0000000000	False
minus f of theta	0.0	0.0	0.0	2.0	0.0000000000	False
apply the same idea	0.0	0.0	0.0	4.0	0.0000000000	False
maximizing the log likelihood	0.0	0.0	0.0	4.0	0.0000000000	False
function l of theta	0.0	0.0	0.0	2.0	0.0000000000	False
function ? you set	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of the function	0.0	0.0	0.0	2.0	0.0000000000	False
theta one equals theta	0.0	0.0	0.0	2.0	0.0000000000	False
double prime of theta	0.0	0.0	0.0	2.0	0.0000000000	False
equal to l prime	0.0	0.0	0.0	2.0	0.0000000000	False
optimum does this make	0.0	0.0	0.0	2.0	0.0000000000	False
sense ? any questions	0.0	0.0	0.0	2.0	0.0000000000	False
complicated there are conditions	0.0	0.0	0.0	2.0	0.0000000000	False
models i ll talk	0.0	0.0	0.0	0.0	0.0000000000	False
matter when i implement	0.0	0.0	0.0	2.0	0.0000000000	False
back to all zeros	0.0	0.0	0.0	2.0	0.0000000000	False
deal how you initialize	0.0	0.0	0.0	2.0	0.0000000000	False
ll sort of answer	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms will generally converge	0.0	0.0	0.0	2.0	0.0000000000	False
large a linear rate	0.0	0.0	0.0	2.0	0.0000000000	False
linear rate for gradient	0.0	0.0	0.0	2.0	0.0000000000	False
rate for gradient ascent	0.0	0.0	0.0	2.0	0.0000000000	False
conversions of these algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
turns out that newton	0.0	0.0	0.0	2.0	0.0000000000	False
method is an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
enjoys extremely fast conversions	0.0	0.0	0.0	2.0	0.0000000000	False
conversions the technical term	0.0	0.0	0.0	2.0	0.0000000000	False
means that every iteration	0.0	0.0	0.0	2.0	0.0000000000	False
number of significant digits	0.0	0.0	0.0	2.0	0.0000000000	False
digits that your solution	0.0	0.0	0.0	2.0	0.0000000000	False
accurate to just lots	0.0	0.0	0.0	2.0	0.0000000000	False
lots of constant factors	0.0	0.0	0.0	2.0	0.0000000000	False
essentially get to square	0.0	0.0	0.0	2.0	0.0000000000	False
error on every iteration	0.0	0.0	0.0	2.0	0.0000000000	False
newton s method result	0.0	0.0	0.0	0.0	0.0000000000	False
method result that holds	0.0	0.0	0.0	2.0	0.0000000000	False
accurate but the fact	0.0	0.0	0.0	2.0	0.0000000000	False
implement newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
method for logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
converges like a dozen	0.0	0.0	0.0	2.0	0.0000000000	False
size problems of tens	0.0	0.0	0.0	2.0	0.0000000000	False
features so one thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing i should talk	0.0	0.0	0.0	2.0	0.0000000000	False
method for the case	0.0	0.0	0.0	2.0	0.0000000000	False
single-row number the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
method for when theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta is a vector	0.0	0.0	0.0	2.0	0.0000000000	False
gradient of your objective	0.0	0.0	0.0	2.0	0.0000000000	False
derivative where hij equals	0.0	0.0	0.0	2.0	0.0000000000	False
vector of first derivatives	0.0	0.0	0.0	2.0	0.0000000000	False
first derivatives times sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of the inverse	0.0	0.0	0.0	2.0	0.0000000000	False
inverse of the matrix	0.0	0.0	0.0	2.0	0.0000000000	False
matrix of second derivatives	0.0	0.0	0.0	4.0	0.0000000000	False
thing of multiple dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
reasonable number of features	0.0	0.0	0.0	4.0	0.0000000000	False
features and training examples	0.0	0.0	0.0	2.0	0.0000000000	False
conversion anywhere from sort	0.0	0.0	0.0	2.0	0.0000000000	False
compare to gradient ascent	0.0	0.0	0.0	4.0	0.0000000000	False
means far fewer iterations	0.0	0.0	0.0	2.0	0.0000000000	False
fewer iterations to converge	0.0	0.0	0.0	2.0	0.0000000000	False
iterations to converge compared	0.0	0.0	0.0	2.0	0.0000000000	False
converge compared to gradient	0.0	0.0	0.0	2.0	0.0000000000	False
large number of features	0.0	0.0	0.0	2.0	0.0000000000	False
features in your learning	0.0	0.0	0.0	2.0	0.0000000000	False
slightly computationally expensive step	0.0	0.0	0.0	2.0	0.0000000000	False
minus thank you problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem also i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
parameters for logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
wanted to use newton	0.0	0.0	0.0	2.0	0.0000000000	False
change ? all right	0.0	0.0	0.0	2.0	0.0000000000	False
change i ll leave	0.0	0.0	0.0	0.0	0.0000000000	False
leave you to work	0.0	0.0	0.0	4.0	0.0000000000	False
right let s talk	0.0	0.0	0.0	0.0	0.0000000000	False
talk about generalized linear	0.0	0.0	0.0	4.0	0.0000000000	False
algorithms we ve talked	0.0	0.0	0.0	0.0	0.0000000000	False
algorithms for modeling pfy	0.0	0.0	0.0	2.0	0.0000000000	False
natural distribution of zeros	0.0	0.0	0.0	2.0	0.0000000000	False
distribution models random variables	0.0	0.0	0.0	2.0	0.0000000000	False
variables with two values	0.0	0.0	0.0	2.0	0.0000000000	False
functions i could ve	0.0	0.0	0.0	0.0	0.0000000000	False
default choice that lead	0.0	0.0	0.0	2.0	0.0000000000	False
longer piece of chalk	0.0	0.0	0.0	2.0	0.0000000000	False
chalk i should warn	0.0	0.0	0.0	2.0	0.0000000000	False
ideas in generalized linear	0.0	0.0	0.0	2.0	0.0000000000	False
point you  point	0.0	0.0	0.0	2.0	0.0000000000	False
out the key ideas	0.0	0.0	0.0	2.0	0.0000000000	False
key ideas and give	0.0	0.0	0.0	2.0	0.0000000000	False
give you a gist	0.0	0.0	0.0	2.0	0.0000000000	False
details in the map	0.0	0.0	0.0	2.0	0.0000000000	False
map and the derivations	0.0	0.0	0.0	2.0	0.0000000000	False
derivations i ll leave	0.0	0.0	0.0	0.0	0.0000000000	False
suppose we have data	0.0	0.0	0.0	2.0	0.0000000000	False
variable parameterized by phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi so the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution has the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability of y equals	0.0	0.0	0.0	4.0	0.0000000000	False
right so the parameter	0.0	0.0	0.0	2.0	0.0000000000	False
phi in the specifies	0.0	0.0	0.0	2.0	0.0000000000	False
vary the parameter theta	0.0	0.0	0.0	2.0	0.0000000000	False
distributions as you vary	0.0	0.0	0.0	2.0	0.0000000000	False
ll say the cost	0.0	0.0	0.0	2.0	0.0000000000	False
ll say a bit	0.0	0.0	0.0	2.0	0.0000000000	False
parameter of the distribution	0.0	0.0	0.0	4.0	0.0000000000	False
choice of these functions	0.0	0.0	0.0	2.0	0.0000000000	False
re gon na sort	0.0	0.0	0.0	2.0	0.0000000000	False
forms of the functions	0.0	0.0	0.0	2.0	0.0000000000	False
write down specific formulas	0.0	0.0	0.0	2.0	0.0000000000	False
gaussians are special cases	0.0	0.0	0.0	2.0	0.0000000000	False
cases of exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
formula of the distributions	0.0	0.0	0.0	2.0	0.0000000000	False
distributions with different means	0.0	0.0	0.0	4.0	0.0000000000	False
ll get gaussian distributions	0.0	0.0	0.0	2.0	0.0000000000	False
means for my fixed	0.0	0.0	0.0	2.0	0.0000000000	False
sufficient statistic and statistics	0.0	0.0	0.0	2.0	0.0000000000	False
formal sense of sufficient	0.0	0.0	0.0	2.0	0.0000000000	False
statistic for a probability	0.0	0.0	0.0	2.0	0.0000000000	False
worry about we sort	0.0	0.0	0.0	2.0	0.0000000000	False
nt need that property	0.0	0.0	0.0	0.0	0.0000000000	False
parameter of this distribution	0.0	0.0	0.0	2.0	0.0000000000	False
product of raw numbers	0.0	0.0	0.0	2.0	0.0000000000	False
examples of exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
distributions we ll start	0.0	0.0	0.0	0.0	0.0000000000	False
equals one by phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi so the parameter	0.0	0.0	0.0	2.0	0.0000000000	False
parameter of phi specifies	0.0	0.0	0.0	2.0	0.0000000000	False
phi specifies the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability that y equals	0.0	0.0	5.99732477261	10.0	0.3255425710	False
identical to my formula	0.0	0.0	0.0	2.0	0.0000000000	False
formula for the distribution	0.0	0.0	0.0	4.0	0.0000000000	False
probability of y parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
notation where we talked	0.0	0.0	0.0	2.0	0.0000000000	False
talked about logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression the probability	0.0	0.0	0.0	2.0	0.0000000000	False
times one minus phi	0.0	0.0	0.0	2.0	0.0000000000	False
exponent of the log	0.0	0.0	0.0	2.0	0.0000000000	False
exponentiation in taking log	0.0	0.0	0.0	2.0	0.0000000000	False
cancel each other out	0.0	0.0	0.0	2.0	0.0000000000	False
make sure it makes	0.0	0.0	0.0	2.0	0.0000000000	False
sense i ll clean	0.0	0.0	0.0	0.0	0.0000000000	False
ll clean another board	0.0	0.0	0.0	2.0	0.0000000000	False
four equal to log	0.0	0.0	0.0	2.0	0.0000000000	False
equal to log phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi over one minus	0.0	0.0	0.0	2.0	0.0000000000	False
theta as a function	0.0	0.0	0.0	2.0	0.0000000000	False
logistic function magically falls	0.0	0.0	0.0	2.0	0.0000000000	False
definitions from the board	0.0	0.0	0.0	2.0	0.0000000000	False
log of one minus	0.0	0.0	0.0	2.0	0.0000000000	False
phi and are function	0.0	0.0	0.0	2.0	0.0000000000	False
plug in this definition	0.0	0.0	0.0	4.0	0.0000000000	False
recap what we ve	0.0	0.0	0.0	0.0	0.0000000000	False
function of the distribution	0.0	0.0	0.0	4.0	0.0000000000	False
expand this term out	0.0	0.0	0.0	2.0	0.0000000000	False
minus y times log	0.0	0.0	2.99839486356	6.0	0.0000000000	False
times log y minus	0.0	0.0	0.0	4.0	0.0000000000	False
log y minus phi	0.0	0.0	0.0	4.0	0.0000000000	False
log  one minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus of a log	0.0	0.0	0.0	2.0	0.0000000000	False
times log one minus	0.0	0.0	0.0	2.0	0.0000000000	False
log one minus phi	0.0	0.0	0.0	2.0	0.0000000000	False
minus phi becomes sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of y times	0.0	0.0	0.0	2.0	0.0000000000	False
phi does that make	0.0	0.0	0.0	2.0	0.0000000000	False
times a real number	0.0	0.0	0.0	2.0	0.0000000000	False
one-dimensional vector transposed times	0.0	0.0	0.0	2.0	0.0000000000	False
times a one-dimensional vector	0.0	0.0	0.0	2.0	0.0000000000	False
number times real number	0.0	0.0	0.0	2.0	0.0000000000	False
number towards the end	0.0	0.0	0.0	2.0	0.0000000000	False
out to be scalers	0.0	0.0	0.0	2.0	0.0000000000	False
imagine that we re	0.0	0.0	0.0	0.0	0.0000000000	False
re restricting the domain	0.0	0.0	0.0	2.0	0.0000000000	False
domain of the input	0.0	0.0	0.0	2.0	0.0000000000	False
input of the function	0.0	0.0	0.0	2.0	0.0000000000	False
function for y equals	0.0	0.0	0.0	2.0	0.0000000000	False
write down y equals	0.0	0.0	0.0	2.0	0.0000000000	False
cool so this takes	0.0	0.0	0.0	2.0	0.0000000000	False
invites in the form	0.0	0.0	0.0	2.0	0.0000000000	False
quickly for the gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
nt do the algebra	0.0	0.0	0.0	0.0	0.0000000000	False
algebra for the gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
basically just write out	0.0	0.0	0.0	2.0	0.0000000000	False
write out the answers	0.0	0.0	0.0	2.0	0.0000000000	False
normal distribution with sequence	0.0	0.0	0.0	2.0	0.0000000000	False
distribution with sequence squared	0.0	0.0	0.0	2.0	0.0000000000	False
dividing the maximum likelihood	0.0	0.0	0.0	4.0	0.0000000000	False
maximum likelihood  excuse	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of ordinary squares	0.0	0.0	0.0	2.0	0.0000000000	False
ordinary squares we showed	0.0	0.0	0.0	2.0	0.0000000000	False
showed that the parameter	0.0	0.0	0.0	2.0	0.0000000000	False
squared did nt matter	0.0	0.0	0.0	0.0	0.0000000000	False
matter when we divide	0.0	0.0	0.0	2.0	0.0000000000	False
value of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
purposes of just writing	0.0	0.0	0.0	2.0	0.0000000000	False
worry about it lecture	0.0	0.0	0.0	2.0	0.0000000000	False
talks a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
class a bit easier	0.0	0.0	0.0	2.0	0.0000000000	False
bit easier and simpler	0.0	0.0	0.0	2.0	0.0000000000	False
easier and simpler today	0.0	0.0	0.0	2.0	0.0000000000	False
square equals one square	0.0	0.0	0.0	2.0	0.0000000000	False
essentially just a scaling	0.0	0.0	0.0	2.0	0.0000000000	False
minus one-half y squared	0.0	0.0	0.0	2.0	0.0000000000	False
one-half y squared times	0.0	0.0	0.0	2.0	0.0000000000	False
equal to minus one-half	0.0	0.0	0.0	2.0	0.0000000000	False
excuse me plus sign	0.0	0.0	0.0	2.0	0.0000000000	False
expresses the gaussian density	0.0	0.0	0.0	2.0	0.0000000000	False
density in the form	0.0	0.0	0.0	2.0	0.0000000000	False
exponential family distribution minus	0.0	0.0	0.0	2.0	0.0000000000	False
family distribution minus half	0.0	0.0	0.0	2.0	0.0000000000	False
right and so result	0.0	0.0	0.0	2.0	0.0000000000	False
written in the form	0.0	0.0	0.0	4.0	0.0000000000	False
normal distribution it turns	0.0	0.0	0.0	2.0	0.0000000000	False
generalization of gaussian random	0.0	0.0	0.0	2.0	0.0000000000	False
high dimension to vectors	0.0	0.0	0.0	2.0	0.0000000000	False
vectors the normal distribution	0.0	0.0	0.0	2.0	0.0000000000	False
exponential family it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
right so the models	0.0	0.0	0.0	2.0	0.0000000000	False
ll be coin tosses	0.0	0.0	0.0	2.0	0.0000000000	False
tosses with two outcomes	0.0	0.0	0.0	2.0	0.0000000000	False
two outcomes the models	0.0	0.0	0.0	2.0	0.0000000000	False
outcomes the models outcomes	0.0	0.0	0.0	2.0	0.0000000000	False
heard of the parson	0.0	0.0	0.0	2.0	0.0000000000	False
things like the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of radioactive decays	0.0	0.0	0.0	2.0	0.0000000000	False
decays in a sample	0.0	0.0	0.0	2.0	0.0000000000	False
customers to your website	0.0	0.0	0.0	2.0	0.0000000000	False
numbers of visitors arriving	0.0	0.0	0.0	2.0	0.0000000000	False
arriving in a store	0.0	0.0	0.0	2.0	0.0000000000	False
store the parson distribution	0.0	0.0	0.0	2.0	0.0000000000	False
exponential distributions are distributions	0.0	0.0	0.0	2.0	0.0000000000	False
numbers so they re	0.0	0.0	0.0	0.0	0.0000000000	False
standing at the bus	0.0	0.0	0.0	2.0	0.0000000000	False
wait for my bus	0.0	0.0	0.0	2.0	0.0000000000	False
model that with sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of gamma distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution or exponential families	0.0	0.0	0.0	2.0	0.0000000000	False
family even more distributions	0.0	0.0	0.0	2.0	0.0000000000	False
probability distributions over probability	0.0	0.0	0.0	2.0	0.0000000000	False
distributions over probability distributions	0.0	0.0	0.0	2.0	0.0000000000	False
distributions and also things	0.0	0.0	0.0	2.0	0.0000000000	False
things like the wisha	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over covariance matrices	0.0	0.0	0.0	2.0	0.0000000000	False
form of exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
set where he asks	0.0	0.0	0.0	2.0	0.0000000000	False
derive a generalized linear	0.0	0.0	0.0	4.0	0.0000000000	False
topic of having chosen	0.0	0.0	0.0	2.0	0.0000000000	False
chosen and exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
model ? so generalized	0.0	0.0	0.0	2.0	0.0000000000	False
models are often abbreviated	0.0	0.0	0.0	2.0	0.0000000000	False
choice of those functions	0.0	0.0	0.0	2.0	0.0000000000	False
exponential families with parameter	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to predict	0.0	0.0	0.0	4.0	0.0000000000	False
predict how many customers	0.0	0.0	0.0	2.0	0.0000000000	False
arrived at your website	0.0	0.0	0.0	4.0	0.0000000000	False
people  the number	0.0	0.0	0.0	2.0	0.0000000000	False
hits on your website	0.0	0.0	0.0	2.0	0.0000000000	False
website by parson distribution	0.0	0.0	0.0	2.0	0.0000000000	False
parson distribution since parson	0.0	0.0	0.0	2.0	0.0000000000	False
distribution since parson distribution	0.0	0.0	0.0	2.0	0.0000000000	False
choose the exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to output	0.0	0.0	0.0	2.0	0.0000000000	False
output the effective value	0.0	0.0	0.0	2.0	0.0000000000	False
features in the website	0.0	0.0	0.0	2.0	0.0000000000	False
ve given a set	0.0	0.0	0.0	2.0	0.0000000000	False
linked to your website	0.0	0.0	0.0	2.0	0.0000000000	False
assume that our goal	0.0	0.0	0.0	2.0	0.0000000000	False
goal in our problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem is to estimate	0.0	0.0	0.0	2.0	0.0000000000	False
estimate the expected number	0.0	0.0	0.0	2.0	0.0000000000	False
expected number of people	0.0	0.0	0.0	2.0	0.0000000000	False
people that will arrive	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms hypothesis to output	0.0	0.0	0.0	2.0	0.0000000000	False
output the expected value	0.0	0.0	0.0	4.0	0.0000000000	False
last one i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
choice which is assume	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
family with some parameter	0.0	0.0	0.0	2.0	0.0000000000	False
day will be parson	0.0	0.0	0.0	2.0	0.0000000000	False
parson or some parameter	0.0	0.0	0.0	2.0	0.0000000000	False
relationship between my input	0.0	0.0	0.0	2.0	0.0000000000	False
teachers and this parameter	0.0	0.0	0.0	2.0	0.0000000000	False
parameter parameterizing my parson	0.0	0.0	0.0	2.0	0.0000000000	False
parameterizing my parson distribution	0.0	0.0	0.0	2.0	0.0000000000	False
make this design choice	0.0	0.0	0.0	2.0	0.0000000000	False
linear model of machinery	0.0	0.0	0.0	2.0	0.0000000000	False
nice algorithms for fitting	0.0	0.0	0.0	2.0	0.0000000000	False
fitting say parson regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression models or performed	0.0	0.0	0.0	2.0	0.0000000000	False
models or performed regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression with a gamma	0.0	0.0	0.0	2.0	0.0000000000	False
outputs or exponential distribution	0.0	0.0	0.0	2.0	0.0000000000	False
theta transpose x works	0.0	0.0	0.0	2.0	0.0000000000	False
works for the case	0.0	0.0	0.0	2.0	0.0000000000	False
real number all right	0.0	0.0	0.0	2.0	0.0000000000	False
family with natural parameter	0.0	0.0	0.0	2.0	0.0000000000	False
first example we worked	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm will make	0.0	0.0	0.0	2.0	0.0000000000	False
make  will sort	0.0	0.0	0.0	2.0	0.0000000000	False
watch our learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to output	0.0	0.0	0.0	4.0	0.0000000000	False
equal to the probability	0.0	0.0	0.0	4.0	0.0000000000	False
parameter of my distribution	0.0	0.0	0.0	2.0	0.0000000000	False
probability of my distribution	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution in the form	0.0	0.0	0.0	2.0	0.0000000000	False
out what the relationship	0.0	0.0	0.0	2.0	0.0000000000	False
relationship was between phi	0.0	0.0	0.0	2.0	0.0000000000	False
worked out the relationship	0.0	0.0	0.0	2.0	0.0000000000	False
relationship between the expected	0.0	0.0	0.0	2.0	0.0000000000	False
made the design choice	0.0	0.0	0.0	2.0	0.0000000000	False
assumption that and theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta are linearly related	0.0	0.0	0.0	2.0	0.0000000000	False
variable y that takes	0.0	0.0	0.0	2.0	0.0000000000	False
takes on two values	0.0	0.0	0.0	4.0	0.0000000000	False
make sense ? raise	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	0.0	2.0	0.0000000000	False
cool so i hope	0.0	0.0	0.0	2.0	0.0000000000	False
sort of the power	0.0	0.0	0.0	2.0	0.0000000000	False
make is i chose	0.0	0.0	0.0	2.0	0.0000000000	False
assume y is distributed	0.0	0.0	0.0	2.0	0.0000000000	False
choose a different distribution	0.0	0.0	0.0	2.0	0.0000000000	False
choose y as parson	0.0	0.0	0.0	2.0	0.0000000000	False
follow a similar process	0.0	0.0	0.0	2.0	0.0000000000	False
model and different learning	0.0	0.0	0.0	2.0	0.0000000000	False
model for whatever learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm you re	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm you re faced	0.0	0.0	0.0	0.0	0.0000000000	False
faced with this tiny	0.0	0.0	0.0	2.0	0.0000000000	False
function g that relates	0.0	0.0	0.0	2.0	0.0000000000	False
relates the natural parameter	0.0	0.0	0.0	2.0	0.0000000000	False
parameter to the expected	0.0	0.0	0.0	2.0	0.0000000000	False
function and g inverse	0.0	0.0	0.0	2.0	0.0000000000	False
nt a huge deal	0.0	0.0	0.0	0.0	0.0000000000	False
nt use this terminology	0.0	0.0	0.0	0.0	0.0000000000	False
mentioning those in case	0.0	0.0	0.0	2.0	0.0000000000	False
hear about  people	0.0	0.0	0.0	2.0	0.0000000000	False
people talk about generalized	0.0	0.0	0.0	2.0	0.0000000000	False
talk about canonical response	0.0	0.0	0.0	2.0	0.0000000000	False
functions or canonical link	0.0	0.0	0.0	2.0	0.0000000000	False
consistent with other algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
nt use the terms	0.0	0.0	0.0	0.0	0.0000000000	False
terms canonical response functions	0.0	0.0	0.0	2.0	0.0000000000	False
functions and canonical link	0.0	0.0	0.0	2.0	0.0000000000	False
link functions in lecture	0.0	0.0	0.0	2.0	0.0000000000	False
big on memorizing lots	0.0	0.0	0.0	2.0	0.0000000000	False
memorizing lots of names	0.0	0.0	0.0	2.0	0.0000000000	False
out there in case	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian distribution and end	0.0	0.0	0.0	2.0	0.0000000000	False
squares model the problem	0.0	0.0	0.0	2.0	0.0000000000	False
confusing than the model	0.0	0.0	0.0	2.0	0.0000000000	False
skip that and leave	0.0	0.0	0.0	2.0	0.0000000000	False
leave you to read	0.0	0.0	0.0	4.0	0.0000000000	False
likelihood of your training	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the parameters	0.0	0.0	0.0	4.0	0.0000000000	False
parameters does that make	0.0	0.0	0.0	2.0	0.0000000000	False
theta is exactly maximum	0.0	0.0	0.0	2.0	0.0000000000	False
method or gradient ascent	0.0	0.0	0.0	2.0	0.0000000000	False
model that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
examples of generalized linear	0.0	0.0	0.0	2.0	0.0000000000	False
give you the gist	0.0	0.0	0.0	2.0	0.0000000000	False
skip or details omitted	0.0	0.0	0.0	2.0	0.0000000000	False
carefully in the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
outcomes imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
problem where the value	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to classify emails	0.0	0.0	0.0	2.0	0.0000000000	False
emails into or predicting	0.0	0.0	0.0	2.0	0.0000000000	False
predicting if the patient	0.0	0.0	0.0	2.0	0.0000000000	False
lots of multi-cause classification	0.0	0.0	0.0	2.0	0.0000000000	False
two causes you model	0.0	0.0	0.0	2.0	0.0000000000	False
set and you find	0.0	0.0	0.0	2.0	0.0000000000	False
find a decision boundary	0.0	0.0	0.0	2.0	0.0000000000	False
decision boundary that separates	0.0	0.0	0.0	2.0	0.0000000000	False
re going to entertain	0.0	0.0	0.0	2.0	0.0000000000	False
taking on multiple values	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm will learn	0.0	0.0	0.0	2.0	0.0000000000	False
write in the form	0.0	0.0	0.0	2.0	0.0000000000	False
distribution so the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
derive the last parameter	0.0	0.0	0.0	2.0	0.0000000000	False
nt think of phi	0.0	0.0	0.0	0.0	0.0000000000	False
rest of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
vector of all zeros	0.0	0.0	0.0	2.0	0.0000000000	False
good point to introduce	0.0	0.0	0.0	2.0	0.0000000000	False
write a true statement	0.0	0.0	0.0	2.0	0.0000000000	False
indicator of that statement	0.0	0.0	0.0	2.0	0.0000000000	False
write a false statement	0.0	0.0	0.0	2.0	0.0000000000	False
value of this indicator	0.0	0.0	0.0	2.0	0.0000000000	False
write indicator two equals	0.0	0.0	0.0	2.0	0.0000000000	False
indicator plus one equals	0.0	0.0	0.0	2.0	0.0000000000	False
indicator of the statement	0.0	0.0	0.0	2.0	0.0000000000	False
notation for indicating sort	0.0	0.0	0.0	2.0	0.0000000000	False
indicating sort of truth	0.0	0.0	0.0	2.0	0.0000000000	False
falsehood of the statement	0.0	0.0	0.0	2.0	0.0000000000	False
carve out a bit	0.0	0.0	0.0	2.0	0.0000000000	False
element of the vector	0.0	0.0	4.99732477261	10.0	0.2880354505	False
make sure you understand	0.0	0.0	0.0	4.0	0.0000000000	False
understand all that notation	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this equation	0.0	0.0	0.0	2.0	0.0000000000	False
equal to this vector	0.0	0.0	0.0	2.0	0.0000000000	False
element of this vector	0.0	0.0	2.99839486356	6.0	0.0000000000	False
rest of the elements	0.0	0.0	0.0	2.0	0.0000000000	False
write out the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
equals one times phi	0.0	0.0	0.0	4.0	0.0000000000	False
times phi two indicator	0.0	0.0	0.0	2.0	0.0000000000	False
two indicator y equals	0.0	0.0	0.0	2.0	0.0000000000	False
phi k times indicator	0.0	0.0	0.0	2.0	0.0000000000	False
times indicator y equals	0.0	0.0	0.0	2.0	0.0000000000	False
shorthand for one minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus phi one minus	0.0	0.0	0.0	2.0	0.0000000000	False
phi one minus phi	0.0	0.0	0.0	2.0	0.0000000000	False
minus phi two minus	0.0	0.0	0.0	2.0	0.0000000000	False
two minus the rest	0.0	0.0	0.0	2.0	0.0000000000	False
equation on the left	0.0	0.0	0.0	2.0	0.0000000000	False
write this as phi	0.0	0.0	0.0	2.0	0.0000000000	False
dot phi k minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one times phi	0.0	0.0	0.0	2.0	0.0000000000	False
out  it takes	0.0	0.0	0.0	2.0	0.0000000000	False
out in a form	0.0	0.0	0.0	2.0	0.0000000000	False
family distribution it turns	0.0	0.0	0.0	2.0	0.0000000000	False
inverted that to write	0.0	0.0	0.0	2.0	0.0000000000	False
phi as a function	0.0	0.0	0.0	4.0	0.0000000000	False
defines as a function	0.0	0.0	0.0	4.0	0.0000000000	False
relationship between and phi	0.0	0.0	0.0	2.0	0.0000000000	False
equal to  excuse	0.0	0.0	0.0	2.0	0.0000000000	False
function of the phi	0.0	0.0	0.0	2.0	0.0000000000	False
function of the axis	0.0	0.0	0.0	2.0	0.0000000000	False
sum over j equals	0.0	0.0	0.0	2.0	0.0000000000	False
fact that i equals	0.0	0.0	0.0	2.0	0.0000000000	False
choice from generalized linear	0.0	0.0	0.0	2.0	0.0000000000	False
models so we re	0.0	0.0	0.0	0.0	0.0000000000	False
minus one all right	0.0	0.0	0.0	2.0	0.0000000000	False
value of this vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector of indicator functions	0.0	0.0	0.0	2.0	0.0000000000	False
indicator functions the expected	0.0	0.0	0.0	2.0	0.0000000000	False
functions the expected value	0.0	0.0	0.0	2.0	0.0000000000	False
expected value of indicator	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm will output	0.0	0.0	0.0	2.0	0.0000000000	False
parameterized by these functions	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm is called softmax	0.0	0.0	0.0	2.0	0.0000000000	False
generalization of logistic regression	0.0	0.0	0.0	4.0	0.0000000000	False
regression of two classes	0.0	0.0	0.0	2.0	0.0000000000	False
classes is widely thought	0.0	0.0	0.0	2.0	0.0000000000	False
regression to the case	0.0	0.0	0.0	2.0	0.0000000000	False
case of k classes	0.0	0.0	0.0	2.0	0.0000000000	False
family then you sort	0.0	0.0	0.0	2.0	0.0000000000	False
choice of using distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution as your choice	0.0	0.0	0.0	2.0	0.0000000000	False
choice of exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
re doing the training	0.0	0.0	0.0	2.0	0.0000000000	False
training set we re	0.0	0.0	0.0	0.0	0.0000000000	False
re now the value	0.0	0.0	0.0	2.0	0.0000000000	False
value of y takes	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the model	0.0	0.0	0.0	2.0	0.0000000000	False
model by maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood so you write	0.0	0.0	0.0	2.0	0.0000000000	False
write down the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
product of your training	0.0	0.0	0.0	4.0	0.0000000000	False
phi two of indicator	0.0	0.0	0.0	2.0	0.0000000000	False
phi k of indicator	0.0	0.0	0.0	2.0	0.0000000000	False
theta through this formula	0.0	0.0	0.0	2.0	0.0000000000	False
shorthand for this formula	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of this formula	0.0	0.0	0.0	2.0	0.0000000000	False
apply say gradient ascent	0.0	0.0	0.0	2.0	0.0000000000	False
gradient ascent to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
theta one through theta	0.0	0.0	0.0	2.0	0.0000000000	False
minus one i ve	0.0	0.0	0.0	0.0	0.0000000000	False
set of parameters comprising	0.0	0.0	0.0	2.0	0.0000000000	False
parameters comprising k minus	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of k minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one parameter vectors	0.0	0.0	0.0	2.0	0.0000000000	False
answer that as sort	0.0	0.0	0.0	2.0	0.0000000000	False
feature  yeah sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of similar interpretation	0.0	0.0	0.0	2.0	0.0000000000	False
running a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
close for the day	0.0	0.0	0.0	2.0	0.0000000000	False
jump into today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s technical	0.0	0.0	0.0	0.0	0.0000000000	False
website a handout	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
sort of guidelines	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
guidelines and suggestions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
suggestions for choosing	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choosing and proposing	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
proposing class projects	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
projects so project	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
due on friday	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
month at noon	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
nt yet formed	0.0	0.0	0.0	0.0	0.0000000000	False
teams or started	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
thinking about project	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ideas of projects	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hours on friday	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
list of project	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of collected	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
senior phd students	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phd students working	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
ideas in topics	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
control so ideas	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
variety of topics	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
re having trouble	0.0	0.0	0.0	0.0	0.0000000000	False
class i mentioned	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
fun and educational	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ll also email	0.0	0.0	0.0	1.58496250072	0.0000000000	False
email everyone registered	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
details about applying	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
submit problem set	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
days for problem	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
select is based	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
based on problem	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
set one solutions	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
today is talk	0.000764797142814	0.0	0.0	1.58496250072	0.0000000000	False
methods for fitting	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
models like logistic	0.00171867221692	0.0	0.0	0.0	0.0000000000	False
talk about exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
exponential family distributions	0.0168738820455	1.0	17.9909042269	25.3594000115	0.0000000000	True
distributions and generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
generalized linear models	0.0129035568583	1.0	7.9925093633	22.1894750101	0.3734610123	True
class of ideas	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ordinary v squares	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
increasingly large amounts	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
amounts of material	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
material on probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
refresher on sort	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
foundations of probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
class in terms	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
background in probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
probability and statistics	0.00198516259359	0.0	0.0	3.16992500144	0.0000000000	False
discussion section taught	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
taught this week	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
review a probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sort of octave	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
section all right	0.0	0.0	0.0	0.0	0.0000000000	False
lecture i talked	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
logistic regression model	0.00305918857126	0.0	2.99785981808	6.33985000288	0.0000000000	False
taking the riveters	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
gradient ascent interval	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
interval for finding	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
finding the maximum	0.00138293404816	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood estimate	0.00126310390896	0.0	0.0	3.16992500144	0.0000000000	False
wrote down gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
favor a logistic	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
find the value	0.0	0.0	4.99785981808	4.75488750216	0.4171122995	False
value of theta	0.0	0.0	10.9957196362	12.6797000058	0.4180704441	False
theta that maximizes	0.00171867221692	0.0	0.0	3.16992500144	0.0000000000	False
maximizes this log	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
ascent or gradient	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
perfectly fine algorithm	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for fitting	0.00297774389038	0.0	2.99839486356	3.16992500144	0.0000000000	False
run much faster	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
faster than gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
theta is equal	0.00343734443383	0.0	5.99785981808	6.33985000288	0.5270270270	False
mass and likelihood	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
guess that works	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
find this value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value for theta	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll call theta	0.0	0.0	0.0	0.0	0.0000000000	False
call theta superscript	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
evaluate the function	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
function  hope	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hope that makes	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sense  starting	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
starting the function	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
work out nicely	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of extend	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
extend this tangent	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
intercepts the horizontal	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
call this theta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
iteration of newton	0.0	0.0	7.99732477261	7.92481250361	0.5342465753	False
call that length	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
call that capital	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
delta so capital	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
remember the definition	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
evaluated at theta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
definition of gradient	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
length a gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
function is defined	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
width of triangle	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
divided by delta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
implies that delta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
delta is equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
prime of theta	0.00732219270464	0.0	11.9967897271	7.92481250361	0.2600000000	False
theta zero minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus capital delta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
theta t minus	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
theta t divided	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for finding	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
finding a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea to maximizing	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the log	0.00171867221692	0.0	0.0	0.0	0.0000000000	False
ant to maximize	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
maximize this function	0.00229439142844	0.0	5.99839486356	4.75488750216	0.0000000000	False
maximize the function	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set the derivative	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
find the place	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
function is equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
theta one equals	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus l prime	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sort of generalizing	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
generalizing any models	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
initialize the parameters	0.000764797142814	0.0	0.0	1.58496250072	0.0000000000	False
sort of answer	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
choose too large	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
large a linear	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
rate for gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
speeds of conversions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
out that newton	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm that enjoys	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
extremely fast conversions	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
conversions the technical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
enjoys a property	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
property called conversions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method will double	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
double the number	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number of significant	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
solution is accurate	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
lots of constant	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
constant factors suppose	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
iteration your solution	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
square the error	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
result that holds	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
slightly rosier picture	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method for logistic	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
reasonable size problems	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
problems of tens	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
tens of hundreds	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hundreds of features	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
case of theta	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number the generalization	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
generalization to newton	0.0	0.0	0.0	1.58496250072	0.0000000000	False
first derivative divided	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
derivative where hij	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vector of first	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
first derivatives times	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
derivatives times sort	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
thing of multiple	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number of features	0.00252620781791	0.0	3.99785981808	4.75488750216	0.0000000000	False
features and training	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
run this algorithm	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
compare to gradient	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
means far fewer	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
iterations to converge	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
disadvantage of newton	0.0	0.0	0.0	1.58496250072	0.0000000000	False
invert the hessian	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
tens of thousands	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
thousands of features	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
slightly computationally expensive	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
computationally expensive step	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm to find	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
maximum likely estimate	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
parameters for logistic	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
regression i wrote	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
maximizing a function	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method to minimize	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
minimize the function	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
talk about generalized	0.00152959428563	0.0	0.0	1.58496250072	0.0000000000	False
give a recap	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
two different algorithms	0.0	0.0	0.0	1.58496250072	0.0000000000	False
algorithms for modeling	0.000764797142814	0.0	0.0	0.0	0.0000000000	False
parameterized by theta	0.0060153527592	0.0	2.99625468165	11.094737505	0.5342465753	False
distribution of zeros	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution models random	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
models random variables	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
natural default choice	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice that lead	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithms and show	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithms called generalized	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
function will fall	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
piece of chalk	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ideas in generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of point	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
out the key	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
ideas and give	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parameterized by phi	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
equals the phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
specifies the probability	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
vary the parameter	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
vary the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set to distributions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
cost of distributions	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
nt be true	0.0	0.0	0.0	0.0	0.0000000000	False
sort of fix	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
fix the forms	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
set of distributions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distributions it defines	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
write down specific	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
true specific choices	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
gaussians are special	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
cases of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
choose specific functions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ll get gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
statistic and statistics	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sense of sufficient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
product of raw	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
first two examples	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ll do today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian are examples	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
examples of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
guess i wrote	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.00229439142844	0.0	1.99839486356	4.75488750216	0.0000000000	False
parameter of phi	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
family becomes identical	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
phi is equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
similar exponential notation	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
talked about logistic	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
regression the probability	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
compactly as phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
times one minus	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
exponentiation in taking	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
taking log cancel	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
clean another board	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
things just copying	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to log	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
solve for phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
phi  excuse	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
solve for theta	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
function of phi	0.00297774389038	0.0	1.99839486356	4.75488750216	0.0000000000	False
phi just invert	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
invert this formula	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
formula you find	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
find that phi	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
function magically falls	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
right so depends	0.0	0.0	0.0	1.58496250072	0.0000000000	False
depends on phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
definition for phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
complete  excuse	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
complete the rest	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice of functions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
probability mass function	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
expand this term	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus y times	0.00366109635232	0.0	2.99839486356	0.0	0.0000000000	False
log y minus	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
term is minus	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
log is log	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
log one minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi becomes sort	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
real number times	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
times a real	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
one-dimensional vector transposed	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vector transposed times	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
times a one-dimensional	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number times real	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
times real number	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
end of today	0.0	0.0	3.99839486356	4.75488750216	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
restricting the domain	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
takes the distribution	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distribution and invites	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
basically just write	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
out the answers	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution with sequence	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
dividing the maximum	0.00198516259359	0.0	0.0	0.0	0.0000000000	False
likelihood  excuse	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parameters of ordinary	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
squares we showed	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parameter for squared	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
divide the model	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
model for square	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
matter what square	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
taking account squared	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
make in class	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
class a bit	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
easier and simpler	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
equals one square	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
couple of steps	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
steps of algebra	0.00488146180309	0.0	3.99785981808	6.33985000288	0.4171122995	False
root two pie	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
one-half y squared	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus one-half squared	0.00366109635232	0.0	2.99839486356	4.75488750216	0.0000000000	False
equal to minus	0.000691467024078	0.0	0.0	0.0	0.0000000000	False
expresses the gaussian	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
family distribution minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution minus half	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
undergrad statistics class	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distribution it turns	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
generalization of gaussian	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
gaussian random variables	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
dimension to vectors	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vectors the normal	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
family it turns	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
out the distribution	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
ll be coin	0.0	0.0	0.0	0.0	0.0000000000	False
outcomes the models	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
modeling counts things	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number of radioactive	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number of customers	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
numbers of visitors	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
store the parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distributions are distributions	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
bus to arrive	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of gamma	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution or exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distributions over fractions	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distributions over probability	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution over covariance	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
form of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distributions and write	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
derive a generalized	0.00198516259359	0.0	0.0	0.0	0.0000000000	False
chosen and exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of turn	0.00198516259359	0.0	0.0	3.16992500144	0.0000000000	False
turn a crank	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
predict is distributed	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distributed exponential family	0.00366109635232	0.0	3.99839486356	4.75488750216	0.0000000000	False
families with parameter	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
customers have arrived	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choose to model	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
model the number	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
number of people	0.00198516259359	0.0	0.0	1.58496250072	0.0000000000	False
number of hits	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
website by parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution since parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
distribution is natural	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
natural for modeling	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
modeling com data	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choose the exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
output the effective	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
set of features	0.000580894484932	0.0	0.0	1.58496250072	0.0000000000	False
estimate the expected	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
meant to write	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
learning algorithms hypothesis	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis to output	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
output the expected	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
learning algorithms output	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
assumptions this last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
parameterizing my parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
make the assumption	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
assume the relationship	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to theta	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
reason i make	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
make this design	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
turn the crank	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
model of machinery	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
fitting say parson	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
parson regression models	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
models or performed	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
gamma distribution outputs	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
outputs or exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
exponential distribution outputs	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equals theta transpose	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
transpose x works	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
number all right	0.0	0.0	0.0	0.0	0.0000000000	False
family with natural	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
algorithm will make	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.000631551954478	0.0	0.0	1.58496250072	0.0000000000	False
sort of output	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
watch our learning	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm to output	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
out the relationship	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
made the design	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
logistic regression algorithm	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
model variable distribution	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sense ? raise	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.000864723492544	0.0	0.0	3.16992500144	0.0000000000	False
decision i made	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
predict the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
automatically having made	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
made the decision	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
decision to model	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
follow a similar	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm you re	0.0	0.0	0.0	0.0	0.0000000000	False
tiny little notation	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
relates the natural	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
canonical response function	0.00366109635232	1.0	2.99839486356	3.16992500144	0.0000000000	False
canonical link function	0.00366109635232	0.0	2.99839486356	4.75488750216	0.0000000000	True
nt a huge	0.0	0.0	0.0	0.0	0.0000000000	False
terminology a lot	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
case you hear	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
talk about canonical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions or canonical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithms in machine	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
terms canonical response	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions and canonical	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions in lecture	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
lecture a lot	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
big on memorizing	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
lots of names	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
names of things	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
distribution and end	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ordinary squares model	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
model the problem	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
problem with gaussian	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
complex example question	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose what theory	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
model that assumes	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
assumes the probability	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
method or gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
examples of generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
quickly and give	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
steps i skip	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
skip or details	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
magically send emails	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
right email folder	0.0	0.0	0.0	1.58496250072	0.0000000000	False
dozen email folders	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to classify	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
learning algorithm figure	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
diseases your patient	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
lots of multi-cause	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
multi-cause classification problems	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	True
find a decision	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
boundary that separates	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
entertain the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of predicting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
taking on multiple	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
algorithm will learn	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi two phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ll actually change	0.0	0.0	0.0	1.58496250072	0.0000000000	False
derive the last	0.0	0.0	0.0	0.0	0.0000000000	False
phi k minus	0.00366109635232	0.0	3.99839486356	3.16992500144	0.0000000000	False
result is over-parameterized	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
treat my parameters	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
minus one parameters	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
minus the rest	0.00244073090155	0.0	0.0	1.58496250072	0.0000000000	False
minus one-dimensional vectors	0.00366109635232	0.0	1.99839486356	4.75488750216	0.0000000000	False
choosing to define	0.0	0.0	0.0	1.58496250072	0.0000000000	False
point to introduce	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
piece of notation	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
indicator function notation	0.00122036545077	1.0	0.0	1.58496250072	0.0000000000	False
write a true	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
true statement inside	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
write a false	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
false statement inside	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
indicator two equals	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
statement was equal	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
notation for indicating	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
sort of truth	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
truth or falsehood	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
out a bit	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
bit of space	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
denote the element	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equal to indicator	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
clean a couple	0.000859336108458	0.0	0.0	1.58496250072	0.0000000000	False
couple more boards	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
true all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
equation makes sense	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
exponential family form	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
form so pfy	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
pfy is equal	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
phi one indicator	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
indicator y equals	0.00854255815542	0.0	10.9962546816	9.50977500433	0.2276897415	False
equals one times	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
times phi two	0.0	0.0	0.0	1.58496250072	0.0000000000	False
phi two indicator	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi k times	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi one minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi two minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
phi one times	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
minus one times	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
show it turns	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
write out phi	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
distributions parameters phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
phi and invert	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
earlier design choice	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice from generalized	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
vector indicator function	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
equals k minus	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
vector of indicator	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
functions the expected	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
value of indicator	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm will output	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
output the probability	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
give this algorithm	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
generalization of logistic	0.00244073090155	0.0	0.0	0.0	0.0000000000	False
apply softmax regression	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
wan na model	0.0	0.0	0.0	1.58496250072	0.0000000000	False
made the choice	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
choice of exponential	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
set we re	0.0	0.0	0.0	0.0	0.0000000000	False
find the parameters	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
model by maximum	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
maximize the likelihood	0.00171867221692	0.0	0.0	3.16992500144	0.0000000000	False
two of indicator	0.0	0.0	0.0	0.0	0.0000000000	False
indicator yi equals	0.00244073090155	0.0	0.0	3.16992500144	0.0000000000	False
phi one depends	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
depends on theta	0.000992581296794	0.0	0.0	1.58496250072	0.0000000000	False
similarly for phi	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
things all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
compute a derivative	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
apply say gradient	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
ascent to maximize	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
rows of theta	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta k minus	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
ve been thinking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.000631551954478	0.0	0.0	0.0	0.0000000000	False
comprising k minus	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
minus one vectors	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
hard to answer	0.00122036545077	0.0	0.0	1.58496250072	0.0000000000	False
sort of similar	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
good morning	0.000288241164181	0.0	0.0	1.0	0.0000000000	False
administrative announcements	0.000572890738972	0.0	0.0	1.0	0.0000000000	False
technical material	0.000572890738972	0.0	0.0	1.0	0.0000000000	False
proposing class	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
class projects	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
project proposals	0.000460978016052	0.0	0.0	0.0	0.0000000000	False
term project	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
half weeks	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
formed teams	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
project ideas	0.00229156295589	0.0	3.99785981808	3.0	0.0000000000	False
re sort	0.0	0.0	0.0	2.0	0.0000000000	False
office hours	0.00229156295589	0.0	3.99785981808	3.0	0.3451327434	False
friday mornings	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
senior phd	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
phd students	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
students working	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
computer vision	0.00101972952375	0.0	0.0	1.0	0.0000000000	False
trouble coming	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
brainstorm ideas	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
previous class	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
educational thing	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
logistical details	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
problem set	0.00214805195534	0.0	4.99678972713	5.0	0.2340936375	False
posted online	0.000921956032104	0.0	0.0	2.0	0.0000000000	False
submit problem	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
late days	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
solutions questions	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
test methods	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
fitting models	0.00132344172906	0.0	0.0	1.0	0.0000000000	False
logistic regression	0.00787619050291	1.0	8.98769395399	22.0	0.4180704441	True
exponential family	0.019478285125	0.0	33.9818084537	32.0	0.4285714286	False
family distributions	0.011249254697	0.0	17.9909042269	14.0	0.0000000000	False
linear models	0.00860237123888	0.0	7.9925093633	7.0	0.3734610123	False
nice class	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
squares models	0.00132344172906	0.0	0.0	1.0	0.0000000000	False
previous lecture	0.00107402597767	0.0	1.99839486356	3.0	0.0000000000	False
large amounts	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
discussion section	0.00126310390896	0.0	2.99839486356	2.0	0.0000000000	False
section taught	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
octave notation	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
last lecture	0.0	0.0	0.0	0.0	0.0000000000	False
regression model	0.00230489008026	0.0	2.99732477261	3.0	0.5270270270	False
training sets	0.00201768814927	0.0	7.99625468165	7.0	0.4401805869	False
derive sort	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
gradient ascent	0.00992581296794	0.0	9.99197431782	14.0	0.2294117647	True
ascent interval	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
maximum likelihood	0.00193631494977	0.0	1.99732477261	4.0	0.4171122995	False
likelihood estimate	0.000842069272637	0.0	0.0	0.0	0.0000000000	False
parameter stated	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
learning rule	0.000509864761876	0.0	0.0	1.0	0.0000000000	False
meaning find	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
log likelihood	0.00184391206421	0.0	3.99785981808	3.0	0.4171122995	False
describe newton	0.0	0.0	0.0	1.0	0.0000000000	False
slowly change	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
fitting mass	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
likelihood models	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
horizontal axis	0.00126310390896	0.0	5.99839486356	2.0	0.0000000000	False
initialize theta	0.00198516259359	0.0	5.99839486356	3.0	0.0000000000	False
call theta	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
theta superscript	0.000813576967182	1.0	0.0	0.0	0.0000000000	False
linear consummation	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
makes sense	0.000824610226281	0.0	3.99571963617	7.0	0.0000000000	False
function work	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
out nicely	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
dec point	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
capital delta	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
first line	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
vertical length	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
horizontal length	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
vertical height	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
minus delta	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
minus capital	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
method precedes	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
equals theta	0.00330860432265	0.0	3.99732477261	4.0	0.4401805869	False
theta equals	0.000572890738972	0.0	0.0	1.0	0.0000000000	False
double prime	0.00101972952375	0.0	0.0	1.0	0.0000000000	False
local optimum	0.000509864761876	0.0	0.0	1.0	0.0000000000	False
fairly complicated	0.00114578147794	0.0	0.0	2.0	0.0000000000	False
nt matter	0.0	0.0	0.0	0.0	0.0000000000	False
huge deal	0.00132344172906	0.0	0.0	2.0	0.0000000000	False
ll sort	0.0	0.0	3.99785981808	3.0	0.0000000000	False
algorithms tend	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
converges problems	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
linear rate	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
fast conversions	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
technical term	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
significant digits	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
constant factors	0.00132344172906	0.0	0.0	1.0	0.0000000000	False
factors suppose	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
method result	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
theoretical result	0.000572890738972	0.0	0.0	1.0	0.0000000000	False
rosier picture	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
dozen iterations	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
reasonable size	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
size problems	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
single-row number	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
row number	0.000813576967182	0.0	0.0	2.0	0.0000000000	False
first derivative	0.00244073090155	0.0	2.99839486356	2.0	0.0000000000	False
usual gradient	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
hij equals	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
derivatives times	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
times sort	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
multiple dimensions	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
reasonable number	0.00162715393436	0.0	0.0	0.0	0.0000000000	False
training examples	0.000309121913399	0.0	0.0	1.0	0.0000000000	False
fewer iterations	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
converge compared	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
n-by-n matrix	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
one-dimensional matrix	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
large number	0.000235406887302	0.0	0.0	0.0	0.0000000000	False
learning problem	0.000332204510761	0.0	3.99732477261	5.0	0.0000000000	False
expensive step	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
re right	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm change	0.000813576967182	0.0	0.0	2.0	0.0000000000	False
nt change	0.0	0.0	0.0	0.0	0.0000000000	False
generalized linear	0.00926409210341	0.0	7.9925093633	11.0	0.4245723173	False
modeling pfy	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
real number	0.00230592931345	0.0	3.99571963617	7.0	0.0000000000	False
gaussian distribution	0.00210517318159	0.0	6.99732477261	4.0	0.0000000000	True
linear regression	0.000387262989955	0.0	0.0	1.0	0.0000000000	False
classification problem	0.00126310390896	0.0	3.99839486356	2.0	0.0000000000	False
natural distribution	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
distribution models	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
models random	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
random variables	0.000996613532283	0.0	1.99839486356	2.0	0.0000000000	False
function turns	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
natural default	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
default choice	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
special cases	0.00116178896986	0.0	4.99839486356	2.0	0.0000000000	False
longer piece	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
key ideas	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
entire story	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
parameter phi	0.00171867221692	0.0	0.0	1.0	0.0000000000	False
parameter theta	0.000842069272637	0.0	0.0	1.0	0.0000000000	False
probability distributions	0.00154905195982	0.0	5.99732477261	4.0	0.0000000000	False
fixed distribution	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
vary theta	0.00162715393436	0.0	0.0	2.0	0.0000000000	False
natural parameter	0.00458312591177	0.0	4.99678972713	5.0	0.5416666667	False
sufficient statistic	0.00488146180309	0.0	9.99678972713	5.0	0.2041884817	True
formula defines	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
specific formulas	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
true specific	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
specific choices	0.00198516259359	0.0	2.99839486356	2.0	0.0000000000	False
specific functions	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
fixed values	0.000813576967182	0.0	0.0	2.0	0.0000000000	False
formal sense	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
statistics class	0.00101972952375	0.0	0.0	1.0	0.0000000000	False
property today	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
last comment	0.0	0.0	0.0	1.0	0.0000000000	False
raw number	0.00244073090155	0.0	5.99839486356	2.0	0.0000000000	False
pfy equals	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
phi specifies	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
similar exponential	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
exponential notation	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
minus phi	0.00976292360619	0.0	5.99357945425	11.0	0.3284210526	False
taking log	0.000572890738972	0.0	0.0	1.0	0.0000000000	False
log cancel	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
previous board	0.00116178896986	0.0	1.99839486356	3.0	0.0000000000	False
log phi	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
logistic function	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
copying definitions	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
minus log	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
phi depends	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
terribly interesting	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
probability mass	0.00132344172906	0.0	0.0	0.0	0.0000000000	False
mass function	0.00162715393436	0.0	0.0	0.0	0.0000000000	False
original parameter	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
times log	0.00254932380938	0.0	4.99732477261	3.0	0.1703056769	False
number times	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
one-dimensional vector	0.00397032518718	0.0	3.99678972713	5.0	0.0000000000	False
vector transposed	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
transposed times	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
main distributions	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
scalers distribution	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
implicit constraint	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
normal distribution	0.00264688345812	0.0	6.99785981808	3.0	0.0000000000	False
sequence squared	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
ordinary squares	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
writing lesson	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
taking account	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
account squared	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
lecture talks	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
bit easier	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
simpler today	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
square equals	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
scaling factor	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
gaussian density	0.00101972952375	0.0	0.0	1.0	0.0000000000	False
minus one-half	0.00330860432265	0.0	4.99732477261	4.0	0.1703056769	False
squared times	0.000460978016052	0.0	0.0	0.0	0.0000000000	False
one-half squared	0.00244073090155	0.0	2.99839486356	0.0	0.0000000000	False
distribution minus	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
minus half	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
undergrad statistics	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
textbook distributions	0.0	0.0	0.0	1.0	0.0000000000	False
gaussian random	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
high dimension	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
models outcomes	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
coin tosses	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
parson distribution	0.00569503877028	0.0	11.9962546816	6.0	0.3742802303	False
modeling counts	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
counts things	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
radioactive decays	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
visitors arriving	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
exponential distributions	0.00325430786873	0.0	5.99785981808	3.0	0.0000000000	False
positive numbers	0.000509864761876	0.0	0.0	1.0	0.0000000000	False
model intervals	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
bus stop	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
gamma distribution	0.00132344172906	0.0	0.0	1.0	0.0000000000	False
wisha distribution	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
covariance matrices	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
abbreviated glm	0.0	0.0	0.0	1.0	0.0000000000	False
design choices	0.00397032518718	0.0	3.99678972713	5.0	0.0000000000	False
conditional distribution	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
effective value	0.0	0.0	0.0	0.0	0.0000000000	False
website examples	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
people linked	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
expected number	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
learning algorithms	0.00349932093765	0.0	9.99357945425	11.0	0.3806566105	False
algorithms hypothesis	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
expected value	0.0	0.0	7.99411449973	10.0	0.2450028555	False
algorithms output	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
last decision	0.0	0.0	0.0	1.0	0.0000000000	False
input teachers	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
parameter parameterizing	0.00162715393436	0.0	0.0	0.0	0.0000000000	False
last step	0.0	0.0	0.0	1.0	0.0000000000	False
axis linear	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
nice algorithms	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
parson regression	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
performed regression	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
distribution outputs	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
theta transpose	0.00203945904751	0.0	0.0	0.0	0.0000000000	False
general case	0.000572890738972	0.0	0.0	1.0	0.0000000000	False
specific forms	0.000813576967182	0.0	0.0	2.0	0.0000000000	False
distribution phi	0.00162715393436	0.0	0.0	2.0	0.0000000000	False
distribution value	0.0	0.0	0.0	1.0	0.0000000000	False
linearly related	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
minus theta	0.000572890738972	0.0	0.0	1.0	0.0000000000	False
regression algorithm	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
variable distribution	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
machine-learning problem	0.00184391206421	0.0	3.99785981808	4.0	0.4171122995	False
chose distribution	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
similar process	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
canonical response	0.00244073090155	0.0	2.99839486356	2.0	0.0000000000	False
response function	0.00244073090155	0.0	2.99839486356	1.0	0.0000000000	False
canonical link	0.00244073090155	0.0	2.99839486356	2.0	0.0000000000	False
link function	0.00244073090155	0.0	2.99839486356	1.0	0.0000000000	False
people talk	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
notation turns	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
machine learning	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
memorizing lots	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
lecture notes	0.00116178896986	0.0	3.99839486356	3.0	0.0000000000	False
choose theta	0.000661720864529	0.0	0.0	1.0	0.0000000000	False
bit trickier	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
textbook examples	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
details omitted	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
outcomes imagine	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
send emails	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
right email	0.0	0.0	0.0	0.0	0.0000000000	False
email folder	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
dozen email	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
classify emails	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
algorithm figure	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
multi-cause classification	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
decision boundary	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
multiple values	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
last parameter	0.0	0.0	0.0	0.0	0.0000000000	False
redundant parameterization	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
write phi	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
good point	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
indicator function	0.00210517318159	0.0	6.99732477261	4.0	0.0000000000	True
function notation	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
curly braces	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
true statement	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
statement inside	0.00325430786873	0.0	3.99785981808	3.0	0.0000000000	False
false statement	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
write indicator	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
indicating sort	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
equation makes	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
first element	0.000716017318446	0.0	0.0	2.0	0.0000000000	False
family form	0.00162715393436	0.0	0.0	0.0	0.0000000000	False
times phi	0.00244073090155	0.0	3.99839486356	2.0	0.0000000000	False
phi two	0.0	0.0	6.99625468165	6.0	0.3513513514	False
two indicator	0.0	0.0	0.0	0.0	0.0000000000	False
times indicator	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
dot phi	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
out phi	0.00162715393436	0.0	0.0	0.0	0.0000000000	False
distributions parameters	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
linear function	0.000387262989955	0.0	0.0	1.0	0.0000000000	False
earlier design	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
vector indicator	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
softmax regression	0.00162715393436	1.0	0.0	1.0	0.0000000000	True
apply softmax	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
entire derivation	0.00162715393436	0.0	0.0	1.0	0.0000000000	False
fit parameters	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
formula theta	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
parameters comprising	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
parameter vectors	0.00114578147794	0.0	0.0	0.0	0.0000000000	False
theta correspond	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
similar interpretation	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
bit late	0.000813576967182	0.0	0.0	1.0	0.0000000000	False
good	6.15220315768e-05	0.0	0.0	0.0	0.0000000000	False
morning	0.000288241164181	0.0	0.0	0.0	0.0000000000	False
administrative	0.00016610225538	0.0	0.0	0.0	0.0000000000	False
announcements	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
jump	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
today	0.000156707680001	0.0	0.0	0.0	0.3959390863	False
technical	0.000358008659223	0.0	0.0	0.0	0.0000000000	False
material	0.000269178533666	0.0	0.0	0.0	0.0000000000	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
post	0.000377463920224	0.0	0.0	0.0	0.0000000000	False
website	0.00149492029842	0.0	0.0	0.0	0.3513513514	False
handout	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
sort	0.00107191041491	0.0	0.0	0.0	0.5599814729	False
guidelines	0.000460978016052	0.0	0.0	0.0	0.0000000000	False
suggestions	0.000269178533666	0.0	0.0	0.0	0.0000000000	False
choosing	0.00117261409395	0.0	0.0	0.0	0.4273972603	False
proposing	0.000537012988835	0.0	0.0	0.0	0.0000000000	False
class	0.000428764165962	0.0	0.0	0.0	0.4266958425	False
projects	0.00113239176067	0.0	0.0	0.0	0.1419472247	False
term	9.97230690916e-05	0.0	0.0	0.0	0.5416666667	False
due	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
friday	0.000421034636319	0.0	0.0	0.0	0.0000000000	False
19th	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
month	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
noon	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.4344232842	False
weeks	0.000470813774604	0.0	0.0	0.0	0.0000000000	False
half	0.000157265810746	0.0	0.0	0.0	0.0000000000	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
formed	0.000277312310597	0.0	0.0	0.0	0.5492957746	False
teams	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
started	0.0	0.0	0.0	0.0	0.4401805869	False
thinking	0.000269178533666	0.0	0.0	0.0	0.5437813720	False
ideas	0.000407223404378	0.0	0.0	0.0	0.2484076433	False
find	0.000157427774876	0.0	0.0	0.0	0.4002932551	False
details	0.000167101569297	0.0	0.0	0.0	0.5270270270	False
send	0.000309121913399	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
fishing	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
strongly	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
encouraged	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
office	0.000842069272637	0.0	0.0	0.0	0.3451327434	False
hours	0.000664409021522	0.0	0.0	0.0	0.3451327434	False
brainstorm	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
list	6.81925307642e-05	0.0	0.0	0.0	0.0000000000	False
collected	9.64353951855e-05	0.0	0.0	0.0	0.0000000000	False
colleagues	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
senior	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
phd	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
students	8.42516253191e-05	0.0	0.0	0.0	0.0000000000	False
working	0.000410146877179	0.0	0.0	0.0	0.3015463918	False
professors	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
hear	0.000251642613483	0.0	0.0	0.0	0.0000000000	False
topics	0.000432361746272	0.0	0.0	0.0	0.0000000000	False
natural	0.000759878870556	0.0	0.0	0.0	0.4804031355	False
computer	7.12307636369e-05	0.0	0.0	0.0	0.5270270270	False
vision	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
neuroscience	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
robotics	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
control	9.64353951855e-05	0.0	0.0	0.0	0.0000000000	False
variety	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
trouble	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
coming	7.8632905373e-05	0.0	0.0	0.0	0.4804031355	False
previous	0.000320313988925	0.0	0.0	0.0	0.5492957746	False
mentioned	0.00020615255657	0.0	0.0	0.0	0.0000000000	False
invite	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
fun	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
educational	0.00016610225538	0.0	0.0	0.0	0.0000000000	False
thing	0.0	0.0	0.0	0.0	0.5735294118	False
email	0.000807535600997	0.0	0.0	0.0	0.2392638037	False
registered	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
logistical	0.00386402391749	0.0	0.0	0.0	0.4560244026	False
applying	0.00029935953249	0.0	0.0	0.0	0.3979591837	False
respond	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
finally	6.3323239213e-05	0.0	0.0	0.0	0.0000000000	False
problem	0.000109563852721	0.0	0.0	0.0	0.4119718310	False
set	0.000166471479851	0.0	0.0	0.0	0.3861386139	False
online	0.000580894484932	0.0	0.0	0.0	0.0000000000	False
shortly	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
submit	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
late	0.000332204510761	0.0	0.0	0.0	0.0000000000	False
days	0.000314531621492	0.0	0.0	0.0	0.0000000000	False
select	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
based	6.3323239213e-05	0.0	0.0	0.0	0.0000000000	False
solutions	0.000252754875957	0.0	0.0	0.0	0.0000000000	False
questions	6.74690463753e-05	0.0	0.0	0.0	0.5571428571	False
back	5.42964539171e-05	0.0	0.0	0.0	0.0000000000	False
talk	7.66946969049e-05	0.0	0.0	0.0	0.4245723173	False
test	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
methods	0.00109108049223	0.0	0.0	0.0	0.4239130435	False
fitting	0.000672946334164	0.0	0.0	0.0	0.5342465753	False
models	0.00433959278335	0.0	0.0	0.0	0.3309759547	False
regression	0.00432770678759	0.0	0.0	0.0	0.4089609152	False
exponential	0.00576482328363	0.0	0.0	0.0	0.2759108596	False
family	0.00715758881742	0.0	0.0	0.0	0.4285714286	False
distributions	0.0110145893921	0.0	0.0	0.0	0.3048275862	False
generalized	0.000199765775821	0.0	0.0	0.0	0.4436401241	False
linear	0.00160078088106	0.0	0.0	0.0	0.4445110978	False
nice	0.000235898716119	0.0	0.0	0.0	0.0000000000	False
tie	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
ordinary	0.000631551954478	0.0	0.0	0.0	0.0000000000	False
squares	0.00122746555375	0.0	0.0	0.0	0.2821997106	False
lecture	0.000644834705247	0.0	0.0	0.0	0.4089609152	False
increasingly	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
large	0.00011379435975	0.0	0.0	0.0	0.0000000000	False
amounts	7.8632905373e-05	0.0	0.0	0.0	0.0000000000	False
probability	0.00377463920224	0.0	0.0	0.0	0.3631721238	False
refresher	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
foundations	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
prerequisites	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
background	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
statistics	0.00196904762573	0.0	0.0	0.0	0.1803468208	False
discussion	0.000149679766245	0.0	0.0	0.0	0.0000000000	False
section	0.000498306766141	0.0	0.0	0.0	0.0000000000	False
taught	0.000460978016052	0.0	0.0	0.0	0.0000000000	False
review	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
briefly	0.000192870790371	0.0	0.0	0.0	0.0000000000	False
octave	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
notation	0.000842516253191	0.0	0.0	0.0	0.4401805869	False
pre-reqs	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
right	0.0	0.0	0.0	0.0	0.5571428571	False
recap	0.000432361746272	0.0	0.0	0.0	0.0000000000	False
end	8.99587285005e-05	0.0	0.0	0.0	0.4747826087	False
last	0.0	0.0	0.0	0.0	0.3152094048	False
algorithm	0.00140293154636	0.0	0.0	0.0	0.3305084746	False
equals	0.00356555660549	0.0	0.0	0.0	0.2530719315	False
give	1.35242702324e-05	0.0	0.0	0.0	0.5342465753	False
theta	0.012364876536	0.0	0.0	0.0	0.1568681470	False
transpose	0.00232705628495	0.0	0.0	0.0	0.3714285714	False
write	0.000485296543544	0.0	0.0	0.0	0.3789035392	False
log	0.00160078088106	0.0	0.0	0.0	0.1881028939	False
heard	0.000498306766141	0.0	0.0	0.0	0.0000000000	False
training	0.00105933099286	0.0	0.0	0.0	0.4105263158	False
taking	0.000244334042627	0.0	0.0	0.0	0.4365109996	False
riveters	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
derive	0.00260375567001	0.0	0.0	0.0	0.3347639485	False
gradient	0.00367899840457	0.0	0.0	0.0	0.1849263788	False
ascent	0.00382398571407	0.0	0.0	0.0	0.2294117647	False
interval	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
maximum	0.000471797432238	0.0	0.0	0.0	0.4588235294	False
likelihood	0.00268506494417	0.0	0.0	0.0	0.3451327434	False
estimate	0.000664409021522	0.0	0.0	0.0	0.5270270270	False
parameter	0.0031514003775	0.0	0.0	0.0	0.4836138175	False
stated	0.000235406887302	0.0	0.0	0.0	0.0000000000	False
wrote	0.00103076278285	0.0	0.0	0.0	0.4665071770	False
learning	0.00101317182741	0.0	0.0	0.0	0.3923541247	False
rule	9.01742040539e-05	0.0	0.0	0.0	0.0000000000	False
favor	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
meaning	2.16388323719e-05	0.0	0.0	0.0	0.4747826087	False
value	0.00054189532461	0.0	0.0	0.0	0.3364705882	False
maximizes	0.00148048193516	0.0	0.0	0.0	0.2671232877	False
perfectly	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
guess	0.000618457669711	0.0	0.0	0.0	0.4588235294	False
run	7.13324039559e-05	0.0	0.0	0.0	0.0000000000	False
faster	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
newton	0.0	0.0	0.0	0.0	0.3551912568	False
describe	9.64353951855e-05	0.0	0.0	0.0	0.0000000000	False
first	0.0	0.0	0.0	0.0	0.3497757848	False
function	0.00104587453681	0.0	0.0	0.0	0.2679097154	False
slowly	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
change	0.000108592907834	0.0	0.0	0.0	0.0000000000	False
mass	0.000691467024078	0.0	0.0	0.0	0.0000000000	False
reduction	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
horizontal	0.000716017318446	0.0	0.0	0.0	0.2943396226	False
axis	0.000772804783498	0.0	0.0	0.0	0.0000000000	False
initialize	0.000234644862025	0.0	0.0	0.0	0.2943396226	False
call	1.08194161859e-05	0.0	0.0	0.0	0.4057217165	False
superscript	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
evaluate	0.000235406887302	0.0	0.0	0.0	0.0000000000	False
consummation	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
tangents	0.00132344172906	0.0	0.0	0.0	0.2943396226	False
hope	0.000269178533666	0.0	0.0	0.0	0.0000000000	False
makes	0.000104085660085	0.0	0.0	0.0	0.4317343173	False
sense	0.000118887339927	0.0	0.0	0.0	0.0000000000	False
out	0.0	0.0	0.0	0.0	0.3424214418	False
point	1.35242702324e-05	0.0	0.0	0.0	0.4171122995	False
extend	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
intercepts	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
iteration	0.00141244132381	0.0	0.0	0.0	0.3931451613	False
dec	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
length	0.000309228834855	0.0	0.0	0.0	0.0000000000	False
capital	0.000537012988835	0.0	0.0	0.0	0.0000000000	False
delta	0.000968157474887	0.0	0.0	0.0	0.2041884817	False
remember	7.58629064997e-05	0.0	0.0	0.0	0.0000000000	False
definition	0.000320313988925	0.0	0.0	0.0	0.3374536465	False
words	0.000167101569297	0.0	0.0	0.0	0.0000000000	False
line	4.17753923244e-05	0.0	0.0	0.0	0.0000000000	False
vertical	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
divided	0.000806172189592	0.0	0.0	0.0	0.2564255828	False
slope	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
defined	0.000162889361751	0.0	0.0	0.0	0.3979591837	False
ratio	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
height	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
width	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
triangle	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
implies	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
prime	0.00143203463689	0.0	0.0	0.0	0.2276897415	False
minus	0.00260827105268	0.0	0.0	0.0	0.2084224027	False
precedes	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
ant	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
place	5.4189532461e-05	0.0	0.0	0.0	0.0000000000	False
double	0.000289306185556	0.0	0.0	0.0	0.0000000000	False
local	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
optimum	0.000764797142814	0.0	0.0	0.0	0.0000000000	False
answer	0.0003660731302	0.0	0.0	0.0	0.5342465753	False
fairly	9.97865108298e-05	0.0	0.0	0.0	0.0000000000	False
complicated	0.000337006501276	0.0	0.0	0.0	0.0000000000	False
conditions	0.000157265810746	0.0	0.0	0.0	0.0000000000	False
guarantee	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
complex	0.000385741580742	0.0	0.0	0.0	0.5270270270	False
practice	7.8632905373e-05	0.0	0.0	0.0	0.0000000000	False
matter	0.000293153523488	0.0	0.0	0.0	0.0000000000	False
implement	0.000219865142616	0.0	0.0	0.0	0.0000000000	False
zeros	0.000921956032104	0.0	0.0	0.0	0.2466403162	False
huge	0.000251642613483	0.0	0.0	0.0	0.0000000000	False
deal	0.000251642613483	0.0	0.0	0.0	0.0000000000	False
conversions	0.000588517218254	1.0	0.0	0.0	0.0000000000	False
tend	0.000125821306741	0.0	0.0	0.0	0.0000000000	False
converges	0.00077452597991	0.0	0.0	0.0	0.0000000000	False
rate	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
speeds	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
turns	0.000682766158497	0.0	0.0	0.0	0.4119718310	False
enjoys	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
extremely	9.01742040539e-05	0.0	0.0	0.0	0.0000000000	False
fast	0.00016610225538	0.0	0.0	0.0	0.0000000000	False
property	9.97865108298e-05	0.0	0.0	0.0	0.0000000000	False
informally	6.81925307642e-05	0.0	0.0	0.0	0.0000000000	False
number	7.03262052086e-05	0.0	0.0	0.0	0.3360364927	False
significant	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
digits	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
accurate	0.000332204510761	0.0	0.0	0.0	0.0000000000	False
lots	0.000189657266249	0.0	0.0	0.0	0.4171122995	False
constant	0.000146576761744	0.0	0.0	0.0	0.0000000000	False
factors	0.000377463920224	0.0	0.0	0.0	0.0000000000	False
suppose	0.000118887339927	0.0	0.0	0.0	0.4171122995	False
error	0.000576482328363	0.0	0.0	0.0	0.0000000000	False
order	1.66471479851e-05	0.0	0.0	0.0	0.0000000000	False
essentially	4.75549359706e-05	0.0	0.0	0.0	0.0000000000	False
result	0.000234644862025	0.0	0.0	0.0	0.4171122995	False
holds	8.42516253191e-05	0.0	0.0	0.0	0.0000000000	False
theoretical	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
true	0.000433516259688	0.0	0.0	0.0	0.4180704441	False
paint	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
slightly	9.15182825501e-05	0.0	0.0	0.0	0.0000000000	False
rosier	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
picture	4.98932554149e-05	0.0	0.0	0.0	0.0000000000	False
fact	4.10146877179e-05	0.0	0.0	0.0	0.0000000000	False
dozen	0.000992581296794	0.0	0.0	0.0	0.0000000000	False
reasonable	0.000136871370377	0.0	0.0	0.0	0.4401805869	False
size	5.4189532461e-05	0.0	0.0	0.0	0.0000000000	False
tens	0.000108379064922	0.0	0.0	0.0	0.0000000000	False
hundreds	9.64353951855e-05	0.0	0.0	0.0	0.0000000000	False
features	0.000613732776877	0.0	0.0	0.0	0.3451327434	False
case	0.0	0.0	0.0	0.0	0.3861386139	False
single-row	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
vector	0.00376651019683	0.0	0.0	0.0	0.2479564033	False
row	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
usual	0.000288241164181	0.0	0.0	0.0	0.2977099237	False
objective	7.3288380872e-05	0.0	0.0	0.0	0.0000000000	False
matrix	0.000895021648058	0.0	0.0	0.0	0.2880354505	False
hessian	0.000859336108458	1.0	0.0	0.0	0.0000000000	False
hij	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.2047244094	False
inverse	0.000631551954478	0.0	0.0	0.0	0.0000000000	False
multiple	0.000192870790371	0.0	0.0	0.0	0.0000000000	False
dimensions	0.000332204510761	0.0	0.0	0.0	0.0000000000	False
examples	0.000596084857071	0.0	0.0	0.0	0.4057217165	False
compare	0.000220291787841	0.0	0.0	0.0	0.0000000000	False
fewer	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
disadvantage	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
invert	0.00198516259359	0.0	0.0	0.0	0.3513513514	False
n-by-n	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
one-dimensional	0.00229156295589	0.0	0.0	0.0	0.4180704441	False
thousands	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
expensive	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
step	0.000166442275897	0.0	0.0	0.0	0.4588235294	False
smaller	6.81925307642e-05	0.0	0.0	0.0	0.0000000000	False
leave	0.000505509751914	0.0	0.0	0.0	0.4588235294	False
wanted	9.64353951855e-05	0.0	0.0	0.0	0.3880597015	False
minimize	9.64353951855e-05	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
pfy	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
parameterized	0.00315775977239	0.0	0.0	0.0	0.4405315615	False
real	0.0003660731302	0.0	0.0	0.0	0.2472266244	False
sealing	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
gaussian	0.00387262989955	0.0	0.0	0.0	0.3372972973	False
classification	0.000432361746272	0.0	0.0	0.0	0.0000000000	False
random	0.000309228834855	0.0	0.0	0.0	0.0000000000	False
variables	0.000762595801581	0.0	0.0	0.0	0.2836363636	False
earth	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
choices	0.00102288796146	0.0	0.0	0.0	0.4804031355	False
plugged	0.000403767800498	0.0	0.0	0.0	0.0000000000	False
default	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
lead	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
show	0.000190219743882	0.0	0.0	0.0	0.4588235294	False
special	0.000252754875957	0.0	0.0	0.0	0.0000000000	False
pauses	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
fall	0.000220291787841	0.0	0.0	0.0	0.0000000000	False
longer	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
piece	0.000136385061528	0.0	0.0	0.0	0.0000000000	False
chalk	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
warn	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
key	6.3323239213e-05	0.0	0.0	0.0	0.0000000000	False
gist	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
entire	6.12520237089e-05	0.0	0.0	0.0	0.0000000000	False
story	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
map	9.01742040539e-05	0.0	0.0	0.0	0.0000000000	False
intellection	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
data	6.12520237089e-05	0.0	0.0	0.0	0.0000000000	False
zero-one	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
phi	0.0168256975859	0.0	0.0	0.0	0.1445515196	False
specifies	0.000332204510761	0.0	0.0	0.0	0.0000000000	False
vary	0.001545609567	0.0	0.0	0.0	0.2472266244	False
fixed	0.000385741580742	0.0	0.0	0.0	0.4171122995	False
cost	0.000403767800498	0.0	0.0	0.0	0.0000000000	False
written	0.000216758129844	0.0	0.0	0.0	0.5270270270	False
names	0.000269178533666	0.0	0.0	0.0	0.0000000000	False
bit	0.000166442275897	0.0	0.0	0.0	0.5416666667	False
sufficient	0.000754927840449	0.0	0.0	0.0	0.2600000000	False
including	7.8632905373e-05	0.0	0.0	0.0	0.0000000000	False
mentally	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
replace	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
formula	0.00201768814927	0.0	0.0	0.0	0.2836363636	False
specific	0.000183756071127	0.0	0.0	0.0	0.3513513514	False
formal	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
worry	0.000126646478426	0.0	0.0	0.0	0.0000000000	False
comment	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
raw	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
product	0.000289306185556	0.0	0.0	0.0	0.0000000000	False
goal	0.000772804783498	0.0	0.0	0.0	0.3742802303	False
identical	0.000125821306741	0.0	0.0	0.0	0.0000000000	False
similar	0.00011379435975	0.0	0.0	0.0	0.0000000000	False
compactly	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
exponent	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
cancel	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
clean	0.000421034636319	0.0	0.0	0.0	0.0000000000	False
board	0.000823924105556	0.0	0.0	0.0	0.3451327434	False
copying	0.000269178533666	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
solve	0.000270522612162	0.0	0.0	0.0	0.0000000000	False
excuse	0.000942124867829	0.0	0.0	0.0	0.4747826087	False
magically	0.000661720864529	0.0	0.0	0.0	0.0000000000	False
depends	9.51098719412e-05	0.0	0.0	0.0	0.4171122995	False
algebra	0.00161342305618	0.0	0.0	0.0	0.4401805869	False
terribly	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
interesting	9.97865108298e-05	0.0	0.0	0.0	0.0000000000	False
complete	4.10146877179e-05	0.0	0.0	0.0	0.0000000000	False
rest	0.000385741580742	0.0	0.0	0.0	0.0000000000	False
relationship	0.00149492029842	0.0	0.0	0.0	0.3929471033	False
original	6.3323239213e-05	0.0	0.0	0.0	0.0000000000	False
expand	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
cool	0.000377463920224	0.0	0.0	0.0	0.0000000000	False
scaler	0.00203394241796	0.0	0.0	0.0	0.0000000000	False
main	0.000125821306741	0.0	0.0	0.0	0.0000000000	False
imagine	0.000192870790371	0.0	0.0	0.0	0.0000000000	False
restricting	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
domain	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
input	0.000149679766245	0.0	0.0	0.0	0.0000000000	False
implicit	0.00016610225538	0.0	0.0	0.0	0.0000000000	False
constraint	0.00016610225538	0.0	0.0	0.0	0.0000000000	False
quickly	0.000126646478426	0.0	0.0	0.0	0.0000000000	False
basically	1.12448410626e-05	0.0	0.0	0.0	0.0000000000	False
normal	0.000253292956852	0.0	0.0	0.0	0.2943396226	False
sequence	6.3323239213e-05	0.0	0.0	0.0	0.0000000000	False
ago	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
purposes	0.000126646478426	0.0	0.0	0.0	0.0000000000	False
lesson	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
account	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
easier	0.000125821306741	0.0	0.0	0.0	0.0000000000	False
simpler	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
scaling	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
density	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
couple	0.000353110330953	0.0	0.0	0.0	0.0000000000	False
download	0.00016610225538	0.0	0.0	0.0	0.0000000000	False
root	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
pie	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
one-half	0.00107402597767	0.0	0.0	0.0	0.1703056769	False
sign	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
expresses	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
undergrad	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
textbook	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
high	6.81925307642e-05	0.0	0.0	0.0	0.0000000000	False
outcomes	0.00135542046484	0.0	0.0	0.0	0.0000000000	False
coin	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
tosses	0.000509864761876	0.0	0.0	0.0	0.0000000000	False
parson	0.00406788483591	0.0	0.0	0.0	0.3181076672	False
counts	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
radioactive	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
decays	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
sample	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
customers	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
visitors	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
arriving	0.000859336108458	0.0	0.0	0.0	0.0000000000	False
store	9.01742040539e-05	0.0	0.0	0.0	0.0000000000	False
gamma	0.000968157474887	0.0	0.0	0.0	0.4401805869	False
positive	3.79314532498e-05	0.0	0.0	0.0	0.0000000000	False
standing	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
bus	0.000764797142814	0.0	0.0	0.0	0.0000000000	False
stop	9.01742040539e-05	0.0	0.0	0.0	0.0000000000	False
long	7.8632905373e-05	0.0	0.0	0.0	0.0000000000	False
wait	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
fractions	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
wisha	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
covariance	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
matrices	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
asks	0.000117703443651	0.0	0.0	0.0	0.3734610123	False
brings	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
chosen	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
abbreviated	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
glm	0.0	0.0	0.0	0.0	0.0000000000	False
assumptions	0.00115296465673	0.0	0.0	0.0	0.0000000000	False
design	0.000471797432238	0.0	0.0	0.0	0.4588235294	False
crank	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
assume	0.000334203138595	0.0	0.0	0.0	0.3577981651	False
output	0.000681925307642	0.0	0.0	0.0	0.3644859813	False
response	0.0010525865908	0.0	0.0	0.0	0.3255425710	False
predict	0.00100657045393	0.0	0.0	0.0	0.3145161290	False
people	0.000234644862025	0.0	0.0	0.0	0.4171122995	False
hits	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
effective	7.3288380872e-05	0.0	0.0	0.0	0.0000000000	False
proportions	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
sales	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
linked	0.000470813774604	0.0	0.0	0.0	0.2943396226	False
expected	0.00132175072705	0.0	0.0	0.0	0.2385321101	False
meant	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
hypothesis	0.000235406887302	0.0	0.0	0.0	0.0000000000	False
lastly	0.000463682870099	0.0	0.0	0.0	0.0000000000	False
wan	0.0	0.0	0.0	0.0	0.0000000000	False
decision	0.000706220661905	0.0	0.0	0.0	0.2600000000	False
teachers	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
governed	0.000179004329612	0.0	0.0	0.0	0.0000000000	False
machinery	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
performed	4.98932554149e-05	0.0	0.0	0.0	0.0000000000	False
watch	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
previously	9.64353951855e-05	0.0	0.0	0.0	0.0000000000	False
negative	0.000192870790371	0.0	0.0	0.0	0.0000000000	False
made	0.000293306077531	0.0	0.0	0.0	0.4171122995	False
linearly	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
related	0.000219865142616	0.0	0.0	0.0	0.0000000000	False
raise	0.000180348408108	0.0	0.0	0.0	0.0000000000	False
hand	8.35507846487e-05	0.0	0.0	0.0	0.0000000000	False
ease	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
power	6.3323239213e-05	0.0	0.0	0.0	0.0000000000	False
machine-learning	0.000842069272637	0.0	0.0	0.0	0.4171122995	False
chose	0.000309121913399	0.0	0.0	0.0	0.0000000000	False
automatically	0.000269178533666	0.0	0.0	0.0	0.0000000000	False
follow	5.86612155062e-05	0.0	0.0	0.0	0.4171122995	False
process	3.06260118544e-05	0.0	0.0	0.0	0.0000000000	False
faced	0.000125821306741	0.0	0.0	0.0	0.0000000000	False
tiny	0.000254932380938	0.0	0.0	0.0	0.0000000000	False
canonical	0.00244073090155	0.0	0.0	0.0	0.1460674157	False
terminology	0.000210517318159	0.0	0.0	0.0	0.0000000000	False
techs	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
reverse	0.000193631494977	0.0	0.0	0.0	0.0000000000	False
consistent	0.000110145893921	0.0	0.0	0.0	0.0000000000	False
machine	7.3288380872e-05	0.0	0.0	0.0	0.0000000000	False
big	6.3323239213e-05	0.0	0.0	0.0	0.0000000000	False
memorizing	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
skip	0.000580894484932	0.0	0.0	0.0	0.0000000000	False
variation	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
simple	4.10146877179e-05	0.0	0.0	0.0	0.0000000000	False
confusing	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
read	9.97865108298e-05	0.0	0.0	0.0	0.0000000000	False
notes	0.000162568597383	0.0	0.0	0.0	0.0000000000	False
theory	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
remaining	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
minutes	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
trickier	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
omitted	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
carefully	5.4189532461e-05	0.0	0.0	0.0	0.0000000000	False
folder	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
classify	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
patient	0.000764797142814	0.0	0.0	0.0	0.0000000000	False
disease	0.00132344172906	0.0	0.0	0.0	0.0000000000	False
figure	5.86612155062e-05	0.0	0.0	0.0	0.0000000000	False
multi-cause	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
eventually	9.01742040539e-05	0.0	0.0	0.0	0.0000000000	False
boundary	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
separates	0.000136385061528	0.0	0.0	0.0	0.0000000000	False
entertain	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
redundant	0.000572890738972	0.0	0.0	0.0	0.0000000000	False
sum	0.000235898716119	0.0	0.0	0.0	0.0000000000	False
over-parameterized	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
treat	0.000134589266833	0.0	0.0	0.0	0.0000000000	False
shorthand	0.00122036545077	0.0	0.0	0.0	0.0000000000	False
introduce	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
indicator	0.00136385061528	0.0	0.0	0.0	0.1616245338	False
curly	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
braces	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
statement	0.000505509751914	0.0	0.0	0.0	0.1460674157	False
inside	0.000293153523488	0.0	0.0	0.0	0.0000000000	False
false	0.000387262989955	0.0	0.0	0.0	0.0000000000	False
truth	0.000230489008026	0.0	0.0	0.0	0.0000000000	False
falsehood	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
combine	7.3288380872e-05	0.0	0.0	0.0	0.0000000000	False
carve	0.000406788483591	0.0	0.0	0.0	0.0000000000	False
space	5.86612155062e-05	0.0	0.0	0.0	0.0000000000	False
denote	9.64353951855e-05	0.0	0.0	0.0	0.0000000000	False
element	0.000527950939556	0.0	0.0	0.0	0.1501925546	False
understand	2.84923054547e-05	0.0	0.0	0.0	0.0000000000	False
equation	0.000192870790371	0.0	0.0	0.0	0.0000000000	False
kind	2.24896821251e-05	0.0	0.0	0.0	0.0000000000	False
home	0.0001545609567	0.0	0.0	0.0	0.0000000000	False
left	3.42178425942e-05	0.0	0.0	0.0	0.0000000000	False
dot	0.000618457669711	0.0	0.0	0.0	0.2880354505	False
simplify	0.000125821306741	0.0	0.0	0.0	0.0000000000	False
earlier	9.97865108298e-05	0.0	0.0	0.0	0.0000000000	False
softmax	0.000813576967182	0.0	0.0	0.0	0.0000000000	False
widely	0.000460978016052	0.0	0.0	0.0	0.0000000000	False
thought	0.000251642613483	0.0	0.0	0.0	0.0000000000	False
concrete	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
sit	0.000103076278285	0.0	0.0	0.0	0.0000000000	False
similarly	3.42178425942e-05	0.0	0.0	0.0	0.0000000000	False
two-dimensional	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
comprising	0.00016610225538	0.0	0.0	0.0	0.0000000000	False
group	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
correspond	0.00020615255657	0.0	0.0	0.0	0.0000000000	False
offline	0.000286445369486	0.0	0.0	0.0	0.0000000000	False
hard	0.000117703443651	0.0	0.0	0.0	0.0000000000	False
interpretation	0.000144120582091	0.0	0.0	0.0	0.0000000000	False
officially	0.000330860432265	0.0	0.0	0.0	0.0000000000	False
close	2.71482269585e-05	0.0	0.0	0.0	0.0000000000	False
quick announcement and reminder	0.0	0.0	0.0	2.0	0.0000000000	False
guidelines handout was posted	0.0	0.0	0.0	2.0	0.0000000000	False
downloaded it and looked	0.0	0.0	0.0	2.0	0.0000000000	False
guidelines for the project	0.0	0.0	0.0	2.0	0.0000000000	False
proposal and the project	0.0	0.0	0.0	2.0	0.0000000000	False
type of learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	True
talk about generative learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm called gaussian discriminant	0.0	0.0	0.0	4.0	0.0000000000	False
analysis take a slight	0.0	0.0	0.0	2.0	0.0000000000	False
briefly discuss generative versus	0.0	0.0	0.0	2.0	0.0000000000	False
generative versus discriminative learning	0.0	0.0	0.0	2.0	0.0000000000	False
versus discriminative learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
lecture with a discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion of naive bayes	0.0	0.0	0.0	2.0	0.0000000000	False
bayes and the laplace	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on generative learning	0.0	0.0	0.0	2.0	0.0000000000	False
source of classification algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
classification algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
re given a training	0.0	0.0	0.0	2.0	0.0000000000	False
progression on those training	0.0	0.0	0.0	2.0	0.0000000000	False
find a straight line	0.0	0.0	2.99850224663	6.0	0.0000000000	False
straight line to divide	0.0	0.0	0.0	2.0	0.0000000000	False
days a bit noisier	0.0	0.0	0.0	2.0	0.0000000000	False
noisier trying to find	0.0	0.0	0.0	2.0	0.0000000000	False
straight line that separates	0.0	0.0	0.0	2.0	0.0000000000	False
set with logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
ve initialized the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
shown in the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
iteration and creating descent	0.0	0.0	0.0	2.0	0.0000000000	False
line changes a bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit after two iterations	0.0	0.0	0.0	2.0	0.0000000000	False
converges and has found	0.0	0.0	0.0	2.0	0.0000000000	False
found the straight line	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative class	0.0	0.0	0.0	2.0	0.0000000000	False
searching for a line	0.0	0.0	0.0	2.0	0.0000000000	False
talk about an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
classify the team malignant	0.0	0.0	0.0	2.0	0.0000000000	False
malignant cancer and benign	0.0	0.0	0.0	2.0	0.0000000000	False
cancer and benign cancer	0.0	0.0	0.0	2.0	0.0000000000	False
meaning a harmless cancer	0.0	0.0	0.0	2.0	0.0000000000	False
find the straight line	0.0	0.0	0.0	2.0	0.0000000000	False
separate the two classes	0.0	0.0	0.0	2.0	0.0000000000	False
cases of malignant cancers	0.0	0.0	0.0	2.0	0.0000000000	False
examples of malignant cancers	0.0	0.0	0.0	2.0	0.0000000000	False
examples of benign cancers	0.0	0.0	0.0	2.0	0.0000000000	False
ll build a model	0.0	0.0	0.99850224663	6.0	0.0000000000	False
model for what benign	0.0	0.0	0.0	2.0	0.0000000000	False
decide is this cancer	0.0	0.0	0.0	2.0	0.0000000000	False
cancer malignant or benign	0.0	0.0	0.0	2.0	0.0000000000	False
model of malignant cancers	0.0	0.0	0.0	2.0	0.0000000000	False
model of benign cancers	0.0	0.0	0.0	2.0	0.0000000000	False
depending on which model	0.0	0.0	0.0	2.0	0.0000000000	False
methods where you build	0.0	0.0	0.0	2.0	0.0000000000	False
build a second model	0.0	0.0	0.0	2.0	0.0000000000	False
model for malignant cancers	0.0	0.0	0.0	2.0	0.0000000000	False
separate model for benign	0.0	0.0	0.0	2.0	0.0000000000	False
model for benign cancers	0.0	0.0	0.0	2.0	0.0000000000	False
models that we ve	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis that outputs value	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm of models	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm of models pfx	0.0	0.0	0.0	2.0	0.0000000000	False
probability of the features	0.0	0.0	0.0	2.0	0.0000000000	False
features given the class	0.0	0.0	0.0	2.0	0.0000000000	False
builds a probabilistic model	0.0	0.0	0.0	2.0	0.0000000000	False
conditioned on the class	0.0	0.0	0.0	2.0	0.0000000000	False
features of the cancer	0.0	0.0	0.0	2.0	0.0000000000	False
model  having built	0.0	0.0	0.0	2.0	0.0000000000	False
model  generative learning	0.0	0.0	0.0	2.0	0.0000000000	False
generative learning algorithm starts	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm starts in modeling	0.0	0.0	0.0	2.0	0.0000000000	False
starts in modeling pfx	0.0	0.0	0.0	2.0	0.0000000000	False
discriminative model a bit	0.0	0.0	0.0	2.0	0.0000000000	False
assume that your input	0.0	0.0	0.0	2.0	0.0000000000	False
re going to assume	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant analysis model	0.0	0.0	4.99700449326	12.0	0.5308641975	False
model of that pfx	0.0	0.0	0.0	2.0	0.0000000000	False
ll be a refresher	0.0	0.0	0.0	2.0	0.0000000000	False
variable z is distributed	0.0	0.0	0.0	2.0	0.0000000000	False
formula for the density	0.0	0.0	0.0	4.0	0.0000000000	False
density as a generalization	0.0	0.0	0.0	2.0	0.0000000000	False
high dimension vector value	0.0	0.0	0.0	2.0	0.0000000000	False
dimension vector value random	0.0	0.0	0.0	2.0	0.0000000000	False
density you rarely end	0.0	0.0	0.0	2.0	0.0000000000	False
rarely end up needing	0.0	0.0	0.0	2.0	0.0000000000	False
quantities are this vector	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian and this matrix	0.0	0.0	0.0	2.0	0.0000000000	False
sigma is the covariance	0.0	0.0	0.0	2.0	0.0000000000	False
covariance matrix  covariance	0.0	0.0	0.0	2.0	0.0000000000	False
covariance of a vector	0.0	0.0	0.0	2.0	0.0000000000	False
re-watch the discussion section	0.0	0.0	0.0	2.0	0.0000000000	False
section that the tas	0.0	0.0	0.0	2.0	0.0000000000	False
tas held last friday	0.0	0.0	0.0	2.0	0.0000000000	False
holding later this week	0.0	0.0	0.0	2.0	0.0000000000	False
multi-grade gaussians is parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of a gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian with covariance matrix	0.0	0.0	0.0	2.0	0.0000000000	False
matrix equals the identity	0.0	0.0	0.0	2.0	0.0000000000	False
identity the covariance matrix	0.0	0.0	0.0	2.0	0.0000000000	False
covariance matrix is shown	0.0	0.0	0.0	2.0	0.0000000000	False
curve in two dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
shrink the covariance matrix	0.0	0.0	0.0	4.0	0.0000000000	False
diagonals of a covariance	0.0	0.0	0.0	2.0	0.0000000000	False
make the variables correlated	0.0	0.0	0.0	2.0	0.0000000000	False
show the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
standard normal of distribution	0.0	0.0	0.0	2.0	0.0000000000	False
increase the off diagonals	0.0	0.0	0.0	2.0	0.0000000000	False
density with negative covariances	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian with negative entries	0.0	0.0	0.0	2.0	0.0000000000	False
entries on the diagonals	0.0	0.0	0.0	4.0	0.0000000000	False
changed the mean parameter	0.0	0.0	0.0	2.0	0.0000000000	False
primer on what gaussians	0.0	0.0	0.0	2.0	0.0000000000	False
described the gaussian discriminant	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant analysis algorithm	0.0	0.0	0.0	4.0	0.0000000000	True
fit a gaussian distribution	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian densities will define	0.0	0.0	0.0	2.0	0.0000000000	False
out that the separator	0.0	0.0	0.0	2.0	0.0000000000	False
bound to be shown	0.0	0.0	0.0	2.0	0.0000000000	False
switch back to chalkboard	0.0	0.0	0.0	2.0	0.0000000000	False
put into model pfy	0.0	0.0	0.0	2.0	0.0000000000	False
pfy as a bernoulli	0.0	0.0	0.0	2.0	0.0000000000	False
parameterized by parameter phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi ; you ve	0.0	0.0	0.0	0.0	0.0000000000	False
excuse me i thought	0.0	0.0	0.0	2.0	0.0000000000	False
thought this looked strange	0.0	0.0	0.0	2.0	0.0000000000	False
determined in a sigma	0.0	0.0	0.0	2.0	0.0000000000	False
one-half of the denominator	0.0	0.0	0.0	2.0	0.0000000000	False
right i was listing	0.0	0.0	0.0	2.0	0.0000000000	False
sigma to the determining	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian with mean mew0	0.0	0.0	0.0	2.0	0.0000000000	False
mew0 and covariance sigma	0.0	0.0	0.0	2.0	0.0000000000	False
sigma to the sigma	0.0	0.0	0.0	2.0	0.0000000000	False
sigma to the minus	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of this model	0.0	0.0	0.0	2.0	0.0000000000	False
write down the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the parameters	0.0	0.0	3.99700449326	12.0	0.4154589372	False
parameters as the log	0.0	0.0	0.0	4.0	0.0000000000	False
write down the log	0.0	0.0	0.0	2.0	0.0000000000	False
probative probabilities of pfxi	0.0	0.0	0.0	2.0	0.0000000000	False
previously when we re	0.0	0.0	0.0	0.0	0.0000000000	False
talking about logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
log of a product	0.0	0.0	0.0	2.0	0.0000000000	False
parameterized by a theater	0.0	0.0	0.0	4.0	0.0000000000	False
back where we re	0.0	0.0	0.0	0.0	0.0000000000	False
re fitting logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
fitting logistic regression models	0.0	0.0	0.0	2.0	0.0000000000	False
regression models or generalized	0.0	0.0	0.0	2.0	0.0000000000	False
models or generalized learning	0.0	0.0	0.0	2.0	0.0000000000	False
re always modeling pfyi	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood which is pfxi	0.0	0.0	0.0	2.0	0.0000000000	False
analysis model to fit	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the model	0.0	0.0	5.99800299551	8.0	0.2935153584	False
ll do maximize likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
respect to the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
find the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood estimate of parameters	0.0	0.0	0.0	2.0	0.0000000000	False
practice for indicating notation	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood estimate for phi	0.0	0.0	3.99800299551	8.0	0.5243902439	False
phi would be sum	0.0	0.0	0.0	2.0	0.0000000000	False
written alternatively as sum	0.0	0.0	0.0	2.0	0.0000000000	False
training examples of indicator	0.0	0.0	0.0	2.0	0.0000000000	False
faction of training examples	0.0	0.0	0.0	2.0	0.0000000000	False
training examples with label	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood estimate for mew0	0.0	0.0	0.0	2.0	0.0000000000	False
sum of your training	0.0	0.0	0.0	2.0	0.0000000000	False
means that you re	0.0	0.0	0.0	0.0	0.0000000000	False
including only the times	0.0	0.0	0.0	2.0	0.0000000000	False
examples where the class	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	0.0	2.0	0.0000000000	False
find all the examples	0.0	0.0	0.0	2.0	0.0000000000	False
average of the value	0.0	0.0	0.0	2.0	0.0000000000	False
notation divide the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
divide the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood estimate for sigma	0.0	0.0	0.0	2.0	0.0000000000	False
fit the parameters find	0.0	0.0	0.0	2.0	0.0000000000	False
sigma to your data	0.0	0.0	0.0	2.0	0.0000000000	False
write semicolon the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
pfx does nt depend	0.0	0.0	0.0	0.0	0.0000000000	False
uniform in other words	0.0	0.0	0.0	2.0	0.0000000000	False
takes the same value	0.0	0.0	0.0	2.0	0.0000000000	False
value for all values	0.0	0.0	0.0	2.0	0.0000000000	False
formula where you compute	0.0	0.0	0.0	2.0	0.0000000000	False
pfy using your model	0.0	0.0	0.0	2.0	0.0000000000	False
min of  arcomatics	0.0	0.0	0.0	2.0	0.0000000000	False
arcomatics means the value	0.0	0.0	0.0	2.0	0.0000000000	False
loose here i meant	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over the set	0.0	0.0	0.0	2.0	0.0000000000	False
turns out gaussian discriminant	0.0	0.0	0.0	2.0	0.0000000000	False
out gaussian discriminant analysis	0.0	0.0	0.0	2.0	0.0000000000	False
relationship to logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression let me illustrate	0.0	0.0	0.0	2.0	0.0000000000	False
draw 1d training set	0.0	0.0	0.0	2.0	0.0000000000	False
run gaussian discriminate analysis	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative training	0.0	0.0	0.0	2.0	0.0000000000	False
examples i will fit	0.0	0.0	0.0	2.0	0.0000000000	False
top of this plot	0.0	0.0	0.0	2.0	0.0000000000	False
examples it just makes	0.0	0.0	0.0	2.0	0.0000000000	False
equal to one conditioned	0.0	0.0	0.0	2.0	0.0000000000	False
gaussians and my phi	0.0	0.0	0.0	2.0	0.0000000000	False
belongs to the left	0.0	0.0	0.0	2.0	0.0000000000	False
study a different value	0.0	0.0	0.0	2.0	0.0000000000	False
ll be pretty small	0.0	0.0	0.0	2.0	0.0000000000	False
densities have equal value	0.0	0.0	0.0	2.0	0.0000000000	False
shown by the arrow	0.0	0.0	0.0	2.0	0.0000000000	False
fill in a bunch	0.0	0.0	0.0	2.0	0.0000000000	False
belongs to this rightmost	0.0	0.0	0.0	2.0	0.0000000000	False
exercise for a bunch	0.0	0.0	0.0	2.0	0.0000000000	False
connect up these points	0.0	0.0	0.0	2.0	0.0000000000	False
find that the curve	0.0	0.0	0.0	2.0	0.0000000000	False
plotted takes a form	0.0	0.0	0.0	2.0	0.0000000000	False
form of sigmoid function	0.0	0.0	0.0	2.0	0.0000000000	False
function that we re	0.0	0.0	0.0	0.0	0.0000000000	False
out the key difference	0.0	0.0	0.0	2.0	0.0000000000	False
discriminant analysis will end	0.0	0.0	0.0	2.0	0.0000000000	False
choosing a different position	0.0	0.0	0.0	2.0	0.0000000000	False
position and a steepness	0.0	0.0	0.0	2.0	0.0000000000	False
sigmoid than would logistic	0.0	0.0	0.0	2.0	0.0000000000	False
drawing all the dots	0.0	0.0	0.0	2.0	0.0000000000	False
out where to draw	0.0	0.0	0.0	2.0	0.0000000000	False
right ? the steps	0.0	0.0	0.0	2.0	0.0000000000	False
fit a gaussian discriminant	0.0	0.0	0.0	2.0	0.0000000000	False
fit a bernoulli distribution	0.0	0.0	0.0	2.0	0.0000000000	False
bernoulli distribution to pfy	0.0	0.0	0.0	2.0	0.0000000000	False
pfy to my data	0.0	0.0	0.0	2.0	0.0000000000	False
ve chosen my parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of find mew0	0.0	0.0	0.0	2.0	0.0000000000	False
plot all these dots	0.0	0.0	0.0	2.0	0.0000000000	False
plug them into bayes	0.0	0.0	0.0	2.0	0.0000000000	False
right here so pfx	0.0	0.0	0.0	2.0	0.0000000000	False
pfx can be written	0.0	0.0	0.0	2.0	0.0000000000	False
talk a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit about the advantages	0.0	0.0	0.0	2.0	0.0000000000	False
case of gaussian discriminant	0.0	0.0	0.0	2.0	0.0000000000	False
assume that x conditions	0.0	0.0	0.0	2.0	0.0000000000	False
implies that the posterior	0.0	0.0	0.0	2.0	0.0000000000	False
distribution or the form	0.0	0.0	0.0	2.0	0.0000000000	False
turns out this implication	0.0	0.0	0.0	2.0	0.0000000000	False
direction does not hold	0.0	0.0	0.0	2.0	0.0000000000	False
hessian with parameter lambda	0.0	0.0	0.0	4.0	0.0000000000	False
out if you assumed	0.0	0.0	0.0	2.0	0.0000000000	False
assumption than the assumption	0.0	0.0	0.0	2.0	0.0000000000	False
right ? that means	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian but not vice	0.0	0.0	0.0	2.0	0.0000000000	False
tradeoffs between gaussian discriminant	0.0	0.0	0.0	2.0	0.0000000000	False
analysis and logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
right ? gaussian discriminant	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant analysis makes	0.0	0.0	0.0	2.0	0.0000000000	False
makes a much stronger	0.0	0.0	0.0	2.0	0.0000000000	False
explicit to the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
information about the data	0.0	0.0	0.0	2.0	0.0000000000	False
holds or roughly holds	0.0	0.0	0.0	2.0	0.0000000000	False
turns out the data	0.0	0.0	0.0	2.0	0.0000000000	False
data was actually poisson	0.0	0.0	0.0	2.0	0.0000000000	False
data were actually poisson	0.0	0.0	0.0	2.0	0.0000000000	False
out that  right	0.0	0.0	0.0	2.0	0.0000000000	False
slightly different it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out the real advantage	0.0	0.0	0.0	2.0	0.0000000000	False
advantage of generative learning	0.0	0.0	0.0	2.0	0.0000000000	False
right ? because data	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
assumptions are not met	0.0	0.0	0.0	2.0	0.0000000000	False
assumptions about the data	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression by making	0.0	0.0	0.0	2.0	0.0000000000	False
robust to your modeling	0.0	0.0	0.0	2.0	0.0000000000	False
assumptions because you re	0.0	0.0	0.0	0.0	0.0000000000	False
re making a weaker	0.0	0.0	0.0	2.0	0.0000000000	False
making a weaker assumption	0.0	0.0	0.0	2.0	0.0000000000	False
assumption ; you re	0.0	0.0	0.0	0.0	0.0000000000	False
re making less assumptions	0.0	0.0	0.0	2.0	0.0000000000	False
slightly larger training set	0.0	0.0	0.0	2.0	0.0000000000	False
training set to fit	0.0	0.0	0.0	2.0	0.0000000000	False
fit than gaussian discriminant	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant analysis question	0.0	0.0	0.0	2.0	0.0000000000	False
question ? in order	0.0	0.0	0.0	2.0	0.0000000000	False
assumption about the number	0.0	0.0	0.0	2.0	0.0000000000	False
true when the number	0.0	0.0	0.0	2.0	0.0000000000	False
differently so the marving	0.0	0.0	0.0	2.0	0.0000000000	False
marving assumptions are made	0.0	0.0	0.0	2.0	0.0000000000	False
independently of the size	0.0	0.0	0.0	2.0	0.0000000000	False
size of your training	0.0	0.0	0.0	2.0	0.0000000000	False
models i m assuming	0.0	0.0	0.0	0.0	0.0000000000	False
flowing from some distribution	0.0	0.0	0.0	2.0	0.0000000000	False
giving a single training	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
back to the philosophy	0.0	0.0	0.0	2.0	0.0000000000	False
philosophy of mass molecular	0.0	0.0	0.0	2.0	0.0000000000	False
assuming that they re	0.0	0.0	0.0	0.0	0.0000000000	False
value of y generating	0.0	0.0	0.0	2.0	0.0000000000	False
generating all my data	0.0	0.0	0.0	2.0	0.0000000000	False
two values of phi	0.0	0.0	0.0	2.0	0.0000000000	False
underlying value of phi	0.0	0.0	5.99850224663	6.0	0.0000000000	False
estimate of the value	0.0	0.0	0.0	2.0	0.0000000000	False
right so maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
estimate is my attempt	0.0	0.0	0.0	2.0	0.0000000000	False
estimate the true value	0.0	0.0	0.0	2.0	0.0000000000	False
distinguish between the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
tease to the friday	0.0	0.0	0.0	2.0	0.0000000000	False
mention one more thing	0.0	0.0	0.0	2.0	0.0000000000	False
exponential family with parameter	0.0	0.0	0.0	4.0	0.0000000000	False
gamma because we ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve seen gaussian right	0.0	0.0	0.0	2.0	0.0000000000	False
gamma exponential they re	0.0	0.0	0.0	0.0	0.0000000000	False
re actually a beta	0.0	0.0	0.0	2.0	0.0000000000	False
list of exponential family	0.0	0.0	0.0	2.0	0.0000000000	False
parameters than the posterior	0.0	0.0	0.0	2.0	0.0000000000	False
robustness of logistic regression	0.0	0.0	0.0	4.0	0.0000000000	False
regression to the choice	0.0	0.0	0.0	2.0	0.0000000000	False
choice of modeling assumptions	0.0	0.0	0.0	2.0	0.0000000000	False
out to be logistic	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression to modeling	0.0	0.0	0.0	2.0	0.0000000000	False
regression to modeling assumptions	0.0	0.0	0.0	2.0	0.0000000000	False
early on i promised	0.0	0.0	0.0	2.0	0.0000000000	False
pulled the logistic function	0.0	0.0	0.0	2.0	0.0000000000	False
out of the hat	0.0	0.0	0.0	2.0	0.0000000000	False
modeling assumptions also lead	0.0	0.0	0.0	2.0	0.0000000000	False
logistic then this implies	0.0	0.0	0.0	2.0	0.0000000000	False
exponential family distribution implies	0.0	0.0	0.0	2.0	0.0000000000	False
rise to logistic function	0.0	0.0	0.0	2.0	0.0000000000	False
first generative learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
spam classification all right	0.0	0.0	0.0	2.0	0.0000000000	False
build a spam classifier	0.0	0.0	0.0	2.0	0.0000000000	False
incoming stream of email	0.0	0.0	0.0	2.0	0.0000000000	False
email using a feature	0.0	0.0	0.0	2.0	0.0000000000	False
words or a list	0.0	0.0	0.0	2.0	0.0000000000	False
list of ascii characters	0.0	0.0	0.0	2.0	0.0000000000	False
email as a feature	0.0	0.0	0.0	2.0	0.0000000000	False
ll use a couple	0.0	0.0	0.0	2.0	0.0000000000	False
couple of different representations	0.0	0.0	0.0	2.0	0.0000000000	False
words in my dictionary	0.0	0.0	1.99850224663	6.0	0.0000000000	False
telling you to buy	0.0	0.0	0.0	2.0	0.0000000000	False
words via other emails	0.0	0.0	0.0	2.0	0.0000000000	False
technological chemistry that deals	0.0	0.0	0.0	2.0	0.0000000000	False
deals with the fermentation	0.0	0.0	0.0	2.0	0.0000000000	False
fermentation process in brewing	0.0	0.0	0.0	2.0	0.0000000000	False
scan through this list	0.0	0.0	0.0	2.0	0.0000000000	False
appears in my email	0.0	0.0	0.0	2.0	0.0000000000	False
email has the word	0.0	0.0	0.0	2.0	0.0000000000	False
nt have the words	0.0	0.0	0.0	0.0	0.0000000000	False
words ausworth or aardvark	0.0	0.0	0.0	2.0	0.0000000000	False
cs229 does nt occur	0.0	0.0	0.0	0.0	0.0000000000	False
creating a feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
feature vector to represent	0.0	0.0	0.0	2.0	0.0000000000	False
throw the generative model	0.0	0.0	0.0	2.0	0.0000000000	False
value vectors they re	0.0	0.0	0.0	0.0	0.0000000000	False
words in your dictionary	0.0	0.0	0.0	4.0	0.0000000000	False
50,000 possible bit vectors	0.0	0.0	0.0	2.0	0.0000000000	False
bit vectors of length	0.0	0.0	0.0	2.0	0.0000000000	False
two to 50,000 possibilities	0.0	0.0	0.0	4.0	0.0000000000	False
re going to make	0.0	0.0	0.0	2.0	0.0000000000	False
strong assumption on pfx	0.0	0.0	0.0	2.0	0.0000000000	False
out what it means	0.0	0.0	0.0	2.0	0.0000000000	False
key rule of probability	0.0	0.0	0.0	2.0	0.0000000000	False
pfx1 given y times	0.0	0.0	0.0	2.0	0.0000000000	False
ll just put dot	0.0	0.0	0.0	2.0	0.0000000000	False
chain were of probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability this always holds	0.0	0.0	0.0	2.0	0.0000000000	False
re gon na meet	0.0	0.0	0.0	2.0	0.0000000000	False
assumption that x defies	0.0	0.0	0.0	2.0	0.0000000000	False
assume that that term	0.0	0.0	0.0	2.0	0.0000000000	False
means assume that pfx1	0.0	0.0	0.0	2.0	0.0000000000	False
informally what this means	0.0	0.0	0.0	2.0	0.0000000000	False
spam or not spam	0.0	0.0	8.99650524214	14.0	0.3355629877	False
knowing whether the word	0.0	0.0	0.0	2.0	0.0000000000	False
email does not affect	0.0	0.0	0.0	2.0	0.0000000000	False
appears in the email	0.0	0.0	4.99800299551	8.0	0.2935153584	False
knowing whether other words	0.0	0.0	0.0	2.0	0.0000000000	False
nt help you predict	0.0	0.0	0.0	0.0	0.0000000000	False
right ? this assumption	0.0	0.0	0.0	2.0	0.0000000000	False
nt possibly be true	0.0	0.0	0.0	0.0	0.0000000000	False
cs229 in an email	0.0	0.0	0.0	2.0	0.0000000000	False
effective algorithm for classifying	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for classifying text	0.0	0.0	0.0	2.0	0.0000000000	False
text documents into spam	0.0	0.0	0.0	2.0	0.0000000000	False
emails into different emails	0.0	0.0	0.0	2.0	0.0000000000	False
web pages and classifying	0.0	0.0	0.0	2.0	0.0000000000	False
classifying whether this webpage	0.0	0.0	0.0	2.0	0.0000000000	False
ll talk a bit	0.0	0.0	0.0	2.0	0.0000000000	False
digression that ll make	0.0	0.0	0.0	0.0	0.0000000000	False
important to our purposes	0.0	0.0	0.0	2.0	0.0000000000	False
find that the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of the parameters	0.0	0.0	5.99850224663	6.0	0.0000000000	False
expect maximum likelihood estimate	0.0	0.0	0.0	2.0	0.0000000000	False
count up the number	0.0	0.0	0.0	2.0	0.0000000000	False
times you saw word	0.0	0.0	0.0	2.0	0.0000000000	False
spam emails and count	0.0	0.0	0.0	2.0	0.0000000000	False
jay  appeared out	0.0	0.0	0.0	2.0	0.0000000000	False
number of spam emails	0.0	0.0	0.0	2.0	0.0000000000	False
emails in your training	0.0	0.0	0.0	2.0	0.0000000000	False
fraction of these emails	0.0	0.0	0.0	2.0	0.0000000000	False
emails did the word	0.0	0.0	0.0	2.0	0.0000000000	False
jay  you wrote	0.0	0.0	0.0	2.0	0.0000000000	False
wrote in your dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for the probability	0.0	0.0	0.0	4.0	0.0000000000	False
conditions on the piece	0.0	0.0	0.0	2.0	0.0000000000	False
similar to your maximum	0.0	0.0	0.0	2.0	0.0000000000	False
estimated all these parameters	0.0	0.0	0.0	2.0	0.0000000000	False
elaboration to this idea	0.0	0.0	0.0	2.0	0.0000000000	False
depend on the number	0.0	0.0	0.0	4.0	0.0000000000	False
number of training examples	0.0	0.0	5.99850224663	6.0	0.0000000000	False
formula for the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
compute the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood estimates is training	0.0	0.0	0.0	2.0	0.0000000000	False
estimates is training examples	0.0	0.0	0.0	2.0	0.0000000000	False
two months and label	0.0	0.0	0.0	2.0	0.0000000000	False
label them as spam	0.0	0.0	0.0	2.0	0.0000000000	False
emails labeled as spam	0.0	0.0	0.0	2.0	0.0000000000	False
comprise your training sets	0.0	0.0	0.0	2.0	0.0000000000	False
vectors representing which words	0.0	0.0	0.0	2.0	0.0000000000	False
representing which words appeared	0.0	0.0	0.0	2.0	0.0000000000	False
model does nt depend	0.0	0.0	0.0	0.0	0.0000000000	False
depend on the models	0.0	0.0	0.0	2.0	0.0000000000	False
assumptions are nt made	0.0	0.0	0.0	0.0	0.0000000000	False
making the naive bayes	0.0	0.0	0.0	2.0	0.0000000000	False
model is an assumption	0.0	0.0	0.0	2.0	0.0000000000	False
fixed number of training	0.0	0.0	0.0	2.0	0.0000000000	False
write the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
common way to count	0.0	0.0	0.0	2.0	0.0000000000	False
times in your training	0.0	0.0	0.0	2.0	0.0000000000	False
training set so words	0.0	0.0	0.0	2.0	0.0000000000	False
times in the emails	0.0	0.0	0.0	2.0	0.0000000000	False
nice way of thinking	0.0	0.0	0.0	2.0	0.0000000000	False
creating your feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
compute all those parameters	0.0	0.0	0.0	2.0	0.0000000000	False
generous of learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
pfy will be parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
changing bullets my model	0.0	0.0	0.0	2.0	0.0000000000	False
product of these probabilities	0.0	0.0	0.0	2.0	0.0000000000	False
probability of each word	0.0	0.0	0.0	2.0	0.0000000000	False
occurring or not occurring	0.0	0.0	0.0	2.0	0.0000000000	False
conditions on the email	0.0	0.0	0.0	2.0	0.0000000000	False
defined the feature vectors	0.0	0.0	0.0	4.0	0.0000000000	False
depending on whether words	0.0	0.0	0.0	2.0	0.0000000000	False
right i should move	0.0	0.0	0.0	2.0	0.0000000000	False
out that this idea	0.0	0.0	0.0	2.0	0.0000000000	False
class and you start	0.0	0.0	0.0	2.0	0.0000000000	False
working on your class	0.0	0.0	0.0	2.0	0.0000000000	False
project for a bit	0.0	0.0	0.0	2.0	0.0000000000	False
submit your class project	0.0	0.0	0.0	2.0	0.0000000000	False
project to a conference	0.0	0.0	0.0	2.0	0.0000000000	False
year is the conference	0.0	0.0	0.0	2.0	0.0000000000	False
send your project partners	0.0	0.0	0.0	2.0	0.0000000000	False
partners or senior friends	0.0	0.0	0.0	2.0	0.0000000000	False
work on a project	0.0	0.0	0.0	2.0	0.0000000000	False
re getting these emails	0.0	0.0	0.0	2.0	0.0000000000	False
emails with the word	0.0	0.0	0.0	2.0	0.0000000000	False
paper to the nips	0.0	0.0	0.0	2.0	0.0000000000	False
classifier will say pfx	0.0	0.0	0.0	2.0	0.0000000000	False
nips is also estimated	0.0	0.0	0.0	2.0	0.0000000000	False
classifier goes to compute	0.0	0.0	0.0	2.0	0.0000000000	False
right here  pfy	0.0	0.0	0.0	2.0	0.0000000000	False
turns out the denominator	0.0	0.0	0.0	2.0	0.0000000000	False
end up with pfy	0.0	0.0	0.0	2.0	0.0000000000	False
undefined and the problem	0.0	0.0	0.0	2.0	0.0000000000	False
statistically a bad idea	0.0	0.0	0.0	2.0	0.0000000000	False
nt seen the word	0.0	0.0	0.0	0.0	0.0000000000	False
last two months worth	0.0	0.0	0.0	2.0	0.0000000000	False
months worth of email	0.0	0.0	0.0	2.0	0.0000000000	False
nips in future emails	0.0	0.0	0.0	2.0	0.0000000000	False
emails ; the chance	0.0	0.0	0.0	2.0	0.0000000000	False
re gon na fix	0.0	0.0	0.0	2.0	0.0000000000	False
fix i ll talk	0.0	0.0	0.0	0.0	0.0000000000	False
losses to gather statistics	0.0	0.0	0.0	2.0	0.0000000000	False
form a betting pool	0.0	0.0	0.0	2.0	0.0000000000	False
re likely to win	0.0	0.0	0.0	2.0	0.0000000000	False
lose the next game	0.0	0.0	0.0	2.0	0.0000000000	False
last season they played	0.0	0.0	0.0	2.0	0.0000000000	False
season they played washington	0.0	0.0	0.0	2.0	0.0000000000	False
22nd they played usc	0.0	0.0	0.0	2.0	0.0000000000	False
ll win or lose	0.0	0.0	0.0	2.0	0.0000000000	False
right ? so find	0.0	0.0	0.0	2.0	0.0000000000	False
find the four guys	0.0	0.0	0.0	2.0	0.0000000000	False
four guys last year	0.0	0.0	0.0	2.0	0.0000000000	False
year or five times	0.0	0.0	0.0	2.0	0.0000000000	False
idea behind laplace smoothing	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood is the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of ones divided	0.0	0.0	0.0	2.0	0.0000000000	False
divided by the number	0.0	0.0	0.0	2.0	0.0000000000	False
zeros plus the number	0.0	0.0	0.0	2.0	0.0000000000	False
hope this informal notation	0.0	0.0	0.0	2.0	0.0000000000	False
informal notation makes sense	0.0	0.0	0.0	2.0	0.0000000000	False
knowing the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
loss for bernoulli random	0.0	0.0	0.0	2.0	0.0000000000	False
total number of examples	0.0	0.0	0.0	2.0	0.0000000000	False
laplace smoothing we re	0.0	0.0	0.0	0.0	0.0000000000	False
winning the next game	0.0	0.0	13.9965052421	14.0	0.2590361446	False
chance of their winning	0.0	0.0	0.0	2.0	0.0000000000	False
games in a row	0.0	0.0	0.0	4.0	0.0000000000	False
probability that the sun	0.0	0.0	0.0	4.0	0.0000000000	False
sun will rise tomorrow	0.0	0.0	5.99850224663	6.0	0.0000000000	False
ve seen the sun	0.0	0.0	0.0	2.0	0.0000000000	False
absolutely certain the sun	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to estimate	0.0	0.0	0.0	2.0	0.0000000000	False
estimate will be sum	0.0	0.0	0.0	2.0	0.0000000000	False
two to the denominator	0.0	0.0	0.0	2.0	0.0000000000	False
friend sends you email	0.0	0.0	0.0	2.0	0.0000000000	False
email about the nips	0.0	0.0	0.0	2.0	0.0000000000	False
make a meaningful prediction	0.0	0.0	0.0	2.0	0.0000000000	False
right ? okay shoot	0.0	0.0	0.0	2.0	0.0000000000	False
games on the right	0.0	0.0	0.0	2.0	0.0000000000	False
assumptions that the probability	0.0	0.0	0.0	2.0	0.0000000000	False
nt have a lot	0.0	0.0	0.0	0.0	0.0000000000	False
case anywhere the learning	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for the chance	0.0	0.0	0.0	2.0	0.0000000000	False
re saying the chances	0.0	0.0	0.0	2.0	0.0000000000	False
set of bayesian assumptions	0.0	0.0	0.0	2.0	0.0000000000	False
assumptions about the prior	0.0	0.0	0.0	2.0	0.0000000000	False
prior on the parameter	0.0	0.0	0.0	2.0	0.0000000000	False
pretty good basketball team	0.0	0.0	0.0	2.0	0.0000000000	False
chose a losing streak	0.0	0.0	0.0	2.0	0.0000000000	False
announcement and reminder	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
handout was posted	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
website last week	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt yet downloaded	0.0	0.0	0.0	0.0	0.0000000000	False
final project presentation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
today is talk	0.00147032391634	0.0	0.0	3.16992500144	0.0000000000	False
type of learning	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
start to talk	0.000516204230291	0.0	0.0	1.58496250072	0.0000000000	False
talk about generative	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
generative learning algorithms	0.0104953165466	1.0	6.99450823764	15.8496250072	0.4473988439	True
algorithm called gaussian	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
gaussian discriminant analysis	0.017346790146	1.0	12.9895157264	30.1142875137	0.4079696395	True
talk about gaussians	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
ll briefly discuss	0.0	0.0	0.0	1.58496250072	0.0000000000	False
briefly discuss generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discuss generative versus	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
generative versus discriminative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
versus discriminative learning	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discriminative learning algorithms	0.00477059843026	0.0	3.99750374438	6.33985000288	0.0000000000	True
wrap up today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
discussion of naive	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
motivate our discussion	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
discussion on generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
source of classification	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve been talking	0.0	0.0	0.0	3.16992500144	0.0000000000	False
run an algorithm	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
find a straight	0.00286235905816	0.0	2.99850224663	0.0	0.0000000000	False
line to divide	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
divide the crosses	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make the days	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
days a bit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
line that separates	0.00147032391634	0.0	0.0	1.58496250072	0.0000000000	False
out the positive	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
pass the law	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
set with logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
initialized the parameters	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
hypothesis that iteration	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
straight line shown	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
iteration and creating	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
logistic regression converges	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
found the straight	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
separates the positive	0.00121415979624	0.0	0.0	3.16992500144	0.0000000000	False
positive and negative	0.00103240846058	0.0	0.0	1.58496250072	0.0000000000	False
classify the team	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
team malignant cancer	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
cancer and benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
meaning a harmless	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
find the straight	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
line to separate	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
cases of malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
examples of malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
build a model	0.00413018812999	0.0	1.99750374438	3.16992500144	0.3726169844	False
examples of benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
malignant or benign	0.00381647874421	0.0	2.99800299551	4.75488750216	0.0000000000	False
model of malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model of benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model it matches	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
cancer is malignant	0.0019082393721	0.0	0.0	3.16992500144	0.0000000000	False
cross of methods	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
model for malignant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model for benign	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
learns a hypothesis	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that outputs	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
algorithm in contrast	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
algorithm of models	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
generative model builds	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
builds a probabilistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
models probability distribution	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
built this model	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
built a model	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
model for pfx	0.00703846448359	0.0	1.99700449326	9.50977500433	0.3957055215	False
pfx  pfx	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
calculate the denominator	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
back to pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
model  generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
learning algorithm starts	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
starts in modeling	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model a bit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discriminant analysis model	0.00572471811631	0.0	4.99700449326	0.0	0.5308641975	False
raise your hand	0.000831216253916	0.0	0.0	3.16992500144	0.0000000000	False
words about gaussians	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
normal with parameters	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
covariance sigma squared	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
dimension of gaussians	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
familiar bell-shape curve	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
high dimension vector	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
dimension vector value	0.0	0.0	0.0	0.0	0.0000000000	False
vector value random	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
value random variable	0.00117307741393	0.0	0.0	3.16992500144	0.0000000000	False
end up needing	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
two key quantities	0.0	0.0	0.0	1.58496250072	0.0000000000	False
matrix  covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
definition of covariance	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt look familiar	0.0	0.0	0.0	0.0	0.0000000000	False
re-watch the discussion	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
tas held last	0.0	0.0	0.0	0.0	0.0000000000	False
held last friday	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll be holding	0.0	0.0	0.0	1.58496250072	0.0000000000	False
recap of probability	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussians is parameterized	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
effects of varying	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
varying a gaussian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussian  varying	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
varying the parameters	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
gaussian with covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
covariance matrix equals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equals the identity	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
identity the covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
matrix is shown	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
upper right-hand corner	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
shrink the covariance	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
covariance your identity	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
widen the covariance	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
stand at normal	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
increase the diagonals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make the variables	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
gaussian becomes flattened	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
right  excuse	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll just show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
thing in contours	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
contours the standard	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
normal of distribution	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
distribution has contours	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
re actually circles	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian covariance matrix	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
density with negative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
strong of covariance	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussian with negative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
gaussian just moves	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
described the gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
discriminant analysis algorithm	0.0019082393721	0.0	0.0	0.0	0.0000000000	False
fit a gaussian	0.0035192322418	0.0	3.99850224663	3.16992500144	0.0000000000	False
two gaussian densities	0.0	0.0	0.0	3.16992500144	0.0000000000	False
densities will define	0.0	0.0	0.0	0.0	0.0000000000	False
define a separator	0.0	0.0	0.0	1.58496250072	0.0000000000	False
separator will turn	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
run logistic regression	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
back to chalkboard	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
put into model	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
bernoulli random variable	0.00286235905816	0.0	3.99850224663	4.75488750216	0.0000000000	False
variable as usual	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
variable and parameterized	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
parameterized by parameter	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
thought this looked	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
listing the sigma	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
determining the sigma	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
mew0 and covariance	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
model are phi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
probabilities of pfxi	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
equations on top	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
joint data likelihood	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	True
talking about logistic	0.000826037625999	0.0	0.0	0.0	0.0000000000	False
parameter s theater	0.0	0.0	0.0	0.0	0.0000000000	False
theater was log	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
re fitting logistic	0.0	0.0	0.0	0.0	0.0000000000	False
fitting logistic regression	0.000664673313974	0.0	0.0	0.0	0.0000000000	False
logistic regression models	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
models or generalized	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
generalized learning models	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
re always modeling	0.0	0.0	0.0	0.0	0.0000000000	False
re modeling pfyi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
regenerative learning algorithms	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	True
model to fit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
fit the parameters	0.002478112878	0.0	1.99850224663	3.16992500144	0.0000000000	False
ll do maximize	0.0	0.0	0.0	0.0	0.0000000000	False
maximize likelihood estimation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
estimation as usual	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
find the maximum	0.000664673313974	0.0	0.0	0.0	0.0000000000	False
maximum likelihood estimate	0.0145699175548	0.0	15.988017973	36.4541375166	0.2927066451	False
estimate of parameters	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
find that phi	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
practice for indicating	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
estimate for phi	0.00469230965573	0.0	3.99800299551	0.0	0.5243902439	False
alternatively as sum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
examples of indicator	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
newly parameter phi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
faction of training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
examples with label	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
estimate for mew0	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	3.16992500144	0.0000000000	False
denominator is sum	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
increment the count	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
number of examples	0.00220548587451	0.0	1.99850224663	3.16992500144	0.0000000000	False
indicator function means	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
negative fitting examples	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
examples and average	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
average the values	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
home and stare	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
divide the maximum	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
estimate for sigma	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
parameters find mew0	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make a prediction	0.000607079898118	0.0	0.0	1.58496250072	0.0000000000	False
benign your prediction	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
semicolon the parameters	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll just give	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pfy is uniform	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
give us arc	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
means the value	0.0	0.0	0.0	0.0	0.0000000000	False
choosing x equals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
squared is equal	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
makes this minimize	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
uniform i meant	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
meant if pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal to pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
turns out gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
out gaussian discriminant	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
relationship to logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
draw 1d training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
kind of work	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
training set comprising	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
run gaussian discriminate	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll fit gaussians	0.0	0.0	0.0	1.58496250072	0.0000000000	False
negative training examples	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
overlay on top	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
variety of values	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
makes this part	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
formulas as usual	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.00147032391634	0.0	0.0	3.16992500144	0.0000000000	False
phi on pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
compute what pfy	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
increment the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
densities have equal	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
bunch more points	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
repeat this exercise	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
bunch of points	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
points all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
compute pfy equals	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
takes a form	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
form of sigmoid	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
make the assumptions	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
back and compute	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
out the key	0.000826037625999	0.0	0.0	0.0	0.0000000000	False
analysis will end	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
end up choosing	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
gaussian of pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
gaussian is pfx	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
draw each dot	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll also fit	0.0	0.0	0.0	1.58496250072	0.0000000000	False
fit a bernoulli	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
distribution to pfy	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll fit pfx	0.0	0.0	0.0	1.58496250072	0.0000000000	False
chosen my parameters	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
parameters of find	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
pick a point	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
advantages and disadvantages	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
case of gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
argument i showed	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
back and prove	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
write logistic posterior	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
home and prove	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
form of pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
out this implication	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
cool it turns	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
hessian with parameter	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
implies that pfy	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
lots of assumptions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lead to pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
logistic posterior holds	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
tradeoffs between gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
analysis and logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
right ? gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
discriminant analysis makes	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
assumption is true	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumption approximately holds	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
plot the data	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
make this assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
algorithm is making	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data the algorithm	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data is gaussian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data was gaussian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
out the data	0.00117307741393	0.0	2.99850224663	3.16992500144	0.0000000000	False
out the real	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
advantage of generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
requires less data	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
making stronger assumptions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
data in order	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
order to fit	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
regression by making	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
making less assumption	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
making a weaker	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
slightly larger training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
larger training set	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
set to fit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
fit than gaussian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
discriminant analysis question	0.0	0.0	0.0	0.0	0.0000000000	False
order to meet	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
meet any assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assume that pfy	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal two number	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
number of samples	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
samples is marginal	0.0	0.0	0.0	1.58496250072	0.0000000000	False
translate that differently	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumptions are made	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
random variables flowing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
giving a single	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
single training set	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
philosophy of mass	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
mass molecular estimation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pfy is equal	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
values of phi	0.00234615482786	0.0	9.99750374438	4.75488750216	0.3440000000	False
true underlying value	0.00117307741393	0.0	7.99800299551	6.33985000288	0.2935153584	False
phi that guards	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
generate the data	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
writing those formulas	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
formulas are writing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
writing for phi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
right so maximum	0.0	0.0	0.0	0.0	0.0000000000	False
attempt to estimate	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
estimate the true	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
notational and convention	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
bothering to distinguish	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hoping to estimate	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
sample of questions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
hope to tease	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
friday discussion section	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
family with parameter	0.0019082393721	0.0	0.0	0.0	0.0000000000	False
cool it means	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
ve seen gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
exponential they re	0.0	0.0	0.0	0.0	0.0000000000	False
list of exponential	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
exponential family extrusions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
exponential family distribution	0.0019082393721	0.0	0.0	1.58496250072	0.0000000000	False
shows the robustness	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
robustness of logistic	0.00234615482786	0.0	0.0	0.0	0.0000000000	False
choice of modeling	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
regression to modeling	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
promised two justifications	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pulled the logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
exponential family derivation	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumptions also lead	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
family distribution implies	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
rise to logistic	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
first generative learning	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
naive bayes algorithm	0.0035192322418	1.0	1.99850224663	4.75488750216	0.0000000000	True
classification all right	0.0	0.0	0.0	0.0	0.0000000000	False
build a spam	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
stream of email	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
email and decide	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
piece of email	0.00858707717447	0.0	8.99550673989	14.2646625065	0.3900226757	False
represent a piece	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
piece of text	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
right ? email	0.0	0.0	0.0	1.58496250072	0.0000000000	False
list of words	0.00703846448359	0.0	8.99650524214	11.094737505	0.0000000000	False
list of ascii	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
feature of vector	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
ll use today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
construct the vector	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
make a listing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
dictionary is aardvark	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
word  buy	0.0	0.0	0.0	1.58496250072	0.0000000000	False
spam email telling	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
collect your list	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt find cs229	0.0	0.0	0.0	0.0	0.0000000000	False
collect a list	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
emails you ve	0.0	0.0	0.0	0.0	0.0000000000	False
dictionary was zicmergue	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
chemistry that deals	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
process in brewing	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll then scan	0.0	0.0	0.0	1.58496250072	0.0000000000	False
word  aid	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ausworth or aardvark	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
creating a feature	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
vector to represent	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
throw the generative	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
binary value vectors	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
vectors they re	0.0	0.0	0.0	0.0	0.0000000000	False
re n dimensional	0.0	0.0	0.0	1.58496250072	0.0000000000	False
atypical so values	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
mid-thousands to tens	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
tens of thousands	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
typical for problems	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
50,000 possible values	0.0019082393721	0.0	0.0	3.16992500144	0.0000000000	False
50,000 possible bit	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
vectors of length	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
parameters to model	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assumption on pfx	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
rule of probability	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
ll just put	0.0	0.0	0.0	0.0	0.0000000000	False
holds i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve not made	0.0	0.0	0.0	1.58496250072	0.0000000000	False
made any assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
naive bayes assumption	0.0035192322418	0.0	2.99850224663	4.75488750216	0.0000000000	False
assume that pfx3	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
equal to pfx2	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
term s equal	0.0	0.0	0.0	0.0	0.0000000000	False
equal to pfx3	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
assume that pfx1	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
50,000 or pfxi	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
appears in email	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
affect the probability	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
word  ausworth	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ausworth  appears	0.0	0.0	0.0	1.58496250072	0.0000000000	False
email is spam	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
assumption is false	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
possibly be true	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
false under english	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
normal written english	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
extremely effective algorithm	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for classifying	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
classifying text documents	0.0019082393721	0.0	0.0	3.16992500144	0.0000000000	False
documents into spam	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
classifying your emails	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pages and classifying	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
talk a bit	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
ll make sense	0.0	0.0	0.0	1.58496250072	0.0000000000	False
familiar with bayesian	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
bayesian x world	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
expect maximum likelihood	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
entire training set	0.000735161958171	0.0	0.0	1.58496250072	0.0000000000	False
number of times	0.000607079898118	0.0	0.0	1.58496250072	0.0000000000	False
word  jay	0.0	0.0	7.99800299551	6.33985000288	0.2935153584	False
emails and count	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
count the number	0.000826037625999	0.0	0.0	1.58496250072	0.0000000000	False
number of emails	0.00117307741393	0.0	0.0	3.16992500144	0.0000000000	False
jay  appeared	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of spam	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
spam the denominator	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
jay  conditions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
email being spam	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
number of inputs	0.00117307741393	0.0	0.0	3.16992500144	0.0000000000	False
number of features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of training	0.00220548587451	0.0	5.99850224663	1.58496250072	0.0000000000	False
compute the maximum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
estimates is training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
email i ve	0.0	0.0	0.0	0.0	0.0000000000	False
last two months	0.0	0.0	3.99850224663	3.16992500144	0.0000000000	False
months and label	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
hundred emails labeled	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
labeled as spam	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
comprise your training	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
representing which words	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
re different things	0.0	0.0	0.0	1.58496250072	0.0000000000	False
making the naive	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
write the maximum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
count this list	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
count a list	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
set so words	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
tests i ve	0.0	0.0	0.0	0.0	0.0000000000	False
select these features	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
creating your feature	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
parameters ? correct	0.0	0.0	0.0	1.58496250072	0.0000000000	False
generous of learning	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
bullets my model	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
assume that pfx	0.00117307741393	0.0	1.99850224663	4.75488750216	0.0000000000	False
defined the feature	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
constructed my features	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
features for email	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
idea almost works	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
complete this class	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
submit your class	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
june every year	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
send your project	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
partners or senior	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
project and submit	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
word  nips	0.0	0.0	0.0	1.58496250072	0.0000000000	False
send a paper	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
compute this right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the denominator	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
statistically a bad	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
worth of email	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
statistically not sound	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nips in future	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
motivate the fix	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
stanford basketball team	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
tracking their wins	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
wins and losses	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
losses to gather	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
form a betting	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
win or lose	0.00234615482786	0.0	0.0	1.58496250072	0.0000000000	False
8th of february	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
february last season	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
season they played	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
played washington state	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
11th of february	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
22nd they played	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
lose against louisville	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
four guys last	0.0	0.0	0.0	0.0	0.0000000000	False
guys last year	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
idea behind laplace	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
number of zeros	0.0035192322418	0.0	5.99850224663	4.75488750216	0.0000000000	False
hope this informal	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
informal notation makes	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
notation makes sense	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
right ? knowing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
knowing the maximum	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
win or loss	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
loss for bernoulli	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
smoothing we re	0.0	0.0	0.0	0.0	0.0000000000	False
zeros and add	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
estimating the probability	0.002478112878	0.0	7.99800299551	6.33985000288	0.4154589372	False
probability of winning	0.00234615482786	0.0	0.0	3.16992500144	0.0000000000	False
historical side note	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
sun will rise	0.0035192322418	0.0	5.99850224663	0.0	0.0000000000	False
lot of days	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
estimate the parameter	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
apply laplace smoothing	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
numerator and adding	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
solves the problem	0.000735161958171	0.0	0.0	1.58496250072	0.0000000000	False
sends you email	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
make a meaningful	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
shoot any questions	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
nt makes sense	0.0	0.0	0.0	0.0	0.0000000000	False
case the prediction	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lose five games	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lot of faith	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
lose one game	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
chances of winning	0.00469230965573	0.0	7.99800299551	6.33985000288	0.2544378698	False
instance we re	0.0	0.0	0.0	0.0	0.0000000000	False
set of assumptions	0.000954119686052	0.0	0.0	1.58496250072	0.0000000000	False
set of bayesian	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
prior and posterior	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pretty reasonable assumption	0.00117307741393	0.0	0.0	1.58496250072	0.0000000000	False
pretty good basketball	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
good basketball team	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
chose a losing	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
good morning	0.000277072084639	0.0	0.0	1.0	0.0000000000	False
quick announcement	0.000404719932079	0.0	0.0	0.0	0.0000000000	False
project guidelines	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
last week	0.0	0.0	0.0	0.0	0.0000000000	False
project proposal	0.000443115542649	0.0	0.0	1.0	0.0000000000	False
project milestone	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
final project	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
project presentation	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
learning algorithm	0.00517496226984	0.0	10.9900149775	18.0	0.4188311688	False
generative learning	0.00660830100799	0.0	6.99400898652	10.0	0.4188311688	False
specific algorithm	0.00110138350133	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant	0.011564526764	0.0	12.9895157264	19.0	0.4221598878	False
discriminant analysis	0.011564526764	0.0	12.9895157264	18.0	0.4079696395	False
slight digression	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
generative versus	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
discriminative learning	0.00318039895351	0.0	3.99750374438	3.0	0.3242835596	False
naive bayes	0.00860256770217	0.0	6.99450823764	9.0	0.4710485133	False
laplace smoothing	0.00381647874421	0.0	9.99700449326	6.0	0.4154589372	True
classification algorithms	0.000443115542649	0.0	0.0	1.0	0.0000000000	False
training set	0.00803509045452	0.0	15.9855217174	28.0	0.4171075838	False
logistic regression	0.00688272307055	1.0	9.99001497753	19.0	0.4613733906	False
straight line	0.00240895307469	0.0	6.99650524214	6.0	0.2590361446	False
bit noisier	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
negative classes	0.00147032391634	0.0	2.99850224663	2.0	0.0000000000	False
small monitors	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
data set	0.000297143724062	0.0	0.0	1.0	0.0000000000	False
line shown	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
bottom right	0.0	0.0	0.0	1.0	0.0000000000	False
creating descent	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
regression converges	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
team malignant	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
malignant cancer	0.00469230965573	0.0	5.99700449326	5.0	0.0000000000	False
benign cancer	0.00391025804644	0.0	4.99750374438	4.0	0.0000000000	False
harmful cancer	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
harmless cancer	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
positive examples	0.00547436126502	0.0	6.99650524214	7.0	0.0000000000	False
cancer malignant	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
separate model	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
learns pfy	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
outputs value	0.0	0.0	0.0	0.0	0.0000000000	False
models pfx	0.00445255853491	0.0	4.99600599101	7.0	0.4321608040	False
class label	0.00132934662795	0.0	1.99850224663	3.0	0.0000000000	False
technical detail	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
important thing	0.000319331892043	0.0	0.0	1.0	0.0000000000	False
generative model	0.0019082393721	0.0	1.99850224663	2.0	0.0000000000	False
model builds	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
probabilistic model	0.0012721595814	0.0	0.0	1.0	0.0000000000	False
models probability	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
probability distribution	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
bayes rule	0.00330415050399	0.0	3.99700449326	6.0	0.3957055215	True
compute pfy	0.0062564128743	0.0	3.99600599101	7.0	0.3900226757	False
modeling pfy	0.001652075252	0.0	3.99800299551	3.0	0.0000000000	False
algorithm starts	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
worse idea	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
discriminative model	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
specific motivating	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
input feature	0.000443115542649	0.0	0.0	1.0	0.0000000000	False
continuous values	0.000550691750666	0.0	0.0	1.0	0.0000000000	False
core assumption	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
analysis model	0.00381647874421	0.0	4.99700449326	2.0	0.5308641975	False
multivariate gaussian	0.00156410321858	0.0	0.0	2.0	0.0000000000	False
higher range	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
covariance sigma	0.0012721595814	0.0	0.0	1.0	0.0000000000	False
sigma squared	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
familiar bell-shape	0.0012721595814	0.0	0.0	0.0	0.0000000000	False
bell-shape curve	0.0012721595814	0.0	0.0	0.0	0.0000000000	False
high dimension	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
dimension vector	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
vector value	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
value random	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
key quantities	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
vector mew	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
matrix sigma	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
covariance matrix	0.00445255853491	0.0	13.9965052421	6.0	0.2268274303	False
discussion section	0.000809439864158	0.0	0.0	1.0	0.0000000000	False
tas held	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
last friday	0.0	0.0	0.0	0.0	0.0000000000	False
multi-grade gaussians	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
laptop displayed	0.000550691750666	0.0	0.0	1.0	0.0000000000	False
matrix equals	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
upper right-hand	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
right-hand corner	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
vectors stand	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
identity covariance	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
variables correlated	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
horizontal axis	0.000809439864158	0.0	0.0	2.0	0.0000000000	False
standard normal	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
aspect ratio	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
gaussian covariance	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
ellipses aligned	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
degree angle	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
gaussian density	0.00245053986057	0.0	5.99750374438	4.0	0.5243902439	False
negative covariances	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
negative entries	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
larger entries	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
mew equals	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
quick primer	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
analysis algorithm	0.00110138350133	0.0	0.0	0.0	0.0000000000	False
gaussian distribution	0.000809439864158	0.0	0.0	1.0	0.0000000000	False
negative examples	0.00202359966039	0.0	5.99750374438	5.0	0.0000000000	False
division bound	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
green line	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
blue line	0.000443115542649	0.0	0.0	1.0	0.0000000000	False
bernoulli random	0.0019082393721	0.0	3.99850224663	1.0	0.0000000000	False
parameter phi	0.00110138350133	0.0	1.99850224663	2.0	0.0000000000	False
looked strange	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
big deal	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
previous board	0.000372256905896	0.0	0.0	1.0	0.0000000000	False
minus one-half	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
log likelihood	0.00132934662795	0.0	2.99850224663	3.0	0.0000000000	False
probative probabilities	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
joint data	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
data likelihood	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
joint likelihood	0.00312820643715	0.0	3.99800299551	4.0	0.3440000000	True
regression models	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
learning models	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
modeling pfyi	0.00156410321858	0.0	0.0	1.0	0.0000000000	False
conditional likelihood	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
regenerative learning	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
maximize likelihood	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
likelihood estimation	0.010117998302	0.0	15.9875187219	21.0	0.2658797077	False
maximum likelihood	0.010795450271	0.0	15.9855217174	26.0	0.2724492025	False
indicating notation	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
training examples	0.00326858096469	0.0	13.9940089865	11.0	0.2935153584	False
newly parameter	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
makes sense	0.00118898600964	0.0	4.99500748877	10.0	0.0000000000	False
indicator function	0.000404719932079	0.0	0.0	0.0	0.0000000000	False
function means	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
negative fitting	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
fitting examples	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
equation translates	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
notation divide	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
parameters find	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
find mew0	0.00156410321858	0.0	0.0	1.0	0.0000000000	False
write semicolon	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
denominator pfx	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
pfy takes	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
compute pfx	0.00156410321858	0.0	0.0	2.0	0.0000000000	False
arcomatics means	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
distributive removing	0.0	0.0	0.0	1.0	0.0000000000	False
uniform distribution	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
interesting relationship	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
set comprising	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
fit gaussians	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
negative training	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
plot pfy	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
fairly small	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
times pfy	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
left gaussian	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
positive class	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
pretty small	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
equal value	0.0	0.0	0.0	0.0	0.0000000000	False
rightmost gaussian	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
pfy equals	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
plotted takes	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
sigmoid function	0.000980215944228	0.0	0.0	1.0	0.0000000000	False
key difference	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
bernoulli distribution	0.00234615482786	0.0	1.99850224663	2.0	0.0000000000	False
fit pfx	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
real number	0.000554144169277	0.0	0.0	2.0	0.0000000000	False
vertical axis	0.000443115542649	0.0	0.0	1.0	0.0000000000	False
previous chalkboard	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
logistic posterior	0.0019082393721	0.0	3.99850224663	2.0	0.0000000000	False
posterior distribution	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
logistic function	0.00196043188846	0.0	6.99800299551	3.0	0.0000000000	False
opposite direction	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
parameter lambda	0.00156410321858	0.0	0.0	0.0	0.0000000000	False
stronger assumption	0.00312820643715	0.0	3.99800299551	3.0	0.4154589372	False
posterior holds	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
vice versa	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
analysis makes	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
gaussian assumption	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
discriminant algorithm	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
real advantage	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
modeling assumptions	0.00469230965573	0.0	7.99700449326	5.0	0.3726169844	False
training data	0.000372256905896	0.0	0.0	1.0	0.0000000000	False
weaker assumption	0.0	0.0	0.0	0.0	0.0000000000	False
larger training	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
analysis question	0.0	0.0	0.0	0.0	0.0000000000	False
marving assumptions	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
random variables	0.00255465513635	0.0	9.99600599101	6.0	0.4321608040	False
variables flowing	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
single training	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
mass molecular	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
molecular estimation	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
true value	0.0	0.0	0.0	1.0	0.0000000000	False
true underlying	0.0025443191628	0.0	7.99800299551	0.0	0.2935153584	False
underlying value	0.000782051609288	0.0	7.99800299551	1.0	0.2935153584	False
likelihood value	0.0	0.0	0.0	0.0	0.0000000000	False
friday discussion	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
probabilistic definitions	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
general version	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
exponential family	0.00330415050399	0.0	11.9970044933	5.0	0.1925373134	False
strange thing	0.000550691750666	0.0	0.0	1.0	0.0000000000	False
gaussian right	0.0	0.0	0.0	0.0	0.0000000000	False
gamma exponential	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
mental list	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
family extrusions	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
family distribution	0.0012721595814	0.0	0.0	1.0	0.0000000000	False
natural parameters	0.000550691750666	0.0	0.0	1.0	0.0000000000	False
posterior pfy	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
gamma distributed	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
family derivation	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
distribution implies	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
reverse assumption	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
bizarre distributions	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
first generative	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
bayes algorithm	0.0019082393721	0.0	1.99850224663	0.0	0.0000000000	False
spam classification	0.000636079790701	0.0	3.99800299551	3.0	0.0000000000	False
spam classifier	0.001652075252	0.0	1.99850224663	2.0	0.0000000000	False
incoming stream	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
spam email	0.00385484225466	0.0	8.99650524214	6.0	0.3495934959	False
first decision	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
feature vector	0.00242831959247	0.0	2.99700449326	5.0	0.4154589372	False
ascii characters	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
represent email	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
first word	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
email telling	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
buy stuff	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
find cs229	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
last word	0.0	0.0	0.0	1.0	0.0000000000	False
technological chemistry	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
fermentation process	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
word appears	0.0019082393721	0.0	4.99800299551	3.0	0.4154589372	False
words ausworth	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
split vectors	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
binary value	0.0	0.0	0.0	1.0	0.0000000000	False
value vectors	0.0	0.0	0.0	1.0	0.0000000000	False
bit vectors	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
multinomial distribution	0.0012721595814	0.0	0.0	2.0	0.0000000000	False
strong assumption	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
key rule	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
times pfx2	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
put dot	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
bayes assumption	0.00234615482786	0.0	2.99850224663	0.0	0.0000000000	False
first term	0.000550691750666	0.0	0.0	1.0	0.0000000000	False
means assume	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
cost label	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
normal written	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
written english	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
literal sense	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
effective algorithm	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
classifying text	0.0012721595814	0.0	0.0	1.0	0.0000000000	False
text documents	0.0012721595814	0.0	0.0	1.0	0.0000000000	False
automatic view	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
web pages	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
assumption works	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
graphical models	0.00156410321858	0.0	0.0	2.0	0.0000000000	False
bayesian network	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
expect maximum	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
indicator xij	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
entire training	0.000490107972114	0.0	0.0	0.0	0.0000000000	False
model depend	0.00156410321858	0.0	0.0	2.0	0.0000000000	False
hundred emails	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
emails labeled	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
vectors representing	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
equal spam	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
last model	0.0	0.0	0.0	1.0	0.0000000000	False
joint distribution	0.000490107972114	0.0	0.0	1.0	0.0000000000	False
fixed number	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
practical question	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
changing bullets	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
word occurring	0.00156410321858	0.0	0.0	2.0	0.0000000000	False
class project	0.001652075252	0.0	2.99850224663	2.0	0.0000000000	False
conference deadline	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
project partners	0.0012721595814	0.0	0.0	1.0	0.0000000000	False
senior friends	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
nips conference	0.000782051609288	0.0	3.99850224663	3.0	0.0000000000	False
stamp classifier	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
30,000th word	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
word nips	0.00469230965573	0.0	5.99700449326	6.0	0.3131067961	False
non-spam mail	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
terms end	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
bad idea	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
future emails	0.0	0.0	0.0	0.0	0.0000000000	False
stanford basketball	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
basketball team	0.00156410321858	0.0	0.0	1.0	0.0000000000	False
gather statistics	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
betting pool	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
february last	0.0	0.0	0.0	0.0	0.0000000000	False
last season	0.0	0.0	0.0	0.0	0.0000000000	False
played washington	0.00156410321858	0.0	0.0	1.0	0.0000000000	False
washington state	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
played usc	0.00156410321858	0.0	0.0	1.0	0.0000000000	False
played ucla	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
last year	0.0	0.0	0.0	0.0	0.0000000000	False
5th game	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
informal notation	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
notation makes	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
total number	0.000344136153527	0.0	0.0	0.0	0.0000000000	False
historical side	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
side note	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
rise tomorrow	0.00234615482786	0.0	5.99850224663	0.0	0.0000000000	False
sun rise	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
multinomial probability	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
friend sends	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
spam filter	0.000636079790701	0.0	0.0	1.0	0.0000000000	False
meaningful prediction	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
liberal assumptions	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
reasonable estimate	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
pretty reasonable	0.00156410321858	0.0	0.0	1.0	0.0000000000	False
bayesian assumptions	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
optimal estimate	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
bayesian prior	0.000782051609288	0.0	0.0	1.0	0.0000000000	False
reasonable assumption	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
good basketball	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
losing streak	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
good	0.000118276219072	0.0	0.0	0.0	0.5308641975	False
morning	0.000138536042319	0.0	0.0	0.0	0.0000000000	False
quick	0.000211755684027	0.0	0.0	0.0	0.0000000000	False
announcement	0.000148571862031	0.0	0.0	0.0	0.0000000000	False
reminder	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
project	0.0012094584703	0.0	0.0	0.0	0.2289669862	False
guidelines	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
handout	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
posted	0.00012094584703	0.0	0.0	0.0	0.0000000000	False
website	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.4046193328	False
week	0.000226285087309	0.0	0.0	0.0	0.0000000000	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
downloaded	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
looked	0.000151171905475	0.0	0.0	0.0	0.3397457918	False
proposal	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
milestone	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
final	0.000121739044072	0.0	0.0	0.0	0.0000000000	False
presentation	7.55859527377e-05	0.0	0.0	0.0	0.0000000000	False
today	4.10823823044e-05	0.0	0.0	0.0	0.4154589372	False
talk	7.3722848062e-05	0.0	0.0	0.0	0.3739130435	False
type	5.63881474525e-05	0.0	0.0	0.0	0.0000000000	False
learning	0.00139999900683	0.0	0.0	0.0	0.2622646513	False
algorithm	0.00124989344336	0.0	0.0	0.0	0.2750533049	False
start	0.0	0.0	0.0	0.0	0.0000000000	False
generative	0.000184023992892	0.0	0.0	0.0	0.4171075838	False
specific	0.000117757128449	0.0	0.0	0.0	0.2935153584	False
gaussian	0.0147041477829	1.0	0.0	0.0	0.1878823187	False
discriminant	0.0068615116096	0.0	0.0	0.0	0.3795712484	False
analysis	0.00194667086192	0.0	0.0	0.0	0.4079696395	False
slight	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
digression	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
briefly	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
discuss	0.000239799688682	0.0	0.0	0.0	0.3242835596	False
versus	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
wrap	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
lecture	7.29232887686e-05	0.0	0.0	0.0	0.0000000000	False
naive	0.00430128385108	0.0	0.0	0.0	0.3894927536	False
bayes	0.00398803988384	0.0	0.0	0.0	0.4452662722	False
laplace	0.00192742112733	0.0	0.0	0.0	0.3957055215	False
smoothing	0.00147032391634	0.0	0.0	0.0	0.4154589372	False
motivate	0.000725675082179	0.0	0.0	0.0	0.4558303887	False
right	0.0	0.0	0.0	0.0	0.5269775585	False
contrast	0.000604729235149	0.0	0.0	0.0	0.4378818737	False
source	0.000148571862031	0.0	0.0	0.0	0.0000000000	False
classification	0.000277072084639	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
training	0.0047519868335	0.0	0.0	0.0	0.3206676136	False
set	0.000264034424584	0.0	0.0	0.0	0.3960092095	False
run	6.85683390243e-05	0.0	0.0	0.0	0.5243902439	False
progression	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
logistic	0.00534858703312	0.0	0.0	0.0	0.2863939106	False
regression	0.00312000910266	0.0	0.0	0.0	0.4744232698	False
find	0.000172945821308	0.0	0.0	0.0	0.4699453552	False
date	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
straight	0.000566908667239	0.0	0.0	0.0	0.2606060606	False
line	0.000401566343613	0.0	0.0	0.0	0.2361195851	False
divide	0.000352242618185	0.0	0.0	0.0	0.4378818737	False
crosses	0.000278095837416	0.0	0.0	0.0	0.0000000000	False
sort	0.000588785642243	0.0	0.0	0.0	0.5168269231	False
make	0.000147445696124	0.0	0.0	0.0	0.4533132530	False
days	0.000151171905475	0.0	0.0	0.0	0.0000000000	False
bit	0.000228561130081	0.0	0.0	0.0	0.5584415584	False
noisier	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
separates	0.000458850931181	0.0	0.0	0.0	0.3355629877	False
out	0.0	0.0	0.0	0.0	0.4526315789	False
positive	0.000474001376996	0.0	0.0	0.0	0.2821807168	False
negative	0.00120508196214	0.0	0.0	0.0	0.2949868074	False
classes	0.00041214994957	0.0	0.0	0.0	0.3768924303	False
pass	0.000148571862031	0.0	0.0	0.0	0.0000000000	False
law	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
fact	3.94254063574e-05	0.0	0.0	0.0	0.0000000000	False
shows	0.000159992791057	0.0	0.0	0.0	0.4710485133	False
laptop	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
screens	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
small	6.66416785153e-05	0.0	0.0	0.0	0.0000000000	False
monitors	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
data	0.000588785642243	0.0	0.0	0.0	0.2554455446	False
initialized	5.63881474525e-05	0.0	0.0	0.0	0.0000000000	False
parameters	0.00288838946912	0.0	0.0	0.0	0.4343434343	False
randomly	0.000148571862031	0.0	0.0	0.0	0.0000000000	False
kind	0.000108091138317	0.0	0.0	0.0	0.5082742317	False
outputting	0.000131100266052	0.0	0.0	0.0	0.0000000000	False
hypothesis	0.000226285087309	0.0	0.0	0.0	0.0000000000	False
iteration	0.000339427630964	0.0	0.0	0.0	0.0000000000	False
shown	0.00022555258981	0.0	0.0	0.0	0.5243902439	False
bottom	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
creating	0.000211345570911	0.0	0.0	0.0	0.0000000000	False
descent	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.3818827709	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
converges	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
found	8.09869524627e-05	0.0	0.0	0.0	0.0000000000	False
searching	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
slightly	0.000131958050132	0.0	0.0	0.0	0.0000000000	False
classify	0.00142311462421	0.0	0.0	0.0	0.2988416988	False
team	0.000516204230291	0.0	0.0	0.0	0.0000000000	False
malignant	0.00349843884886	0.0	0.0	0.0	0.1740890688	False
cancer	0.00636079790701	0.0	0.0	0.0	0.1762295082	False
benign	0.00318039895351	0.0	0.0	0.0	0.1870468826	False
patient	0.000490107972114	0.0	0.0	0.0	0.0000000000	False
harmful	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
meaning	2.86004778871e-05	0.0	0.0	0.0	0.4619834711	False
harmless	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
cases	0.0	0.0	0.0	0.0	0.4378818737	False
examples	0.00166687161617	0.0	0.0	0.0	0.3304867635	False
build	0.000693440293826	0.0	0.0	0.0	0.3553719008	False
model	0.00685969732294	0.0	0.0	0.0	0.2058541923	False
decide	0.000156269214016	0.0	0.0	0.0	0.0000000000	False
match	0.000744513811793	0.0	0.0	0.0	0.2037914692	False
depending	0.000159992791057	0.0	0.0	0.0	0.3711467324	False
predict	0.000967566776239	0.0	0.0	0.0	0.3957055215	False
described	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
methods	0.000131100266052	0.0	0.0	0.0	0.0000000000	False
formalize	0.000297246502411	0.0	0.0	0.0	0.0000000000	False
previously	0.000185397224944	1.0	0.0	0.0	0.0000000000	False
studied	0.000185397224944	0.0	0.0	0.0	0.0000000000	False
pfy	0.0145933313926	0.0	0.0	0.0	0.3411467724	False
directly	0.00048378338812	0.0	0.0	0.0	0.0000000000	False
value	0.000677166594069	0.0	0.0	0.0	0.2879671635	False
pfx	0.011767476128	0.0	0.0	0.0	0.2526283241	False
probability	0.00278175448169	0.0	0.0	0.0	0.4283239498	False
features	0.000852151729335	0.0	0.0	0.0	0.3274111675	False
label	0.00133714675828	0.0	0.0	0.0	0.4069400631	False
technical	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
detail	4.01566343613e-05	0.0	0.0	0.0	0.0000000000	False
important	8.79720334211e-05	0.0	0.0	0.0	0.0000000000	False
thing	0.0	0.0	0.0	0.0	0.4378818737	False
interpretation	0.000138536042319	0.0	0.0	0.0	0.0000000000	False
probabilistic	0.000826037625999	0.0	0.0	0.0	0.0000000000	False
conditioned	0.000907031432853	0.0	0.0	0.0	0.3915022762	False
words	0.00216845825551	0.0	0.0	0.0	0.2074788902	False
distribution	0.00222343468228	0.0	0.0	0.0	0.4577714691	False
built	0.000258748113492	0.0	0.0	0.0	0.0000000000	False
rule	0.000606760257098	0.0	0.0	0.0	0.4151724138	False
compute	0.000219106038957	0.0	0.0	0.0	0.4205378973	False
calculate	0.000664673313974	0.0	0.0	0.0	0.0000000000	False
denominator	0.00269559384663	0.0	0.0	0.0	0.4321608040	False
back	0.000182673807237	0.0	0.0	0.0	0.4710485133	False
tradeoffs	0.000826037625999	0.0	0.0	0.0	0.0000000000	False
worse	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
idea	0.000182673807237	0.0	0.0	0.0	0.4710485133	False
assume	0.00100391585903	0.0	0.0	0.0	0.3146034533	False
input	9.59198754728e-05	0.0	0.0	0.0	0.0000000000	False
continuous	7.29232887686e-05	0.0	0.0	0.0	0.0000000000	False
assumption	0.00581851377741	0.0	0.0	0.0	0.2855245684	False
guess	0.000693575172291	0.0	0.0	0.0	0.4710485133	False
core	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
raise	0.000173360073456	0.0	0.0	0.0	0.0000000000	False
hand	8.03132687226e-05	0.0	0.0	0.0	0.0000000000	False
multivariate	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
higher	0.000105877842013	0.0	0.0	0.0	0.0000000000	False
range	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
cool	0.000967566776239	0.0	0.0	0.0	0.0000000000	False
half	7.55859527377e-05	0.0	0.0	0.0	0.0000000000	False
two-thirds	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
refresher	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
random	0.000792657339762	0.0	0.0	0.0	0.4321608040	False
variable	0.000620269621977	0.0	0.0	0.0	0.4223968566	False
script	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
normal	0.000365217132216	0.0	0.0	0.0	0.3726169844	False
covariance	0.00376648211252	0.0	0.0	0.0	0.1708957505	False
sigma	0.00367580979086	0.0	0.0	0.0	0.2016075017	False
squared	0.000196650399077	0.0	0.0	0.0	0.0000000000	False
density	0.00294064783269	0.0	0.0	0.0	0.4069400631	False
formula	0.00110828833855	0.0	0.0	0.0	0.4845070423	False
dimension	0.000478997838065	0.0	0.0	0.0	0.0000000000	False
familiar	0.000346720146913	0.0	0.0	0.0	0.2935153584	False
bell-shape	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
curve	0.000688272307055	0.0	0.0	0.0	0.0000000000	False
high	6.55501330258e-05	0.0	0.0	0.0	0.0000000000	False
vector	0.00181028069848	0.0	0.0	0.0	0.3463087248	False
worry	6.08695220359e-05	0.0	0.0	0.0	0.0000000000	False
rarely	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
end	0.000108091138317	0.0	0.0	0.0	0.3894927536	False
needing	0.000172068076764	0.0	0.0	0.0	0.4188311688	False
key	0.000182608566108	0.0	0.0	0.0	0.0000000000	False
quantities	0.000185397224944	0.0	0.0	0.0	0.0000000000	False
mew	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
matrix	0.00137654461411	0.0	0.0	0.0	0.2077294686	False
equal	0.0011667726203	0.0	0.0	0.0	0.3990719258	False
definition	0.000131958050132	0.0	0.0	0.0	0.0000000000	False
conspose	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
re-watch	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
section	0.000319331892043	0.0	0.0	0.0	0.0000000000	False
tas	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
held	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
friday	0.000404719932079	0.0	0.0	0.0	0.0000000000	False
holding	0.000566908667239	0.0	0.0	0.0	0.4154589372	False
recap	0.000138536042319	0.0	0.0	0.0	0.0000000000	False
multi-grade	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
parameterized	0.0010117998302	0.0	0.0	0.0	0.3711467324	False
displayed	0.000138536042319	0.0	0.0	0.0	0.0000000000	False
graphically	0.000664673313974	0.0	0.0	0.0	0.0000000000	False
effects	0.000140897047274	0.0	0.0	0.0	0.0000000000	False
varying	0.000445715586094	0.0	0.0	0.0	0.0000000000	False
identity	0.00036283754109	0.0	0.0	0.0	0.0000000000	False
upper	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
right-hand	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
corner	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
shrink	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
peaked	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
widen	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
spread	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
stand	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
increase	0.000242960857388	0.0	0.0	0.0	0.0000000000	False
diagonals	0.00110138350133	0.0	0.0	0.0	0.0000000000	False
correlated	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
flattened	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
direction	0.000211755684027	0.0	0.0	0.0	0.0000000000	False
excuse	0.00064687028373	0.0	0.0	0.0	0.3242835596	False
horizontal	0.000344136153527	0.0	0.0	0.0	0.0000000000	False
axis	0.000742859310156	0.0	0.0	0.0	0.0000000000	False
contours	0.000826037625999	0.0	0.0	0.0	0.0000000000	False
standard	7.0448523637e-05	0.0	0.0	0.0	0.0000000000	False
circles	0.000258748113492	0.0	0.0	0.0	0.0000000000	False
aspect	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
ratio	0.000404719932079	0.0	0.0	0.0	0.0000000000	False
ellipses	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
aligned	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
degree	0.00012094584703	0.0	0.0	0.0	0.0000000000	False
angle	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
strong	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
entries	0.000404719932079	0.0	0.0	0.0	0.0000000000	False
larger	0.000104179476011	0.0	0.0	0.0	0.0000000000	False
mew0	0.00430128385108	0.0	0.0	0.0	0.4367497692	False
changed	5.21925163535e-05	0.0	0.0	0.0	0.5243902439	False
location	8.66800367282e-05	0.0	0.0	0.0	0.0000000000	False
moves	0.000109384933153	0.0	0.0	0.0	0.0000000000	False
primer	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
roadmap	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
picture	4.79599377364e-05	0.0	0.0	0.0	0.0000000000	False
mind	8.09869524627e-05	0.0	0.0	0.0	0.0000000000	False
fit	0.00194061085119	0.0	0.0	0.0	0.3679406731	False
figure	0.000112776294905	0.0	0.0	0.0	0.0000000000	False
centered	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
concept	0.000105877842013	0.0	0.0	0.0	0.0000000000	False
define	2.60962581767e-05	0.0	0.0	0.0	0.0000000000	False
turn	0.000948002753992	0.0	0.0	0.0	0.4095238095	False
division	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
bound	0.00012094584703	0.0	0.0	0.0	0.0000000000	False
green	0.000138536042319	0.0	0.0	0.0	0.0000000000	False
blue	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
switch	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
chalkboard	0.000490107972114	0.0	0.0	0.0	0.0000000000	False
put	4.99812588865e-05	0.0	0.0	0.0	0.0000000000	False
bernoulli	0.00222627926745	0.0	0.0	0.0	0.3553719008	False
usual	0.000554144169277	0.0	0.0	0.0	0.5308641975	False
phi	0.00509582874047	0.0	0.0	0.0	0.2724654378	False
thought	0.00012094584703	0.0	0.0	0.0	0.0000000000	False
strange	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
determined	0.000185397224944	0.0	0.0	0.0	0.0000000000	False
one-half	0.000516204230291	0.0	0.0	0.0	0.0000000000	False
big	6.08695220359e-05	0.0	0.0	0.0	0.0000000000	False
deal	0.00024189169406	0.0	0.0	0.0	0.0000000000	False
listing	0.00078660159631	0.0	0.0	0.0	0.2466539197	False
previous	8.79720334211e-05	0.0	0.0	0.0	0.0000000000	False
board	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
minus	4.39860167105e-05	0.0	0.0	0.0	0.0000000000	False
mew1	0.00312820643715	0.0	0.0	0.0	0.3553719008	False
write	0.00028322713369	0.0	0.0	0.0	0.3190746399	False
likelihood	0.00688272307055	0.0	0.0	0.0	0.2262562484	False
log	0.000485921714776	0.0	0.0	0.0	0.1457627119	False
probative	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
pfxi	0.00159019947675	0.0	0.0	0.0	0.3242835596	False
terms	0.000123247146913	0.0	0.0	0.0	0.3726169844	False
pfyi	0.00110138350133	0.0	0.0	0.0	0.2037914692	False
equations	0.000185397224944	0.0	0.0	0.0	0.0000000000	False
top	0.000104179476011	0.0	0.0	0.0	0.0000000000	False
give	1.30002172214e-05	0.0	0.0	0.0	0.5082742317	False
joint	0.00111677071769	0.0	0.0	0.0	0.3131067961	False
theater	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
product	0.000463493062361	0.0	0.0	0.0	0.4378818737	False
regenerative	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
maximize	0.000388122170238	0.0	0.0	0.0	0.0000000000	False
estimation	0.00654630378689	0.0	0.0	0.0	0.2311097060	False
respect	8.66800367282e-05	0.0	0.0	0.0	0.0000000000	False
maximum	0.00219199262939	0.0	0.0	0.0	0.2724492025	False
surprise	0.000516204230291	0.0	0.0	0.0	0.0000000000	False
practice	0.000377929763689	0.0	0.0	0.0	0.0000000000	False
indicating	0.000458850931181	0.0	0.0	0.0	0.3711467324	False
notation	0.000404934762313	0.0	0.0	0.0	0.0000000000	False
sum	0.000755859527377	0.0	0.0	0.0	0.3157121880	False
written	0.000208358952021	0.0	0.0	0.0	0.4154589372	False
alternatively	0.00012094584703	0.0	0.0	0.0	0.0000000000	False
newly	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
faction	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
stare	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
sense	0.000182848904065	0.0	0.0	0.0	0.0000000000	False
increment	0.000297143724062	0.0	0.0	0.0	0.0000000000	False
count	0.000905618397222	0.0	0.0	0.0	0.3131067961	False
number	8.06013467728e-05	0.0	0.0	0.0	0.1638719512	False
numerator	0.000831216253916	0.0	0.0	0.0	0.4378818737	False
function	0.000137988922251	0.0	0.0	0.0	0.4558303887	False
including	7.55859527377e-05	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.3915022762	False
multiply	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
fancifully	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
average	0.000478997838065	0.0	0.0	0.0	0.0000000000	False
cryptic	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
translates	0.000258748113492	0.0	0.0	0.0	0.0000000000	False
home	0.000297143724062	0.0	0.0	0.0	0.0000000000	False
read	4.79599377364e-05	0.0	0.0	0.0	0.0000000000	False
notes	0.000104179476011	0.0	0.0	0.0	0.0000000000	False
semicolon	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
uniform	0.000478997838065	0.0	0.0	0.0	0.0000000000	False
constants	7.0448523637e-05	0.0	0.0	0.0	0.0000000000	False
takes	0.000104385032707	0.0	0.0	0.0	0.4474505723	False
arc	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
min	0.000226285087309	0.0	0.0	0.0	0.0000000000	False
arcomatics	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
choosing	0.000140897047274	0.0	0.0	0.0	0.0000000000	False
argument	0.000478997838065	0.0	0.0	0.0	0.0000000000	False
minimize	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
questions	0.000118900252149	0.0	0.0	0.0	0.4053662074	False
removing	0.0	0.0	0.0	0.0	0.0000000000	False
meant	0.000516204230291	0.0	0.0	0.0	0.0000000000	False
loose	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
interesting	4.79599377364e-05	0.0	0.0	0.0	0.0000000000	False
relationship	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
illustrate	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
draw	0.000196650399077	0.0	0.0	0.0	0.0000000000	False
work	9.85635158935e-05	0.0	0.0	0.0	0.5308641975	False
comprising	0.000319331892043	0.0	0.0	0.0	0.0000000000	False
hope	0.000517496226984	0.0	0.0	0.0	0.4378818737	False
overlay	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
plot	0.00103499245397	0.0	0.0	0.0	0.5443037975	False
variety	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
realize	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
call	5.20008688857e-06	0.0	0.0	0.0	0.4967907574	False
part	5.26591771872e-06	0.0	0.0	0.0	0.0000000000	False
fairly	9.59198754728e-05	0.0	0.0	0.0	0.0000000000	False
plug	0.000517496226984	0.0	0.0	0.0	0.4154589372	False
essentially	2.28561130081e-05	0.0	0.0	0.0	0.0000000000	False
belongs	0.000415608126958	0.0	0.0	0.0	0.0000000000	False
left	3.289193272e-05	0.0	0.0	0.0	0.0000000000	False
close	5.21925163535e-05	0.0	0.0	0.0	0.0000000000	False
pretty	0.000725675082179	0.0	0.0	0.0	0.5243902439	False
point	2.08003475543e-05	0.0	0.0	0.0	0.4154589372	False
arrow	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
fill	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
bunch	0.000516204230291	0.0	0.0	0.0	0.0000000000	False
rightmost	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
repeat	8.09869524627e-05	0.0	0.0	0.0	0.0000000000	False
exercise	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
connect	9.90821674702e-05	0.0	0.0	0.0	0.0000000000	False
pause	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
form	4.99812588865e-05	0.0	0.0	0.0	0.0000000000	False
sigmoid	0.000735161958171	0.0	0.0	0.0	0.0000000000	False
difference	1.05318354374e-05	0.0	0.0	0.0	0.5082742317	False
steepness	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
wondering	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
dots	0.000792657339762	0.0	0.0	0.0	0.1925373134	False
steps	2.28561130081e-05	0.0	0.0	0.0	0.0000000000	False
chosen	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
process	5.88785642243e-05	0.0	0.0	0.0	0.0000000000	False
pick	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
real	0.000131958050132	0.0	0.0	0.0	0.0000000000	False
vertical	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
advantages	0.000297143724062	0.0	0.0	0.0	0.0000000000	False
disadvantages	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
prove	0.000260040110185	0.0	0.0	0.0	0.2037914692	False
implies	0.000693575172291	0.0	0.0	0.0	0.3355629877	False
posterior	0.001652075252	0.0	0.0	0.0	0.4378818737	False
implication	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
opposite	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
true	0.000677166594069	0.0	0.0	0.0	0.2958098812	False
hessian	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
lambda	0.000490107972114	0.0	0.0	0.0	0.0000000000	False
lots	0.000145846577537	0.0	0.0	0.0	0.4154589372	False
lead	0.000297143724062	0.0	0.0	0.0	0.0000000000	False
stronger	0.00156410321858	0.0	0.0	0.0	0.4154589372	False
vice	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
versa	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
leaves	8.09869524627e-05	0.0	0.0	0.0	0.0000000000	False
approximately	0.000516204230291	0.0	0.0	0.0	0.0000000000	False
explicit	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
information	0.000196650399077	0.0	0.0	0.0	0.0000000000	False
roughly	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
conversely	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
poisson	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
perfectly	0.000344136153527	0.0	0.0	0.0	0.0000000000	False
requires	4.79599377364e-05	0.0	0.0	0.0	0.0000000000	False
surprisingly	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
met	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
order	2.40031295076e-05	0.0	0.0	0.0	0.0000000000	False
robust	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
weaker	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
meet	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
samples	0.000445715586094	0.0	0.0	0.0	0.0000000000	False
marginal	0.0	0.0	0.0	0.0	0.0000000000	False
marving	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
made	0.000169164442357	0.0	0.0	0.0	0.0000000000	False
independently	0.000260040110185	0.0	0.0	0.0	0.0000000000	False
size	5.20897380053e-05	0.0	0.0	0.0	0.0000000000	False
flowing	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
single	5.20897380053e-05	0.0	0.0	0.0	0.0000000000	False
philosophy	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
mass	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
molecular	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
underlying	0.000809439864158	0.0	0.0	0.0	0.2935153584	False
guards	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
earlier	4.79599377364e-05	0.0	0.0	0.0	0.0000000000	False
mic	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
attempt	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
convention	0.000105877842013	0.0	0.0	0.0	0.0000000000	False
bothering	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
distinguish	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
tease	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
great	0.000104179476011	0.0	0.0	0.0	0.0000000000	False
mention	9.90821674702e-05	0.0	0.0	0.0	0.0000000000	False
version	9.90821674702e-05	0.0	0.0	0.0	0.0000000000	False
exponential	0.000969752296235	0.0	0.0	0.0	0.1925373134	False
family	0.00121415979624	0.0	0.0	0.0	0.1925373134	False
gamma	0.000558385358845	0.0	0.0	0.0	0.0000000000	False
beta	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
rattling	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
mental	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
extrusions	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
natural	6.08695220359e-05	0.0	0.0	0.0	0.0000000000	False
choice	6.55501330258e-05	0.0	0.0	0.0	0.0000000000	False
early	0.000138536042319	0.0	0.0	0.0	0.0000000000	False
promised	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
justifications	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
pulled	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
hat	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
derivation	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
reverse	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
bizarre	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
rise	0.00122526993029	0.0	0.0	0.0	0.2334419110	False
first	0.0	0.0	0.0	0.0	0.4154589372	False
spam	0.0056660790491	0.0	0.0	0.0	0.2476007678	False
incoming	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
stream	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
email	0.00595120661031	0.0	0.0	0.0	0.1928251121	False
non-spam	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
decision	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
piece	0.000655501330258	0.0	0.0	0.0	0.3613445378	False
represent	0.000191839750946	0.0	0.0	0.0	0.4154589372	False
text	0.000445715586094	0.0	0.0	0.0	0.0000000000	False
ascii	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
characters	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
couple	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
representations	8.09869524627e-05	0.0	0.0	0.0	0.0000000000	False
construct	0.000173360073456	0.0	0.0	0.0	0.0000000000	False
dictionary	0.00167515607653	0.0	0.0	0.0	0.0000000000	False
aardvark	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
ausworth	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
buy	0.000319331892043	0.0	0.0	0.0	0.0000000000	False
telling	7.55859527377e-05	0.0	0.0	0.0	0.4154589372	False
stuff	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
collect	0.000185397224944	0.0	0.0	0.0	0.0000000000	False
cs229	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
zicmergue	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
pertains	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
technological	0.000148571862031	0.0	0.0	0.0	0.0000000000	False
chemistry	0.000245053986057	0.0	0.0	0.0	0.0000000000	False
fermentation	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
brewing	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
scan	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
appears	0.000831216253916	0.0	0.0	0.0	0.3414783140	False
aid	0.0	0.0	0.0	0.0	0.0000000000	False
zeros	0.000886231085299	0.0	0.0	0.0	0.3006993007	False
occur	0.000396328669881	0.0	0.0	0.0	0.0000000000	False
throw	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
split	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
binary	0.000161973904925	0.0	0.0	0.0	0.0000000000	False
dimensional	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
50,000	0.00294064783269	0.0	0.0	0.0	0.1856115108	False
atypical	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
mid-thousands	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
tens	5.20897380053e-05	0.0	0.0	0.0	0.0000000000	False
thousands	0.000113142543655	0.0	0.0	0.0	0.0000000000	False
typical	7.55859527377e-05	0.0	0.0	0.0	0.0000000000	False
problems	2.10636708749e-05	0.0	0.0	0.0	0.0000000000	False
length	9.90821674702e-05	0.0	0.0	0.0	0.0000000000	False
multinomial	0.00110138350133	0.0	0.0	0.0	0.0000000000	False
possibilities	0.00019816433494	0.0	0.0	0.0	0.3131067961	False
pfx1	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
x50,000	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
pfx2	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
pfx50,000	0.00117307741393	0.0	0.0	0.0	0.0000000000	False
chain	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
defies	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
pfx3	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
compactly	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
stating	0.000339427630964	0.0	0.0	0.0	0.0000000000	False
cost	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
long	7.55859527377e-05	0.0	0.0	0.0	0.0000000000	False
knowing	0.000478997838065	0.0	0.0	0.0	0.3755458515	False
affect	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
false	0.000558385358845	0.0	0.0	0.0	0.0000000000	False
names	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
english	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
literal	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
extremely	0.000173360073456	0.0	0.0	0.0	0.0000000000	False
documents	0.000443115542649	0.0	0.0	0.0	0.0000000000	False
automatic	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
view	8.66800367282e-05	0.0	0.0	0.0	0.0000000000	False
web	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
pages	0.000159665946022	0.0	0.0	0.0	0.0000000000	False
webpage	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
sell	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
applications	5.20897380053e-05	0.0	0.0	0.0	0.0000000000	False
bayesian	0.00110138350133	0.0	0.0	0.0	0.3385826772	False
world	0.00012094584703	0.0	0.0	0.0	0.0000000000	False
network	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
net	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
ignore	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
purposes	6.08695220359e-05	0.0	0.0	0.0	0.0000000000	False
expect	0.000211755684027	0.0	0.0	0.0	0.0000000000	False
xij	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
simply	0.00012094584703	0.0	0.0	0.0	0.0000000000	False
entire	2.94392821122e-05	0.0	0.0	0.0	0.0000000000	False
jay	0.0	0.0	0.0	0.0	0.2334419110	False
fraction	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
wrote	9.90821674702e-05	0.0	0.0	0.0	0.0000000000	False
similar	3.64616443843e-05	0.0	0.0	0.0	0.0000000000	False
elaboration	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
check	6.08695220359e-05	0.0	0.0	0.0	0.0000000000	False
months	0.000445715586094	0.0	0.0	0.0	0.0000000000	False
hundred	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
fixed	0.000278095837416	0.0	0.0	0.0	0.0000000000	False
offline	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
common	0.000278095837416	0.0	0.0	0.0	0.0000000000	False
discard	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
nice	7.55859527377e-05	0.0	0.0	0.0	0.0000000000	False
thinking	0.000129374056746	0.0	0.0	0.0	0.4321608040	False
union	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
tests	9.90821674702e-05	0.0	0.0	0.0	0.0000000000	False
select	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
confused	0.000148571862031	0.0	0.0	0.0	0.0000000000	False
correct	6.55501330258e-05	0.0	0.0	0.0	0.0000000000	False
bullets	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
complete	1.97127031787e-05	0.0	0.0	0.0	0.0000000000	False
submit	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
conference	0.00110138350133	0.0	0.0	0.0	0.0000000000	False
june	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
year	0.000161973904925	0.0	0.0	0.0	0.0000000000	False
deadline	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
acronym	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
send	0.000445715586094	0.0	0.0	0.0	0.0000000000	False
partners	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
senior	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
friends	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
hey	0.0	0.0	0.0	0.0	0.0000000000	False
nips	0.00391025804644	0.0	0.0	0.0	0.2013108614	False
paper	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
stamp	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
30,000th	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
x30,000	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
similarly	3.289193272e-05	0.0	0.0	0.0	0.0000000000	False
mail	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
chance	0.00172068076764	0.0	0.0	0.0	0.3200992556	False
pfx30,000	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
undefined	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
statistically	0.000688272307055	0.0	0.0	0.0	0.0000000000	False
bad	9.90821674702e-05	0.0	0.0	0.0	0.0000000000	False
worth	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
sound	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
event	0.000172068076764	0.0	0.0	0.0	0.0000000000	False
impossible	0.000607079898118	0.0	0.0	0.0	0.0000000000	False
future	0.000186128452948	0.0	0.0	0.0	0.0000000000	False
stanford	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
basketball	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
games	0.00332336656987	0.0	0.0	0.0	0.2013108614	False
tracking	0.000202359966039	0.0	0.0	0.0	0.0000000000	False
wins	0.0034307558048	0.0	0.0	0.0	0.2118226601	False
losses	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
gather	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
betting	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
pool	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
lose	0.00103240846058	0.0	0.0	0.0	0.3726169844	False
8th	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
february	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
season	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
played	0.00064687028373	0.0	0.0	0.0	0.1699604743	False
washington	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
11th	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
22nd	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
usc	0.000782051609288	0.0	0.0	0.0	0.0000000000	False
ucla	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
louisville	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
guys	9.26986124722e-05	0.0	0.0	0.0	0.0000000000	False
harsh	0.000636079790701	0.0	0.0	0.0	0.0000000000	False
5th	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
total	6.08695220359e-05	0.0	0.0	0.0	0.0000000000	False
add	0.000338328884715	0.0	0.0	0.0	0.2384473198	False
row	0.000372256905896	0.0	0.0	0.0	0.0000000000	False
terribly	0.000404719932079	0.0	0.0	0.0	0.0000000000	False
historical	0.000221557771325	0.0	0.0	0.0	0.0000000000	False
side	4.79599377364e-05	0.0	0.0	0.0	0.0000000000	False
sun	0.00110138350133	0.0	0.0	0.0	0.2037914692	False
tomorrow	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
rationale	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
absolutely	0.000105877842013	0.0	0.0	0.0	0.0000000000	False
apply	4.79599377364e-05	0.0	0.0	0.0	0.0000000000	False
shoot	0.000954119686052	0.0	0.0	0.0	0.0000000000	False
adding	0.000173360073456	0.0	0.0	0.0	0.0000000000	False
solves	8.66800367282e-05	0.0	0.0	0.0	0.0000000000	False
filter	0.000275345875333	0.0	0.0	0.0	0.0000000000	False
meaningful	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
instance	7.29232887686e-05	0.0	0.0	0.0	0.0000000000	False
liberal	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
faith	0.000318039895351	0.0	0.0	0.0	0.0000000000	False
suppose	2.28561130081e-05	0.0	0.0	0.0	0.0000000000	False
reasonable	0.00013156773088	0.0	0.0	0.0	0.0000000000	False
prior	0.000550691750666	0.0	0.0	0.0	0.0000000000	False
optimal	0.000129374056746	0.0	0.0	0.0	0.0000000000	False
chose	0.000148571862031	0.0	0.0	0.0	0.0000000000	False
streak	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
funnier	0.000391025804644	0.0	0.0	0.0	0.0000000000	False
good morning welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
quick announcement for today	0.0	0.0	0.0	2.0	0.0000000000	False
program matlab or octave	0.0	0.0	0.0	2.0	0.0000000000	False
direct terms and matlab	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that i started	0.0	0.0	0.0	2.0	0.0000000000	False
previous lecture and talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about a couple	0.0	0.0	0.0	2.0	0.0000000000	False
couple of different event	0.0	0.0	0.0	2.0	0.0000000000	False
talk about neural networks	0.0	0.0	0.0	4.0	0.0000000000	False
nt spend a lot	0.0	0.0	0.0	0.0	0.0000000000	False
talk about support vector	0.0	0.0	0.0	4.0	0.0000000000	False
machines is the learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that many people	0.0	0.0	0.0	2.0	0.0000000000	False
off-the-shelf supervised learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm that point	0.0	0.0	0.0	2.0	0.0000000000	False
start discussing that today	0.0	0.0	0.0	2.0	0.0000000000	False
started off describing spam	0.0	0.0	0.0	2.0	0.0000000000	False
words in a dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
based on what words	0.0	0.0	0.0	2.0	0.0000000000	False
represented as a feature	0.0	0.0	0.0	2.0	0.0000000000	False
modeled it as product	0.0	0.0	0.0	2.0	0.0000000000	False
product from i equals	0.0	0.0	0.0	2.0	0.0000000000	False
spam or not spam	0.0	0.0	6.99791558103	8.0	0.0000000000	False
bayes rule is rfx	0.0	0.0	0.0	2.0	0.0000000000	False
attention to two things	0.0	0.0	0.0	2.0	0.0000000000	False
indicating whether different words	0.0	0.0	0.0	2.0	0.0000000000	False
length or the feature	0.0	0.0	0.0	2.0	0.0000000000	False
vector was the number	0.0	0.0	0.0	2.0	0.0000000000	False
words in the dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
version on the order	0.0	0.0	0.0	2.0	0.0000000000	False
order of 50,000 words	0.0	0.0	0.0	2.0	0.0000000000	False
variations on this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
takes on more values	0.0	0.0	0.0	2.0	0.0000000000	False
takes on k values	0.0	0.0	0.0	2.0	0.0000000000	False
similar model where pfx	0.0	0.0	0.0	2.0	0.0000000000	False
probabilities rather than bernoulli	0.0	0.0	0.0	2.0	0.0000000000	False
situation where this arises	0.0	0.0	0.0	2.0	0.0000000000	False
value feature and dispertise	0.0	0.0	0.0	2.0	0.0000000000	False
set of k values	0.0	0.0	0.0	2.0	0.0000000000	False
first supervised learning problem	0.0	0.0	0.0	2.0	0.0000000000	False
learning problem of predicting	0.0	0.0	0.0	2.0	0.0000000000	False
problem on these houses	0.0	0.0	0.0	2.0	0.0000000000	False
features of a house	0.0	0.0	0.0	2.0	0.0000000000	False
house will be sold	0.0	0.0	0.0	2.0	0.0000000000	False
feature like the living	0.0	0.0	0.0	2.0	0.0000000000	False
continuous value living area	0.0	0.0	0.0	2.0	0.0000000000	False
area and just dispertise	0.0	0.0	0.0	2.0	0.0000000000	False
area of the house	0.0	0.0	0.0	2.0	0.0000000000	False
greater than 2,000 square	0.0	0.0	0.0	2.0	0.0000000000	False
first variation or generalization	0.0	0.0	0.0	2.0	0.0000000000	False
out that in practice	0.0	0.0	0.0	2.0	0.0000000000	False
ten buckets to dispertise	0.0	0.0	0.0	2.0	0.0000000000	False
dispertise a continuous value	0.0	0.0	0.0	2.0	0.0000000000	False
value feature i drew	0.0	0.0	0.0	2.0	0.0000000000	False
bayes is a variation	0.0	0.0	0.0	2.0	0.0000000000	False
specific to classifying text	0.0	0.0	0.0	2.0	0.0000000000	False
sequences so the text	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm as i ve	0.0	0.0	0.0	0.0	0.0000000000	False
binary vector value representation	0.0	0.0	0.0	2.0	0.0000000000	False
things that this loses	0.0	0.0	0.0	2.0	0.0000000000	False
times that different words	0.0	0.0	0.0	2.0	0.0000000000	False
word appears a lot	0.0	0.0	0.0	2.0	0.0000000000	False
buy  a lot	0.0	0.0	0.0	2.0	0.0000000000	False
word viagra a ton	0.0	0.0	0.0	2.0	0.0000000000	False
times in the email	0.0	0.0	0.0	2.0	0.0000000000	False
spam than it appears	0.0	0.0	0.0	2.0	0.0000000000	False
times a word appears	0.0	0.0	0.0	4.0	0.0000000000	False
appears in the email	0.0	0.0	0.0	2.0	0.0000000000	False
give this previous model	0.0	0.0	0.0	2.0	0.0000000000	False
model for text classification	0.0	0.0	0.0	2.0	0.0000000000	False
multivariate bernoulli event model	0.0	0.0	0.0	2.0	0.0000000000	True
refers to the fact	0.0	0.0	0.0	2.0	0.0000000000	False
multiple bernoulli random variables	0.0	0.0	0.0	2.0	0.0000000000	False
describe a different representation	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the feature	0.0	0.0	0.0	2.0	0.0000000000	False
email as a feature	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the number	0.0	0.0	0.0	2.0	0.0000000000	False
words in this email	0.0	0.0	0.0	2.0	0.0000000000	False
examples is an email	0.0	0.0	0.0	2.0	0.0000000000	False
email via a feature	0.0	0.0	0.0	2.0	0.0000000000	False
elements of the feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature vector  lets	0.0	0.0	0.0	2.0	0.0000000000	False
dictionary has 50,000 words	0.0	0.0	0.0	2.0	0.0000000000	False
position in my feature	0.0	0.0	0.0	2.0	0.0000000000	False
position of my email	0.0	0.0	0.0	2.0	0.0000000000	False
words in my email	0.0	0.0	0.0	2.0	0.0000000000	False
word in my dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
dictionary was each word	0.0	0.0	0.0	2.0	0.0000000000	False
word in the email	0.0	0.0	0.0	4.0	0.0000000000	False
indexed into the dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
components of the feature	0.0	0.0	0.0	2.0	0.0000000000	False
longer binary random variables	0.0	0.0	0.0	2.0	0.0000000000	False
variables ; they re	0.0	0.0	0.0	0.0	0.0000000000	False
larger set of values	0.0	0.0	0.0	2.0	0.0000000000	False
length of the email	0.0	0.0	0.0	2.0	0.0000000000	False
formula is you imagine	0.0	0.0	0.0	2.0	0.0000000000	False
random distribution that generates	0.0	0.0	0.0	2.0	0.0000000000	False
first the class label	0.0	0.0	0.0	2.0	0.0000000000	False
email or not spam	0.0	0.0	0.0	2.0	0.0000000000	False
spam emails is chosen	0.0	0.0	0.0	2.0	0.0000000000	False
class label of spam	0.0	0.0	0.0	2.0	0.0000000000	False
positions of the email	0.0	0.0	0.0	2.0	0.0000000000	False
compose them as email	0.0	0.0	0.0	2.0	0.0000000000	False
words from some distribution	0.0	0.0	0.0	2.0	0.0000000000	False
ll send you words	0.0	0.0	0.0	2.0	0.0000000000	False
ll tend to generate	0.0	0.0	0.0	2.0	0.0000000000	False
tend to generate words	0.0	0.0	0.0	2.0	0.0000000000	False
send you not spam	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of this model	0.0	0.0	0.0	2.0	0.0000000000	False
conditioned on someone deciding	0.0	0.0	0.0	2.0	0.0000000000	False
guess  and phi	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the model	0.0	0.0	0.0	2.0	0.0000000000	False
work out the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out the maximum likelihood	0.0	0.0	0.0	4.0	0.0000000000	False
estimates of the parameters	0.0	0.0	3.99843668577	6.0	0.0000000000	False
parameters so the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
big indicator function things	0.0	0.0	0.0	2.0	0.0000000000	False
ll be a sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum over your training	0.0	0.0	0.0	2.0	0.0000000000	False
spam times the sum	0.0	0.0	0.0	2.0	0.0000000000	False
words in that email	0.0	0.0	0.0	2.0	0.0000000000	False
email where n subscript	0.0	0.0	0.0	2.0	0.0000000000	False
account all the emails	0.0	0.0	0.0	2.0	0.0000000000	False
emails that had class	0.0	0.0	0.0	2.0	0.0000000000	False
emails that were spam	0.0	0.0	0.0	2.0	0.0000000000	False
words in your spam	0.0	0.0	0.0	2.0	0.0000000000	False
counts up the number	0.0	0.0	0.0	2.0	0.0000000000	False
emails in your training	0.0	0.0	0.0	4.0	0.0000000000	False
training set and count	0.0	0.0	0.0	2.0	0.0000000000	False
total number of times	0.0	0.0	0.0	2.0	0.0000000000	False
appeared in this email	0.0	0.0	0.0	2.0	0.0000000000	False
denominator then is sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum up the length	0.0	0.0	0.0	2.0	0.0000000000	False
length of that spam	0.0	0.0	0.0	2.0	0.0000000000	False
ratio is just out	0.0	0.0	0.0	2.0	0.0000000000	False
emails that were word	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for the probability	0.0	0.0	2.99843668577	6.0	0.0000000000	False
piece of spam mail	0.0	0.0	0.0	2.0	0.0000000000	False
mail generating the word	0.0	0.0	0.0	2.0	0.0000000000	False
talked about laplace smoothing	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of this parameter	0.0	0.0	0.0	2.0	0.0000000000	False
work out the estimates	0.0	0.0	0.0	2.0	0.0000000000	False
words of your email	0.0	0.0	0.0	2.0	0.0000000000	False
email of their probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability the ith word	0.0	0.0	0.0	2.0	0.0000000000	False
word in your email	0.0	0.0	0.0	2.0	0.0000000000	False
apologize i just realized	0.0	0.0	0.0	2.0	0.0000000000	False
right so in laplace	0.0	0.0	0.0	2.0	0.0000000000	False
words in your dictionary	0.0	0.0	0.0	2.0	0.0000000000	False
great i stole notation	0.0	0.0	0.0	2.0	0.0000000000	False
nt translate it properly	0.0	0.0	0.0	0.0	0.0000000000	False
properly so laplace smoothing	0.0	0.0	0.0	2.0	0.0000000000	False
number of possible values	0.0	0.0	0.0	4.0	0.0000000000	False
values that the random	0.0	0.0	0.0	2.0	0.0000000000	False
cool raise your hand	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	0.0	4.0	0.0000000000	False
smoothing is a method	0.0	0.0	0.0	2.0	0.0000000000	False
estimates of their probability	0.0	0.0	0.0	2.0	0.0000000000	False
definition for the random	0.0	0.0	0.0	2.0	0.0000000000	False
variable y because suppose	0.0	0.0	0.0	2.0	0.0000000000	False
variable x which takes	0.0	0.0	0.0	2.0	0.0000000000	False
observations the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
observations of x equals	0.0	0.0	0.0	2.0	0.0000000000	False
total number of observations	0.0	0.0	0.0	2.0	0.0000000000	False
estimate and to add	0.0	0.0	0.0	2.0	0.0000000000	False
probability that x equals	0.0	0.0	0.0	2.0	0.0000000000	False
50,000 is the length	0.0	0.0	0.0	2.0	0.0000000000	False
50,000 to the denominator	0.0	0.0	0.0	2.0	0.0000000000	False
definition for a maximum	0.0	0.0	0.0	2.0	0.0000000000	False
estimation of a parameter	0.0	0.0	0.0	2.0	0.0000000000	False
parameter ? we ve	0.0	0.0	0.0	0.0	0.0000000000	False
right so the definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
definition for maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
lecture when i talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about gaussian discriminant	0.0	0.0	0.0	4.0	0.0000000000	False
throwing out the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
estimates on the board	0.0	0.0	0.0	2.0	0.0000000000	False
write down the likelihood	0.0	0.0	0.0	4.0	0.0000000000	False
estimates is to write	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
log of the product	0.0	0.0	0.0	2.0	0.0000000000	False
product of i equals	0.0	0.0	0.0	2.0	0.0000000000	False
parameterized by these things	0.0	0.0	0.0	2.0	0.0000000000	False
set of fixed iyi	0.0	0.0	0.0	2.0	0.0000000000	False
maximize this in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of these parameters	0.0	0.0	0.0	2.0	0.0000000000	False
estimates that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve been writing out	0.0	0.0	0.0	2.0	0.0000000000	False
previous section of today	0.0	0.0	0.0	2.0	0.0000000000	False
wrote out some maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out some maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant analysis model	0.0	0.0	0.0	2.0	0.0000000000	False
maximize the log likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
derived is by maximizing	0.0	0.0	0.0	2.0	0.0000000000	False
right so that wraps	0.0	0.0	0.0	2.0	0.0000000000	False
out that for text	0.0	0.0	0.0	4.0	0.0000000000	False
bayes model i presented	0.0	0.0	0.0	2.0	0.0000000000	False
bayes model i talked	0.0	0.0	0.0	2.0	0.0000000000	False
specific of text classification	0.0	0.0	0.0	2.0	0.0000000000	False
appears in a document	0.0	0.0	0.0	2.0	0.0000000000	False
truth that actually turns	0.0	0.0	0.0	2.0	0.0000000000	False
researchers are still debating	0.0	0.0	0.0	2.0	0.0000000000	False
model is still positioning	0.0	0.0	0.0	2.0	0.0000000000	False
care where the words	0.0	0.0	0.0	2.0	0.0000000000	False
care about the ordering	0.0	0.0	0.0	2.0	0.0000000000	False
ordering of the words	0.0	0.0	0.0	4.0	0.0000000000	False
words you can shuffle	0.0	0.0	0.0	2.0	0.0000000000	False
shuffle all the words	0.0	0.0	0.0	2.0	0.0000000000	False
model in natural language	0.0	0.0	0.0	2.0	0.0000000000	False
higher order markup models	0.0	0.0	0.0	2.0	0.0000000000	False
models like the bigram	0.0	0.0	0.0	2.0	0.0000000000	False
bigram models or trigram	0.0	0.0	0.0	2.0	0.0000000000	False
models or trigram models	0.0	0.0	0.0	2.0	0.0000000000	False
applying them to text	0.0	0.0	0.0	2.0	0.0000000000	False
start again to discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion of non-linear classifiers	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
classification algorithm we talked	0.0	0.0	0.0	2.0	0.0000000000	False
forming form for hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
right ? logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
find a straight line	0.0	0.0	0.0	2.0	0.0000000000	False
line that reasonably separates	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative classes	0.0	0.0	0.0	2.0	0.0000000000	False
sorts of non-linear division	0.0	0.0	0.0	2.0	0.0000000000	False
result is that remember	0.0	0.0	0.0	2.0	0.0000000000	False
talked about generative learning	0.0	0.0	0.0	2.0	0.0000000000	False
build a generative learning	0.0	0.0	0.0	2.0	0.0000000000	False
family with natural parameter	0.0	0.0	0.0	2.0	0.0000000000	False
posterior it actually turns	0.0	0.0	0.0	2.0	0.0000000000	False
bayes model actually falls	0.0	0.0	0.0	4.0	0.0000000000	False
talk about one method	0.0	0.0	0.0	2.0	0.0000000000	False
briefly which is taking	0.0	0.0	0.0	2.0	0.0000000000	False
taking a simpler algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
suppose you have features	0.0	0.0	0.0	2.0	0.0000000000	False
follow our earlier convention	0.0	0.0	0.0	2.0	0.0000000000	False
denote our logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
denoting a computation note	0.0	0.0	0.0	2.0	0.0000000000	False
computation note that takes	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses that can output	0.0	0.0	0.0	2.0	0.0000000000	False
output non-linear division boundaries	0.0	0.0	0.0	2.0	0.0000000000	False
pictures that i drew	0.0	0.0	0.0	2.0	0.0000000000	False
output my final output	0.0	0.0	0.0	2.0	0.0000000000	False
final output h subscript	0.0	0.0	0.0	2.0	0.0000000000	False
output h subscript theta	0.0	0.0	0.0	2.0	0.0000000000	False
give these things names	0.0	0.0	0.0	2.0	0.0000000000	False
call the values output	0.0	0.0	0.0	2.0	0.0000000000	False
units in the middle	0.0	0.0	0.0	2.0	0.0000000000	False
ll write as theta	0.0	0.0	0.0	2.0	0.0000000000	False
vector is a vector	0.0	0.0	0.0	2.0	0.0000000000	False
theta one through theta	0.0	0.0	0.0	4.0	0.0000000000	False
parameters for this model	0.0	0.0	0.0	2.0	0.0000000000	False
model is to write	0.0	0.0	0.0	2.0	0.0000000000	False
write down the cost	0.0	0.0	0.0	2.0	0.0000000000	False
theta equals one-half sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum from y equals	0.0	0.0	0.0	2.0	0.0000000000	False
minus h subscript theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta of xi squared	0.0	0.0	0.0	2.0	0.0000000000	False
familiar quadratic cost function	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
gradient interscent to minimize	0.0	0.0	0.0	2.0	0.0000000000	False
minimize j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta as a function	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent to minimize	0.0	0.0	0.0	2.0	0.0000000000	False
minimize this square area	0.0	0.0	0.0	2.0	0.0000000000	False
means you use gradient	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent to make	0.0	0.0	0.0	2.0	0.0000000000	False
observed as the labels	0.0	0.0	0.0	2.0	0.0000000000	False
labels in your training	0.0	0.0	0.0	2.0	0.0000000000	False
turns out green descent	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that implements grand	0.0	0.0	0.0	2.0	0.0000000000	False
interscent on a cost	0.0	0.0	0.0	2.0	0.0000000000	False
intermediate notes are computing	0.0	0.0	0.0	2.0	0.0000000000	False
feed into these computation	0.0	0.0	0.0	2.0	0.0000000000	False
feed into more layers	0.0	0.0	0.0	2.0	0.0000000000	False
layers of computation units	0.0	0.0	0.0	2.0	0.0000000000	False
layer at the end	0.0	0.0	0.0	2.0	0.0000000000	False
end and one cool	0.0	0.0	0.0	2.0	0.0000000000	False
network do nt worry	0.0	0.0	0.0	0.0	0.0000000000	False
computations of the hidden	0.0	0.0	0.0	2.0	0.0000000000	False
computing the neural network	0.0	0.0	0.0	2.0	0.0000000000	False
sense of neural networks	0.0	0.0	0.0	2.0	0.0000000000	False
show you a video	0.0	0.0	3.99843668577	6.0	0.0000000000	False
switch to the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
made by a friend	0.0	0.0	0.0	2.0	0.0000000000	False
professor at new york	0.0	0.0	0.0	2.0	0.0000000000	False
university can i show	0.0	0.0	0.0	2.0	0.0000000000	False
video on the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
video from yann lecun	0.0	0.0	0.0	2.0	0.0000000000	False
network that he developed	0.0	0.0	0.0	2.0	0.0000000000	False
developed for hammerton digit	0.0	0.0	0.0	2.0	0.0000000000	False
system is called lenet	0.0	0.0	0.0	2.0	0.0000000000	False
put on the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
laptop display ? hum	0.0	0.0	0.0	2.0	0.0000000000	False
put on the screen	0.0	0.0	0.0	2.0	0.0000000000	False
screen on the side	0.0	0.0	0.0	2.0	0.0000000000	False
screen is nt working	0.0	0.0	0.0	0.0	0.0000000000	False
entertained while we re	0.0	0.0	0.0	0.0	0.0000000000	False
waiting for the video	0.0	0.0	0.0	2.0	0.0000000000	False
things about neural network	0.0	0.0	0.0	2.0	0.0000000000	False
network so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
write a quadratic cost	0.0	0.0	0.0	2.0	0.0000000000	False
function like i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
respond to non-convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
regression if you run	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent or newton	0.0	0.0	0.0	2.0	0.0000000000	False
converse the global optimer	0.0	0.0	0.0	2.0	0.0000000000	False
true for neural networks	0.0	0.0	0.0	2.0	0.0000000000	False
lots of local optimer	0.0	0.0	0.0	2.0	0.0000000000	False
problem so neural networks	0.0	0.0	0.0	2.0	0.0000000000	False
re good at making	0.0	0.0	0.0	2.0	0.0000000000	False
good at making design	0.0	0.0	0.0	2.0	0.0000000000	False
choices like what learning	0.0	0.0	0.0	2.0	0.0000000000	False
vast majority of machine	0.0	0.0	0.0	2.0	0.0000000000	False
majority of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
machine learning researchers today	0.0	0.0	0.0	2.0	0.0000000000	False
today seem to perceive	0.0	0.0	0.0	2.0	0.0000000000	False
perceive support vector machines	0.0	0.0	0.0	2.0	0.0000000000	False
effective off-the-shelf learning algorithm	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm than neural networks	0.0	0.0	0.0	2.0	0.0000000000	False
neural networks this point	0.0	0.0	0.0	2.0	0.0000000000	False
personally use a lot	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm before support	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm before support vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector machines were invented	0.0	0.0	0.0	2.0	0.0000000000	False
yann lecun s video	0.0	0.0	0.0	0.0	0.0000000000	False
happening what you re	0.0	0.0	0.0	0.0	0.0000000000	False
display where my mouse	0.0	0.0	0.0	2.0	0.0000000000	False
mouse pointer is pointing	0.0	0.0	0.0	2.0	0.0000000000	False
network so you re	0.0	0.0	0.0	0.0	0.0000000000	False
showing the neural network	0.0	0.0	0.0	2.0	0.0000000000	False
neural network this image	0.0	0.0	0.0	2.0	0.0000000000	False
network is this number	0.0	0.0	0.0	2.0	0.0000000000	False
neural network correctly recognizes	0.0	0.0	0.0	2.0	0.0000000000	False
correctly recognizes this image	0.0	0.0	0.0	2.0	0.0000000000	False
left of this image	0.0	0.0	0.0	2.0	0.0000000000	False
display on the left	0.0	0.0	0.0	2.0	0.0000000000	False
showing the intermediate computations	0.0	0.0	0.0	2.0	0.0000000000	False
network in other words	0.0	0.0	0.0	2.0	0.0000000000	False
right ? we re	0.0	0.0	0.0	0.0	0.0000000000	False
re just computing digits	0.0	0.0	0.0	2.0	0.0000000000	False
digits on the right-hand	0.0	0.0	0.0	2.0	0.0000000000	False
side of the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
display of the input	0.0	0.0	0.0	2.0	0.0000000000	False
noise all right multiple	0.0	0.0	0.0	2.0	0.0000000000	False
produced by wgbh television	0.0	0.0	0.0	2.0	0.0000000000	False
wgbh television in corporation	0.0	0.0	0.0	2.0	0.0000000000	False
corporation with british foreclass	0.0	0.0	0.0	2.0	0.0000000000	False
pbs a few years	0.0	0.0	0.0	2.0	0.0000000000	False
video describing the nettalk	0.0	0.0	0.0	2.0	0.0000000000	False
developed by terry sejnowski	0.0	0.0	0.0	2.0	0.0000000000	False
researcher and so nettalk	0.0	0.0	0.0	2.0	0.0000000000	False
milestones in the history	0.0	0.0	0.0	2.0	0.0000000000	False
history of neural network	0.0	0.0	3.99843668577	6.0	0.0000000000	False
neural network to read	0.0	0.0	0.0	2.0	0.0000000000	False
network to read text	0.0	0.0	0.0	2.0	0.0000000000	False
english to a computer	0.0	0.0	0.0	2.0	0.0000000000	False
sounds that could respond	0.0	0.0	0.0	2.0	0.0000000000	False
respond to the reading	0.0	0.0	0.0	2.0	0.0000000000	False
reading of the text	0.0	0.0	0.0	2.0	0.0000000000	False
text and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
history of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
video created a lot	0.0	0.0	0.0	2.0	0.0000000000	False
excitement about neural networks	0.0	0.0	0.0	2.0	0.0000000000	False
networks and about machine	0.0	0.0	0.0	2.0	0.0000000000	False
part of the reason	0.0	0.0	0.0	2.0	0.0000000000	False
sejnowski had the foresight	0.0	0.0	0.0	2.0	0.0000000000	False
voice talking about visiting	0.0	0.0	0.0	2.0	0.0000000000	False
perception of  created	0.0	0.0	0.0	2.0	0.0000000000	False
learning how to speak	0.0	0.0	0.0	2.0	0.0000000000	False
helped generate a lot	0.0	0.0	0.0	2.0	0.0000000000	False
academia and outside academia	0.0	0.0	0.0	2.0	0.0000000000	False
academia on neural networks	0.0	0.0	0.0	2.0	0.0000000000	False
early in the history	0.0	0.0	0.0	2.0	0.0000000000	False
show you the video	0.0	0.0	0.0	2.0	0.0000000000	False
re going to hear	0.0	0.0	0.0	2.0	0.0000000000	False
first what the network	0.0	0.0	0.0	2.0	0.0000000000	False
beginning of the training	0.0	0.0	0.0	2.0	0.0000000000	False
nt sound like words	0.0	0.0	0.0	0.0	0.0000000000	False
ll sound like attempts	0.0	0.0	0.0	2.0	0.0000000000	False
network takes the letters	0.0	0.0	0.0	2.0	0.0000000000	False
makes a random attempt	0.0	0.0	0.0	2.0	0.0000000000	False
random attempt at pronouncing	0.0	0.0	0.0	2.0	0.0000000000	False
house the phonetic difference	0.0	0.0	0.0	2.0	0.0000000000	False
difference between the guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess and the right	0.0	0.0	0.0	2.0	0.0000000000	False
back through the network	0.0	0.0	0.0	2.0	0.0000000000	False
adjusting the connection strengths	0.0	0.0	0.0	2.0	0.0000000000	False
strengths after each attempt	0.0	0.0	0.0	2.0	0.0000000000	False
associating letters with sounds	0.0	0.0	0.0	2.0	0.0000000000	False
amazing piece of work	0.0	0.0	0.0	2.0	0.0000000000	False
text to speech systems	0.0	0.0	0.0	2.0	0.0000000000	False
speech systems that work	0.0	0.0	0.0	2.0	0.0000000000	False
candy from your grandmother	0.0	0.0	0.0	2.0	0.0000000000	False
talking about the dow	0.0	0.0	0.0	2.0	0.0000000000	False
landmark in the history	0.0	0.0	0.0	2.0	0.0000000000	False
back to the chalkboard	0.0	0.0	0.0	2.0	0.0000000000	False
wraps up our discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on neural networks	0.0	0.0	0.0	2.0	0.0000000000	False
networks so i started	0.0	0.0	0.0	2.0	0.0000000000	False
neural networks by motivating	0.0	0.0	0.0	2.0	0.0000000000	False
drew on the chalkboard	0.0	0.0	0.0	2.0	0.0000000000	False
chalkboard earlier support vector	0.0	0.0	0.0	2.0	0.0000000000	False
earlier support vector machines	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that will give	0.0	0.0	0.0	2.0	0.0000000000	False
start off by describing	0.0	0.0	0.0	2.0	0.0000000000	False
describing yet another class	0.0	0.0	0.0	2.0	0.0000000000	False
class of linear classifiers	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers with linear division	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine idea	0.0	0.0	0.0	2.0	0.0000000000	False
generate non-linear division boundaries	0.0	0.0	0.0	2.0	0.0000000000	False
talking about linear classifiers	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
two intuitions about classification	0.0	0.0	0.0	2.0	0.0000000000	False
function that was outputting	0.0	0.0	0.0	2.0	0.0000000000	False
probability that y equals	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that computes theta	0.0	0.0	0.0	2.0	0.0000000000	False
right ? iff stands	0.0	0.0	0.0	2.0	0.0000000000	False
means the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
case that theta transpose	0.0	0.0	0.0	2.0	0.0000000000	False
double greater than sign	0.0	0.0	0.0	2.0	0.0000000000	False
greater than sign means	0.0	0.0	0.0	2.0	0.0000000000	False
right so if theta	0.0	0.0	0.0	2.0	0.0000000000	False
right ? if theta	0.0	0.0	0.0	2.0	0.0000000000	False
re gon na predict	0.0	0.0	0.0	2.0	0.0000000000	False
estimating that the probability	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers is your training	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm not only makes	0.0	0.0	0.0	2.0	0.0000000000	False
examples in a training	0.0	0.0	0.0	2.0	0.0000000000	False
talk about functional margins	0.0	0.0	0.0	2.0	0.0000000000	False
out for the rest	0.0	0.0	0.0	2.0	0.0000000000	False
assume that a training	0.0	0.0	0.0	2.0	0.0000000000	False
line that can separate	0.0	0.0	0.0	2.0	0.0000000000	False
separate your training set	0.0	0.0	0.0	2.0	0.0000000000	False
ll remove this assumption	0.0	0.0	0.0	2.0	0.0000000000	False
linearly separable training set	0.0	0.0	0.0	2.0	0.0000000000	False
separate the training set	0.0	0.0	0.0	2.0	0.0000000000	False
line in the middle	0.0	0.0	0.0	2.0	0.0000000000	False
negative examples and division	0.0	0.0	0.0	2.0	0.0000000000	False
examples and division boundary	0.0	0.0	0.0	2.0	0.0000000000	False
line that i drew	0.0	0.0	0.0	2.0	0.0000000000	False
distance from the training	0.0	0.0	0.0	2.0	0.0000000000	False
talk about geometric margins	0.0	0.0	0.0	2.0	0.0000000000	False
margins of our classifiers	0.0	0.0	0.0	2.0	0.0000000000	False
order to describe support	0.0	0.0	0.0	2.0	0.0000000000	False
describe support vector machine	0.0	0.0	0.0	2.0	0.0000000000	False
pull a notation change	0.0	0.0	0.0	2.0	0.0000000000	False
slightly for linear classifiers	0.0	0.0	0.0	2.0	0.0000000000	False
lectures to actually talk	0.0	0.0	0.0	2.0	0.0000000000	False
machine but the notation	0.0	0.0	0.0	2.0	0.0000000000	False
development of a support	0.0	0.0	0.0	2.0	0.0000000000	False
wrote g subscript theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta of x equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals g of theta	0.0	0.0	0.0	2.0	0.0000000000	False
letting x zero equals	0.0	0.0	0.0	2.0	0.0000000000	False
parameterize my linear classifier	0.0	0.0	0.0	2.0	0.0000000000	False
classifier as h subscript	0.0	0.0	0.0	2.0	0.0000000000	False
role of the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
separating out the interceptor	0.0	0.0	0.0	2.0	0.0000000000	False
develop support vector machines	0.0	0.0	0.0	2.0	0.0000000000	False
notion of functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin and germesh margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin let me make	0.0	0.0	0.0	2.0	0.0000000000	False
margin of the hyper	0.0	0.0	0.0	2.0	0.0000000000	False
plane wb with respect	0.0	0.0	0.0	4.0	0.0000000000	False
xiyi is  wrt	0.0	0.0	0.0	2.0	0.0000000000	False
stands for with respect	0.0	0.0	0.0	2.0	0.0000000000	False
margin of a hyper	0.0	0.0	0.0	4.0	0.0000000000	False
xiyi has been defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined as gamma hat	0.0	0.0	0.0	2.0	0.0000000000	False
gamma hat i equals	0.0	0.0	0.0	4.0	0.0000000000	False
defines a linear separating	0.0	0.0	0.0	2.0	0.0000000000	False
boundary that s defined	0.0	0.0	0.0	0.0	0.0000000000	False
defined by the parameters	0.0	0.0	0.0	4.0	0.0000000000	False
confused by the hyper	0.0	0.0	0.0	2.0	0.0000000000	False
ignore it the hyper	0.0	0.0	0.0	2.0	0.0000000000	False
respect to a training	0.0	0.0	0.0	2.0	0.0000000000	False
order for the function	0.0	0.0	0.0	4.0	0.0000000000	False
earlier about functional margins	0.0	0.0	0.0	2.0	0.0000000000	False
margins  the intuition	0.0	0.0	0.0	2.0	0.0000000000	False
practice of two cases	0.0	0.0	0.0	2.0	0.0000000000	False
cases into one statement	0.0	0.0	0.0	2.0	0.0000000000	False
margin to be large	0.0	0.0	5.99687337155	12.0	0.0000000000	False
long as yi times	0.0	0.0	0.0	2.0	0.0000000000	False
hyper plane with respect	0.0	0.0	0.0	2.0	0.0000000000	False
training examples of gamma	0.0	0.0	0.0	2.0	0.0000000000	False
define the functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
functional margin with respect	0.0	0.0	0.0	2.0	0.0000000000	False
function like an intuition	0.0	0.0	0.0	2.0	0.0000000000	False
problem with this intuition	0.0	0.0	0.0	2.0	0.0000000000	False
make the functional margin	0.0	0.0	2.99843668577	6.0	0.0000000000	False
times w times transpose	0.0	0.0	0.0	2.0	0.0000000000	False
double my functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin so this goal	0.0	0.0	0.0	2.0	0.0000000000	False
large just by scaling	0.0	0.0	0.0	2.0	0.0000000000	False
add a normalization condition	0.0	0.0	0.0	4.0	0.0000000000	False
alter-norm of the parameter	0.0	0.0	0.0	2.0	0.0000000000	False
margin of a training	0.0	0.0	0.0	4.0	0.0000000000	False
boundary of my classifier	0.0	0.0	0.0	2.0	0.0000000000	False
re going to draw	0.0	0.0	0.0	2.0	0.0000000000	False
draw relatively few training	0.0	0.0	0.0	2.0	0.0000000000	False
drawing deliberately few training	0.0	0.0	0.0	2.0	0.0000000000	False
deliberately few training examples	0.0	0.0	0.0	2.0	0.0000000000	False
define the geometric margin	0.0	0.0	5.99791558103	8.0	0.3445378151	False
distance between a point	0.0	0.0	0.0	2.0	0.0000000000	False
point between the training	0.0	0.0	0.0	2.0	0.0000000000	False
fairly quickly in case	0.0	0.0	0.0	2.0	0.0000000000	False
read through the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
carefully for details sort	0.0	0.0	0.0	2.0	0.0000000000	False
degrees to the separating	0.0	0.0	0.0	2.0	0.0000000000	False
divided by the norm	0.0	0.0	4.99843668577	6.0	0.0000000000	False
planes and high dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
work if this stuff	0.0	0.0	0.0	2.0	0.0000000000	False
notes on the website	0.0	0.0	0.0	2.0	0.0000000000	False
ll put a hat	0.0	0.0	0.0	2.0	0.0000000000	False
referring to functional margins	0.0	0.0	0.0	2.0	0.0000000000	False
top for geometric margins	0.0	0.0	0.0	2.0	0.0000000000	False
gamma i that means	0.0	0.0	0.0	2.0	0.0000000000	False
means that this point	0.0	0.0	0.0	2.0	0.0000000000	False
minus gamma i times	0.0	0.0	0.0	2.0	0.0000000000	False
normal to the separating	0.0	0.0	0.0	2.0	0.0000000000	False
subtract gamma i times	0.0	0.0	0.0	2.0	0.0000000000	False
times the unit vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector from this point	0.0	0.0	0.0	2.0	0.0000000000	False
point that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
satisfy w transpose times	0.0	0.0	0.0	2.0	0.0000000000	False
transpose times that point	0.0	0.0	0.0	2.0	0.0000000000	False
times that point equals	0.0	0.0	0.0	2.0	0.0000000000	False
separating hyper plane satisfy	0.0	0.0	0.0	2.0	0.0000000000	False
plane satisfy the equation	0.0	0.0	0.0	2.0	0.0000000000	False
fast in this geometry	0.0	0.0	0.0	2.0	0.0000000000	False
details in the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
ll solve for gamma	0.0	0.0	0.0	2.0	0.0000000000	False
equation i just wrote	0.0	0.0	0.0	2.0	0.0000000000	False
previous equation from gamma	0.0	0.0	0.0	2.0	0.0000000000	False
equals gamma i times	0.0	0.0	0.0	2.0	0.0000000000	False
transpose w over norm	0.0	0.0	0.0	2.0	0.0000000000	False
equal to gamma times	0.0	0.0	0.0	2.0	0.0000000000	False
gamma times the norm	0.0	0.0	0.0	2.0	0.0000000000	False
norm of w squared	0.0	0.0	0.0	2.0	0.0000000000	False
separating hyper plane defined	0.0	0.0	0.0	2.0	0.0000000000	False
computed by this formula	0.0	0.0	0.0	2.0	0.0000000000	False
classification of the training	0.0	0.0	0.0	2.0	0.0000000000	False
assuming that we ve	0.0	0.0	0.0	0.0	0.0000000000	False
classifying an example correctly	0.0	0.0	0.0	4.0	0.0000000000	False
find the geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
normalization by the norm	0.0	0.0	0.0	2.0	0.0000000000	False
long as we re	0.0	0.0	0.0	0.0	0.0000000000	False
side of the separating	0.0	0.0	0.0	2.0	0.0000000000	False
couple of easy facts	0.0	0.0	0.0	2.0	0.0000000000	False
geometric margin with respect	0.0	0.0	0.0	4.0	0.0000000000	False
training set as gamma	0.0	0.0	0.0	2.0	0.0000000000	False
set as gamma equals	0.0	0.0	0.0	2.0	0.0000000000	False
precursor to the support	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm that chooses	0.0	0.0	0.0	2.0	0.0000000000	False
maximize the geometric margin	0.0	0.0	5.99843668577	6.0	0.0000000000	False
maximum margin classified poses	0.0	0.0	0.0	2.0	0.0000000000	False
poses the following optimization	0.0	0.0	0.0	2.0	0.0000000000	False
problem it says choose	0.0	0.0	0.0	2.0	0.0000000000	False
minutes i m guessing	0.0	0.0	0.0	0.0	0.0000000000	False
classifier is the maximization	0.0	0.0	0.0	2.0	0.0000000000	False
maximization problem over parameter	0.0	0.0	0.0	2.0	0.0000000000	False
problem over parameter gamma	0.0	0.0	0.0	2.0	0.0000000000	False
margin does nt change	0.0	0.0	0.0	0.0	0.0000000000	False
depending on the norm	0.0	0.0	0.0	2.0	0.0000000000	False
notice that we re	0.0	0.0	0.0	0.0	0.0000000000	False
change the geometric margin	0.0	0.0	0.0	4.0	0.0000000000	False
impose any normalization constant	0.0	0.0	0.0	2.0	0.0000000000	False
scaling factor and replace	0.0	0.0	0.0	2.0	0.0000000000	False
margin at least gamma	0.0	0.0	0.0	2.0	0.0000000000	False
comparable to logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature spaces	0.0	0.0	0.0	2.0	0.0000000000	False
re given a fixed	0.0	0.0	0.0	4.0	0.0000000000	False
scaling of the training	0.0	0.0	0.0	2.0	0.0000000000	False
ll talk about authorization	0.0	0.0	0.0	2.0	0.0000000000	False
talk about authorization algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
morning welcome back	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
announcement for today	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
tutorial on matlab	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
matlab and octaves	0.00198039004665	0.0	0.0	3.16992500144	0.0000000000	False
matlab or octave	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
terms and matlab	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
today is continue	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
continue our discussion	0.000762958487242	0.0	0.0	1.58496250072	0.0000000000	False
started to discuss	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
lecture and talk	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
digression to talk	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
talk about neural	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
spend a lot	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
start to talk	0.00107144390232	0.0	0.0	3.16992500144	0.0000000000	False
talk about support	0.00198039004665	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.00811297131912	1.0	12.9927045336	20.6045125094	0.4389721627	True
supervised learning algorithm	0.00198039004665	0.0	0.0	1.58496250072	0.0000000000	False
off-the-shelf supervised learning	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
algorithm that point	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
point of view	0.0017384938541	0.0	1.99843668577	4.75488750216	0.0000000000	False
view is debatable	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
people that hold	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hold that point	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ll start discussing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
discussing that today	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lectures to complete	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
bayes to recap	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
started off describing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
describing spam classification	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
create feature vectors	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
correspond to words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
piece of email	0.00594117013994	0.0	6.99687337155	9.50977500433	0.4572490706	False
email were represented	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
generative learning algorithm	0.00297058506997	1.0	3.99843668577	4.75488750216	0.0000000000	True
rule is rfx	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
number of words	0.00396078009329	0.0	4.99791558103	6.33985000288	0.5256410256	False
describe two variations	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
algorithm the first	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
bayes to problems	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
model where pfx	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
values it turns	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
choose to dispertise	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
continuous value feature	0.00365229467821	0.0	2.99843668577	4.75488750216	0.0000000000	False
feature and dispertise	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
first supervised learning	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
supervised learning problem	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
problem of predicting	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
predicting the price	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
price of houses	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
based on features	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
pretty common thing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
continuous value living	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
value living area	0.0	0.0	0.0	0.0	0.0000000000	False
2,000 square feet	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
choose the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
variation or generalization	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
bayes i wanted	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
wanted to talk	0.0012174315594	0.0	1.99843668577	4.75488750216	0.0000000000	False
buckets to dispertise	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
dispertise a continuous	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
feature i drew	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
save on writing	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
specific to classifying	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
classifying text documents	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
sequence of words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
describe to classifying	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
classifying other sequences	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
focus on text	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
binary vector value	0.0	0.0	0.0	0.0	0.0000000000	False
vector value representation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
number of times	0.0031501681742	0.0	3.99739447629	6.33985000288	0.3734061931	False
appears a lot	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lot of times	0.00160716585348	0.0	4.99843668577	4.75488750216	0.0000000000	False
word  viagra	0.0	0.0	0.0	1.58496250072	0.0000000000	False
viagra a ton	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ton of times	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
account the number	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
times a word	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
give this previous	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
model for text	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
multivariate bernoulli event	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
bernoulli event model	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
means it refers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
multiple bernoulli random	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
bernoulli random variables	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
means in contrast	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
representation for email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
email in terms	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
multinomial event model	0.00486972623762	0.0	5.99739447629	7.92481250361	0.3734061931	True
represent my email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
represent this email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
vector  lets	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
variable that takes	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
50,000 possible values	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
longer binary random	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
binary random variables	0.0	0.0	0.0	0.0	0.0000000000	False
re these indices	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of values	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
distribution over emails	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
distribution that generates	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
generates the emails	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
first the class	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
send you spam	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
emails is chosen	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
label of spam	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
spam is generated	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
distribution that depends	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
chose to send	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
send you words	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
tend to generate	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
previous event model	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
deciding to spend	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
spend you spam	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
word they choose	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
choose to email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the maximum	0.00198039004665	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood estimates	0.00693036998325	0.0	13.9937467431	19.0195500087	0.2979651163	True
big indicator function	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
indicator function things	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
training sets indicator	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
times the sum	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
words in email	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times indicator xij	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
numerator says sum	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times you observed	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
observed the word	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
set and count	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
times the word	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
word k appeared	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
email the denominator	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
examples is spam	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
fraction of words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
piece of spam	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
spam mail generating	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
generating the word	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
talked about laplace	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
laplace smoothed estimate	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
out the estimates	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
essentially the identity	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
realized that overload	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
overload the notation	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
re absolutely right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
great i stole	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
translate it properly	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
properly so laplace	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.000862644603151	0.0	0.0	1.58496250072	0.0000000000	False
number of values	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
method to give	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
estimate the probability	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
multinomial random variable	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
number of observations	0.00365229467821	0.0	2.99843668577	3.16992500144	0.0000000000	False
observations the maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
equals k divided	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
add laplace smoothing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
examples make sense	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
definition of maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
definition for maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
talk about gaussian	0.00198039004665	0.0	0.0	0.0	0.0000000000	False
gaussian discriminant analysis	0.00257181051277	1.0	4.99843668577	3.16992500144	0.0000000000	True
board without proving	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
writing log likelihood	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ll just drop	0.0	0.0	0.0	1.58496250072	0.0000000000	False
drop the parameters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
parameters to write	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
fixed training set	0.00396078009329	0.0	5.99791558103	6.33985000288	0.5061728395	False
set of fixed	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ve been writing	0.0	0.0	0.0	0.0	0.0000000000	False
section of today	0.0	0.0	0.0	0.0	0.0000000000	False
lecture i wrote	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
out some maximum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
discriminant analysis model	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
maximize the likelihood	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
likelihood and maximize	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
maximize the log	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
cool all right	0.0	0.0	0.0	3.16992500144	0.0000000000	False
model i presented	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
model i talked	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
specific of text	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
reasons is hypothesized	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
takes into account	0.0012174315594	0.0	5.99687337155	9.50977500433	0.4572490706	False
model does nt	0.0	0.0	0.0	0.0	0.0000000000	False
text classification problem	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
straightforward to implement	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
positioning a variant	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
nt actually care	0.0	0.0	0.0	0.0	0.0000000000	False
natural language processing	0.00198039004665	0.0	0.0	3.16992500144	0.0000000000	False
unique grand model	0.0012174315594	1.0	0.0	1.58496250072	0.0000000000	False
model in natural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
higher order markup	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
order markup models	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
words it turns	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
models or trigram	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
discussion of non-linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
first classification algorithm	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
algorithm we talked	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
form for hypothesis	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
probability is greater	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
greater or equal	0.00171454034184	0.0	0.0	3.16992500144	0.0000000000	False
right ? logistic	0.0	0.0	0.0	0.0	0.0000000000	False
grade and descends	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
method to find	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
find a straight	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
separates the positive	0.000630033634841	0.0	0.0	1.58496250072	0.0000000000	False
positive and negative	0.000535721951161	0.0	0.0	0.0	0.0000000000	False
nt be separated	0.0	0.0	0.0	0.0	0.0000000000	False
start to learn	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
learn these sorts	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
sorts of non-linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
non-linear division boundaries	0.00486972623762	0.0	1.99739447629	6.33985000288	0.0000000000	True
talked about generative	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
build a generative	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
family with natural	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
model actually falls	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
taking a simpler	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
algorithm like logistic	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
complex non-linear classifiers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
motivate this discussion	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
follow our earlier	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
denote our logistic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
logistic regression unit	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
circle as denoting	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
denoting a computation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
note that takes	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
takes this input	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
outputs another number	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
output non-linear division	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
put a bunch	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
output my final	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
output h subscript	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
give these things	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
call the values	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
intermediate sigmoidal units	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.00189010090452	0.0	1.99843668577	4.75488750216	0.0000000000	False
write as theta	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hypothesis will output	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
equals one-half sum	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
minus h subscript	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
familiar quadratic cost	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
quadratic cost function	0.00243486311881	0.0	0.0	1.58496250072	0.0000000000	False
learn the parameters	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
interscent to minimize	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
function of theta	0.000762958487242	0.0	0.0	1.58496250072	0.0000000000	False
phi gradient descent	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
descent to minimize	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
minimize this square	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
stated differently means	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
descent to make	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make the predictions	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
network as close	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
turns out green	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
out green descent	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
algorithm that implements	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
implements grand descent	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
means gradient interscent	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
advantages and disadvantages	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
notes are computing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
layers of computation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hidden unit computing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
computing the neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
sense of neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
show a video	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
video from yann	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
developed for hammerton	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hammerton digit recognition	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
convolutional neural network	0.0012174315594	1.0	0.0	1.58496250072	0.0000000000	False
display ? hum	0.0	0.0	0.0	0.0	0.0000000000	False
things about neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
write a quadratic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
out that unlike	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
unlike logistic regression	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
respond to non-convex	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
non-convex optimization problem	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
run gradient descent	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
descent or newton	0.0	0.0	0.0	0.0	0.0000000000	False
converse the global	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
true for neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
networks in general	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
lots of local	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
harder optimization problem	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
problem so neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
good at making	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
making design choices	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
majority of machine	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
machine learning researchers	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
learning researchers today	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
perceive support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
effective off-the-shelf learning	0.00365229467821	0.0	0.0	0.0	0.0000000000	False
off-the-shelf learning algorithm	0.00365229467821	0.0	1.99843668577	1.58496250072	0.0000000000	True
algorithm than neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
networks this point	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
view is contested	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
contested a bit	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hard optimization problem	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
sort of works	0.00198039004665	0.0	0.0	1.58496250072	0.0000000000	False
effective learning algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
algorithm before support	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
machines were invented	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lecun s video	0.0	0.0	0.0	0.0	0.0000000000	False
trained neural network	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
pointer is pointing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
showing the neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
network this image	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
final answer output	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
network correctly recognizes	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
recognizes this image	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
showing the intermediate	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
neural network computing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
edges into digits	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
re just computing	0.0	0.0	0.0	0.0	0.0000000000	False
play this video	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
inputs and outputs	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
robustness to noise	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
noise all right	0.0	0.0	0.0	0.0	0.0000000000	False
right multiple digits	0.0	0.0	0.0	1.58496250072	0.0000000000	False
machine that changed	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
changed the world	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
produced by wgbh	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
television in corporation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
corporation with british	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
british foreclass incorporation	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
aired on pbs	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
describing the nettalk	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
nettalk neural network	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
developed by terry	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
history of neural	0.00365229467821	0.0	3.99843668577	0.0	0.0000000000	False
network to read	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
show a piece	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
piece of english	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
verbally produce sounds	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
history of machine	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
created a lot	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lot of excitement	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
excitement about neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
machine learning part	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
foresight to choose	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
child-like voice talking	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
talking about visiting	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
visiting your grandmother	0.0	0.0	0.0	1.58496250072	0.0000000000	False
grandmother s house	0.0	0.0	0.0	0.0	0.0000000000	False
created the perception	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
created the impression	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
young child learning	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
generate a lot	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
excitement within academia	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
academia on neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
sound like words	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
sound like attempts	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
computer s voice	0.0	0.0	0.0	0.0	0.0000000000	False
takes the letters	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
makes a random	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
attempt at pronouncing	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
house the phonetic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
house by adjusting	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
adjusting the connection	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
net slowly improves	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
letting it train	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
morning it sounds	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
simply associating letters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
letters with sounds	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
piece of work	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
text to speech	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
systems that work	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
bit less impressive	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
impressive than talking	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
dow jones falling	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
wanted to show	0.0012174315594	0.0	0.0	3.16992500144	0.0000000000	False
discussion on neural	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
started off talking	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
networks by motivating	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
output non-linear classifiers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
nt really approve	0.0	0.0	0.0	0.0	0.0000000000	False
chalkboard earlier support	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
earlier support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
progression and development	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
class of linear	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
classifiers with linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
linear division boundaries	0.000990195023323	0.0	2.99687337155	9.50977500433	0.0000000000	False
vector machine idea	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make it work	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
generate non-linear division	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ll actually start	0.0	0.0	0.0	1.58496250072	0.0000000000	False
start by talking	0.000857270170922	0.0	0.0	1.58496250072	0.0000000000	False
talking about linear	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
convey two intuitions	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
intuitions about classification	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
outputting the probability	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
crosses this line	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
run logistic regression	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that computes	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
computes theta transpose	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
right ? iff	0.0	0.0	0.0	0.0	0.0000000000	False
case that theta	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
greater than sign	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
re very confident	0.0	0.0	0.0	3.16992500144	0.0000000000	False
fit logistic regression	0.000689804662093	0.0	0.0	1.58496250072	0.0000000000	False
find parameters theta	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
makes correct classifications	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
talk about functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
rest of today	0.0012174315594	0.0	3.99843668577	4.75488750216	0.0000000000	False
separate your training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
remove this assumption	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
develop the algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
linearly separable training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
separable training set	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lines that separate	0.000762958487242	0.0	0.0	1.58496250072	0.0000000000	False
separate the training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
separates the data	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
examples and division	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
line this notion	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
notion of distance	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
talk about geometric	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
order to describe	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
describe support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
pull a notation	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
completely consistent notation	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
slightly for linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
easier later today	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
week s lectures	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis output values	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
previously i wrote	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
wrote g subscript	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
drop this convention	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
convention of letting	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
parameterize my linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
plays the role	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
role of theta	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
out the interceptor	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make it easier	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
develop support vector	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
formalize the notion	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
notion of functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
margin and germesh	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
make a definition	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
defined as gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hat i equals	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
equals yi times	0.00365229467821	0.0	2.99843668577	4.75488750216	0.0000000000	False
times w transpose	0.00365229467821	0.0	3.99843668577	4.75488750216	0.0000000000	False
defines a classifier	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
defines a linear	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
linear separating boundary	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hyper plane term	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
classifier with parameters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
large functional margin	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
margins to large	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
equal to minus	0.00137960932419	0.0	0.0	3.16992500144	0.0000000000	False
captures the intuition	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
earlier about functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
large and notice	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
means we classified	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
plane with respect	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
entire training set	0.00305183394897	0.0	3.99791558103	6.33985000288	0.0000000000	False
equal to min	0.000990195023323	0.0	5.99843668577	4.75488750216	0.0000000000	False
examples of gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
define the functional	0.0	0.0	0.0	0.0	0.0000000000	False
margin with respect	0.00365229467821	0.0	4.99843668577	3.16992500144	0.0000000000	False
worst-case functional margin	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
easy to make	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
make the functional	0.00365229467821	0.0	2.99843668577	0.0	0.0000000000	False
functional margin large	0.00243486311881	0.0	0.0	3.16992500144	0.0000000000	False
times w times	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
double my functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
goal of making	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
margin arbitrarily large	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
scaling other parameters	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
add a normalization	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
plane w transpose	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
deliberately few training	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
assuming we classified	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
define the geometric	0.000990195023323	0.0	5.99791558103	0.0	0.3445378151	False
separating hyper plane	0.0109568840346	0.0	11.9953100573	12.6797000058	0.2810357959	False
algebra fairly quickly	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
quickly in case	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
carefully for details	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
planes and high	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
high dimensions work	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
distance is gamma	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
put a hat	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
hat on top	0.00198039004665	0.0	0.0	3.16992500144	0.0000000000	False
referring to functional	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
top for geometric	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
gamma i times	0.00486972623762	0.0	3.99791558103	4.75488750216	0.2939068100	False
length one vector	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times the unit	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
minus this vector	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
vector is gamma	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
point must satisfy	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
satisfy w transpose	0.00243486311881	0.0	0.0	1.58496250072	0.0000000000	False
times that point	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
hyper plane satisfy	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
satisfy the equation	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
equation w transpose	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
transpose this point	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
solve for gamma	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
solve this equation	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
equation for gamma	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
gamma or gamma	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
equation from gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
equal to gamma	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
times the norm	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
transpose x equals	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
calculation just showed	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
hyper plane defined	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
account the sign	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
ve been assuming	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ve been classifying	0.0	0.0	0.0	1.58496250072	0.0000000000	False
find the geometric	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
gamma i equals	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
times that thing	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
thing on top	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
couple of easy	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
margin is equal	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
functional margin divided	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
set as gamma	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
gamma equals min	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
maximum margin classifier	0.00365229467821	0.0	5.99843668577	3.16992500144	0.0000000000	False
algorithm that chooses	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
chooses the parameters	0.000689804662093	0.0	0.0	1.58496250072	0.0000000000	False
maximize the geometric	0.00297058506997	0.0	5.99843668577	0.0	0.0000000000	False
margin classified poses	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
ways to write	0.0012174315594	0.0	0.0	3.16992500144	0.0000000000	False
maximizing your classifier	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
problem over parameter	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
nt change depending	0.0	0.0	0.0	0.0	0.0000000000	False
set the norm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
change the geometric	0.00243486311881	0.0	0.0	0.0	0.0000000000	False
impose any normalization	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
factor and replace	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
impose a constraint	0.000990195023323	0.0	0.0	1.58496250072	0.0000000000	False
ll say maximize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
geometric margins subject	0.00243486311881	0.0	0.0	1.58496250072	0.0000000000	False
maximize gamma subject	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
margin are identical	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
comparable to logistic	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
develop this algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
change this algorithm	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
work in infinite	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.000689804662093	0.0	0.0	0.0	0.0000000000	False
dimensional feature spaces	0.000689804662093	0.0	0.0	0.0	0.0000000000	False
efficient non-linear classifiers	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
right next week	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talk about authorization	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
octaves so show	0.0012174315594	0.0	0.0	1.58496250072	0.0000000000	False
good morning	0.00028754820105	0.0	0.0	0.0	0.0000000000	False
quick announcement	0.000420022423227	0.0	0.0	0.0	0.0000000000	False
discussion section	0.000840044846454	0.0	0.0	2.0	0.0000000000	False
program matlab	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
direct terms	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
learning algorithm	0.00456503378594	0.0	7.99114121939	16.0	0.3432066967	False
previous lecture	0.0017857398372	0.0	3.99687337155	5.0	0.0000000000	False
event models	0.00892783143563	0.0	12.9937467431	10.0	0.3912213740	False
neural networks	0.0244248105753	1.0	55.9801980198	37.0	0.2212536322	True
support vector	0.00540864754608	0.0	12.9927045336	12.0	0.3432066967	False
vector machines	0.00540864754608	0.0	12.9927045336	12.0	0.4389721627	False
supervised learning	0.00152591697448	0.0	2.99843668577	2.0	0.0000000000	False
describing spam	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
spam classification	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
create feature	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
feature vectors	0.00504026907873	0.0	19.9937467431	11.0	0.2051709758	False
generative learning	0.00171454034184	0.0	3.99843668577	2.0	0.0000000000	False
model pfx	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
model pfy	0.000571513447281	0.0	0.0	1.0	0.0000000000	False
bayes rule	0.00114302689456	0.0	0.0	1.0	0.0000000000	False
predict rfx	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
draw attention	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
similar model	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
multinomial probabilities	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
continuous value	0.000571513447281	0.0	4.99739447629	4.0	0.2939068100	False
value feature	0.0	0.0	2.99843668577	2.0	0.0000000000	False
finite set	0.000420022423227	0.0	0.0	1.0	0.0000000000	False
learning problem	0.00033140585496	0.0	0.0	0.0	0.0000000000	False
classification problem	0.00168008969291	0.0	3.99791558103	2.0	0.4162436548	False
living area	0.00137960932419	0.0	2.99843668577	2.0	0.0000000000	False
common thing	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
value living	0.0	0.0	0.0	0.0	0.0000000000	False
discreet buckets	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
square feet	0.00171454034184	0.0	2.99843668577	2.0	0.0000000000	False
first variation	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
final variation	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
classifying text	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
text documents	0.0013202600311	0.0	0.0	1.0	0.0000000000	False
classifying sequences	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
bayes algorithm	0.0013202600311	0.0	0.0	2.0	0.0000000000	False
binary vector	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
vector value	0.0	0.0	0.0	0.0	0.0000000000	False
value representation	0.0	0.0	0.0	0.0	0.0000000000	False
word appears	0.0026405200622	0.0	9.99635226681	6.0	0.3364595545	False
common email	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
word viagra	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
previous model	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
text classification	0.00457210757825	0.0	13.9958311621	7.0	0.0000000000	True
multivariate bernoulli	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
bernoulli event	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
multiple bernoulli	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
bernoulli random	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
random variables	0.00198843512976	0.0	5.99635226681	6.0	0.4162436548	False
multinomial event	0.00405810519802	0.0	5.99739447629	0.0	0.3734061931	False
sub group	0.0	0.0	0.0	2.0	0.0000000000	False
training examples	0.00185027250405	0.0	14.9895779052	19.0	0.3542812255	False
binary random	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
larger set	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
generative model	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
joint distribution	0.000508638991495	0.0	0.0	1.0	0.0000000000	False
random distribution	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
process proceeds	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
class label	0.00137960932419	0.0	3.99843668577	2.0	0.0000000000	False
spam emails	0.00571513447281	0.0	6.99478895258	9.0	0.3273453094	False
generate words	0.00162324207921	0.0	0.0	1.0	0.0000000000	False
normal words	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
previous event	0.00162324207921	0.0	0.0	0.0	0.0000000000	False
phi subscript	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
training set	0.00747625322731	0.0	11.9864512767	25.0	0.2827586207	False
maximum likelihood	0.0050223155785	0.0	14.9932256384	10.0	0.2326494980	False
likelihood estimates	0.0046202466555	0.0	13.9937467431	0.0	0.2979651163	False
big indicator	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
indicator function	0.000420022423227	0.0	0.0	0.0	0.0000000000	False
function things	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
sets indicator	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
spam times	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
times indicator	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
indicator xij	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
times sum	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
total number	0.000714295934881	0.0	0.0	1.0	0.0000000000	False
total length	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
spam mail	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
mail generating	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
laplace smoothing	0.00462091010884	1.0	6.99635226681	6.0	0.0000000000	False
smoothed estimate	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
makes sense	0.000616970830159	0.0	3.99687337155	6.0	0.0000000000	False
absolutely right	0.0	0.0	0.0	0.0	0.0000000000	False
stole notation	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
cool raise	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
probability distribution	0.000386331967577	0.0	0.0	2.0	0.0000000000	False
multinomial random	0.00162324207921	0.0	0.0	0.0	0.0000000000	False
alphabet suppose	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
pfx equals	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
add laplace	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
specific definition	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
couple times	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
examples make	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
general formula	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
gaussian discriminant	0.00171454034184	0.0	4.99843668577	1.0	0.0000000000	False
discriminant analysis	0.00171454034184	0.0	4.99843668577	2.0	0.0000000000	False
writing log	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
log likelihood	0.00137960932419	0.0	5.99843668577	2.0	0.0000000000	False
times pfyi	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
fixed training	0.0026405200622	0.0	5.99791558103	0.0	0.5061728395	False
fixed iyi	0.0	0.0	0.0	0.0	0.0000000000	False
writing out	0.000268531399173	0.0	0.0	0.0	0.0000000000	False
previous section	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
analysis model	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
homework problem	0.000508638991495	0.0	0.0	1.0	0.0000000000	False
bayes model	0.00405810519802	0.0	3.99739447629	4.0	0.2875175316	False
specific case	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
bayes classify	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
good algorithm	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
natural language	0.000919739549457	0.0	0.0	1.0	0.0000000000	False
language processing	0.0013202600311	0.0	0.0	0.0	0.0000000000	False
unique grand	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
grand model	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
higher order	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
order markup	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
markup models	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
bigram models	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
trigram models	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
non-linear classifiers	0.00405810519802	0.0	3.99635226681	6.0	0.0000000000	True
first classification	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
classification algorithm	0.000459869774728	0.0	0.0	0.0	0.0000000000	False
logistic regression	0.00357147967441	0.0	5.99426784784	10.0	0.4389721627	True
forming form	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
estimator probability	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
straight line	0.0017857398372	0.0	4.99739447629	4.0	0.2875175316	False
negative classes	0.000508638991495	0.0	0.0	0.0	0.0000000000	False
data set	0.000308378750674	0.0	0.0	1.0	0.0000000000	False
non-linear division	0.00405810519802	0.0	1.99739447629	4.0	0.3734061931	False
division boundaries	0.00462091010884	0.0	4.99583116206	6.0	0.0000000000	False
cool result	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
exponential family	0.00171454034184	0.0	3.99843668577	3.0	0.0000000000	False
natural parameter	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
holds true	0.000386331967577	0.0	0.0	1.0	0.0000000000	False
logistic posterior	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
linear classifier	0.00254319495747	1.0	7.9937467431	11.0	0.5256410256	False
method today	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
simpler algorithm	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
complex non-linear	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
earlier convention	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
regression unit	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
computation note	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
subscript theta	0.00285756723641	0.0	3.99739447629	4.0	0.4389721627	False
sigmoid function	0.00152591697448	0.0	1.99843668577	3.0	0.0000000000	False
computational unit	0.00243486311881	0.0	2.99843668577	2.0	0.0000000000	False
parameters theta	0.00168008969291	0.0	2.99843668577	2.0	0.0000000000	False
represent hypotheses	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
previous board	0.000386331967577	0.0	0.0	1.0	0.0000000000	False
sigmoidal units	0.00162324207921	0.0	2.99843668577	2.0	0.0000000000	False
final output	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
things names	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
values output	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
intermediate sigmoidal	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
formula represents	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
transpose theta	0.00198039004665	0.0	0.0	2.0	0.0000000000	False
cluttered board	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
learn parameters	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
cost function	0.0026405200622	0.0	4.99791558103	3.0	0.2939068100	False
theta equals	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
familiar quadratic	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
quadratic cost	0.00162324207921	0.0	0.0	1.0	0.0000000000	False
gradient interscent	0.00162324207921	0.0	0.0	1.0	0.0000000000	False
phi gradient	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
gradient descent	0.00152591697448	0.0	3.99843668577	2.0	0.0000000000	True
square area	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
green descent	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
implements grand	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
grand descent	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
back propagation	0.000811621039603	1.0	0.0	1.0	0.0000000000	True
interesting things	0.000386331967577	0.0	0.0	1.0	0.0000000000	False
intermediate notes	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
hidden layer	0.00243486311881	1.0	3.99843668577	3.0	0.0000000000	False
output layer	0.00162324207921	0.0	0.0	2.0	0.0000000000	False
inputs feed	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
cool thing	0.000571513447281	0.0	0.0	1.0	0.0000000000	False
intermediate units	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
hidden unit	0.00243486311881	0.0	3.99843668577	2.0	0.0000000000	False
unit computing	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
yann lecun	0.00162324207921	0.0	3.99843668577	3.0	0.0000000000	False
york university	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
hammerton digit	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
digit recognition	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
convolutional neural	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
laptop display	0.0	0.0	0.0	0.0	0.0000000000	False
big screen	0.000571513447281	0.0	0.0	1.0	0.0000000000	False
nt working	0.0	0.0	0.0	0.0	0.0000000000	False
unlike logistic	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
non-convex optimization	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
optimization problem	0.00168008969291	0.0	5.99791558103	3.0	0.0000000000	False
global optimer	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
local optimer	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
harder optimization	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
making design	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
design choices	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
learning rate	0.000571513447281	0.0	0.0	1.0	0.0000000000	False
ongoing debates	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
vast majority	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
machine learning	0.00115899590273	0.0	5.99843668577	2.0	0.0000000000	False
learning researchers	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
researchers today	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
perceive support	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
effective off-the-shelf	0.00324648415841	0.0	0.0	0.0	0.0000000000	False
off-the-shelf learning	0.00243486311881	0.0	1.99843668577	1.0	0.0000000000	False
hard optimization	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
effective learning	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
mouse pointer	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
final answer	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
answer output	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
left portion	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
intermediate computations	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
network computing	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
computing digits	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
right-hand side	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
input display	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
input image	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
right multiple	0.0	0.0	0.0	0.0	0.0000000000	False
multiple digits	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
wgbh television	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
british foreclass	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
foreclass incorporation	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
video describing	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
terry sejnowski	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
major milestones	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
specific application	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
read text	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
computer read	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
produce sounds	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
video created	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
learning part	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
child-like voice	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
voice talking	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
young child	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
child learning	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
begin video	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
network sounds	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
network takes	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
random attempt	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
phonetic difference	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
right pronunciation	0.0	0.0	0.0	1.0	0.0000000000	False
connection strengths	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
slowly improves	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
nettalk understands	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
associating letters	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
end video	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
amazing piece	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
speech systems	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
dow jones	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
jones falling	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
profit taking	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
major landmark	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
chalkboard earlier	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
earlier support	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
linear division	0.000660130015549	0.0	2.99687337155	3.0	0.0000000000	False
machine idea	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
clever things	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
logistic function	0.000508638991495	0.0	0.0	1.0	0.0000000000	False
computes theta	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
theta transpose	0.00559502890644	0.0	11.9942678478	10.0	0.1640596581	False
iff stands	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
double implication	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
double greater	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
sign means	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
confident prediction	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
find parameters	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
correct classifications	0.00198039004665	0.0	1.99843668577	2.0	0.0000000000	False
first intuition	0.00162324207921	0.0	0.0	2.0	0.0000000000	False
functional margins	0.0137163227348	1.0	20.9874934862	23.0	0.1887743916	True
separable training	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
linear separator	0.0013202600311	0.0	0.0	1.0	0.0000000000	False
greater distance	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
negative examples	0.000420022423227	0.0	0.0	0.0	0.0000000000	False
final line	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
geometric margins	0.0137163227348	1.0	39.9874934862	23.0	0.2033363390	True
describe support	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
notation change	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
consistent notation	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
change notations	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
ll make	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis output	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
output values	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
develop support	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
real number	0.00028754820105	0.0	0.0	1.0	0.0000000000	False
germesh margin	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
hyper plane	0.012174315594	0.0	11.9921834289	13.0	0.3092006033	False
specific training	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
wrt stands	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
separating boundary	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
decision boundary	0.000508638991495	0.0	0.0	1.0	0.0000000000	False
plane term	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
large functional	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
equal minus	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
entire training	0.00203455596598	0.0	3.99791558103	0.0	0.2939068100	False
define gamma	0.0	0.0	0.0	1.0	0.0000000000	False
worst case	0.00033140585496	0.0	0.0	1.0	0.0000000000	False
first function	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
worst-case functional	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
classifiable parameters	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
times transpose	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
normalization condition	0.0013202600311	0.0	0.0	0.0	0.0000000000	False
add things	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
geometric distance	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
separating line	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
separating hyper	0.00730458935643	0.0	11.9953100573	6.0	0.2810357959	False
fairly quickly	0.000508638991495	0.0	0.0	0.0	0.0000000000	False
lecture notes	0.00115899590273	0.0	2.99843668577	3.0	0.0000000000	False
details sort	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
standard geometry	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
high dimensions	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
dimensions work	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
minus gamma	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
unit vector	0.00162324207921	0.0	0.0	1.0	0.0000000000	False
subtract gamma	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
heavy circle	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
heavy point	0.00162324207921	0.0	0.0	2.0	0.0000000000	False
transpose times	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
point equals	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
plane satisfy	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
normal vector	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
previous equation	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
equals gamma	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
gamma times	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
plane defined	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
last thing	0.0	0.0	0.0	1.0	0.0000000000	False
right side	0.0	0.0	0.0	1.0	0.0000000000	False
easy facts	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
margin divided	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
final definition	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
single training	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
gamma equals	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
equals min	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
maximum margin	0.00243486311881	0.0	5.99843668577	1.0	0.0000000000	False
margin classifier	0.00171454034184	0.0	5.99843668577	2.0	0.0000000000	False
classified poses	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
choose gamma	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
maximization problem	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
parameter gamma	0.000508638991495	0.0	0.0	0.0	0.0000000000	False
normalization constant	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
scaling factor	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
first formulation	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
margins subject	0.00162324207921	0.0	0.0	0.0	0.0000000000	False
maximize gamma	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
gamma subject	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
infinite dimensional	0.000420022423227	0.0	0.0	0.0	0.0000000000	False
dimensional feature	0.000459869774728	0.0	0.0	0.0	0.0000000000	False
feature spaces	0.000459869774728	0.0	0.0	0.0	0.0000000000	False
efficient non-linear	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
first step	0.000308378750674	0.0	0.0	1.0	0.0000000000	False
authorization algorithms	0.000660130015549	1.0	0.0	0.0	0.0000000000	False
final reminder	0.000811621039603	0.0	0.0	1.0	0.0000000000	False
discussion session	0.000660130015549	0.0	0.0	1.0	0.0000000000	False
good	8.1832167889e-05	0.0	0.0	0.0	0.5256410256	False
morning	0.00028754820105	0.0	0.0	0.0	0.0000000000	False
back	0.000216663677329	0.0	0.0	0.0	0.5466666667	False
quick	0.000109881091203	0.0	0.0	0.0	0.0000000000	False
announcement	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
today	0.000113695227405	0.0	0.0	0.0	0.4212328767	False
discussion	0.000497733065985	0.0	0.0	0.0	0.2195448461	False
section	0.00049710878244	0.0	0.0	0.0	0.0000000000	False
sort	0.00113043819278	0.0	0.0	0.0	0.4478889873	False
tutorial	0.000689804662093	0.0	0.0	0.0	0.0000000000	False
matlab	0.0013202600311	0.0	0.0	0.0	0.2546583851	False
octaves	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
program	5.40592549269e-05	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.4866468843	False
direct	0.000109881091203	0.0	0.0	0.0	0.0000000000	False
terms	5.68476137026e-05	0.0	0.0	0.0	0.5256410256	False
continue	0.000227041571447	0.0	0.0	0.0	0.3137755102	False
bayes	0.00551843729674	0.0	0.0	0.0	0.2677551020	False
learning	0.0016424460846	0.0	0.0	0.0	0.3062682689	False
algorithm	0.00119474527117	0.0	0.0	0.0	0.3648358392	False
started	0.0	0.0	0.0	0.0	0.3786733837	False
previous	0.000547789575828	0.0	0.0	0.0	0.4900398406	False
lecture	0.000567603928616	0.0	0.0	0.0	0.4530386740	False
talk	0.000158485651477	0.0	0.0	0.0	0.4453064391	False
couple	0.000352261415284	0.0	0.0	0.0	0.0000000000	False
event	0.00214288780464	0.0	0.0	0.0	0.3693693694	False
models	0.00413675282197	0.0	0.0	0.0	0.1826687458	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
digression	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
neural	0.0125424702954	0.0	0.0	0.0	0.1855645545	False
networks	0.00537062798346	0.0	0.0	0.0	0.2316384181	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
spend	0.000234840943523	0.0	0.0	0.0	0.0000000000	False
lot	0.000264881833354	0.0	0.0	0.0	0.4165457184	False
support	0.0014395986037	0.0	0.0	0.0	0.3432066967	False
vector	0.0045793983987	0.0	0.0	0.0	0.2861866275	False
machines	0.0013160193773	0.0	0.0	0.0	0.4086378738	False
supervised	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
people	0.000117040375119	0.0	0.0	0.0	0.0000000000	False
effective	0.000438673125766	0.0	0.0	0.0	0.0000000000	False
off-the-shelf	0.0013202600311	0.0	0.0	0.0	0.5189873418	False
point	4.58719718103e-05	0.0	0.0	0.0	0.1098802930	False
view	0.000269872246358	0.0	0.0	0.0	0.0000000000	False
debatable	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
hold	0.000168098150484	0.0	0.0	0.0	0.0000000000	False
complete	8.1832167889e-05	0.0	0.0	0.0	0.0000000000	False
recap	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
describing	0.000673424877995	0.0	0.0	0.0	0.4866468843	False
spam	0.00567030271357	0.0	0.0	0.0	0.1786791820	False
classification	0.0023003856084	0.0	0.0	0.0	0.4993234100	False
create	0.000292448750511	0.0	0.0	0.0	0.2939068100	False
feature	0.00163268612395	0.0	0.0	0.0	0.2353101940	False
right	0.0	0.0	0.0	0.0	0.6096242228	False
correspond	0.000102828471693	0.0	0.0	0.0	0.4162436548	False
words	0.00212542294645	0.0	0.0	0.0	0.2094508301	False
dictionary	0.00154532787031	0.0	0.0	0.0	0.0000000000	False
based	0.000126342006508	0.0	0.0	0.0	0.0000000000	False
piece	0.000612257296483	0.0	0.0	0.0	0.4993234100	False
email	0.00604195648139	0.0	0.0	0.0	0.1914098973	False
represented	0.000298639839591	0.0	0.0	0.0	0.4389721627	False
zeros	0.000229934887364	0.0	0.0	0.0	0.2802262550	False
places	5.40592549269e-05	0.0	0.0	0.0	0.0000000000	False
generative	0.00015776770108	0.0	0.0	0.0	0.4663167104	False
pfx	0.00165032503887	0.0	0.0	0.0	0.4389721627	False
specifically	0.000244419068709	0.0	0.0	0.0	0.4728171334	False
product	0.000288610661998	0.0	0.0	0.0	0.0000000000	False
equals	0.00185417283348	0.0	0.0	0.0	0.3433356595	False
pfxi	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
pfy	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
rule	0.000179914830906	0.0	0.0	0.0	0.0000000000	False
combine	7.31121876277e-05	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.4391431353	False
predictions	0.00138070700488	0.0	0.0	0.0	0.3168469861	False
give	1.34917564148e-05	0.0	0.0	0.0	0.5394736842	False
rfx	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.2951156812	False
draw	0.00034014294249	0.0	0.0	0.0	0.4389721627	False
attention	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
things	0.0	0.0	0.0	0.0	0.5351149782	False
indicating	0.00034014294249	0.0	0.0	0.0	0.3248811410	False
length	0.000719799301852	0.0	0.0	0.0	0.4728171334	False
number	4.85703230933e-05	0.0	0.0	0.0	0.3472845042	False
version	0.000102828471693	0.0	0.0	0.0	0.0000000000	False
order	6.64285057178e-05	0.0	0.0	0.0	0.3565217391	False
50,000	0.00228887546173	0.0	0.0	0.0	0.3211488251	False
variations	0.000770946876686	0.0	0.0	0.0	0.3248811410	False
first	0.0	0.0	0.0	0.0	0.4214390602	False
simpler	0.000268531399173	0.0	0.0	0.0	0.0000000000	False
takes	0.000270829596661	0.0	0.0	0.0	0.4154129567	False
values	0.00086494807883	0.0	0.0	0.0	0.3350357508	False
commonly	0.000630033634841	0.0	0.0	0.0	0.0000000000	False
apply	0.000199093226394	0.0	0.0	0.0	0.5256410256	False
problems	7.10452920414e-05	0.0	0.0	0.0	0.4066726781	False
build	0.000269872246358	0.0	0.0	0.0	0.0000000000	False
similar	0.000113520785723	0.0	0.0	0.0	0.0000000000	False
multinomial	0.00285756723641	0.0	0.0	0.0	0.3458294283	False
probabilities	0.00163174464213	0.0	0.0	0.0	0.3215686275	False
bernoulli	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
turns	0.000832485761971	0.0	0.0	0.0	0.4324894515	False
out	0.0	0.0	0.0	0.0	0.4619324001	False
situation	0.000234840943523	0.0	0.0	0.0	0.0000000000	False
arises	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
choose	0.000511785313394	0.0	0.0	0.0	0.4165457184	False
dispertise	0.00162324207921	0.0	0.0	0.0	0.3445378151	False
finite	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
set	0.000290624712515	0.0	0.0	0.0	0.3378457916	False
perfect	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
remember	7.56805238155e-05	0.0	0.0	0.0	0.0000000000	False
price	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
houses	0.00182273220228	0.0	0.0	0.0	0.4162436548	False
sold	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
months	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
living	0.000431322301576	0.0	0.0	0.0	0.0000000000	False
area	0.000359829661811	0.0	0.0	0.0	0.2939068100	False
pretty	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
common	0.000288610661998	0.0	0.0	0.0	0.0000000000	False
discreet	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
buckets	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
depending	7.11609130929e-05	0.0	0.0	0.0	0.0000000000	False
square	0.000408171530989	0.0	0.0	0.0	0.2939068100	False
feet	0.000857270170922	0.0	0.0	0.0	0.0000000000	False
1,000	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
greater	0.000877346251532	0.0	0.0	0.0	0.2376811594	False
2,000	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.4162436548	False
wanted	0.000384814215997	0.0	0.0	0.0	0.4065155807	False
check	0.0	0.0	0.0	0.0	0.0000000000	False
questions	6.73068434445e-05	0.0	0.0	0.0	0.5394736842	False
cool	0.00112966936763	0.0	0.0	0.0	0.5256410256	False
practice	0.00015688772662	0.0	0.0	0.0	0.0000000000	False
fairly	0.000199093226394	0.0	0.0	0.0	0.5256410256	False
ten	0.000162177764781	0.0	0.0	0.0	0.0000000000	False
drew	0.000714295934881	0.0	0.0	0.0	0.5256410256	False
save	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
writing	0.000276645621619	0.0	0.0	0.0	0.3369863014	False
final	0.000631710032538	0.0	0.0	0.0	0.5394736842	False
classifying	0.00375943958842	0.0	0.0	0.0	0.4847542004	False
text	0.00215865125472	0.0	0.0	0.0	0.2581322141	False
documents	0.000689804662093	0.0	0.0	0.0	0.0000000000	False
sequences	0.000189513009761	0.0	0.0	0.0	0.0000000000	False
focus	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
idea	5.41659193322e-05	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
binary	0.000168098150484	0.0	0.0	0.0	0.0000000000	False
representation	0.000168098150484	0.0	0.0	0.0	0.0000000000	False
loses	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
instance	3.78402619078e-05	0.0	0.0	0.0	0.0000000000	False
appears	0.000862644603151	0.0	0.0	0.0	0.3565217391	False
buy	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
viagra	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
ton	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
guess	0.000719799301852	0.0	0.0	0.0	0.4728171334	False
account	0.000704522830569	0.0	0.0	0.0	0.4572490706	False
multivariate	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
great	0.000162177764781	0.0	0.0	0.0	0.0000000000	False
worry	0.000252684013015	0.0	0.0	0.0	0.2939068100	False
means	2.69835128296e-05	0.0	0.0	0.0	0.4351020408	False
refers	9.9546613197e-05	0.0	0.0	0.0	0.0000000000	False
fact	4.09160839445e-05	0.0	0.0	0.0	0.0000000000	False
multiple	0.000192407107999	0.0	0.0	0.0	0.0000000000	False
random	0.000925456245239	0.0	0.0	0.0	0.3211488251	False
variables	0.000468161500475	0.0	0.0	0.0	0.3734061931	False
contrast	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
rationale	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
slightly	0.000182596525276	0.0	0.0	0.0	0.5256410256	False
cryptic	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
training	0.00575360311631	0.0	0.0	0.0	0.3170474517	False
sub	0.0	0.0	0.0	0.0	0.0000000000	False
group	0.000431322301576	0.0	0.0	0.0	0.0000000000	False
subscript	0.00198843512976	0.0	0.0	0.0	0.4530386740	False
examples	0.000540592549269	0.0	0.0	0.0	0.3533158486	False
elements	0.000117040375119	0.0	0.0	0.0	0.0000000000	False
lets	0.000182596525276	0.0	0.0	0.0	0.4720394737	False
index	0.000308378750674	0.0	0.0	0.0	0.0000000000	False
position	0.000264881833354	0.0	0.0	0.0	0.5394736842	False
definition	0.000639087838466	0.0	0.0	0.0	0.3936000000	False
varies	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
components	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
longer	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
larger	5.40592549269e-05	0.0	0.0	0.0	0.0000000000	False
joint	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
distribution	0.000549405456017	0.0	0.0	0.0	0.3248811410	False
formula	0.000862644603151	0.0	0.0	0.0	0.5394736842	False
imagine	9.62035539994e-05	0.0	0.0	0.0	0.0000000000	False
process	9.16571507658e-05	0.0	0.0	0.0	0.0000000000	False
proceeds	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
chosen	0.000234840943523	0.0	0.0	0.0	0.0000000000	False
class	0.000152761917943	0.0	0.0	0.0	0.4162436548	False
label	0.000616757501349	0.0	0.0	0.0	0.0000000000	False
send	0.000770946876686	0.0	0.0	0.0	0.2337514253	False
decided	0.000162177764781	0.0	0.0	0.0	0.0000000000	False
iterates	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
compose	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
chose	0.000308378750674	0.0	0.0	0.0	0.0000000000	False
tend	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
discounts	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
sale	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
normal	0.000631710032538	0.0	0.0	0.0	0.3912213740	False
careful	0.000216237019708	0.0	0.0	0.0	0.0000000000	False
parameters	0.00219336562883	0.0	0.0	0.0	0.4264487370	False
phi	0.00114967443682	0.0	0.0	0.0	0.3734061931	False
conditioned	0.00031377545324	0.0	0.0	0.0	0.0000000000	False
similarly	0.000102406737529	0.0	0.0	0.0	0.0000000000	False
work	0.000265954545639	0.0	0.0	0.0	0.5540540541	False
maximum	0.00125510181296	0.0	0.0	0.0	0.2590837283	False
likelihood	0.00357147967441	0.0	0.0	0.0	0.1542268858	False
estimates	0.00298265269464	0.0	0.0	0.0	0.2883740174	False
big	0.000315855016269	0.0	0.0	0.0	0.4389721627	False
function	0.000777405594946	0.0	0.0	0.0	0.2306098283	False
sum	0.00054910704317	0.0	0.0	0.0	0.1635327635	False
xij	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
numerator	0.000575096402101	0.0	0.0	0.0	0.0000000000	False
counts	0.000268531399173	0.0	0.0	0.0	0.0000000000	False
observed	0.000671328497933	0.0	0.0	0.0	0.4162436548	False
total	0.000189513009761	0.0	0.0	0.0	0.0000000000	False
denominator	0.00152591697448	0.0	0.0	0.0	0.5256410256	False
ratio	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
fraction	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
mail	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
end	4.4871228963e-05	0.0	0.0	0.0	0.5256410256	False
laplace	0.00200029706549	0.0	0.0	0.0	0.3069518717	False
smoothing	0.00178023647023	0.0	0.0	0.0	0.0000000000	False
add	0.000468161500475	0.0	0.0	0.0	0.3565217391	False
top	0.000270296274635	0.0	0.0	0.0	0.4389721627	False
wondering	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
essentially	4.74406087286e-05	0.0	0.0	0.0	0.0000000000	False
identity	0.000251037637251	0.0	0.0	0.0	0.0000000000	False
apologize	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
realized	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
overload	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
notation	0.000504294451451	0.0	0.0	0.0	0.2939068100	False
alphabet	0.000386331967577	0.0	0.0	0.0	0.0000000000	False
makes	9.8370404365e-05	0.0	0.0	0.0	0.4489051095	False
sense	0.000118601521822	0.0	0.0	0.0	0.0000000000	False
absolutely	0.000109881091203	0.0	0.0	0.0	0.0000000000	False
stole	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
translate	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
properly	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
raise	0.000179914830906	0.0	0.0	0.0	0.0000000000	False
hand	8.33499194687e-05	0.0	0.0	0.0	0.0000000000	False
method	0.000272114353992	0.0	0.0	0.0	0.5256410256	False
suppose	7.11609130929e-05	0.0	0.0	0.0	0.0000000000	False
divided	0.000292448750511	0.0	0.0	0.0	0.5256410256	False
gaussian	0.000579497951366	0.0	0.0	0.0	0.0000000000	False
discriminant	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
analysis	0.000288610661998	0.0	0.0	0.0	0.0000000000	False
throwing	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
board	0.000469681887046	0.0	0.0	0.0	0.0000000000	False
proving	0.000179914830906	0.0	0.0	0.0	0.0000000000	False
figure	0.000117040375119	0.0	0.0	0.0	0.0000000000	False
log	0.000336196300967	0.0	0.0	0.0	0.3445378151	False
parameterized	0.000630033634841	0.0	0.0	0.0	0.4389721627	False
drop	0.000308378750674	0.0	0.0	0.0	0.0000000000	False
simply	0.000251037637251	0.0	0.0	0.0	0.0000000000	False
put	8.6451756756e-05	0.0	0.0	0.0	0.4389721627	False
pfyi	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
fixed	0.000481017769997	0.0	0.0	0.0	0.3388429752	False
iyi	0.0	0.0	0.0	0.0	0.0000000000	False
maximize	0.00134265699587	0.0	0.0	0.0	0.2295632699	False
wrote	0.000411313886773	0.0	0.0	0.0	0.5256410256	False
play	0.000671328497933	0.0	0.0	0.0	0.4162436548	False
homework	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
verify	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
find	5.60890362037e-05	0.0	0.0	0.0	0.5324675325	False
derived	9.62035539994e-05	0.0	0.0	0.0	0.0000000000	False
wraps	0.000535721951161	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.0000000000	False
presented	7.84438633101e-05	0.0	0.0	0.0	0.0000000000	False
reasons	0.000102406737529	0.0	0.0	0.0	0.5324675325	False
hypothesized	0.000508638991495	0.0	0.0	0.0	0.0000000000	False
truth	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
understood	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
researchers	0.000462568126011	0.0	0.0	0.0	0.0000000000	False
bit	0.000118601521822	0.0	0.0	0.0	0.5324675325	False
straightforward	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
implement	0.000146224375255	0.0	0.0	0.0	0.0000000000	False
variant	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
exclamation	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
data	9.16571507658e-05	0.0	0.0	0.0	0.4162436548	False
shuffle	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
natural	0.000189513009761	0.0	0.0	0.0	0.0000000000	False
language	0.000352261415284	0.0	0.0	0.0	0.0000000000	False
unique	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
grand	0.000459869774728	0.0	0.0	0.0	0.0000000000	False
higher	0.000109881091203	0.0	0.0	0.0	0.0000000000	False
markup	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
bigram	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
trigram	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
non-linear	0.00342908068369	0.0	0.0	0.0	0.2581322141	False
logistic	0.00200446187938	0.0	0.0	0.0	0.3837293017	False
regression	0.00154189375337	0.0	0.0	0.0	0.4389721627	False
forming	3.45807027024e-05	0.0	0.0	0.0	0.0000000000	False
hypothesis	0.000352261415284	0.0	0.0	0.0	0.0000000000	False
grade	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
descends	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
newton	0.0	0.0	0.0	0.0	0.0000000000	False
straight	0.000420245376209	0.0	0.0	0.0	0.2875175316	False
line	0.000458424557078	0.0	0.0	0.0	0.1744680851	False
separates	0.00136057176996	0.0	0.0	0.0	0.2668722165	False
negative	0.000192407107999	0.0	0.0	0.0	0.0000000000	False
division	0.00132562341984	0.0	0.0	0.0	0.3565217391	False
boundaries	0.00129396690473	0.0	0.0	0.0	0.4162436548	False
result	5.85201875594e-05	0.0	0.0	0.0	0.0000000000	False
assume	0.000208374798672	0.0	0.0	0.0	0.5324675325	False
exponential	0.000431322301576	0.0	0.0	0.0	0.0000000000	False
family	0.000630033634841	0.0	0.0	0.0	0.0000000000	False
true	0.000108118509854	0.0	0.0	0.0	0.0000000000	False
posterior	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
falls	0.00032964327361	0.0	0.0	0.0	0.0000000000	False
linear	0.000672392601935	0.0	0.0	0.0	0.4866468843	False
briefly	9.62035539994e-05	0.0	0.0	0.0	0.0000000000	False
complex	9.62035539994e-05	0.0	0.0	0.0	0.0000000000	False
motivate	0.000251037637251	0.0	0.0	0.0	0.0000000000	False
picture	0.000199093226394	0.0	0.0	0.0	0.2939068100	False
convention	0.000549405456017	0.0	0.0	0.0	0.5256410256	False
follow	5.85201875594e-05	0.0	0.0	0.0	0.0000000000	False
earlier	0.000199093226394	0.0	0.0	0.0	0.0000000000	False
diagram	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
denote	0.000192407107999	0.0	0.0	0.0	0.0000000000	False
unit	0.00164388660466	0.0	0.0	0.0	0.3382838284	False
circle	0.000268531399173	0.0	0.0	0.0	0.0000000000	False
computation	0.000241602358236	0.0	0.0	0.0	0.3239277652	False
note	0.000270296274635	0.0	0.0	0.0	0.4162436548	False
input	0.000298639839591	0.0	0.0	0.0	0.3504273504	False
outputs	0.000884371650475	0.0	0.0	0.0	0.3259938838	False
theta	0.00462568126011	0.0	0.0	0.0	0.1795801238	False
sigmoid	0.00152591697448	0.0	0.0	0.0	0.2594936709	False
bunch	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
feed	0.00114302689456	0.0	0.0	0.0	0.3445378151	False
names	0.000134265699587	0.0	0.0	0.0	0.3504273504	False
call	5.39670256592e-06	0.0	0.0	0.0	0.3224960671	False
intermediate	0.00114302689456	0.0	0.0	0.0	0.4162436548	False
concrete	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
middle	0.000308378750674	0.0	0.0	0.0	0.0000000000	False
transpose	0.00517864552789	0.0	0.0	0.0	0.2494929006	False
append	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
cluttered	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
cost	0.000537062798346	0.0	0.0	0.0	0.2939068100	False
one-half	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
minus	0.000502140444509	0.0	0.0	0.0	0.2662337662	False
familiar	0.000179914830906	0.0	0.0	0.0	0.0000000000	False
quadratic	0.00028754820105	0.0	0.0	0.0	0.0000000000	False
gradient	0.000965829918943	0.0	0.0	0.0	0.2337514253	False
interscent	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
minimize	0.000192407107999	0.0	0.0	0.0	0.0000000000	False
descent	0.00114967443682	0.0	0.0	0.0	0.2337514253	False
stated	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
differently	1.09300449294e-05	0.0	0.0	0.0	0.4081858407	False
close	5.41659193322e-05	0.0	0.0	0.0	0.0000000000	False
green	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
propagation	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
hear	0.000251037637251	0.0	0.0	0.0	0.0000000000	False
advantages	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
disadvantages	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
show	0.000355804565465	0.0	0.0	0.0	0.2844400396	False
interesting	9.9546613197e-05	0.0	0.0	0.0	0.0000000000	False
hidden	0.00137960932419	0.0	0.0	0.0	0.2594936709	False
layer	0.00142859186976	0.0	0.0	0.0	0.1927899687	False
video	0.00231984098472	0.0	0.0	0.0	0.3104251602	False
switch	0.000234840943523	0.0	0.0	0.0	0.0000000000	False
laptop	0.000386331967577	0.0	0.0	0.0	0.0000000000	False
made	5.85201875594e-05	0.0	0.0	0.0	0.0000000000	False
friend	0.000386331967577	0.0	0.0	0.0	0.0000000000	False
yann	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
lecun	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
professor	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
york	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
university	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
developed	0.000719799301852	0.0	0.0	0.0	0.5466666667	False
hammerton	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
digit	0.000469681887046	0.0	0.0	0.0	0.0000000000	False
recognition	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
convolutional	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
system	0.00015688772662	0.0	0.0	0.0	0.0000000000	False
lenet	0.000405810519802	1.0	0.0	0.0	0.0000000000	False
display	0.000431322301576	0.0	0.0	0.0	0.4162436548	False
hum	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
screen	0.00033140585496	0.0	0.0	0.0	0.0000000000	False
side	9.9546613197e-05	0.0	0.0	0.0	0.0000000000	False
guys	0.000192407107999	0.0	0.0	0.0	0.0000000000	False
entertained	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
waiting	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
chalkboard	0.000762958487242	0.0	0.0	0.0	0.0000000000	False
unlike	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
respond	0.000357147967441	0.0	0.0	0.0	0.0000000000	False
non-convex	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
optimization	0.000805594197519	0.0	0.0	0.0	0.3248811410	False
run	7.11609130929e-05	0.0	0.0	0.0	0.0000000000	False
converse	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
global	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
local	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
harder	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
design	7.84438633101e-05	0.0	0.0	0.0	0.0000000000	False
choices	6.80285884981e-05	0.0	0.0	0.0	0.0000000000	False
rate	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
ongoing	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
vast	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
majority	0.000431322301576	0.0	0.0	0.0	0.0000000000	False
perceive	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
contested	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
personally	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
hard	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
verge	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
complicated	8.40490752418e-05	0.0	0.0	0.0	0.0000000000	False
years	0.000168098150484	0.0	0.0	0.0	0.0000000000	False
invented	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
audio	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
soundboard	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
happening	2.70829596661e-05	0.0	0.0	0.0	0.0000000000	False
mouse	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
pointer	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
image	0.000770946876686	0.0	0.0	0.0	0.0000000000	False
recognize	0.000357147967441	0.0	0.0	0.0	0.0000000000	False
answer	4.5649131319e-05	0.0	0.0	0.0	0.0000000000	False
lenet-5	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
correctly	0.000965829918943	0.0	0.0	0.0	0.0000000000	False
left	6.82711583526e-05	0.0	0.0	0.0	0.0000000000	False
portion	0.00017857398372	0.0	0.0	0.0	0.0000000000	False
edges	0.000386331967577	0.0	0.0	0.0	0.0000000000	False
right-hand	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
bottom	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
fonts	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
robustness	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
noise	8.40490752418e-05	0.0	0.0	0.0	0.0000000000	False
kind	1.12178072407e-05	0.0	0.0	0.0	0.0000000000	False
fun	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
changed	0.000324995515993	0.0	0.0	0.0	0.2997562957	False
world	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
produced	0.000234840943523	0.0	0.0	0.0	0.0000000000	False
wgbh	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
television	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
corporation	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
british	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
foreclass	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
incorporation	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
aired	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
pbs	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
ago	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
nettalk	0.0012174315594	0.0	0.0	0.0	0.0000000000	False
terry	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
sejnowski	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
milestones	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
history	0.000892869918602	0.0	0.0	0.0	0.2337514253	False
application	5.40592549269e-05	0.0	0.0	0.0	0.0000000000	False
read	0.000199093226394	0.0	0.0	0.0	0.2939068100	False
english	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
verbally	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
sounds	0.00126006726968	0.0	0.0	0.0	0.2337514253	False
excitement	0.000459869774728	0.0	0.0	0.0	0.0000000000	False
part	5.46502246472e-06	0.0	0.0	0.0	0.0000000000	False
foresight	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
child-like	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
voice	0.00114302689456	0.0	0.0	0.0	0.0000000000	False
visiting	0.000210011211614	1.0	0.0	0.0	0.0000000000	False
grandmother	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
perception	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
impression	0.000571513447281	0.0	0.0	0.0	0.0000000000	False
young	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
child	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
speak	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
helped	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
academia	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
early	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
begin	0.000117040375119	0.0	0.0	0.0	0.0000000000	False
attempts	0.000579497951366	0.0	0.0	0.0	0.0000000000	False
letters	0.000386331967577	0.0	0.0	0.0	0.0000000000	False
phrase	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
pronouncing	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
phonetic	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
pronunciation	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
adjusting	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
connection	0.000102828471693	0.0	0.0	0.0	0.0000000000	False
strengths	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
net	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
slowly	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
improves	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
overnight	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
candy	0.000811621039603	0.0	0.0	0.0	0.0000000000	False
understands	1.42119034257e-05	0.0	0.0	0.0	0.0000000000	False
associating	0.000102828471693	0.0	0.0	0.0	0.0000000000	False
amazing	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
speech	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
dow	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
jones	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
profit	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
landmark	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
approve	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
progression	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
pursue	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
clever	0.000508638991495	0.0	0.0	0.0	0.0000000000	False
convey	0.000579497951366	0.0	0.0	0.0	0.0000000000	False
intuitions	0.00117420471761	0.0	0.0	0.0	0.3458294283	False
crosses	9.62035539994e-05	0.0	0.0	0.0	0.0000000000	False
iff	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
stands	0.000268531399173	0.0	0.0	0.0	0.0000000000	False
double	0.000384814215997	0.0	0.0	0.0	0.3445378151	False
implication	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
sign	0.000268531399173	0.0	0.0	0.0	0.0000000000	False
confident	0.00101727798299	0.0	0.0	0.0	0.3445378151	False
nice	0.00023533158993	0.0	0.0	0.0	0.0000000000	False
fit	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
correct	0.000204085765494	0.0	0.0	0.0	0.0000000000	False
margins	0.0109205830039	0.0	0.0	0.0	0.1688753582	False
define	0.000162497757997	0.0	0.0	0.0	0.3693693694	False
rest	0.000384814215997	0.0	0.0	0.0	0.5256410256	False
linearly	0.000386331967577	0.0	0.0	0.0	0.0000000000	False
remove	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
assumption	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
distance	0.000925136252023	0.0	0.0	0.0	0.3137755102	False
shortly	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
notion	0.000126342006508	0.0	0.0	0.0	0.0000000000	False
formalize	0.000205656943386	0.0	0.0	0.0	0.0000000000	False
geometric	0.00714391809102	0.0	0.0	0.0	0.1941655617	False
pull	0.000254319495747	0.0	0.0	0.0	0.0000000000	False
impossible	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
consistent	0.000109881091203	0.0	0.0	0.0	0.0000000000	False
easier	0.000376556455877	0.0	0.0	0.0	0.0000000000	False
week	0.000234840943523	0.0	0.0	0.0	0.0000000000	False
previously	9.62035539994e-05	0.0	0.0	0.0	0.0000000000	False
role	0.000386331967577	0.0	0.0	0.0	0.0000000000	False
interceptor	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
lumping	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
lowercase	0.000285756723641	0.0	0.0	0.0	0.0000000000	False
real	4.5649131319e-05	0.0	0.0	0.0	0.0000000000	False
germesh	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
hyper	0.00495097511662	0.0	0.0	0.0	0.3092006033	False
plane	0.00281694976716	0.0	0.0	0.0	0.2789115646	False
respect	0.000719659323622	0.0	0.0	0.0	0.3565217391	False
xiyi	0.000660130015549	0.0	0.0	0.0	0.0000000000	False
wrt	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
gamma	0.00463598361093	0.0	0.0	0.0	0.2265193370	False
hat	0.00126006726968	0.0	0.0	0.0	0.3967741935	False
decision	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
confused	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
ignore	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
interpretation	0.000143774100525	0.0	0.0	0.0	0.0000000000	False
large	0.000454083142893	0.0	0.0	0.0	0.0000000000	False
captures	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
small	1.72903513512e-05	0.0	0.0	0.0	0.0000000000	False
statement	8.40490752418e-05	0.0	0.0	0.0	0.0000000000	False
notice	0.00040279709876	0.0	0.0	0.0	0.0000000000	False
long	0.00039221931655	0.0	0.0	0.0	0.2875175316	False
entire	0.000122209534354	0.0	0.0	0.0	0.2939068100	False
min	0.000234840943523	0.0	0.0	0.0	0.0000000000	False
worst	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
purposes	6.31710032538e-05	0.0	0.0	0.0	0.0000000000	False
worst-case	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
easy	0.000288610661998	0.0	0.0	0.0	0.0000000000	False
multiply	0.000537062798346	0.0	0.0	0.0	0.4162436548	False
easily	0.000205656943386	0.0	0.0	0.0	0.0000000000	False
goal	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
arbitrarily	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
scaling	0.000579497951366	0.0	0.0	0.0	0.0000000000	False
de-norm	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
alter-norm	0.000405810519802	0.0	0.0	0.0	0.0000000000	False
minutes	0.00030848541508	0.0	0.0	0.0	0.0000000000	False
axis	0.000154189375337	0.0	0.0	0.0	0.0000000000	False
deliberately	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
algebra	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
quickly	6.31710032538e-05	0.0	0.0	0.0	0.0000000000	False
details	8.33499194687e-05	0.0	0.0	0.0	0.0000000000	False
standard	7.31121876277e-05	0.0	0.0	0.0	0.0000000000	False
geometry	0.000459869774728	0.0	0.0	0.0	0.0000000000	False
degrees	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
norm	0.00251115778925	0.0	0.0	0.0	0.3104251602	False
high	6.80285884981e-05	0.0	0.0	0.0	0.0000000000	False
dimensions	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
stuff	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
website	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
subtract	0.000420022423227	0.0	0.0	0.0	0.0000000000	False
drawn	0.000109881091203	0.0	0.0	0.0	0.0000000000	False
heavy	0.000990195023323	0.0	0.0	0.0	0.0000000000	False
satisfy	0.000352261415284	0.0	0.0	0.0	0.0000000000	False
equation	0.000481017769997	0.0	0.0	0.0	0.2939068100	False
excuse	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
fast	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
solve	0.000179914830906	0.0	0.0	0.0	0.0000000000	False
calculation	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
ideally	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
hope	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
single	5.40592549269e-05	0.0	0.0	0.0	0.0000000000	False
precursor	0.000330065007774	0.0	0.0	0.0	0.0000000000	False
poses	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
subject	0.000616757501349	0.0	0.0	0.0	0.3445378151	False
ways	7.56805238155e-05	0.0	0.0	0.0	0.4275782155	False
difficult	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
constant	7.31121876277e-05	0.0	0.0	0.0	0.0000000000	False
important	4.5649131319e-05	0.0	0.0	0.0	0.0000000000	False
impose	0.000459869774728	0.0	0.0	0.0	0.0000000000	False
factor	0.000125518818626	0.0	0.0	0.0	0.0000000000	False
replace	0.000102828471693	0.0	0.0	0.0	0.0000000000	False
formulation	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
constraint	0.00016570292748	0.0	0.0	0.0	0.0000000000	False
slight	0.000193165983789	0.0	0.0	0.0	0.0000000000	False
comparable	0.000109881091203	0.0	0.0	0.0	0.0000000000	False
infinite	0.000117420471761	0.0	0.0	0.0	0.0000000000	False
dimensional	0.000134265699587	0.0	0.0	0.0	0.0000000000	False
spaces	5.85201875594e-05	0.0	0.0	0.0	0.0000000000	False
efficient	8.40490752418e-05	0.0	0.0	0.0	0.0000000000	False
step	2.37203043643e-05	0.0	0.0	0.0	0.0000000000	False
authorization	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
reminder	0.000229934887364	0.0	0.0	0.0	0.0000000000	False
session	0.000210011211614	0.0	0.0	0.0	0.0000000000	False
students taking the classes	0.0	0.0	0.0	2.0	0.0000000000	False
remotely  to turn	0.0	0.0	0.0	2.0	0.0000000000	False
turn in the process	0.0	0.0	0.0	2.0	0.0000000000	False
solutions due this wednesday	0.0	0.0	0.0	2.0	0.0000000000	False
top of the problem	0.0	0.0	0.0	2.0	0.0000000000	False
longer for your solutions	0.0	0.0	0.0	2.0	0.0000000000	False
re not an scpd	0.0	0.0	0.0	2.0	0.0000000000	False
turn in hard copies	0.0	0.0	0.0	2.0	0.0000000000	False
copies of your solutions	0.0	0.0	0.0	2.0	0.0000000000	False
send them by fax	0.0	0.0	0.0	2.0	0.0000000000	False
fax unless you re	0.0	0.0	0.0	0.0	0.0000000000	False
re an scpd student	0.0	0.0	0.0	2.0	0.0000000000	False
last few office hours	0.0	0.0	0.0	2.0	0.0000000000	False
lively discussions with people	0.0	0.0	0.0	2.0	0.0000000000	False
holding extra office hours	0.0	0.0	0.0	2.0	0.0000000000	False
office hours in case	0.0	0.0	0.0	2.0	0.0000000000	False
people in the back	0.0	0.0	0.0	2.0	0.0000000000	False
turn up the volume	0.0	0.0	0.0	2.0	0.0000000000	False
announcements so welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
wan na do today	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on support vector	0.0	0.0	0.0	2.0	0.0000000000	False
classifier then i wan	0.0	0.0	0.0	2.0	0.0000000000	False
primal and duo optimization	0.0	0.0	0.0	4.0	0.0000000000	False
ll derive the duo	0.0	0.0	0.0	4.0	0.0000000000	False
duo to the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
lecture and as part	0.0	0.0	0.0	2.0	0.0000000000	False
spend some time talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking about optimization problems	0.0	0.0	0.0	2.0	0.0000000000	False
topic justice i wan	0.0	0.0	0.0	2.0	0.0000000000	False
talk about convex optimization	0.0	0.0	0.0	4.0	0.0000000000	False
week s discussion session	0.0	0.0	0.0	0.0	0.0000000000	False
teach a discussion session	0.0	0.0	0.0	2.0	0.0000000000	False
discussion session  focus	0.0	0.0	0.0	2.0	0.0000000000	False
focus on convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
convex optimization  sort	0.0	0.0	0.0	2.0	0.0000000000	False
beautiful and useful theory	0.0	0.0	0.0	2.0	0.0000000000	False
listen to this friday	0.0	0.0	0.0	2.0	0.0000000000	False
friday s discussion session	0.0	0.0	0.0	0.0	0.0000000000	False
session just to recap	0.0	0.0	0.0	2.0	0.0000000000	False
developing on support vector	0.0	0.0	0.0	2.0	0.0000000000	False
represented as h sub	0.0	0.0	0.0	2.0	0.0000000000	False
development of support vector	0.0	0.0	0.0	2.0	0.0000000000	False
ll change the convention	0.0	0.0	0.0	2.0	0.0000000000	False
note the class labels	0.0	0.0	0.0	2.0	0.0000000000	False
correctly and very confidently	0.0	0.0	0.0	2.0	0.0000000000	False
large and it makes	0.0	0.0	0.0	2.0	0.0000000000	False
margins to be large	0.0	0.0	0.0	2.0	0.0000000000	False
margin is a strange	0.0	0.0	0.0	2.0	0.0000000000	False
defined the geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin had the interpretation	0.0	0.0	0.0	2.0	0.0000000000	False
examples the geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
interpretation as a distance	0.0	0.0	0.0	2.0	0.0000000000	False
distance between a training	0.0	0.0	0.0	2.0	0.0000000000	False
positive if you re	0.0	0.0	0.0	0.0	0.0000000000	False
classifying the example correctly	0.0	0.0	0.0	2.0	0.0000000000	False
ll be the minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus of the distance	0.0	0.0	0.0	2.0	0.0000000000	False
hyperplane where you re	0.0	0.0	0.0	0.0	0.0000000000	False
separating hyperplane is defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined by the equation	0.0	0.0	0.0	2.0	0.0000000000	False
respect to training set	0.0	0.0	0.0	2.0	0.0000000000	False
training set i defined	0.0	0.0	0.0	2.0	0.0000000000	False
minimum functional geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm would choose	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm would choose parameters	0.0	0.0	0.0	2.0	0.0000000000	False
maximize the geometric margin	0.0	0.0	0.0	4.0	0.0000000000	False
margin so our goal	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to find	0.0	0.0	0.0	2.0	0.0000000000	False
find the separating hyperplane	0.0	0.0	0.0	2.0	0.0000000000	False
separating hyperplane that separates	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative examples	0.0	0.0	1.9978689398	8.0	0.0000000000	False
margin i can choose	0.0	0.0	0.0	2.0	0.0000000000	False
change my geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
line you re separating	0.0	0.0	0.0	0.0	0.0000000000	False
positive and negative training	0.0	0.0	0.0	2.0	0.0000000000	False
examples if i scale	0.0	0.0	0.0	2.0	0.0000000000	False
nt change the position	0.0	0.0	0.0	0.0	0.0000000000	False
position of this plane	0.0	0.0	0.0	2.0	0.0000000000	False
easily meet this condition	0.0	0.0	0.0	2.0	0.0000000000	False
condition that  excuse	0.0	0.0	0.0	2.0	0.0000000000	False
find the absolute solution	0.0	0.0	0.0	2.0	0.0000000000	False
rescale w and meet	0.0	0.0	0.0	2.0	0.0000000000	False
choose any scaling condition	0.0	0.0	0.0	2.0	0.0000000000	False
break down the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to choose	0.0	0.0	0.0	2.0	0.0000000000	False
first attempt at writing	0.0	0.0	0.0	2.0	0.0000000000	False
writing down the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem actually wrote	0.0	0.0	0.0	2.0	0.0000000000	False
right at the end	0.0	0.0	0.0	2.0	0.0000000000	False
lecture begin to solve	0.0	0.0	0.0	2.0	0.0000000000	False
solve the parameters gamma	0.0	0.0	0.0	2.0	0.0000000000	False
add this normalization condition	0.0	0.0	0.0	2.0	0.0000000000	False
condition so the norm	0.0	0.0	0.0	2.0	0.0000000000	False
examples have functional margin	0.0	0.0	0.0	4.0	0.0000000000	False
greater than or equals	0.0	0.0	0.0	2.0	0.0000000000	False
margin and geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
gamma so you solve	0.0	0.0	0.0	2.0	0.0000000000	False
solve this optimization problem	0.0	0.0	1.9978689398	8.0	0.0000000000	False
derived the optimal margin	0.0	0.0	0.0	4.0	0.0000000000	False
parameters w that lie	0.0	0.0	0.0	2.0	0.0000000000	False
lie on the surface	0.0	0.0	0.0	2.0	0.0000000000	False
lies on a unicircle	0.0	0.0	0.0	2.0	0.0000000000	False
unicircle  a unisphere	0.0	0.0	0.0	2.0	0.0000000000	False
guaranteed that our descend	0.0	0.0	0.0	2.0	0.0000000000	False
optimal and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
change the optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
slightly different optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem let me maximize	0.0	0.0	0.0	2.0	0.0000000000	False
maximize the functional margin	0.0	0.0	3.9978689398	8.0	0.0000000000	False
examples has functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
greater than the gamma	0.0	0.0	0.0	2.0	0.0000000000	False
maximize gamma hat divided	0.0	0.0	0.0	4.0	0.0000000000	False
previously the function margin	0.0	0.0	0.0	2.0	0.0000000000	False
posing the same optimization	0.0	0.0	0.0	4.0	0.0000000000	False
functional margin y divided	0.0	0.0	0.0	2.0	0.0000000000	False
re saying the data	0.0	0.0	0.0	2.0	0.0000000000	False
functional margin is divided	0.0	0.0	0.0	2.0	0.0000000000	False
stage the functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem where gamma	0.0	0.0	0.0	2.0	0.0000000000	False
convex optimization software solves	0.0	0.0	0.0	2.0	0.0000000000	False
software solves this problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem for some set	0.0	0.0	0.0	2.0	0.0000000000	False
set of parameters gamma	0.0	0.0	0.0	2.0	0.0000000000	False
constraint that whatever values	0.0	0.0	0.0	2.0	0.0000000000	False
greater than gamma hat	0.0	0.0	0.0	2.0	0.0000000000	False
equal to gamma hat	0.0	0.0	0.0	4.0	0.0000000000	False
constraint to the function	0.0	0.0	0.0	2.0	0.0000000000	False
margin and a constraint	0.0	0.0	0.0	2.0	0.0000000000	False
constraint to the gamma	0.0	0.0	0.0	2.0	0.0000000000	False
hat does that make	0.0	0.0	0.0	2.0	0.0000000000	False
maximize gamma or gamma	0.0	0.0	0.0	2.0	0.0000000000	False
hat so that gamma	0.0	0.0	0.0	2.0	0.0000000000	False
write down an optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem in order	0.0	0.0	0.0	2.0	0.0000000000	False
out that the question	0.0	0.0	0.0	2.0	0.0000000000	False
gamma hat the function	0.0	0.0	0.0	2.0	0.0000000000	False
software for solving convex	0.0	0.0	0.0	2.0	0.0000000000	False
solving convex optimization problems	0.0	0.0	0.0	2.0	0.0000000000	False
optimization software to find	0.0	0.0	0.0	2.0	0.0000000000	False
subject to this constraint	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
choose to make gamma	0.0	0.0	0.0	2.0	0.0000000000	False
big can we make	0.0	0.0	0.0	2.0	0.0000000000	False
limited by use constraints	0.0	0.0	0.0	2.0	0.0000000000	False
bigger you can make	0.0	0.0	0.0	2.0	0.0000000000	False
margins of your training	0.0	0.0	0.0	2.0	0.0000000000	False
two class of data	0.0	0.0	2.99840170485	6.0	0.0000000000	False
draw me a line	0.0	0.0	0.0	2.0	0.0000000000	False
line and the data	0.0	0.0	0.0	2.0	0.0000000000	False
guess i m wondering	0.0	0.0	0.0	0.0	0.0000000000	False
formalization of the problem	0.0	0.0	0.0	2.0	0.0000000000	False
maximizing the worst-case distance	0.0	0.0	0.0	2.0	0.0000000000	False
distance between the point	0.0	0.0	0.0	2.0	0.0000000000	False
point and this line	0.0	0.0	0.0	2.0	0.0000000000	False
care about the worst-case	0.0	0.0	2.99840170485	6.0	0.0000000000	False
nice way to formulate	0.0	0.0	0.0	2.0	0.0000000000	False
formulate this optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	2.99840170485	6.0	0.0000000000	False
rid of this nasty	0.0	0.0	0.0	2.0	0.0000000000	False
convex function in parameters	0.0	0.0	0.0	2.0	0.0000000000	False
fairly bizarre scaling constraints	0.0	0.0	0.0	2.0	0.0000000000	False
choose any scaling constraint	0.0	0.0	0.0	2.0	0.0000000000	False
assume for the purposes	0.0	0.0	0.0	2.0	0.0000000000	False
assume that these examples	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative classes	0.0	0.0	0.0	2.0	0.0000000000	False
find that your worst-case	0.0	0.0	0.0	2.0	0.0000000000	False
scaling constraint would imply	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem and add	0.0	0.0	0.0	2.0	0.0000000000	False
add the scaling constraint	0.0	0.0	0.0	2.0	0.0000000000	False
maximization over gamma hats	0.0	0.0	0.0	2.0	0.0000000000	False
squared it was great	0.0	0.0	0.0	2.0	0.0000000000	False
normal w is min	0.0	0.0	0.0	2.0	0.0000000000	False
constraints since i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve added the constraint	0.0	0.0	0.0	2.0	0.0000000000	False
optimal margin classifier problem	0.0	0.0	0.0	4.0	0.0000000000	False
function and those pictures	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
number of linear constraints	0.0	0.0	0.0	2.0	0.0000000000	False
constraints in your parameters	0.0	0.0	0.0	2.0	0.0000000000	False
linear constraints that eliminates	0.0	0.0	0.0	2.0	0.0000000000	False
eliminates that half space	0.0	0.0	0.0	4.0	0.0000000000	False
space or linear constraint	0.0	0.0	0.0	2.0	0.0000000000	False
ruling out various half	0.0	0.0	0.0	2.0	0.0000000000	False
out various half spaces	0.0	0.0	0.0	2.0	0.0000000000	False
constraints and i hope	0.0	0.0	0.0	2.0	0.0000000000	False
hope you can convince	0.0	0.0	0.0	2.0	0.0000000000	False
great within this set	0.0	0.0	0.0	2.0	0.0000000000	False
optimal margin classifier algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
formulation of the problem	0.0	0.0	0.0	4.0	0.0000000000	False
program software this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic convex objective function	0.0	0.0	0.0	2.0	0.0000000000	False
objective function and constraints	0.0	0.0	0.0	2.0	0.0000000000	False
download software to solve	0.0	0.0	0.0	2.0	0.0000000000	False
solve these optimization problems	0.0	0.0	0.0	2.0	0.0000000000	False
form of this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
problem and the reason	0.0	0.0	0.0	4.0	0.0000000000	False
turns out this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
out this optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem has certain properties	0.0	0.0	0.0	2.0	0.0000000000	False
apply the optimal margin	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature spaces	0.0	0.0	0.0	2.0	0.0000000000	False
method of lagrange multipliers	0.0	0.0	7.9968034097	12.0	0.2600000000	False
lagrange multipliers for solving	0.0	0.0	0.0	2.0	0.0000000000	False
solving an optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
subject to some constraint	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
generalization of this method	0.0	0.0	0.0	2.0	0.0000000000	False
subject to some set	0.0	0.0	0.0	2.0	0.0000000000	False
multipliers where you construct	0.0	0.0	0.0	2.0	0.0000000000	False
objective plus some lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
multipliers the highest constraints	0.0	0.0	0.0	2.0	0.0000000000	False
constraints and these parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters  they derive	0.0	0.0	0.0	2.0	0.0000000000	False
derive  we call	0.0	0.0	0.0	2.0	0.0000000000	False
call the lagrange multipliers	0.0	0.0	0.0	2.0	0.0000000000	False
solve the optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
original parameters and set	0.0	0.0	0.0	2.0	0.0000000000	False
partial derivative with respect	0.0	0.0	0.998401704848	6.0	0.0000000000	False
respect to your lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
exists so there exists	0.0	0.0	0.0	2.0	0.0000000000	False
multipliers is to solve	0.0	0.0	0.0	2.0	0.0000000000	False
respect to the lagrange	0.0	0.0	0.0	4.0	0.0000000000	False
lagrange multipliers beta set	0.0	0.0	0.0	2.0	0.0000000000	False
set the partial derivatives	0.0	0.0	0.0	2.0	0.0000000000	False
solve for our solutions	0.0	0.0	0.0	2.0	0.0000000000	False
write down the generalization	0.0	0.0	0.0	4.0	0.0000000000	False
slightly more difficult type	0.0	0.0	0.0	2.0	0.0000000000	False
difficult type of constraint	0.0	0.0	0.0	2.0	0.0000000000	False
type of constraint optimization	0.0	0.0	0.0	2.0	0.0000000000	False
subject to the constraint	0.0	0.0	1.99840170485	6.0	0.0000000000	False
original optimization for parameters	0.0	0.0	0.0	2.0	0.0000000000	False
two sets of lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
sets of lagrange multipliers	0.0	0.0	0.0	4.0	0.0000000000	False
max of alpha beta	0.0	0.0	0.0	2.0	0.0000000000	False
constraints that the alphas	0.0	0.0	0.0	2.0	0.0000000000	False
max over alpha beta	0.0	0.0	0.0	2.0	0.0000000000	False
sense of primal problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem and that refers	0.0	0.0	0.0	2.0	0.0000000000	False
entire thing this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
thing this optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem that written	0.0	0.0	0.0	2.0	0.0000000000	False
primal problem this means	0.0	0.0	0.0	2.0	0.0000000000	False
problem in which solving	0.0	0.0	0.0	2.0	0.0000000000	False
derive in another version	0.0	0.0	0.0	2.0	0.0000000000	False
minimize w  minimize	0.0	0.0	0.0	2.0	0.0000000000	False
minimize as a function	0.0	0.0	0.0	2.0	0.0000000000	False
beta  the lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
setting the other responding	0.0	0.0	0.0	2.0	0.0000000000	False
make this arbitrarily large	0.0	0.0	0.0	2.0	0.0000000000	False
primal problem s constraints	0.0	0.0	0.0	0.0	0.0000000000	False
alpha of this lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
infinity or minus infinity	0.0	0.0	0.0	2.0	0.0000000000	False
depending on the sign	0.0	0.0	0.0	2.0	0.0000000000	False
make this plus infinity	0.0	0.0	0.0	2.0	0.0000000000	False
setting all the lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
theta p just left	0.0	0.0	0.0	2.0	0.0000000000	False
equal to plus infinity	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down that minimizes	0.0	0.0	0.0	2.0	0.0000000000	False
cool so all right	0.0	0.0	0.0	2.0	0.0000000000	False
problem to find theta	0.0	0.0	0.0	2.0	0.0000000000	False
function of the lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
lagrange and my duo	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
theta d over alpha	0.0	0.0	0.0	2.0	0.0000000000	False
beta so this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
previous prime optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem the only difference	0.0	0.0	0.0	2.0	0.0000000000	False
primal and the duo	0.0	0.0	7.99733617475	10.0	0.3255425710	False
star in other words	0.0	0.0	0.0	4.0	0.0000000000	False
defined p star previously	0.0	0.0	0.0	2.0	0.0000000000	False
star previously p star	0.0	0.0	0.0	2.0	0.0000000000	False
star was a value	0.0	0.0	0.0	2.0	0.0000000000	False
true that the max	0.0	0.0	0.0	2.0	0.0000000000	False
max of the min	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the min	0.0	0.0	0.0	2.0	0.0000000000	False
min of the max	0.0	0.0	0.0	2.0	0.0000000000	False
min of the set	0.0	0.0	0.0	2.0	0.0000000000	False
min so this equality	0.0	0.0	0.0	2.0	0.0000000000	False
equality  this inequality	0.0	0.0	0.0	2.0	0.0000000000	False
true for any function	0.0	0.0	0.0	4.0	0.0000000000	False
function you might find	0.0	0.0	0.0	2.0	0.0000000000	False
function you might put	0.0	0.0	0.0	2.0	0.0000000000	False
solve the duo problem	0.0	0.0	3.9978689398	8.0	0.0000000000	False
support vector machine problem	0.0	0.0	0.0	4.0	0.0000000000	False
properties that will make	0.0	0.0	0.0	2.0	0.0000000000	False
compared to the primal	0.0	0.0	0.0	2.0	0.0000000000	False
formally the certain conditions	0.0	0.0	0.0	2.0	0.0000000000	False
duo problems are equivalent	0.0	0.0	0.0	2.0	0.0000000000	False
out the of support	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
derive the duo optimization	0.0	0.0	0.0	2.0	0.0000000000	False
ll solve the duo	0.0	0.0	0.0	2.0	0.0000000000	False
problem and by modifying	0.0	0.0	0.0	2.0	0.0000000000	False
ll derive this support	0.0	0.0	0.0	2.0	0.0000000000	False
derive this support vector	0.0	0.0	0.0	2.0	0.0000000000	False
write down the conditions	0.0	0.0	0.0	2.0	0.0000000000	False
duo optimization problems give	0.0	0.0	0.0	2.0	0.0000000000	False
convex if you re	0.0	0.0	0.0	0.0	0.0000000000	False
purposes of this class	0.0	0.0	0.0	2.0	0.0000000000	False
learn more about optimization	0.0	0.0	0.0	2.0	0.0000000000	False
taught by the tas	0.0	0.0	0.0	2.0	0.0000000000	False
equals alpha i transpose	0.0	0.0	0.0	2.0	0.0000000000	False
means the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
linear without the term	0.0	0.0	0.0	2.0	0.0000000000	False
stricter than the equality	0.0	0.0	0.0	2.0	0.0000000000	False
solves the primal problem	0.0	0.0	0.0	2.0	0.0000000000	False
primal problem and alpha	0.0	0.0	0.0	2.0	0.0000000000	False
problem and alpha star	0.0	0.0	0.0	2.0	0.0000000000	False
alpha star and beta	0.0	0.0	0.0	2.0	0.0000000000	False
star and beta star	0.0	0.0	0.0	2.0	0.0000000000	False
problem and the value	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the value	0.0	0.0	2.99840170485	6.0	0.0000000000	False
value of the duo	0.0	0.0	0.0	2.0	0.0000000000	False
value of your lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
lagrange multiplier  excuse	0.0	0.0	0.0	2.0	0.0000000000	False
value of your generalized	0.0	0.0	0.0	2.0	0.0000000000	False
primal or the duo	0.0	0.0	0.0	2.0	0.0000000000	False
conditions partial derivative perspective	0.0	0.0	0.0	2.0	0.0000000000	False
partial derivative perspective parameters	0.0	0.0	0.0	2.0	0.0000000000	False
derive our duo problem	0.0	0.0	0.0	2.0	0.0000000000	False
out this will hold	0.0	0.0	0.0	2.0	0.0000000000	False
kkt complementary condition kkt	0.0	0.0	0.0	2.0	0.0000000000	False
complementary condition kkt stands	0.0	0.0	0.0	2.0	0.0000000000	False
kkt stands for karush-kuhn-tucker	0.0	0.0	0.0	2.0	0.0000000000	False
authors of this theorem	0.0	0.0	0.0	2.0	0.0000000000	False
constraints are actually satisfied	0.0	0.0	0.0	2.0	0.0000000000	False
optimal margin optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
word about this ktt	0.0	0.0	0.0	2.0	0.0000000000	False
alpha star i times	0.0	0.0	0.0	2.0	0.0000000000	False
product of two numbers	0.0	0.0	0.0	2.0	0.0000000000	False
product of two things	0.0	0.0	0.0	2.0	0.0000000000	False
karush-kuhn-tucker  most people	0.0	0.0	0.0	2.0	0.0000000000	False
people just say kkt	0.0	0.0	0.0	2.0	0.0000000000	False
show you the right	0.0	0.0	0.0	2.0	0.0000000000	False
spelling of their names	0.0	0.0	0.0	2.0	0.0000000000	False
kkt complementary condition implies	0.0	0.0	0.0	2.0	0.0000000000	False
implies that if alpha	0.0	0.0	0.0	2.0	0.0000000000	False
case that both alpha	0.0	0.0	0.0	2.0	0.0000000000	False
constraint because we call	0.0	0.0	0.0	2.0	0.0000000000	False
constraint  our constraint	0.0	0.0	0.0	2.0	0.0000000000	False
constraint once we talk	0.0	0.0	0.0	2.0	0.0000000000	False
idea a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit more board turn	0.0	0.0	0.0	2.0	0.0000000000	False
turn to this board	0.0	0.0	0.0	2.0	0.0000000000	False
classifier for the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
problem that we worked	0.0	0.0	0.0	2.0	0.0000000000	False
deriving the kkt conditions	0.0	0.0	0.0	2.0	0.0000000000	False
lagrange multipliers were alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i and beta	0.0	0.0	0.0	2.0	0.0000000000	False
out that when applied	0.0	0.0	0.0	2.0	0.0000000000	False
working out the kkt	0.0	0.0	0.0	2.0	0.0000000000	False
out the kkt conditions	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem i wanted	0.0	0.0	0.0	2.0	0.0000000000	False
problem finding the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
two sets of parameters	0.0	0.0	0.0	2.0	0.0000000000	False
sort of slight notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation change in mind	0.0	0.0	0.0	2.0	0.0000000000	False
half there by convention	0.0	0.0	0.0	2.0	0.0000000000	False
convention because it makes	0.0	0.0	0.0	2.0	0.0000000000	False
work  math work	0.0	0.0	0.0	2.0	0.0000000000	False
work a little nicer	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the kkt	0.0	0.0	0.0	2.0	0.0000000000	False
kkt duo complementary condition	0.0	0.0	0.0	2.0	0.0000000000	False
means that my training	0.0	0.0	0.0	2.0	0.0000000000	False
guess so in pictures	0.0	0.0	0.0	2.0	0.0000000000	False
ll have some separating	0.0	0.0	0.0	2.0	0.0000000000	False
examples with functional margin	0.0	0.0	5.99840170485	6.0	0.0000000000	False
closest to my separating	0.0	0.0	0.0	2.0	0.0000000000	False
examples of functional margin	0.0	0.0	0.0	4.0	0.0000000000	False
suggested by this picture	0.0	0.0	0.0	2.0	0.0000000000	False
out that we find	0.0	0.0	0.0	2.0	0.0000000000	False
picture i ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
distance to your separating	0.0	0.0	0.0	2.0	0.0000000000	False
re going to call	0.0	0.0	0.0	2.0	0.0000000000	False
call the support vectors	0.0	0.0	0.0	2.0	0.0000000000	False
vector machine there ll	0.0	0.0	0.0	0.0	0.0000000000	False
points with functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
re calling support vectors	0.0	0.0	0.0	2.0	0.0000000000	False
vectors and the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that they re	0.0	0.0	0.0	0.0	0.0000000000	False
re relatively few support	0.0	0.0	0.0	2.0	0.0000000000	False
support vectors also means	0.0	0.0	0.0	2.0	0.0000000000	False
out the actual optimization	0.0	0.0	0.0	2.0	0.0000000000	False
write down the margin	0.0	0.0	0.0	2.0	0.0000000000	False
constraint we have inequality	0.0	0.0	0.0	2.0	0.0000000000	False
constraints and no equality	0.0	0.0	0.0	2.0	0.0000000000	False
ll only have lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
lagrange multipliers of type	0.0	0.0	0.0	2.0	0.0000000000	False
multipliers of type alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha  no betas	0.0	0.0	0.0	2.0	0.0000000000	False
betas in my generalized	0.0	0.0	0.0	2.0	0.0000000000	False
lagrange but my lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
one-half w squared minus	0.0	0.0	0.0	2.0	0.0000000000	False
out what the duo	0.0	0.0	0.0	2.0	0.0000000000	False
figure out what theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta d of alpha	0.0	0.0	3.9968034097	12.0	0.3145161290	False
alpha so the duo	0.0	0.0	0.0	2.0	0.0000000000	False
problem is the maximize	0.0	0.0	0.0	2.0	0.0000000000	False
work out what theta	0.0	0.0	0.0	2.0	0.0000000000	False
give us our duo	0.0	0.0	0.0	2.0	0.0000000000	False
lagrange as a function	0.0	0.0	0.0	2.0	0.0000000000	False
write down the answer	0.0	0.0	0.0	2.0	0.0000000000	False
combination of your input	0.0	0.0	0.0	2.0	0.0000000000	False
examples in your training	0.0	0.0	0.0	2.0	0.0000000000	False
partial derivative of lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
equal to minus sum	0.0	0.0	0.0	2.0	0.0000000000	False
out what the lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
putting in the value	0.0	0.0	0.0	2.0	0.0000000000	False
angle brackets to denote	0.0	0.0	0.0	2.0	0.0000000000	False
brackets to denote end	0.0	0.0	0.0	2.0	0.0000000000	False
means the end product	0.0	0.0	0.0	2.0	0.0000000000	False
first and second terms	0.0	0.0	0.0	2.0	0.0000000000	False
half so to simplify	0.0	0.0	0.0	2.0	0.0000000000	False
alpha my duo problem	0.0	0.0	0.0	2.0	0.0000000000	False
maximize w of alpha	0.0	0.0	0.0	4.0	0.0000000000	False
notation is somewhat unfortunate	0.0	0.0	0.0	2.0	0.0000000000	False
capital w of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
problem lowercase w transpose	0.0	0.0	0.0	2.0	0.0000000000	False
transpose xi so uppercase	0.0	0.0	0.0	2.0	0.0000000000	False
subject to the alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i is related	0.0	0.0	0.0	2.0	0.0000000000	False
constraint was the constraint	0.0	0.0	0.0	2.0	0.0000000000	False
years that i taught	0.0	0.0	0.0	2.0	0.0000000000	False
derivative of the lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
excuse me then theta	0.0	0.0	0.0	2.0	0.0000000000	False
equal to minus infinity	0.0	0.0	0.0	4.0	0.0000000000	False
minus infinity for minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
turns out my lagrange	0.0	0.0	0.0	2.0	0.0000000000	False
function of my parameters	0.0	0.0	0.0	2.0	0.0000000000	False
interpretation of that constraint	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
maximize as a function	0.0	0.0	0.0	2.0	0.0000000000	False
ve got ta choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose values of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha for which sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum of yi alpha	0.0	0.0	2.99840170485	6.0	0.0000000000	False
subject to that sum	0.0	0.0	0.0	2.0	0.0000000000	False
bit of extra notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation in our derivation	0.0	0.0	0.0	2.0	0.0000000000	False
derivation of the duo	0.0	0.0	0.0	2.0	0.0000000000	False
action of the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
cool so what derived	0.0	0.0	0.0	2.0	0.0000000000	False
derived a duo optimization	0.0	0.0	0.0	2.0	0.0000000000	False
worked out this constraint	0.0	0.0	0.0	2.0	0.0000000000	False
worked out the duo	0.0	0.0	0.0	2.0	0.0000000000	False
duo of the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
finding  to deriving	0.0	0.0	0.0	2.0	0.0000000000	False
margin classifier or support	0.0	0.0	0.0	2.0	0.0000000000	False
classifier or support vector	0.0	0.0	0.0	2.0	0.0000000000	False
solve along this duo	0.0	0.0	0.0	2.0	0.0000000000	False
problem for the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
equation that we worked	0.0	0.0	0.0	2.0	0.0000000000	False
derive w in parameters	0.0	0.0	0.0	2.0	0.0000000000	False
problem and we worked	0.0	0.0	0.0	2.0	0.0000000000	False
worked this out earlier	0.0	0.0	0.0	2.0	0.0000000000	False
interpretation of training set	0.0	0.0	0.0	2.0	0.0000000000	False
separating hyperplane s direction	0.0	0.0	0.0	0.0	0.0000000000	False
orientation and separating hyperplane	0.0	0.0	0.0	2.0	0.0000000000	False
decide where to place	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem and solve	0.0	0.0	0.0	2.0	0.0000000000	False
intuition behind this formula	0.0	0.0	0.0	2.0	0.0000000000	False
place the separating hyperplane	0.0	0.0	0.0	2.0	0.0000000000	False
duo problem we re	0.0	0.0	0.0	0.0	0.0000000000	False
re going to solve	0.0	0.0	0.0	2.0	0.0000000000	False
problem for the alpha	0.0	0.0	0.0	2.0	0.0000000000	False
wan na point out	0.0	0.0	0.0	2.0	0.0000000000	False
out as i lead	0.0	0.0	0.0	2.0	0.0000000000	False
express the entire algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
entire algorithm in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of inner products	0.0	0.0	0.0	2.0	0.0000000000	False
sum of your input	0.0	0.0	0.0	2.0	0.0000000000	False
value of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis on the value	0.0	0.0	0.0	2.0	0.0000000000	False
threshold function that outputs	0.0	0.0	0.0	2.0	0.0000000000	False
function that outputs minus	0.0	0.0	0.0	2.0	0.0000000000	False
expressed as a sum	0.0	0.0	0.0	2.0	0.0000000000	False
products between your training	0.0	0.0	0.0	2.0	0.0000000000	False
value of x value	0.0	0.0	0.0	2.0	0.0000000000	False
kernels and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
source of feature spaces	0.0	0.0	0.0	2.0	0.0000000000	False
machines  it turns	0.0	0.0	0.0	2.0	0.0000000000	False
case that the features	0.0	0.0	0.0	2.0	0.0000000000	False
products like these efficiently	0.0	0.0	0.0	2.0	0.0000000000	False
efficiently and this holds	0.0	0.0	0.0	2.0	0.0000000000	False
true for arbitrary sets	0.0	0.0	0.0	2.0	0.0000000000	False
arbitrary sets of features	0.0	0.0	0.0	2.0	0.0000000000	False
features but we talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the idea	0.0	0.0	0.0	2.0	0.0000000000	False
extremely high-dimensional feature vectors	0.0	0.0	0.0	2.0	0.0000000000	False
store in computer memory	0.0	0.0	0.0	2.0	0.0000000000	False
products between different feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature vectors very efficiently	0.0	0.0	0.0	2.0	0.0000000000	False
make predictions by making	0.0	0.0	0.0	2.0	0.0000000000	False
transpose you will compute	0.0	0.0	0.0	2.0	0.0000000000	False
compute these inner products	0.0	0.0	0.0	2.0	0.0000000000	False
alpha is again written	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem and step	0.0	0.0	0.0	2.0	0.0000000000	False
steps of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
products with your feature	0.0	0.0	0.0	2.0	0.0000000000	False
property of this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that s kinda	0.0	0.0	0.0	0.0	0.0000000000	False
previously that the alpha	0.0	0.0	0.0	2.0	0.0000000000	False
small fraction of training	0.0	0.0	0.0	2.0	0.0000000000	False
fraction of training examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples because mostly alpha	0.0	0.0	0.0	2.0	0.0000000000	False
summing up the sum	0.0	0.0	0.0	2.0	0.0000000000	False
fraction of your training	0.0	0.0	0.0	2.0	0.0000000000	False
make much more sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense when we talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about kernels quick	0.0	0.0	0.0	2.0	0.0000000000	False
questions before i close	0.0	0.0	0.0	2.0	0.0000000000	False
ve done the work	0.0	0.0	0.0	2.0	0.0000000000	False
today s lecture asks	0.0	0.0	0.0	0.0	0.0000000000	False
generalize this in multiple	0.0	0.0	0.0	2.0	0.0000000000	False
ll talk about kernels	0.0	0.0	0.0	2.0	0.0000000000	False
taking the classes	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
process solutions due	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
due this wednesday	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
fax the solutions	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
fax number written	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
takes me longer	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
turn in hard	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
physical paper copies	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solutions from set	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
re an scpd	0.0	0.0	0.0	0.0	0.0000000000	False
proposals are due	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
due this friday	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
last few office	0.0	0.0	0.0	0.0	0.0000000000	False
discussions with people	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
people about ideas	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ideas this wednesday	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
immediately after class	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
right after class	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll be holding	0.0	0.0	0.0	1.58496250072	0.0000000000	False
holding extra office	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
extra office hours	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hours in case	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
discuss project ideas	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
due on friday	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
today is continue	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
continue our discussion	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
discussion on support	0.000861790545327	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.00640809000136	1.0	5.99413958444	15.8496250072	0.4401805869	True
wan na talk	0.0	0.0	0.0	3.16992500144	0.0000000000	False
optimal margin classifier	0.00995416308737	0.0	5.99467234949	14.2646625065	0.5492957746	True
digression and talk	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
talk about primal	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
primal and duo	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
duo optimization problems	0.0110146595409	0.0	5.99520511454	12.6797000058	0.3979591837	True
derive the duo	0.00367155318031	0.0	1.99840170485	3.16992500144	0.0000000000	False
discussion of kernels	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
part of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
talking about optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
justice i wan	0.0	0.0	0.0	0.0	0.0000000000	False
talk about convex	0.00199083261747	0.0	0.0	0.0	0.0000000000	False
week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
teach a discussion	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
session  focus	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
focus on convex	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
optimization  sort	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
friday s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
beginning on developing	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
developing on support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
development of support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
change the convention	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
convention of letting	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
note the class	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
labels so last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
large positive number	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
classifying a training	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
large negative number	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
increase functional margin	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
taking your parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
defined the geometric	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
functional margin divided	0.00497708154369	0.0	6.99733617475	7.92481250361	0.3255425710	False
examples the geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
reaching the point	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
reaching the training	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
re separating hyperplane	0.0	0.0	0.0	3.16992500144	0.0000000000	False
hyperplane is defined	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
equation w transpose	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
guess also defined	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
defined these things	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
respect to training	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
set i defined	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
minimum functional geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
functional geometric margin	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
algorithm would choose	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximize the geometric	0.00199083261747	0.0	0.0	0.0	0.0000000000	False
find the separating	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hyperplane that separates	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
separates the positive	0.00126671158792	0.0	0.0	3.16992500144	0.0000000000	False
positive and negative	0.00323128083604	0.0	3.9968034097	6.33985000288	0.3979591837	False
large a distance	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
multiply my parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
change my geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
line you re	0.0	0.0	0.0	0.0	0.0000000000	False
separating by positive	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
negative training examples	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
change the position	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
choose whatever scaling	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find a solution	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
rescaling the parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
meet this condition	0.00367155318031	0.0	5.99840170485	3.16992500144	0.0000000000	False
add the condition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
essentially not change	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
change the problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
add other conditions	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
add a condition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find the absolute	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
ensure you meet	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ability to choose	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
choose any scaling	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
attempt at writing	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem actually wrote	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
previous lecture begin	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
begin to solve	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solve the parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
choose to add	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
add this normalization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
makes the geometric	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find a value	0.0	0.0	0.0	3.16992500144	0.0000000000	False
value for gamma	0.0012238510601	0.0	3.99840170485	4.75488750216	0.0000000000	False
gamma as big	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
examples have functional	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
functional margin greater	0.00298624892621	0.0	3.99840170485	4.75488750216	0.0000000000	False
constraint that normal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
normal w equals	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
margin and geometric	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
find the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
margins are greater	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
greater or equal	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
equal to gamma	0.00298624892621	0.0	1.99840170485	1.58496250072	0.0000000000	False
solve this optimization	0.00344716218131	0.0	1.9978689398	0.0	0.5270270270	False
derived the optimal	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
nice optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solve for parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization problem	0.00344716218131	0.0	4.9978689398	4.75488750216	0.0000000000	False
change the optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
slightly different optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximize the functional	0.00489540424041	0.0	3.9978689398	0.0	0.3451327434	False
normal w subject	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
find a number	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
examples has functional	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
gamma hat divided	0.00367155318031	0.0	2.99840170485	1.58496250072	0.0000000000	False
wan na maximize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
previously the function	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
optimization problem confused	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
margin y divided	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin is divided	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
end up dividing	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
stage the functional	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem where gamma	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
convex optimization software	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
optimization software solves	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solves this problem	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
set of parameters	0.00126671158792	0.0	0.0	1.58496250072	0.0000000000	False
imposing the constraint	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
greater than gamma	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
greater than equal	0.00126671158792	0.0	0.0	3.16992500144	0.0000000000	False
gamma or gamma	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
respect to gamma	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
problem in order	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
order to solve	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
hat the function	0.0012238510601	0.0	5.99733617475	6.33985000288	0.0000000000	False
previous mathematical definition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization solvers	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
software for solving	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solving convex optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
software to find	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
find me values	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
make this value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value as big	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose for gamma	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
maximize gamma hat	0.00367155318031	0.0	1.99840170485	1.58496250072	0.0000000000	False
choose to make	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hat as big	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
smallest functional margin	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
value of gamma	0.0	0.0	0.0	1.58496250072	0.0000000000	False
class of data	0.00367155318031	0.0	2.99840170485	0.0	0.0000000000	False
maximize the distance	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find separate hyperplane	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
find a line	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
repeating the questions	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
questions in case	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
line that separates	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the worst-case	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
formulate this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.0013007899753	0.0	2.99840170485	4.75488750216	0.0000000000	False
formulation makes sense	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ve now added	0.0	0.0	0.0	1.58496250072	0.0000000000	False
added a nasty	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
function in parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
fairly bizarre scaling	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
bizarre scaling constraints	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
purposes of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
impose a constraint	0.00298624892621	0.0	5.99840170485	4.75488750216	0.0000000000	False
margin is equal	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
constraint that min	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
worst-case function margin	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
constraint would imply	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin be equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
previous optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem and add	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
add the scaling	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximization over gamma	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
minimizing the normal	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
normal w squared	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
great maximum normal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
added the constraint	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin classifier problem	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
pictures can draw	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
minimize the quadratic	0.000861790545327	0.0	0.0	0.0	0.0000000000	False
number of linear	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
constraints that eliminates	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
space or linear	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
linear constraint eliminates	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
out various half	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
guess kinda draw	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
set of points	0.000633355793961	0.0	0.0	1.58496250072	0.0000000000	False
margin classifier algorithm	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem and throw	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
quadratic program software	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
software this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
quadratic convex objective	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
convex objective function	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
function and constraints	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
software to solve	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solve these optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
digression to talk	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
back and derive	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
out this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
properties that make	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
make it amenable	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ll be deriving	0.0	0.0	0.0	1.58496250072	0.0000000000	False
apply the optimal	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
high-dimensional feature spaces	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.000693441993058	0.0	0.0	0.0	0.0000000000	False
dimensional feature spaces	0.000693441993058	0.0	0.0	1.58496250072	0.0000000000	False
remember the method	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
method of lagrange	0.00734310636061	0.0	7.9968034097	0.0	0.2600000000	False
multipliers for solving	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solving an optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem like minimum	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
minimum  minimization	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
maximization problem subject	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
set of constraints	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
vector value function	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
arrow on top	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
denote the vector	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
construct this lagrange	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
original optimization objective	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
multipliers the highest	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
call the lagrange	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
solve the optimization	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
parameters and set	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
derivative with respect	0.00517074327196	0.0	3.9968034097	4.75488750216	0.3979591837	False
value w star	0.0	0.0	0.0	1.58496250072	0.0000000000	False
star ? right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
right the backwards	0.0	0.0	0.0	1.58496250072	0.0000000000	False
exists beta star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
derivatives are equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
construct a lagrange	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lagrange multipliers beta	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
multipliers beta set	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
set the partial	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
partial derivatives equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
great so great	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
slightly more difficult	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
type of constraint	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
constraint optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
inequality for constraint	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
optimization for parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
sets of lagrange	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
alpha and beta	0.00734310636061	0.0	8.9968034097	9.50977500433	0.4171122995	False
define theta subscript	0.0	0.0	0.0	1.58496250072	0.0000000000	False
equal to max	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
max of alpha	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
alpha beta subject	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
optimization problem min	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
max over alpha	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
equal to min	0.00199083261747	0.0	2.99733617475	7.92481250361	0.0000000000	False
sense of primal	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
thing this optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem that written	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem this means	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
original optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
pick the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
primal problems constraints	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
suppose i pick	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
pick a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
maximize this function	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
function of alpha	0.00398166523495	0.0	2.9978689398	6.33985000288	0.0000000000	False
make this arbitrarily	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem s constraints	0.0	0.0	0.0	0.0	0.0000000000	False
minus infinity depending	0.0	0.0	0.0	1.58496250072	0.0000000000	False
maximize in terms	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
terms of alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lagrange multiply theorems	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
obtained by setting	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
constraints are satisfied	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
problem i wrote	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
minimizes the function	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
original primal problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
choose a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
violates the constraints	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
satisfy the constraints	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
minimizing the state	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
right i hope	0.0	0.0	0.0	1.58496250072	0.0000000000	False
thing we started	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem to find	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
problem to maximize	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
maximize over alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
previous prime optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
prime optimization problem	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
max and min	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
switched the order	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
defined p star	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
previously p star	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
inequality actually holds	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
exchange the order	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
order to min	0.0012238510601	0.0	0.0	3.16992500144	0.0000000000	False
min and max	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
two optimization problems	0.0	0.0	0.0	1.58496250072	0.0000000000	False
solve the duo	0.00489540424041	0.0	3.9978689398	3.16992500144	0.4171122995	False
vector machine problem	0.0024477021202	0.0	0.0	0.0	0.0000000000	False
duo problem turns	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
make user compared	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problems are equivalent	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
strategy for working	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
vector machine algorithm	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
primal optimization problem	0.00298624892621	0.0	1.99840170485	4.75488750216	0.0000000000	False
derive this support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
sake of completeness	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
optimization problems give	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
discussion session taught	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
tas then suppose	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha i transpose	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
thing as linear	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
writing these things	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
details strictly feasible	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
satisfy were stricter	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
exists w star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solves the primal	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
problem and alpha	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
star and beta	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
multiplier  excuse	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
parameters will satisfy	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
satisfy these conditions	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
conditions partial derivative	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
partial derivative perspective	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
derivative perspective parameters	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
equation in mind	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
derive our duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
ll actually perform	0.0	0.0	0.0	1.58496250072	0.0000000000	False
perform this step	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
beta is equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
kkt complementary condition	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
complementary condition kkt	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
condition kkt stands	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
stands for karush-kuhn-tucker	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
optimal margin optimization	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
margin optimization problem	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
ktt complementary condition	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
star i times	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
numbers is equal	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
wan na show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
names so kkt	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
complementary condition implies	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
star is equal	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
kkt condition guarantees	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha i star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
call a constraint	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
extend this idea	0.000766981557372	0.0	0.0	1.58496250072	0.0000000000	False
bit more board	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
back and work	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
point of notation	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
ve been writing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
deriving the kkt	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
multipliers were alpha	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
lagrange multipliers alpha	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
out the kkt	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
denote the parameters	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem i wanted	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
wanted to minimize	0.0012238510601	0.0	3.99733617475	7.92481250361	0.4171122995	False
first optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
optimization problem finding	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
finding the parameters	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
sort of slight	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
slight notation change	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
change in mind	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
mind so problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem we worked	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
add a half	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
makes other work	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
work  math	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
nicer and subject	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
kkt duo complementary	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
duo complementary condition	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
functional margin equal	0.0110146595409	0.0	17.9952051145	14.2646625065	0.2146788991	False
equality that means	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
examples with functional	0.00298624892621	0.0	5.99840170485	0.0	0.0000000000	False
alpha i equal	0.00367155318031	0.0	3.99840170485	4.75488750216	0.0000000000	False
examples of functional	0.00199083261747	0.0	0.0	0.0	0.0000000000	False
true in general	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
picture i ve	0.0	0.0	0.0	0.0	0.0000000000	False
minimum possible distance	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
call the support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
machine there ll	0.0	0.0	0.0	0.0	0.0000000000	False
points with functional	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
re calling support	0.0	0.0	0.0	0.0	0.0000000000	False
calling support vectors	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
vectors also means	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
out the actual	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
actual optimization problem	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
multipliers of type	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
one-half w squared	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
out what theta	0.0024477021202	0.0	0.0	1.58496250072	0.0000000000	False
alpha is min	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
min with respect	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lagrange and minimize	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
order to minimize	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
minimize the lagrange	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
lagrange with respect	0.00489540424041	0.0	5.9978689398	6.33985000288	0.4171122995	False
wan na minimize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minimize this function	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
derivative and set	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
input feature vectors	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
derivative of lagrange	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
equal to minus	0.00208032597918	0.0	1.99840170485	3.16992500144	0.0000000000	False
ll just set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minimize with respect	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
transpose w minus	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
sum y equals	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
worked out previously	0.00258537163598	0.0	1.99840170485	4.75488750216	0.0000000000	False
brackets to denote	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
denote end product	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
means the end	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
minus one half	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha my duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
realize the notation	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
alpha to denote	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
denote that formula	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
formula i wrote	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
wrote down earlier	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
primal problem lowercase	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
lowercase w transpose	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
uppercase and lowercase	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
totally different things	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
notation is standard	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
constraint that sum	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
alpha is equal	0.00734310636061	0.0	5.9968034097	9.50977500433	0.2392638037	False
infinity for minimizing	0.0	0.0	0.0	0.0	0.0000000000	False
out my lagrange	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
constraint we worked	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
values of alpha	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
ended up deciding	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
deciding to maximize	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
bit of extra	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
derived a duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
out this constraint	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
out the duo	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
approach to finding	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
classifier or support	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
parameters alpha star	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
solve for alpha	0.00367155318031	0.0	2.99840170485	4.75488750216	0.0000000000	False
easy to solve	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
interpretation of training	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
found the direction	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
hyperplane s direction	0.0	0.0	0.0	0.0	0.0000000000	False
orientation and separating	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
place this hyperplane	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem and solve	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
find the worst	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
set the threshold	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
place the separating	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
hope the process	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
process is clear	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
problem we re	0.0	0.0	0.0	0.0	0.0000000000	False
thing i wan	0.0	0.0	0.0	1.58496250072	0.0000000000	False
wan na point	0.0	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
express the entire	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
algorithm in terms	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.000633355793961	0.0	0.0	1.58496250072	0.0000000000	False
function that outputs	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
compute w transpose	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
equal to alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
idea of kernels	0.00199083261747	0.0	0.0	3.16992500144	0.0000000000	False
source of feature	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
inner-dimensional feature vectors	0.0024477021202	0.0	0.0	3.16992500144	0.0000000000	False
compute inner products	0.00398166523495	0.0	7.9978689398	6.33985000288	0.3451327434	False
nt hold true	0.0	0.0	0.0	0.0	0.0000000000	False
true for arbitrary	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
sets of features	0.000582553636488	0.0	0.0	0.0	0.0000000000	False
ll see examples	0.0	0.0	0.0	1.58496250072	0.0000000000	False
extremely high-dimensional feature	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
high-dimensional feature vectors	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
store in computer	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
vectors very efficiently	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
predictions by making	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
reason we derive	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
written in terms	0.000861790545327	0.0	0.0	1.58496250072	0.0000000000	False
problem and step	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
learn the parameters	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
parameters of alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
needing to represent	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
represent xi directly	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
represent this compute	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
vectors that function	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
fairly small fraction	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
fraction of training	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
nice because alpha	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
talk about kernels	0.00199083261747	0.0	0.0	1.58496250072	0.0000000000	False
kernels quick questions	0.0012238510601	1.0	0.0	1.58496250072	0.0000000000	False
points are kinda	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
nt we assume	0.0	0.0	0.0	0.0	0.0000000000	False
assume that point	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
ways to generalize	0.0012238510601	0.0	0.0	1.58496250072	0.0000000000	False
close for today	0.000995416308737	0.0	0.0	1.58496250072	0.0000000000	False
good morning	0.000289064438955	0.0	0.0	1.0	0.0000000000	False
quick announcements	0.000422237195974	0.0	0.0	1.0	0.0000000000	False
scpd students	0.0024477021202	0.0	2.99840170485	2.0	0.0000000000	False
students taking	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
process solutions	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
fax number	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
number written	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
problem set	0.000359031204004	0.0	0.0	1.0	0.0000000000	False
hard copies	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
physical paper	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
paper copies	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
project proposals	0.000462294662039	0.0	0.0	1.0	0.0000000000	False
office hours	0.00114905406044	0.0	0.0	1.0	0.0000000000	False
lively discussions	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
extra office	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
discuss project	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
project ideas	0.000574527030218	0.0	0.0	0.0	0.0000000000	False
back hear	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
administrative announcements	0.000574527030218	0.0	0.0	1.0	0.0000000000	False
support vector	0.00660227454686	1.0	10.9909429941	16.0	0.3959390863	False
vector machines	0.00427206000091	0.0	5.99413958444	9.0	0.4401805869	False
optimal margin	0.0079633304699	0.0	5.99360681939	10.0	0.5909090909	False
margin classifier	0.00574527030218	0.0	5.99467234949	8.0	0.5492957746	False
duo optimization	0.00897490777408	0.0	7.99467234949	8.0	0.4266958425	False
optimization problems	0.0244897573665	1.0	23.9690996271	57.0	0.3961401727	True
kkt conditions	0.00407950353367	0.0	3.99733617475	4.0	0.0000000000	True
posed earlier	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
couple words	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
topic justice	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
convex optimization	0.00511321038248	1.0	8.99467234949	9.0	0.4105263158	True
discussion session	0.00265444348997	0.0	2.9978689398	4.0	0.0000000000	False
previous lecture	0.000718062408008	0.0	0.0	1.0	0.0000000000	False
hypothesis represented	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
class labels	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
functional margin	0.0247046622994	0.0	28.9770911028	41.0	0.2312481471	True
large positive	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
positive number	0.000511321038248	0.0	0.0	0.0	0.0000000000	False
large negative	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
negative number	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
strange property	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
geometric margin	0.00919243248348	0.0	21.9909429941	16.0	0.3929471033	True
margin divided	0.00331805436246	0.0	6.99733617475	0.0	0.3255425710	False
sin distance	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
separating hyperplane	0.00815900706735	0.0	5.99413958444	10.0	0.0000000000	False
training set	0.00173438663373	0.0	3.9968034097	5.0	0.0000000000	False
worst case	0.000999460061102	0.0	2.99840170485	3.0	0.0000000000	False
minimum functional	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
functional geometric	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
learning algorithm	0.00026994736173	0.0	0.0	0.0	0.0000000000	False
choose parameters	0.00153396311474	0.0	3.99840170485	2.0	0.0000000000	False
negative examples	0.0016889487839	0.0	1.99733617475	1.0	0.0000000000	False
negative training	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
training examples	0.00248003862236	0.0	10.9925412893	13.0	0.5820895522	False
straight line	0.000359031204004	0.0	0.0	1.0	0.0000000000	False
perfect constraint	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
absolute value	0.0	0.0	0.0	2.0	0.0000000000	False
adding condition	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
first component	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
absolute solution	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
esoteric conditions	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
scaling condition	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
first attempt	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
lecture begin	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
parameters gamma	0.0010226420765	0.0	0.0	1.0	0.0000000000	False
normalization condition	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
norm condition	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
margin greater	0.00199083261747	0.0	3.99840170485	0.0	0.0000000000	False
equals gamma	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
nice optimization	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
nonconvex constraints	0.0024477021202	0.0	3.99840170485	3.0	0.0000000000	False
local optimal	0.000574527030218	0.0	0.0	2.0	0.0000000000	False
nasty constraint	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
optimization objective	0.00402168921152	0.0	5.99627064465	6.0	0.4401805869	False
maximize gamma	0.00265444348997	0.0	2.9978689398	2.0	0.4171122995	False
problem confused	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
optimization software	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
software solves	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
gamma hat	0.0132722174498	0.0	16.9888119339	20.0	0.2410383189	False
make sense	0.000826965479042	0.0	4.99733617475	4.0	0.0000000000	False
previous mathematical	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
mathematical definition	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
optimization solvers	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
solving convex	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
independent variables	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
make gamma	0.0024477021202	0.0	2.99840170485	2.0	0.0000000000	False
smallest functional	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
smallest distance	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
data points	0.0	0.0	0.0	1.0	0.0000000000	False
audio catches	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
worst-case distance	0.0024477021202	0.0	3.9978689398	3.0	0.0000000000	False
formulation makes	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
cool great	0.000462294662039	0.0	0.0	1.0	0.0000000000	False
nonconvex objective	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
convex function	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
usual guarantees	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
global minimum	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
bizarre scaling	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
scaling constraints	0.00489540424041	0.0	9.9968034097	5.0	0.2600000000	False
negative classes	0.000511321038248	0.0	0.0	0.0	0.0000000000	False
worst-case function	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
previous optimization	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
hats divided	0.0024477021202	0.0	2.99840170485	1.0	0.0000000000	False
great maximum	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
final formulation	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
classifier problem	0.00163180141347	0.0	0.0	0.0	0.0000000000	False
quadratic function	0.00211118597987	0.0	7.99733617475	4.0	0.2943396226	False
linear constraints	0.00265444348997	0.0	7.9978689398	3.0	0.0000000000	False
constraint eliminates	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
half spaces	0.00287263515109	0.0	7.9978689398	3.0	0.2041884817	False
guess kinda	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
kinda draw	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
convex problem	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
local optimum	0.000511321038248	0.0	0.0	1.0	0.0000000000	False
global optimum	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
classifier algorithm	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
off-the-shelf software	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
quadratic program	0.00163180141347	1.0	0.0	1.0	0.0000000000	False
program software	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
quadratic convex	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
convex objective	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
objective function	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
download software	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
modify work	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
declare success	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
efficient algorithms	0.000511321038248	0.0	0.0	1.0	0.0000000000	False
duo formulation	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
high-dimensional feature	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
feature spaces	0.00184917864816	0.0	3.9978689398	3.0	0.0000000000	False
infinite dimensional	0.000422237195974	0.0	0.0	0.0	0.0000000000	False
dimensional feature	0.000462294662039	0.0	5.99733617475	4.0	0.0000000000	False
lagrange multipliers	0.0179498155482	0.0	10.9888119339	20.0	0.2901531729	True
maximization problem	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
problem subject	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
nt worry	0.0	0.0	0.0	0.0	0.0000000000	False
calculus classes	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
vectorial form	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
vector value	0.0	0.0	0.0	0.0	0.0000000000	False
value function	0.0	0.0	0.0	0.0	0.0000000000	False
original optimization	0.0024477021202	0.0	2.99840170485	2.0	0.0000000000	False
highest constraints	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
partial derivative	0.00517074327196	0.0	3.99520511454	8.0	0.3007712082	False
original parameters	0.00199083261747	0.0	2.99840170485	2.0	0.0000000000	False
guess lagrange	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
exists beta	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
beta star	0.00326360282694	0.0	2.9978689398	3.0	0.0000000000	False
multipliers beta	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
beta set	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
minimum great	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
difficult type	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
constraint optimization	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
vector notation	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
equality constraint	0.00163180141347	0.0	0.0	2.0	0.0000000000	False
generalized lagrange	0.00326360282694	0.0	2.9978689398	4.0	0.0000000000	False
cool part	0.00163180141347	0.0	0.0	2.0	0.0000000000	False
define theta	0.0	0.0	0.0	0.0	0.0000000000	False
theta subscript	0.000574527030218	0.0	0.0	0.0	0.0000000000	False
alpha beta	0.00132722174498	0.0	0.0	1.0	0.0000000000	False
beta subject	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
problem min	0.00163180141347	0.0	0.0	0.0	0.0000000000	False
primal problem	0.00663610872491	1.0	8.99413958444	11.0	0.4171122995	True
entire thing	0.000289064438955	0.0	0.0	0.0	0.0000000000	False
quantity theta	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
problems constraints	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
responding alpha	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
arbitrarily large	0.000574527030218	0.0	0.0	0.0	0.0000000000	False
similar reason	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
setting beta	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
minus infinity	0.000815900706735	0.0	1.99840170485	2.0	0.0000000000	False
infinity depending	0.0	0.0	0.0	0.0	0.0000000000	False
original primal	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
find theta	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
duo problem	0.0146862127212	0.0	13.9904102291	17.0	0.3152094048	False
previous prime	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
prime optimization	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
star previously	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
general fact	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
machine problem	0.00163180141347	0.0	0.0	0.0	0.0000000000	False
problem turns	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
make user	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
user compared	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
machine algorithm	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
primal optimization	0.00199083261747	0.0	1.99840170485	0.0	0.0000000000	False
maximizing classifier	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
problems give	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
convex means	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
session taught	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
equals alpha	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
constant interceptor	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
strictly feasible	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
technical details	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
alpha star	0.00407950353367	0.0	3.99733617475	4.0	0.4171122995	False
star solves	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
derivative perspective	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
perspective parameters	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
kkt complementary	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
complementary condition	0.00326360282694	0.0	4.9978689398	3.0	0.0000000000	False
condition kkt	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
kkt stands	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
margin optimization	0.00163180141347	0.0	0.0	1.0	0.0000000000	False
ktt complementary	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
right spelling	0.0	0.0	0.0	1.0	0.0000000000	False
condition implies	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
condition guarantees	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
large part	0.000511321038248	0.0	0.0	1.0	0.0000000000	False
solve problems	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
active constraint	0.00326360282694	0.0	5.9978689398	4.0	0.0000000000	False
board turn	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
multipliers alpha	0.00163180141347	0.0	0.0	0.0	0.0000000000	False
first optimization	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
problem finding	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
svn problem	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
slight notation	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
notation change	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
math work	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
kkt duo	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
duo complementary	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
greater equal	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
inequality holds	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
hold true	0.00271858363694	0.0	3.99627064465	7.0	0.3979591837	False
calling support	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
actual optimization	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
inequality constraints	0.00163180141347	0.0	0.0	2.0	0.0000000000	False
star constraints	0.00163180141347	0.0	0.0	2.0	0.0000000000	False
type alpha	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
squared minus	0.000574527030218	0.0	0.0	0.0	0.0000000000	False
maximize theta	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
ll give	0.0	0.0	0.0	2.0	0.0000000000	False
minimize lagrange	0.0	0.0	0.0	1.0	0.0000000000	False
usual thing	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
linear combination	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
input feature	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
feature vectors	0.00253342317584	0.0	9.9968034097	5.0	0.0000000000	False
minus sum	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
first term	0.000574527030218	0.0	0.0	1.0	0.0000000000	False
out previously	0.00172358109065	0.0	1.99840170485	0.0	0.0000000000	False
angle brackets	0.000574527030218	0.0	0.0	0.0	0.0000000000	False
denote end	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
end product	0.00132722174498	0.0	0.0	1.0	0.0000000000	False
problem lowercase	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
alpha related	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
last constraint	0.0	0.0	0.0	1.0	0.0000000000	False
previous years	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
slightly confusing	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
real interpretation	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
big deal	0.000663610872491	0.0	0.0	1.0	0.0000000000	False
linear function	0.000388369090992	0.0	0.0	1.0	0.0000000000	False
choose values	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
alpha subject	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
extra notation	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
parameters alpha	0.00114905406044	0.0	0.0	1.0	0.0000000000	False
previous board	0.000388369090992	0.0	0.0	1.0	0.0000000000	False
out earlier	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
solve alpha	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
plug alpha	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
worst positive	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
worst negative	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
entire algorithm	0.0010226420765	0.0	0.0	1.0	0.0000000000	False
input examples	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
threshold function	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
inner-dimensional feature	0.00163180141347	0.0	0.0	0.0	0.0000000000	False
interesting representation	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
arbitrary sets	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
computer memory	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
make predictions	0.0010226420765	0.0	0.0	1.0	0.0000000000	False
last property	0.0	0.0	0.0	1.0	0.0000000000	False
kinda nice	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
small fraction	0.00132722174498	0.0	0.0	1.0	0.0000000000	False
kernels quick	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
quick questions	0.000663610872491	0.0	0.0	0.0	0.0000000000	False
point file	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
wrong side	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
lecture asks	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
excellent assumption	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
multiple classes	0.000815900706735	0.0	0.0	1.0	0.0000000000	False
good	2.05659169601e-05	0.0	0.0	0.0	0.0000000000	False
morning	0.000144532219478	0.0	0.0	0.0	0.0000000000	False
quick	0.000220920985522	0.0	0.0	0.0	0.0000000000	False
announcements	0.000310004827795	0.0	0.0	0.0	0.0000000000	False
scpd	0.00165902718123	0.0	0.0	0.0	0.2041884817	False
students	0.000337969059667	0.0	0.0	0.0	0.0000000000	False
taking	8.16773032752e-05	0.0	0.0	0.0	0.3805685193	False
classes	0.000337848344986	0.0	0.0	0.0	0.3577981651	False
remotely	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
turn	0.00102707441408	0.0	0.0	0.0	0.4552529183	False
process	6.14269718157e-05	0.0	0.0	0.0	0.0000000000	False
solutions	0.00109839944392	0.0	0.0	0.0	0.2820976492	False
due	0.000582553636488	0.0	0.0	0.0	0.0000000000	False
wednesday	0.000766981557372	0.0	0.0	0.0	0.0000000000	False
fax	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
number	1.8988057578e-05	0.0	0.0	0.0	0.5416666667	False
written	0.000217377234686	0.0	0.0	0.0	0.5270270270	False
top	0.000108688617343	0.0	0.0	0.0	0.0000000000	False
problem	0.000598828500784	0.0	0.0	0.0	0.3520464944	False
set	0.000225378390465	0.0	0.0	0.0	0.4748544203	False
longer	0.000289064438955	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
hard	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
copies	0.000539894723461	0.0	0.0	0.0	0.4171122995	False
physical	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
paper	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
email	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
send	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
project	0.000252361355431	0.0	0.0	0.0	0.0000000000	False
proposals	0.000359031204004	0.0	0.0	0.0	0.0000000000	False
friday	0.000422237195974	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.5270270270	False
office	0.000422237195974	0.0	0.0	0.0	0.0000000000	False
hours	0.000333153353701	0.0	0.0	0.0	0.0000000000	False
lively	0.000144532219478	0.0	0.0	0.0	0.0000000000	False
discussions	0.000400286084748	0.0	0.0	0.0	0.2200282087	False
people	0.00017648629123	0.0	0.0	0.0	0.0000000000	False
ideas	0.000136128838792	0.0	0.0	0.0	0.5270270270	False
immediately	0.000388369090992	0.0	0.0	0.0	0.0000000000	False
starting	0.0	0.0	0.0	0.0	0.0000000000	False
guess	0.00144718958832	0.0	0.0	0.0	0.5379310345	False
right	0.0	0.0	0.0	0.0	0.4747826087	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
holding	0.000760430384251	0.0	0.0	0.0	0.4105263158	False
extra	0.000333153353701	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.5021459227	False
loud	0.000287263515109	0.0	0.0	0.0	0.0000000000	False
back	0.000381160748617	0.0	0.0	0.0	0.3861386139	False
hear	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
louder	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
volume	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
testing	0.00020674136976	0.0	0.0	0.0	0.0000000000	False
great	0.000326065852029	0.0	0.0	0.0	0.0000000000	False
administrative	0.00016657667685	0.0	0.0	0.0	0.0000000000	False
wan	0.0	0.0	0.0	0.0	0.3397212544	False
today	4.28605278199e-05	0.0	0.0	0.0	0.2943396226	False
continue	3.80397931141e-05	0.0	0.0	0.0	0.0000000000	False
support	0.00175730164296	0.0	0.0	0.0	0.3004077934	False
vector	0.0031870699661	0.0	0.0	0.0	0.4246418338	False
machines	0.00080847477961	0.0	0.0	0.0	0.4401805869	False
talk	6.59260734808e-05	0.0	0.0	0.0	0.3343725643	False
optimal	0.0121476312779	0.0	0.0	0.0	0.3271622794	False
margin	0.0154116576531	0.0	0.0	0.0	0.2250977472	False
classifier	0.00175465785125	0.0	0.0	0.0	0.5652173913	False
digression	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
primal	0.00763152503365	1.0	0.0	0.0	0.3354182955	False
duo	0.0142782623679	0.0	0.0	0.0	0.2648821414	False
kkt	0.00407950353367	0.0	0.0	0.0	0.3181076672	False
conditions	0.00236572490327	0.0	0.0	0.0	0.2058366967	False
derive	0.00280461418838	0.0	0.0	0.0	0.3206691239	False
posed	0.00138688398612	0.0	0.0	0.0	0.4588235294	False
earlier	0.000200143042374	0.0	0.0	0.0	0.0000000000	False
lead	0.000465007241693	0.0	0.0	0.0	0.0000000000	False
kernels	0.00116510727298	1.0	0.0	0.0	0.0000000000	True
couple	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
words	0.000544631246279	0.0	0.0	0.0	0.4171122995	False
lecture	0.000380397931141	0.0	0.0	0.0	0.0000000000	False
part	2.74691972837e-05	0.0	0.0	0.0	0.0000000000	False
spend	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
topic	0.000289064438955	0.0	0.0	0.0	0.0000000000	False
justice	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
convex	0.00249865015275	0.0	0.0	0.0	0.4002932551	False
week	0.0	0.0	0.0	0.0	0.0000000000	False
session	0.000844474391948	0.0	0.0	0.0	0.0000000000	False
tas	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
teach	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
focus	0.000422237195974	0.0	0.0	0.0	0.0000000000	False
sort	0.000122853943631	0.0	0.0	0.0	0.5270270270	False
beautiful	0.000287263515109	0.0	0.0	0.0	0.0000000000	False
theory	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
learn	0.000254016412512	0.0	0.0	0.0	0.5270270270	False
listen	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
recap	0.000144532219478	0.0	0.0	0.0	0.0000000000	False
previous	0.000321228870142	0.0	0.0	0.0	0.5492957746	False
beginning	0.000117657527487	0.0	0.0	0.0	0.0000000000	False
developing	0.000310112054641	0.0	0.0	0.0	0.0000000000	False
hypothesis	0.000236079256748	0.0	0.0	0.0	0.0000000000	False
represented	0.000300214563561	0.0	0.0	0.0	0.2600000000	False
sub	0.0	0.0	0.0	0.0	0.0000000000	False
transpose	0.00287224963203	0.0	0.0	0.0	0.3592105263	False
depending	4.76907624383e-05	0.0	0.0	0.0	0.0000000000	False
greater	0.000955470194085	0.0	0.0	0.0	0.4698795181	False
change	0.000190580374309	0.0	0.0	0.0	0.4747826087	False
convention	0.000220920985522	0.0	0.0	0.0	0.0000000000	False
letting	4.58898385917e-05	0.0	0.0	0.0	0.4463346737	False
note	5.43443086714e-05	0.0	0.0	0.0	0.0000000000	False
labels	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
functional	0.00148074602113	0.0	0.0	0.0	0.3296305240	False
thing	0.0	0.0	0.0	0.0	0.4804031355	False
gamma	0.00601972091037	0.0	0.0	0.0	0.1539068666	False
hat	0.00422237195974	0.0	0.0	0.0	0.2410383189	False
intuition	0.000236079256748	0.0	0.0	0.0	0.0000000000	False
large	0.000266278551799	0.0	0.0	0.0	0.4171122995	False
positive	0.000532557103598	0.0	0.0	0.0	0.3644859813	False
means	5.1539013426e-05	0.0	0.0	0.0	0.3073065903	False
training	0.00236079256748	0.0	0.0	0.0	0.4572098476	False
correctly	0.000388369090992	0.0	0.0	0.0	0.0000000000	False
confidently	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
makes	0.000115370628591	0.0	0.0	0.0	0.4142640364	False
excuse	0.00107978944692	0.0	0.0	0.0	0.3929471033	False
negative	0.000773686672656	0.0	0.0	0.0	0.4357541899	False
strange	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
property	0.000300214563561	0.0	0.0	0.0	0.5416666667	False
increase	8.44922649168e-05	0.0	0.0	0.0	0.0000000000	False
parameters	0.00220493121712	0.0	0.0	0.0	0.4466330738	False
multiplying	0.00323936834077	0.0	0.0	0.0	0.3127902068	False
defined	0.00016335460655	0.0	0.0	0.0	0.3734610123	False
geometric	0.00517074327196	0.0	0.0	0.0	0.2510729614	False
essentially	4.76907624383e-05	0.0	0.0	0.0	0.0000000000	False
divided	0.00110246560856	0.0	0.0	0.0	0.2373913043	False
normal	0.00127008206256	0.0	0.0	0.0	0.2787705504	False
interpretation	0.00101172553634	0.0	0.0	0.0	0.3734610123	False
give	1.0850318616e-05	0.0	0.0	0.0	0.4105263158	False
examples	0.00141295202546	0.0	0.0	0.0	0.2610441767	False
distance	0.00186002896677	0.0	0.0	0.0	0.2671232877	False
hyperplane	0.00530335459378	0.0	0.0	0.0	0.0000000000	False
sin	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
misclassify	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
minus	0.000413008547325	0.0	0.0	0.0	0.4747826087	False
reaching	0.00020674136976	0.0	0.0	0.0	0.0000000000	False
point	2.9838376194e-05	0.0	0.0	0.0	0.5021459227	False
separating	0.00116258414005	0.0	0.0	0.0	0.3110047847	False
equation	0.000676975838574	0.0	0.0	0.0	0.4588235294	False
respect	0.00153733991538	0.0	0.0	0.0	0.3004077934	False
worst	0.000832883384251	0.0	0.0	0.0	0.4401805869	False
minimum	0.000809842085191	0.0	0.0	0.0	0.5270270270	False
algorithm	0.000274524605112	0.0	0.0	0.0	0.3979591837	False
choose	0.00110246560856	0.0	0.0	0.0	0.3391304348	False
maximize	0.00323936834077	0.0	0.0	0.0	0.4193548387	False
goal	0.000620009655591	0.0	0.0	0.0	0.0000000000	False
find	0.0002706470062	0.0	0.0	0.0	0.4345403900	False
scale	0.00233021454595	0.0	0.0	0.0	0.2827949901	False
arbitrarily	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
definition	9.17796771833e-05	0.0	0.0	0.0	0.0000000000	False
constant	0.000146995414475	0.0	0.0	0.0	0.0000000000	False
line	0.000335157690018	0.0	0.0	0.0	0.3742802303	False
plane	0.00016657667685	0.0	0.0	0.0	0.0000000000	False
straight	8.44922649168e-05	0.0	0.0	0.0	0.0000000000	False
convenient	0.000388369090992	0.0	0.0	0.0	0.0000000000	False
minute	0.00020674136976	0.0	0.0	0.0	0.0000000000	False
perfect	0.000693441993058	0.0	0.0	0.0	0.0000000000	False
constraint	0.0123266740869	0.0	0.0	0.0	0.3769187038	False
rescaling	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
easily	0.00010337068488	0.0	0.0	0.0	0.0000000000	False
meet	0.000582553636488	0.0	0.0	0.0	0.0000000000	False
add	0.000470630109947	0.0	0.0	0.0	0.3734610123	False
absolute	0.000331381478283	0.0	0.0	0.0	0.0000000000	False
value	0.000217377234686	0.0	0.0	0.0	0.2885326757	False
adding	0.000271295279185	0.0	0.0	0.0	0.0000000000	False
first	0.0	0.0	0.0	0.0	0.5416666667	False
component	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
esoteric	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
solve	0.00325554335022	0.0	0.0	0.0	0.3108631291	False
ensure	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
ability	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
break	0.000211118597987	0.0	0.0	0.0	0.0000000000	False
attempt	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
writing	0.000295485893513	0.0	0.0	0.0	0.4405315615	False
wrote	0.000516853424401	0.0	0.0	0.0	0.5342465753	False
end	6.76617515501e-05	0.0	0.0	0.0	0.4588235294	False
norm	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
equal	0.00327142220781	0.0	0.0	0.0	0.2343252986	False
big	0.000381024618769	0.0	0.0	0.0	0.2600000000	False
nice	0.000394287483879	0.0	0.0	0.0	0.4401805869	False
nasty	0.00114905406044	0.0	0.0	0.0	0.0000000000	False
nonconvex	0.00165902718123	0.0	0.0	0.0	0.3451327434	False
lie	0.000271295279185	0.0	0.0	0.0	0.0000000000	False
surface	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
unisphere	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
unicircle	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
guaranteed	0.000538546806006	0.0	0.0	0.0	0.0000000000	False
descend	0.000211118597987	0.0	0.0	0.0	0.0000000000	False
local	0.000354118885122	0.0	0.0	0.0	0.0000000000	False
out	0.0	0.0	0.0	0.0	0.3904881101	False
rid	0.000422237195974	0.0	0.0	0.0	0.0000000000	False
slightly	0.000137669515775	0.0	0.0	0.0	0.0000000000	False
subject	0.00155002413898	0.0	0.0	0.0	0.5145118734	False
objective	0.000661479365135	0.0	0.0	0.0	0.4588235294	False
previously	0.0010638191749	0.0	0.0	0.0	0.5342465753	False
confused	0.000465007241693	0.0	0.0	0.0	0.0000000000	False
questions	0.000101492627325	0.0	0.0	0.0	0.4747826087	False
statement	0.000168984529834	0.0	0.0	0.0	0.0000000000	False
made	5.88287637434e-05	0.0	0.0	0.0	0.0000000000	False
data	0.000184280915447	0.0	0.0	0.0	0.4171122995	False
wondering	0.000499730030551	0.0	0.0	0.0	0.0000000000	False
stage	0.00016657667685	0.0	0.0	0.0	0.0000000000	False
software	0.00100944542172	0.0	0.0	0.0	0.3979591837	False
imposing	0.0011557366551	0.0	0.0	0.0	0.3742802303	False
care	0.000326065852029	0.0	0.0	0.0	0.2392638037	False
sense	0.000143072287315	0.0	0.0	0.0	0.5270270270	False
order	3.338939118e-05	0.0	0.0	0.0	0.5270270270	False
mathematical	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
solvers	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
hen	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
pretend	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
independent	9.04317597285e-05	0.0	0.0	0.0	0.0000000000	False
variables	5.88287637434e-05	0.0	0.0	0.0	0.0000000000	False
limited	0.000110460492761	0.0	0.0	0.0	0.0000000000	False
bigger	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
smallest	0.000220920985522	0.0	0.0	0.0	0.0000000000	False
justin	0.0	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.4105263158	False
draw	0.000205161907068	0.0	0.0	0.0	0.0000000000	False
kind	1.12769585917e-05	0.0	0.0	0.0	0.0000000000	False
complicated	0.000168984529834	0.0	0.0	0.0	0.0000000000	False
difference	2.19753578269e-05	0.0	0.0	0.0	0.4665071770	False
repeating	8.44922649168e-05	0.0	0.0	0.0	0.0000000000	False
audio	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
catches	0.000287263515109	0.0	0.0	0.0	0.0000000000	False
answer	9.17796771833e-05	0.0	0.0	0.0	0.0000000000	False
formalization	0.00020674136976	0.0	0.0	0.0	0.0000000000	False
worst-case	0.00165902718123	0.0	0.0	0.0	0.2340936375	False
fix	0.000290132502246	0.0	0.0	0.0	0.0000000000	False
formulate	0.000999460061102	0.0	0.0	0.0	0.4588235294	False
raise	0.000271295279185	0.0	0.0	0.0	0.0000000000	False
hand	0.000209473556261	0.0	0.0	0.0	0.3255425710	False
cool	0.000883264744007	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
usual	0.000289064438955	0.0	0.0	0.0	0.5021459227	False
global	0.000333153353701	0.0	0.0	0.0	0.0000000000	False
follow	5.88287637434e-05	0.0	0.0	0.0	0.0000000000	False
fairly	0.000150107281781	0.0	0.0	0.0	0.0000000000	False
bizarre	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
assume	0.000125684133757	0.0	0.0	0.0	0.0000000000	False
purposes	0.000127008206256	0.0	0.0	0.0	0.0000000000	False
linearly	0.000388369090992	0.0	0.0	0.0	0.0000000000	False
min	0.00200667368236	0.0	0.0	0.0	0.2178770950	False
factor	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
imply	0.000620224109281	0.0	0.0	0.0	0.3255425710	False
compactly	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
minimizing	0.0021276383498	0.0	0.0	0.0	0.3127902068	False
squared	0.000273549209424	0.0	0.0	0.0	0.0000000000	False
maximum	7.88574967758e-05	0.0	0.0	0.0	0.0000000000	False
final	0.000127008206256	0.0	0.0	0.0	0.0000000000	False
picture	0.000350250324155	0.0	0.0	0.0	0.3145161290	False
mind	0.00025347679475	0.0	0.0	0.0	0.0000000000	False
quadratic	0.00115625775582	0.0	0.0	0.0	0.2472266244	False
linear	0.000760430384251	0.0	0.0	0.0	0.2829015544	False
eliminates	0.000388369090992	0.0	0.0	0.0	0.0000000000	False
half	0.000473144980655	0.0	0.0	0.0	0.2340936375	False
space	0.000529458873691	0.0	0.0	0.0	0.2600000000	False
ruling	0.000180863519457	0.0	0.0	0.0	0.0000000000	False
hope	0.000539894723461	0.0	0.0	0.0	0.4171122995	False
kinda	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
convince	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
optimum	0.000511321038248	0.0	0.0	0.0	0.0000000000	False
run	2.38453812191e-05	0.0	0.0	0.0	0.0000000000	False
convert	0.00016657667685	0.0	0.0	0.0	0.0000000000	False
throw	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
off-the-shelf	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
program	0.000108688617343	0.0	0.0	0.0	0.0000000000	False
download	0.00016657667685	0.0	0.0	0.0	0.0000000000	False
modify	0.000193421668164	0.0	0.0	0.0	0.0000000000	False
work	0.000473016090083	0.0	0.0	0.0	0.3569438918	False
declare	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
success	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
form	3.47630462957e-05	0.0	0.0	0.0	0.0000000000	False
reason	0.000137262302556	0.0	0.0	0.0	0.5270270270	False
amenable	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
efficient	0.000337969059667	0.0	0.0	0.0	0.0000000000	False
apply	0.000150107281781	0.0	0.0	0.0	0.0000000000	False
high-dimensional	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
feature	0.000820647628271	0.0	0.0	0.0	0.2161209068	False
infinite	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
dimensional	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
calculus	0.000995416308737	0.0	0.0	0.0	0.0000000000	False
remember	0.000114119379342	0.0	0.0	0.0	0.0000000000	False
method	0.000410323814136	0.0	0.0	0.0	0.2600000000	False
lagrange	0.0191736666083	0.0	0.0	0.0	0.2892784895	False
worry	0.000381024618769	0.0	0.0	0.0	0.4401805869	False
describe	9.6710834082e-05	0.0	0.0	0.0	0.0000000000	False
briefly	9.6710834082e-05	0.0	0.0	0.0	0.0000000000	False
generalization	0.000125210216925	0.0	0.0	0.0	0.4266958425	False
suppose	0.000143072287315	0.0	0.0	0.0	0.4588235294	False
vectorial	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
arrow	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
denote	0.000386843336328	0.0	0.0	0.0	0.4171122995	False
construct	0.000180863519457	0.0	0.0	0.0	0.0000000000	False
original	0.000508032825025	0.0	0.0	0.0	0.3577981651	False
highest	0.000287263515109	0.0	0.0	0.0	0.0000000000	False
call	1.356289827e-05	0.0	0.0	0.0	0.4057217165	False
partial	0.00190006738188	0.0	0.0	0.0	0.3007712082	False
theorem	0.000775012069488	0.0	0.0	0.0	0.0000000000	False
star	0.00356505551965	0.0	0.0	0.0	0.2367736340	False
backwards	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
exists	0.00025347679475	0.0	0.0	0.0	0.0000000000	False
beta	0.00485754986335	0.0	0.0	0.0	0.3812535940	False
check	0.000127008206256	0.0	0.0	0.0	0.0000000000	False
difficult	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
type	0.000117657527487	0.0	0.0	0.0	0.0000000000	False
notation	0.000506953589501	0.0	0.0	0.0	0.4171122995	False
inequality	0.00127830259562	0.0	0.0	0.0	0.4401805869	False
alpha	0.0121600974101	0.0	0.0	0.0	0.2561823802	False
theta	0.00341005310575	0.0	0.0	0.0	0.2402015677	False
subscript	0.000333153353701	0.0	0.0	0.0	0.0000000000	False
max	0.00213603000045	0.0	0.0	0.0	0.2671232877	False
refers	5.00357605935e-05	0.0	0.0	0.0	0.0000000000	False
entire	9.21404577236e-05	0.0	0.0	0.0	0.0000000000	False
version	0.00010337068488	0.0	0.0	0.0	0.0000000000	False
stands	0.00026994736173	0.0	0.0	0.0	0.0000000000	False
quantity	9.6710834082e-05	0.0	0.0	0.0	0.0000000000	False
notice	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
pick	0.000193421668164	0.0	0.0	0.0	0.0000000000	False
state	0.000354118885122	0.0	0.0	0.0	0.0000000000	False
violates	0.000620009655591	0.0	0.0	0.0	0.2943396226	False
infinity	0.00143631757554	0.0	0.0	0.0	0.1930693069	False
responding	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
gis	0.000407950353367	0.0	0.0	0.0	0.2551688040	False
similar	7.60795862282e-05	0.0	0.0	0.0	0.0000000000	False
sign	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
satisfies	0.000826277398618	0.0	0.0	0.0	0.3513513514	False
terms	0.000100007898246	0.0	0.0	0.0	0.5492957746	False
obtained	9.04317597285e-05	0.0	0.0	0.0	0.0000000000	False
left	3.4315575639e-05	0.0	0.0	0.0	0.0000000000	False
mad	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
compare	0.000220920985522	0.0	0.0	0.0	0.0000000000	False
prime	0.000359031204004	0.0	0.0	0.0	0.0000000000	False
switched	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
fact	8.22636678406e-05	0.0	0.0	0.0	0.0000000000	False
true	0.000652131704057	0.0	0.0	0.0	0.3343725643	False
concrete	0.000144532219478	0.0	0.0	0.0	0.0000000000	False
indicator	6.83873023559e-05	0.0	0.0	0.0	0.0000000000	False
specific	3.07134859079e-05	0.0	0.0	0.0	0.0000000000	False
exchange	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
put	3.47630462957e-05	0.0	0.0	0.0	0.0000000000	False
easier	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
user	0.00010337068488	0.0	0.0	0.0	0.0000000000	False
sake	0.0010226420765	0.0	0.0	0.0	0.4171122995	False
equivalent	0.00016657667685	0.0	0.0	0.0	0.0000000000	False
strategy	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
bit	7.15361436574e-05	0.0	0.0	0.0	0.0000000000	False
completeness	6.16977508804e-05	0.0	0.0	0.0	0.0000000000	False
hessian	0.000287263515109	0.0	0.0	0.0	0.0000000000	False
taught	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
interceptor	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
technically	0.000359031204004	0.0	0.0	0.0	0.0000000000	False
strictly	0.000844474391948	0.0	0.0	0.0	0.4171122995	False
feasible	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
details	4.18947112522e-05	0.0	0.0	0.0	0.0000000000	False
stricter	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
perspective	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
perform	5.00357605935e-05	0.0	0.0	0.0	0.0000000000	False
step	7.15361436574e-05	0.0	0.0	0.0	0.0000000000	False
complementary	0.00163180141347	0.0	0.0	0.0	0.4171122995	False
karush-kuhn-tucker	0.000815900706735	0.0	0.0	0.0	0.0000000000	True
authors	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
tradition	0.000287263515109	0.0	0.0	0.0	0.0000000000	False
ktt	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.3513513514	False
product	0.00125724084307	0.0	0.0	0.0	0.3397212544	False
show	2.38453812191e-05	0.0	0.0	0.0	0.0000000000	False
spelling	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
names	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
necessarily	0.00020674136976	0.0	0.0	0.0	0.0000000000	False
practice	0.000236572490327	0.0	0.0	0.0	0.0000000000	False
non-0	0.0012238510601	0.0	0.0	0.0	0.0000000000	False
active	0.000718062408008	0.0	0.0	0.0	0.4171122995	False
extend	0.000144532219478	0.0	0.0	0.0	0.0000000000	False
board	0.00059019814187	0.0	0.0	0.0	0.0000000000	False
wanted	9.6710834082e-05	0.0	0.0	0.0	0.5530562347	False
svn	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
slight	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
math	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
nicer	0.000287263515109	0.0	0.0	0.0	0.0000000000	False
rewrite	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
implications	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
basically	1.12769585917e-05	0.0	0.0	0.0	0.0000000000	False
closest	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
cartoon	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
correspond	0.00010337068488	0.0	0.0	0.0	0.0000000000	False
suggested	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
drawn	0.000110460492761	0.0	0.0	0.0	0.0000000000	False
actual	7.88574967758e-05	0.0	0.0	0.0	0.5282868526	False
one-half	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
figure	0.000117657527487	0.0	0.0	0.0	0.0000000000	False
combination	7.34977072373e-05	0.0	0.0	0.0	0.0000000000	False
input	0.000100071521187	0.0	0.0	0.0	0.0000000000	False
sum	0.00126171994841	0.0	0.0	0.0	0.2604340568	False
weights	0.000231147331019	0.0	0.0	0.0	0.0000000000	False
thought	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
plug	0.000404921042596	0.0	0.0	0.0	0.0000000000	False
deal	0.000252361355431	0.0	0.0	0.0	0.0000000000	False
expand	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
angle	0.000194184545496	0.0	0.0	0.0	0.0000000000	False
brackets	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
simplify	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
realize	0.000118039628374	0.0	0.0	0.0	0.0000000000	False
unfortunate	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
capital	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
formula	0.000289064438955	0.0	0.0	0.0	0.0000000000	False
lowercase	0.000861790545327	0.0	0.0	0.0	0.0000000000	False
uppercase	0.000407950353367	0.0	0.0	0.0	0.0000000000	False
totally	6.35041031281e-05	0.0	0.0	0.0	0.0000000000	False
standard	7.34977072373e-05	0.0	0.0	0.0	0.0000000000	False
related	0.000146995414475	0.0	0.0	0.0	0.0000000000	False
years	8.44922649168e-05	0.0	0.0	0.0	0.0000000000	False
real	4.58898385917e-05	0.0	0.0	0.0	0.0000000000	False
understand	1.42868426066e-05	0.0	0.0	0.0	0.0000000000	False
deciding	0.000108688617343	0.0	0.0	0.0	0.0000000000	False
action	0.000211118597987	0.0	0.0	0.0	0.0000000000	False
approach	0.000179515602002	0.0	0.0	0.0	0.0000000000	False
quickly	6.35041031281e-05	0.0	0.0	0.0	0.0000000000	False
easy	0.000193421668164	0.0	0.0	0.0	0.0000000000	False
found	8.44922649168e-05	0.0	0.0	0.0	0.0000000000	False
direction	0.000220920985522	0.0	0.0	0.0	0.0000000000	False
orientation	0.000211118597987	0.0	0.0	0.0	0.0000000000	False
place	0.000108688617343	0.0	0.0	0.0	0.0000000000	False
tells	7.88574967758e-05	0.0	0.0	0.0	0.0000000000	False
threshold	0.000462294662039	0.0	0.0	0.0	0.0000000000	False
clear	5.43443086714e-05	0.0	0.0	0.0	0.0000000000	False
express	0.00020674136976	0.0	0.0	0.0	0.0000000000	False
prediction	0.000378542033146	0.0	0.0	0.0	0.0000000000	False
outputs	6.83873023559e-05	0.0	0.0	0.0	0.0000000000	False
compute	0.000114294740853	0.0	0.0	0.0	0.2200282087	False
source	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
inner-dimensional	0.000815900706735	0.0	0.0	0.0	0.0000000000	False
interesting	5.00357605935e-05	0.0	0.0	0.0	0.0000000000	False
representation	8.44922649168e-05	0.0	0.0	0.0	0.0000000000	False
arbitrary	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
extremely	9.04317597285e-05	0.0	0.0	0.0	0.0000000000	False
store	9.04317597285e-05	0.0	0.0	0.0	0.0000000000	False
memory	0.000134973680865	0.0	0.0	0.0	0.0000000000	False
nonetheless	0.000255660519124	0.0	0.0	0.0	0.0000000000	False
needing	0.000179515602002	0.0	0.0	0.0	0.3007712082	False
directly	0.000126180677715	0.0	0.0	0.0	0.0000000000	False
small	3.47630462957e-05	0.0	0.0	0.0	0.0000000000	False
fraction	0.00026994736173	0.0	0.0	0.0	0.0000000000	False
close	2.72257677584e-05	0.0	0.0	0.0	0.0000000000	False
file	0.000155002413898	0.0	0.0	0.0	0.0000000000	False
behaved	0.000211118597987	0.0	0.0	0.0	0.0000000000	False
wrong	0.000110460492761	0.0	0.0	0.0	0.0000000000	False
side	5.00357605935e-05	0.0	0.0	0.0	0.0000000000	False
asks	0.000118039628374	0.0	0.0	0.0	0.4401805869	False
excellent	0.000331805436246	0.0	0.0	0.0	0.0000000000	False
assumption	0.000144532219478	0.0	0.0	0.0	0.0000000000	False
ways	3.80397931141e-05	0.0	0.0	0.0	0.5263803681	False
multiple	9.6710834082e-05	0.0	0.0	0.0	0.0000000000	False
good morning welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
reminder  i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve actually seen project	0.0	0.0	0.0	2.0	0.0000000000	False
proposals start to trickle	0.0	0.0	0.0	2.0	0.0000000000	False
great as a reminder	0.0	0.0	0.0	2.0	0.0000000000	False
chat more about project	0.0	0.0	0.0	2.0	0.0000000000	False
hours immediately after lecture	0.0	0.0	0.0	2.0	0.0000000000	False
immediately after lecture today	0.0	0.0	0.0	2.0	0.0000000000	False
started today ? great	0.0	0.0	0.0	2.0	0.0000000000	False
great okay welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
wrap up our discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on support vector	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the idea	0.0	0.0	0.0	4.0	0.0000000000	False
kernels and then talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the smo	0.0	0.0	0.0	2.0	0.0000000000	False
solving the optimization problem	0.0	0.0	1.99833147942	6.0	0.0000000000	False
problem that we posed	0.0	0.0	0.0	2.0	0.0000000000	False
last time to recap	0.0	0.0	0.0	2.0	0.0000000000	False
assuming that the data	0.0	0.0	0.0	2.0	0.0000000000	False
find the optimal margin	0.0	0.0	0.0	4.0	0.0000000000	False
classifier for the data	0.0	0.0	0.0	2.0	0.0000000000	False
data set that maximizes	0.0	0.0	0.0	2.0	0.0000000000	False
maximizes this geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin from your training	0.0	0.0	0.0	2.0	0.0000000000	False
dual of this problem	0.0	0.0	0.0	2.0	0.0000000000	False
angle brackets to denote	0.0	0.0	0.0	2.0	0.0000000000	False
transpose xj for vectors	0.0	0.0	0.0	2.0	0.0000000000	False
worked out the ways	0.0	0.0	0.0	2.0	0.0000000000	False
sum over i alpha	0.0	0.0	3.9977753059	8.0	0.4180790960	False
value of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
threshold function that outputs	0.0	0.0	0.0	2.0	0.0000000000	False
terms of inner products	0.0	0.0	2.9977753059	8.0	0.0000000000	False
products between input vectors	0.0	0.0	0.0	2.0	0.0000000000	False
property because it turns	0.0	0.0	0.0	2.0	0.0000000000	False
dependers of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
write the entire algorithm	0.0	0.0	0.0	4.0	0.0000000000	False
vector between input feature	0.0	0.0	0.0	2.0	0.0000000000	False
vectors and the idea	0.0	0.0	0.0	2.0	0.0000000000	False
area of a house	0.0	0.0	0.0	2.0	0.0000000000	False
house that you re	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to make	0.0	0.0	0.0	2.0	0.0000000000	False
ll take this feature	0.0	0.0	0.0	2.0	0.0000000000	False
richer set of features	0.0	0.0	0.0	2.0	0.0000000000	False
acutely call this mapping	0.0	0.0	0.0	2.0	0.0000000000	False
call this mapping phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi of x denote	0.0	0.0	0.0	2.0	0.0000000000	False
dimensional set of features	0.0	0.0	0.0	2.0	0.0000000000	False
back to the learning	0.0	0.0	0.0	2.0	0.0000000000	False
running a support vector	0.0	0.0	3.99833147942	6.0	0.0000000000	False
machine with the features	0.0	0.0	0.0	2.0	0.0000000000	False
features given by phi	0.0	0.0	0.0	2.0	0.0000000000	False
original one-dimensional input feature	0.0	0.0	0.0	2.0	0.0000000000	False
high degree polynomial features	0.0	0.0	0.0	2.0	0.0000000000	False
polynomial features sometimes phi	0.0	0.0	0.0	2.0	0.0000000000	False
dimensional vector of features	0.0	0.0	0.0	2.0	0.0000000000	False
question is if phi	0.0	0.0	0.0	2.0	0.0000000000	False
computers need to represent	0.0	0.0	0.0	2.0	0.0000000000	False
extremely high dimensional feature	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional feature vector	0.0	0.0	2.9977753059	8.0	0.0000000000	False
call the kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
product between those feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature vectors it turns	0.0	0.0	0.0	4.0	0.0000000000	False
special cases where computing	0.0	0.0	0.0	2.0	0.0000000000	False
cases where computing phi	0.0	0.0	0.0	2.0	0.0000000000	False
compute infinite dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
special cases where phi	0.0	0.0	0.0	2.0	0.0000000000	False
compute the inner product	0.0	0.0	6.9977753059	8.0	0.5285714286	False
two vectors very inexpensively	0.0	0.0	0.0	2.0	0.0000000000	False
idea of the support	0.0	0.0	0.0	2.0	0.0000000000	False
re going to replace	0.0	0.0	0.0	2.0	0.0000000000	False
work in feature spaces	0.0	0.0	0.0	2.0	0.0000000000	False
concrete examples of phi	0.0	0.0	0.0	2.0	0.0000000000	False
explicitly this best illustrates	0.0	0.0	0.0	2.0	0.0000000000	False
right ? x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
thing is x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
corresponds to the feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature mapping where phi	0.0	0.0	0.0	2.0	0.0000000000	False
case of n equals	0.0	0.0	0.0	2.0	0.0000000000	False
product between two vectors	0.0	0.0	3.99833147942	6.0	0.0000000000	False
elements of the vectors	0.0	0.0	0.0	4.0	0.0000000000	False
elements of this vector	0.0	0.0	2.9977753059	8.0	0.0000000000	False
times the corresponding elements	0.0	0.0	0.0	2.0	0.0000000000	False
order to compute phi	0.0	0.0	0.0	2.0	0.0000000000	False
vector of all pairs	0.0	0.0	0.0	2.0	0.0000000000	False
squared you need order	0.0	0.0	0.0	2.0	0.0000000000	False
compute the kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
kernel function is defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined as x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
ve computed this kernel	0.0	0.0	0.0	2.0	0.0000000000	False
computed this kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
vectors where each vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector has n squared	0.0	0.0	0.0	2.0	0.0000000000	False
kernel later please raise	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	0.0	2.0	0.0000000000	False
couple of quick generalizations	0.0	0.0	0.0	2.0	0.0000000000	False
equal to x transpose	0.0	0.0	0.0	2.0	0.0000000000	False
turns out to correspond	0.0	0.0	0.0	2.0	0.0000000000	False
correspond to a feature	0.0	0.0	0.0	4.0	0.0000000000	False
elements at the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
bottom where you add	0.0	0.0	0.0	2.0	0.0000000000	False
creating a feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
meaning the first order	0.0	0.0	0.0	2.0	0.0000000000	False
control the relative waiting	0.0	0.0	0.0	2.0	0.0000000000	False
features of all monomials	0.0	0.0	0.0	2.0	0.0000000000	False
terms up to degree	0.0	0.0	0.0	2.0	0.0000000000	False
implicitly construct the feature	0.0	0.0	0.0	2.0	0.0000000000	False
construct the feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
number to the power	0.0	0.0	0.0	2.0	0.0000000000	False
extremely high dimensional computing	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional computing space	0.0	0.0	0.0	2.0	0.0000000000	False
specific examples of kernels	0.0	0.0	0.0	2.0	0.0000000000	False
generally if you re	0.0	0.0	0.0	0.0	0.0000000000	False
intuition that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
feature vector of phi	0.0	0.0	0.0	2.0	0.0000000000	False
input feature vector phi	0.0	0.0	0.0	2.0	0.0000000000	False
nt as rigorous intuition	0.0	0.0	0.0	0.0	0.0000000000	False
product would be large	0.0	0.0	0.0	2.0	0.0000000000	False
large whereas in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
product may be small	0.0	0.0	0.0	2.0	0.0000000000	False
give you some random	0.0	0.0	0.0	2.0	0.0000000000	False
random thing to classify	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to classify	0.0	0.0	0.0	4.0	0.0000000000	False
thing  you re	0.0	0.0	0.0	0.0	0.0000000000	False
classify or dna sequences	0.0	0.0	0.0	2.0	0.0000000000	False
write down the function	0.0	0.0	0.0	4.0	0.0000000000	False
write down this function	0.0	0.0	0.0	2.0	0.0000000000	False
phi such that kxz	0.0	0.0	0.0	4.0	0.0000000000	False
valid kernel it turns	0.0	0.0	0.0	2.0	0.0000000000	False
part of that result	0.0	0.0	0.0	2.0	0.0000000000	False
exist some function phi	0.0	0.0	0.0	2.0	0.0000000000	False
matrix k i apologize	0.0	0.0	0.0	2.0	0.0000000000	False
apologize for overloading notation	0.0	0.0	0.0	2.0	0.0000000000	False
denote both the kernel	0.0	0.0	0.0	2.0	0.0000000000	False
find the kernel matrix	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the kernel	0.0	0.0	0.0	2.0	0.0000000000	False
two of my examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples then it turns	0.0	0.0	0.0	2.0	0.0000000000	False
transpose kz by definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of matrix multiplication	0.0	0.0	0.0	2.0	0.0000000000	False
kij is a kernel	0.0	0.0	0.0	2.0	0.0000000000	False
exist such a value	0.0	0.0	0.0	2.0	0.0000000000	False
product between two feature	0.0	0.0	0.0	2.0	0.0000000000	False
make that inner product	0.0	0.0	0.0	2.0	0.0000000000	False
sum over the elements	0.0	0.0	0.0	2.0	0.0000000000	False
denote the k element	0.0	0.0	0.0	2.0	0.0000000000	False
vector just rearrange sums	0.0	0.0	0.0	2.0	0.0000000000	False
sums you get sum	0.0	0.0	0.0	2.0	0.0000000000	False
steps and just make	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you buy	0.0	0.0	0.0	2.0	0.0000000000	False
product between the vector	0.0	0.0	0.0	2.0	0.0000000000	False
vectors is the sum	0.0	0.0	0.0	2.0	0.0000000000	False
transpose b equals sum	0.0	0.0	0.0	2.0	0.0000000000	False
make sure it makes	0.0	0.0	0.0	2.0	0.0000000000	False
definitions of a matrix	0.0	0.0	0.0	2.0	0.0000000000	False
matrix k being posisemidefinite	0.0	0.0	0.0	2.0	0.0000000000	False
posisemidefinite when a matrix	0.0	0.0	0.0	2.0	0.0000000000	False
matrix must be posisemidefinite	0.0	0.0	0.0	2.0	0.0000000000	False
out that the converse	0.0	0.0	0.0	2.0	0.0000000000	False
theorem due to mercer	0.0	0.0	0.0	2.0	0.0000000000	False
mercer kernels it means	0.0	0.0	0.0	2.0	0.0000000000	False
means the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing it just means	0.0	0.0	0.0	2.0	0.0000000000	False
phi of x transpose	0.0	0.0	0.0	4.0	0.0000000000	False
set of m examples	0.0	0.0	0.0	2.0	0.0000000000	False
means for any set	0.0	0.0	0.0	2.0	0.0000000000	False
set of m points	0.0	0.0	0.0	4.0	0.0000000000	False
necessarily a training set	0.0	0.0	0.0	2.0	0.0000000000	False
points you may choose	0.0	0.0	0.0	2.0	0.0000000000	False
true that the kernel	0.0	0.0	0.0	2.0	0.0000000000	False
proved only one direction	0.0	0.0	0.0	2.0	0.0000000000	False
direction of this result	0.0	0.0	0.0	2.0	0.0000000000	False
nt show it turns	0.0	0.0	0.0	0.0	0.0000000000	False
choose is a kernel	0.0	0.0	0.0	2.0	0.0000000000	False
functions that will fail	0.0	0.0	0.0	2.0	0.0000000000	False
conditions of this theorem	0.0	0.0	0.0	2.0	0.0000000000	False
products of a vector	0.0	0.0	0.0	2.0	0.0000000000	False
explicitly to an svm	0.0	0.0	0.0	2.0	0.0000000000	False
machine with a kernel	0.0	0.0	0.0	2.0	0.0000000000	False
turns out that function	0.0	0.0	0.0	2.0	0.0000000000	False
galceans so you choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose some kernel function	0.0	0.0	0.0	2.0	0.0000000000	False
apply a support vector	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine kernel	0.0	0.0	0.0	2.0	0.0000000000	False
depend on your problem	0.0	0.0	0.0	2.0	0.0000000000	False
back to our formulation	0.0	0.0	0.0	2.0	0.0000000000	False
formulation of support vector	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine algorithm	0.0	0.0	0.0	2.0	0.0000000000	True
ve taken a support	0.0	0.0	0.0	2.0	0.0000000000	False
machine and you ve	0.0	0.0	0.0	0.0	0.0000000000	False
infinite dimensional feature vectors	0.0	0.0	0.0	4.0	0.0000000000	False
dimensional feature vectors explicitly	0.0	0.0	0.0	2.0	0.0000000000	False
idea ? it turns	0.0	0.0	0.0	2.0	0.0000000000	False
talking about support vector	0.0	0.0	0.0	2.0	0.0000000000	False
vector machines i started	0.0	0.0	0.0	2.0	0.0000000000	False
develop non-linear learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
nt mean to draw	0.0	0.0	0.0	0.0	0.0000000000	False
takes your original input	0.0	0.0	0.0	2.0	0.0000000000	False
input data and maps	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional feature space	0.0	0.0	3.99833147942	6.0	0.0000000000	False
space in the case	0.0	0.0	0.0	2.0	0.0000000000	False
case of galcean kernels	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature space	0.0	0.0	0.0	4.0	0.0000000000	False
ll draw two dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
takes all your data	0.0	0.0	0.0	2.0	0.0000000000	False
machine in this infinite	0.0	0.0	0.0	2.0	0.0000000000	False
exponentially high dimensional space	0.0	0.0	0.0	2.0	0.0000000000	False
largest possible geometric margin	0.0	0.0	0.0	2.0	0.0000000000	False
originally one dimensional space	0.0	0.0	0.0	2.0	0.0000000000	False
classifier to which data	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machines output	0.0	0.0	0.0	2.0	0.0000000000	False
machines output nonlinear decision	0.0	0.0	0.0	2.0	0.0000000000	False
output nonlinear decision boundaries	0.0	0.0	0.0	2.0	0.0000000000	False
solve complex optimization problems	0.0	0.0	0.0	2.0	0.0000000000	False
complex optimization problems questions	0.0	0.0	0.0	2.0	0.0000000000	False
amount of your data	0.0	0.0	0.0	2.0	0.0000000000	False
thirds of your data	0.0	0.0	0.0	2.0	0.0000000000	False
data try different values	0.0	0.0	0.0	2.0	0.0000000000	False
separate hold out cross	0.0	0.0	0.0	2.0	0.0000000000	False
hold out cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation set	0.0	0.0	0.0	2.0	0.0000000000	False
set that you re	0.0	0.0	0.0	0.0	0.0000000000	False
testing something about learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms we talked	0.0	0.0	0.0	2.0	0.0000000000	False
locally linear aggressions bandwidth	0.0	0.0	0.0	2.0	0.0000000000	False
linear aggressions bandwidth parameter	0.0	0.0	0.0	2.0	0.0000000000	False
choose ids by saving	0.0	0.0	0.0	2.0	0.0000000000	False
saving aside some data	0.0	0.0	0.0	2.0	0.0000000000	False
talk more about model	0.0	0.0	0.0	2.0	0.0000000000	False
separation ? good question	0.0	0.0	0.0	2.0	0.0000000000	False
separable if you tend	0.0	0.0	0.0	2.0	0.0000000000	False
linearly separated by mapping	0.0	0.0	0.0	2.0	0.0000000000	False
mapping a higher dimension	0.0	0.0	0.0	2.0	0.0000000000	False
work with a discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion of soft margin	0.0	0.0	0.0	2.0	0.0000000000	False
run an svm algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
svm algorithm that assumes	0.0	0.0	0.0	2.0	0.0000000000	False
linearly separable on data	0.0	0.0	0.0	2.0	0.0000000000	False
separable ? you guys	0.0	0.0	0.0	2.0	0.0000000000	False
guys are really giving	0.0	0.0	0.0	2.0	0.0000000000	False
data s linearly separable	0.0	0.0	0.0	0.0	0.0000000000	False
linearly separable it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm wo nt work	0.0	0.0	0.0	0.0	0.0000000000	False
work if the data	0.0	0.0	0.0	2.0	0.0000000000	False
work if i move	0.0	0.0	0.0	2.0	0.0000000000	False
move on to talk	0.0	0.0	0.0	2.0	0.0000000000	False
final word about kernels	0.0	0.0	0.0	2.0	0.0000000000	False
kernels in a context	0.0	0.0	0.0	2.0	0.0000000000	False
context of support vector	0.0	0.0	0.0	2.0	0.0000000000	False
made support vector machines	0.0	0.0	0.0	2.0	0.0000000000	False
out that the idea	0.0	0.0	0.0	2.0	0.0000000000	False
general than support vector	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm and we derived	0.0	0.0	0.0	2.0	0.0000000000	False
entire algorithm in terms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms that you ve	0.0	0.0	0.0	0.0	0.0000000000	False
class  in fact	0.0	0.0	0.0	2.0	0.0000000000	False
linear algorithms we talked	0.0	0.0	0.0	2.0	0.0000000000	False
regression and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
means you can replace	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms and implicitly map	0.0	0.0	0.0	2.0	0.0000000000	False
implicitly map the features	0.0	0.0	0.0	2.0	0.0000000000	False
map the features vectors	0.0	0.0	0.0	2.0	0.0000000000	False
widely used with support	0.0	0.0	0.0	2.0	0.0000000000	False
write them in terms	0.0	0.0	0.0	2.0	0.0000000000	False
products and thereby kernalize	0.0	0.0	0.0	2.0	0.0000000000	False
apply them to infinite	0.0	0.0	0.0	2.0	0.0000000000	False
set let s talk	0.0	0.0	0.0	0.0	0.0000000000	False
talk about non-linear decision	0.0	0.0	0.0	2.0	0.0000000000	False
norm soft margin svm	0.0	0.0	3.99833147942	6.0	0.0000000000	False
soft margin svm machine	0.0	0.0	0.0	2.0	0.0000000000	False
svm machine only people	0.0	0.0	0.0	2.0	0.0000000000	False
nt great at coming	0.0	0.0	0.0	0.0	0.0000000000	False
linearly separable data set	0.0	0.0	0.0	4.0	0.0000000000	False
couple of other examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples there that makes	0.0	0.0	0.0	2.0	0.0000000000	False
decision boundary that separates	0.0	0.0	0.0	2.0	0.0000000000	False
linearly separate this data	0.0	0.0	0.0	2.0	0.0000000000	False
separate this data set	0.0	0.0	0.0	2.0	0.0000000000	False
slightly suspicious example skew	0.0	0.0	0.0	2.0	0.0000000000	False
skew my entire decision	0.0	0.0	0.0	2.0	0.0000000000	False
boundary by a lot	0.0	0.0	0.0	2.0	0.0000000000	False
formulation of the svm	0.0	0.0	0.0	2.0	0.0000000000	False
choose that original decision	0.0	0.0	0.0	2.0	0.0000000000	False
formulation our svm primal	0.0	0.0	0.0	2.0	0.0000000000	False
problem was to minimize	0.0	0.0	0.0	2.0	0.0000000000	False
minimize one-half w squared	0.0	0.0	0.0	2.0	0.0000000000	False
modify this by adding	0.0	0.0	0.0	2.0	0.0000000000	False
add these penalty terms	0.0	0.0	0.0	2.0	0.0000000000	False
training examples is separated	0.0	0.0	0.0	2.0	0.0000000000	False
separated with functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
equal to one minus	0.0	0.0	0.0	2.0	0.0000000000	False
misclassified it by setting	0.0	0.0	0.0	2.0	0.0000000000	False
examples with functional margin	0.0	0.0	0.0	2.0	0.0000000000	False
examples of the training	0.0	0.0	0.0	2.0	0.0000000000	False
ll encourage the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
adding to the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
sort of penalty term	0.0	0.0	0.0	2.0	0.0000000000	False
penalty term that penalizes	0.0	0.0	0.0	2.0	0.0000000000	False
term that penalizes setting	0.0	0.0	0.0	2.0	0.0000000000	False
cis to be large	0.0	0.0	0.0	4.0	0.0000000000	False
problem where the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem it turns	0.0	0.0	0.0	4.0	0.0000000000	False
dual of the support	0.0	0.0	0.0	2.0	0.0000000000	False
dual for this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
show you the steps	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective minus sum	0.0	0.0	0.0	2.0	0.0000000000	False
minus or plus alpha	0.0	0.0	0.0	2.0	0.0000000000	False
dual of this optimization	0.0	0.0	0.0	2.0	0.0000000000	False
out when you derive	0.0	0.0	0.0	2.0	0.0000000000	False
constraint that the alpha	0.0	0.0	5.99721913237	10.0	0.3752535497	False
essentially the same math	0.0	0.0	0.0	2.0	0.0000000000	False
constraints of the alphas	0.0	0.0	0.0	2.0	0.0000000000	False
out that  remember	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down the conditions	0.0	0.0	0.0	2.0	0.0000000000	False
lecture the necessary conditions	0.0	0.0	0.0	2.0	0.0000000000	False
optimal solution to constrain	0.0	0.0	0.0	2.0	0.0000000000	False
solution to constrain optimization	0.0	0.0	0.0	2.0	0.0000000000	False
solve this optimization problem	0.0	0.0	7.9977753059	8.0	0.0000000000	False
optimum ? it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out from the conditions	0.0	0.0	0.0	2.0	0.0000000000	False
conditions you can derive	0.0	0.0	0.0	2.0	0.0000000000	False
conditions for an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the alphas	0.0	0.0	0.0	2.0	0.0000000000	False
handle non-linearly separable data	0.0	0.0	0.0	2.0	0.0000000000	False
non-linearly separable data sets	0.0	0.0	0.0	2.0	0.0000000000	False
choose not to separate	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this stuff	0.0	0.0	0.0	2.0	0.0000000000	False
sense at all great	0.0	0.0	0.0	2.0	0.0000000000	False
talk about an algorithm	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm for actually solving	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem we wrote	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem with convergence	0.0	0.0	0.0	2.0	0.0000000000	False
problem with convergence criteria	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to actually solve	0.0	0.0	0.0	2.0	0.0000000000	False
give me an excuse	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm called coordinate assent	0.0	0.0	0.0	4.0	0.0000000000	False
apply in the simplest	0.0	0.0	0.0	2.0	0.0000000000	False
form to this problem	0.0	0.0	0.0	2.0	0.0000000000	False
efficient algorithm for solving	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm like the smo	0.0	0.0	0.0	2.0	0.0000000000	False
talk about coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
optimization algorithm to describe	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one through alpha	0.0	0.0	0.0	4.0	0.0000000000	False
forget about the constraint	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm it will repeat	0.0	0.0	0.0	2.0	0.0000000000	False
coordinate assent essentially holds	0.0	0.0	0.0	2.0	0.0000000000	False
holds all the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters let me write	0.0	0.0	0.0	2.0	0.0000000000	False
write that as alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i gets updated	0.0	0.0	0.0	2.0	0.0000000000	False
updated as over alpha	0.0	0.0	0.0	2.0	0.0000000000	False
hat of w alpha	0.0	0.0	0.0	2.0	0.0000000000	False
hold everything except alpha	0.0	0.0	0.0	2.0	0.0000000000	False
optimize w by optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective with respect	0.0	0.0	0.0	2.0	0.0000000000	False
respect to only alpha	0.0	0.0	0.0	2.0	0.0000000000	False
fancy way of writing	0.0	0.0	0.0	2.0	0.0000000000	False
coordinate assent one picture	0.0	0.0	0.0	2.0	0.0000000000	False
picture that s kind	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to optimize	0.0	0.0	0.0	4.0	0.0000000000	False
optimize a quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
function and the minimums	0.0	0.0	0.0	2.0	0.0000000000	False
ll call this alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one my alpha	0.0	0.0	0.0	2.0	0.0000000000	False
minimizing this with respect	0.0	0.0	0.0	2.0	0.0000000000	False
ll minimize with respect	0.0	0.0	0.0	4.0	0.0000000000	False
taking these axis-aligned steps	0.0	0.0	0.0	2.0	0.0000000000	False
order we always optimize	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one then alpha	0.0	0.0	0.0	2.0	0.0000000000	False
choose to always visit	0.0	0.0	0.0	2.0	0.0000000000	False
order you may choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose which alphas update	0.0	0.0	0.0	2.0	0.0000000000	False
alphas update next depending	0.0	0.0	0.0	2.0	0.0000000000	False
make the most progress	0.0	0.0	0.0	2.0	0.0000000000	False
makes sense to alternate	0.0	0.0	0.0	2.0	0.0000000000	False
progress towards the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out that coordinate assent	0.0	0.0	0.0	4.0	0.0000000000	False
advantage of coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
assent when it works	0.0	0.0	0.0	2.0	0.0000000000	False
optimize w with respect	0.0	0.0	2.99833147942	6.0	0.0000000000	False
group of coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
coordinate assent with optimizing	0.0	0.0	0.0	2.0	0.0000000000	False
true when we modify	0.0	0.0	0.0	2.0	0.0000000000	False
solve the svm optimization	0.0	0.0	0.0	2.0	0.0000000000	False
svm optimization problem questions	0.0	0.0	0.0	2.0	0.0000000000	False
vector machine dual optimization	0.0	0.0	0.0	2.0	0.0000000000	False
machine dual optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
form does not work	0.0	0.0	0.0	2.0	0.0000000000	False
constrains on the alpha	0.0	0.0	0.0	2.0	0.0000000000	False
constraint that the sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum of y alpha	0.0	0.0	0.0	2.0	0.0000000000	False
fix all the alphas	0.0	0.0	0.0	2.0	0.0000000000	False
nt change one alpha	0.0	0.0	0.0	0.0	0.0000000000	False
determined as a function	0.0	0.0	0.0	2.0	0.0000000000	False
due to john platt	0.0	0.0	0.0	2.0	0.0000000000	False
microsoft the smo algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization and the term	0.0	0.0	0.0	2.0	0.0000000000	False
refers to the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that we re	0.0	0.0	0.0	0.0	0.0000000000	False
choosing the smallest number	0.0	0.0	0.0	2.0	0.0000000000	False
smallest number of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha is to change	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm we will select	0.0	0.0	0.0	2.0	0.0000000000	False
two alphas to change	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i and alpha	0.0	0.0	8.99388209121	22.0	0.2574320051	False
thumb we ll hold	0.0	0.0	0.0	0.0	0.0000000000	False
hold all the alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha j and optimize	0.0	0.0	0.0	2.0	0.0000000000	False
out the key step	0.0	0.0	0.0	2.0	0.0000000000	False
optimize w of alpha	0.0	0.0	0.0	4.0	0.0000000000	False
subject to the constraints	0.0	0.0	0.0	2.0	0.0000000000	False
satisfied these convergence criteria	0.0	0.0	0.0	2.0	0.0000000000	False
criteria up to epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
efficiently that the smo	0.0	0.0	0.0	2.0	0.0000000000	False
large number of iterations	0.0	0.0	0.0	2.0	0.0000000000	False
iteration is very cheap	0.0	0.0	0.0	2.0	0.0000000000	False
cheap let s talk	0.0	0.0	0.0	0.0	0.0000000000	False
step where we update	0.0	0.0	0.0	2.0	0.0000000000	False
alpha one and alpha	0.0	0.0	11.9949944383	18.0	0.3019038985	False
notation on the board	0.0	0.0	0.0	2.0	0.0000000000	False
analogous on every step	0.0	0.0	0.0	2.0	0.0000000000	False
step of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem this means	0.0	0.0	0.0	2.0	0.0000000000	False
constraints on our dual	0.0	0.0	0.0	2.0	0.0000000000	False
constraint that the values	0.0	0.0	0.0	2.0	0.0000000000	False
alpha two must lie	0.0	0.0	0.0	2.0	0.0000000000	False
lie within this box	0.0	0.0	0.0	2.0	0.0000000000	False
picture of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
two y2 must equal	0.0	0.0	0.0	2.0	0.0000000000	False
equal to zeta minus	0.0	0.0	0.0	4.0	0.0000000000	False
plug in my definition	0.0	0.0	0.0	2.0	0.0000000000	False
alphas  it turns	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic function of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
two if you hold	0.0	0.0	0.0	2.0	0.0000000000	False
simplified to some expression	0.0	0.0	0.0	2.0	0.0000000000	False
expression of the form	0.0	0.0	0.0	2.0	0.0000000000	False
squared plus b alpha	0.0	0.0	0.0	2.0	0.0000000000	False
high school or undergrad	0.0	0.0	0.0	2.0	0.0000000000	False
optimal value for alpha	0.0	0.0	0.0	2.0	0.0000000000	False
value for alpha two	0.0	0.0	0.0	2.0	0.0000000000	False
two the last step	0.0	0.0	0.0	2.0	0.0000000000	False
step with a bosk	0.0	0.0	0.0	2.0	0.0000000000	False
lie on this line	0.0	0.0	0.0	4.0	0.0000000000	False
ll be some sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
function over this line	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
lies in the box	0.0	0.0	0.0	2.0	0.0000000000	False
optimize your quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
solution just to map	0.0	0.0	0.0	2.0	0.0000000000	False
map it back inside	0.0	0.0	0.0	2.0	0.0000000000	False
back inside the box	0.0	0.0	0.0	2.0	0.0000000000	False
box that ll give	0.0	0.0	0.0	0.0	0.0000000000	False
quadratic optimization problem subject	0.0	0.0	0.0	2.0	0.0000000000	False
subject to your solution	0.0	0.0	0.0	2.0	0.0000000000	False
solution satisfying this box	0.0	0.0	0.0	2.0	0.0000000000	False
satisfying this box constraint	0.0	0.0	0.0	2.0	0.0000000000	False
box constraint and lying	0.0	0.0	0.0	2.0	0.0000000000	False
subject to the solution	0.0	0.0	0.0	2.0	0.0000000000	False
segment within the box	0.0	0.0	0.0	2.0	0.0000000000	False
back within the box	0.0	0.0	0.0	2.0	0.0000000000	False
makes the inner loop	0.0	0.0	0.0	2.0	0.0000000000	False
loop of the smo	0.0	0.0	0.0	2.0	0.0000000000	False
smo algorithm very efficient	0.0	0.0	0.0	2.0	0.0000000000	False
talking about ascent suppose	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum from i equals	0.0	0.0	0.0	4.0	0.0000000000	False
two to m alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha i yi divided	0.0	0.0	0.0	2.0	0.0000000000	False
alpha four through alpha	0.0	0.0	0.0	2.0	0.0000000000	False
choose to change alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha two must satisfy	0.0	0.0	0.0	2.0	0.0000000000	False
satisfy that linear constraint	0.0	0.0	0.0	2.0	0.0000000000	False
two accordingly to make	0.0	0.0	0.0	2.0	0.0000000000	False
make sure this satisfies	0.0	0.0	0.0	2.0	0.0000000000	False
setting of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to talk	0.0	0.0	0.0	0.0	0.0000000000	False
ll say a couple	0.0	0.0	0.0	2.0	0.0000000000	False
outline of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
iteration of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
re going to select	0.0	0.0	0.0	2.0	0.0000000000	False
alpha j to update	0.0	0.0	0.0	4.0	0.0000000000	False
procedure i just described	0.0	0.0	0.0	2.0	0.0000000000	False
described to actually update	0.0	0.0	0.0	2.0	0.0000000000	False
alpha is that function	0.0	0.0	0.0	2.0	0.0000000000	False
function we had previously	0.0	0.0	0.0	2.0	0.0000000000	False
previously w of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
alpha was the sum	0.0	0.0	0.0	2.0	0.0000000000	False
problem for the svm	0.0	0.0	0.0	2.0	0.0000000000	False
farther from its optimal	0.0	0.0	0.0	2.0	0.0000000000	False
optimal let me translate	0.0	0.0	0.0	2.0	0.0000000000	False
differently what we re	0.0	0.0	0.0	0.0	0.0000000000	False
optimize the objective function	0.0	0.0	0.0	2.0	0.0000000000	False
function w of alpha	0.0	0.0	0.0	2.0	0.0000000000	False
progress that we care	0.0	0.0	0.0	2.0	0.0000000000	False
true for coordinate assent	0.0	0.0	0.0	2.0	0.0000000000	False
assent and for smo	0.0	0.0	0.0	2.0	0.0000000000	False
alpha can only increase	0.0	0.0	0.0	2.0	0.0000000000	False
increase it may stay	0.0	0.0	0.0	2.0	0.0000000000	False
converge at some value	0.0	0.0	0.0	2.0	0.0000000000	False
true that in intervening	0.0	0.0	0.0	2.0	0.0000000000	False
true just a couple	0.0	0.0	0.0	2.0	0.0000000000	False
smo before i wrap	0.0	0.0	0.0	2.0	0.0000000000	False
platt s original algorithm	0.0	0.0	0.0	0.0	0.0000000000	False
john platt s paper	0.0	0.0	0.0	0.0	0.0000000000	False
paper on the smo	0.0	0.0	0.0	2.0	0.0000000000	False
pretty easy to read	0.0	0.0	0.0	2.0	0.0000000000	False
readings in more details	0.0	0.0	0.0	2.0	0.0000000000	False
details one other thing	0.0	0.0	0.0	2.0	0.0000000000	False
solving all your alphas	0.0	0.0	0.0	2.0	0.0000000000	False
ll let you read	0.0	0.0	0.0	2.0	0.0000000000	False
briefly about a couple	0.0	0.0	0.0	2.0	0.0000000000	False
handler s integer recognition	0.0	0.0	0.0	0.0	0.0000000000	False
integer recognition in handler	0.0	0.0	0.0	2.0	0.0000000000	False
re given a pixel	0.0	0.0	0.0	2.0	0.0000000000	False
array with a scanned	0.0	0.0	0.0	2.0	0.0000000000	False
code somewhere in britain	0.0	0.0	0.0	2.0	0.0000000000	False
character one the question	0.0	0.0	0.0	2.0	0.0000000000	False
ten pixels by ten	0.0	0.0	0.0	4.0	0.0000000000	False
pixels by ten pixels	0.0	0.0	0.0	4.0	0.0000000000	False
hundred dimensional feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
binary features of xb01	0.0	0.0	0.0	2.0	0.0000000000	False
out for many years	0.0	0.0	0.0	2.0	0.0000000000	False
champion algorithm for handler	0.0	0.0	0.0	2.0	0.0000000000	False
recognition and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
writing down this kernel	0.0	0.0	0.0	2.0	0.0000000000	False
neuronetworks this is surprising	0.0	0.0	0.0	2.0	0.0000000000	False
surprising because support vector	0.0	0.0	0.0	2.0	0.0000000000	False
nt take into account	0.0	0.0	0.0	0.0	0.0000000000	False
knowledge about the pixels	0.0	0.0	0.0	2.0	0.0000000000	False
representing the pixel intensity	0.0	0.0	0.0	2.0	0.0000000000	False
value as a vector	0.0	0.0	0.0	2.0	0.0000000000	False
shuffle all the pixels	0.0	0.0	0.0	2.0	0.0000000000	False
development for many years	0.0	0.0	0.0	2.0	0.0000000000	False
sequences into different classes	0.0	0.0	0.0	2.0	0.0000000000	False
biologists in the room	0.0	0.0	0.0	2.0	0.0000000000	False
proteins in our bodies	0.0	0.0	0.0	2.0	0.0000000000	False
made up by sequences	0.0	0.0	0.0	2.0	0.0000000000	False
sequences of amino acids	0.0	0.0	0.0	4.0	0.0000000000	False
acids by the alphabet	0.0	0.0	0.0	2.0	0.0000000000	False
apologizes to the biologists	0.0	0.0	0.0	2.0	0.0000000000	False
amino acid sequence represented	0.0	0.0	0.0	2.0	0.0000000000	False
represented by a series	0.0	0.0	0.0	2.0	0.0000000000	False
depending on what type	0.0	0.0	0.0	2.0	0.0000000000	False
construct my feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
challenging for many reasons	0.0	0.0	0.0	2.0	0.0000000000	False
nt have a feature	0.0	0.0	0.0	0.0	0.0000000000	False
position in this protein	0.0	0.0	0.0	2.0	0.0000000000	False
combinations of four alphabets	0.0	0.0	0.0	4.0	0.0000000000	False
aaac down to aaaz	0.0	0.0	0.0	2.0	0.0000000000	False
aaaz and then aaba	0.0	0.0	0.0	2.0	0.0000000000	False
alphabets and my feature	0.0	0.0	0.0	2.0	0.0000000000	False
scan through this sequence	0.0	0.0	0.0	2.0	0.0000000000	False
amino acids and count	0.0	0.0	0.0	2.0	0.0000000000	False
feature representation for protein	0.0	0.0	0.0	2.0	0.0000000000	False
protein this representation applies	0.0	0.0	0.0	2.0	0.0000000000	False
representation applies no matter	0.0	0.0	0.0	2.0	0.0000000000	False
long my protein sequence	0.0	0.0	0.0	2.0	0.0000000000	False
160,000 dimensional feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
dimensional feature vectors imagine	0.0	0.0	0.0	2.0	0.0000000000	False
examples and you store	0.0	0.0	0.0	2.0	0.0000000000	False
efficient dynamic programming algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
efficiently compute inner products	0.0	0.0	0.0	2.0	0.0000000000	False
products between these feature	0.0	0.0	0.0	2.0	0.0000000000	False
apply this feature representation	0.0	0.0	0.0	2.0	0.0000000000	False
ridiculously high feature vector	0.0	0.0	0.0	2.0	0.0000000000	False
feature vector to classify	0.0	0.0	0.0	2.0	0.0000000000	False
vector to classify protein	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for finding subsequences	0.0	0.0	0.0	2.0	0.0000000000	False
choose a standard kernel	0.0	0.0	0.0	2.0	0.0000000000	False
problem two last sentences	0.0	0.0	0.0	2.0	0.0000000000	False
effective off the shelf	0.0	0.0	0.0	2.0	0.0000000000	False
lot of learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
class by saying congrats	0.0	0.0	0.0	2.0	0.0000000000	False
re now well qualified	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms to a lot	0.0	0.0	0.0	2.0	0.0000000000	False
re still in week	0.0	0.0	0.0	2.0	0.0000000000	False
four of the quarter	0.0	0.0	0.0	2.0	0.0000000000	False
understand the learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
morning welcome back	0.000797923784772	0.0	0.0	0.0	0.0000000000	False
end of class	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
project proposals start	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
start to trickle	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
proposals are due	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
due this friday	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
meet and chat	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
immediately after lecture	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
today ? great	0.0	0.0	0.0	0.0	0.0000000000	False
today is wrap	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
discussion on support	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.0115150547778	1.0	17.989432703	28.529325013	0.4135855546	True
ll also talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea of kernels	0.00517787123339	0.0	2.99721913237	7.92481250361	0.4180790960	False
algorithm for solving	0.00207114849336	0.0	0.0	1.58496250072	0.0000000000	False
solving the optimization	0.00310672274003	0.0	1.99833147942	0.0	0.0000000000	False
context optimization problem	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
find the optimal	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
optimal margin classifier	0.00207114849336	0.0	0.0	3.16992500144	0.0000000000	False
set that maximizes	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
maximizes this geometric	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
derived the dual	0.00509289883434	0.0	5.9977753059	6.33985000288	0.4180790960	False
primal optimization problem	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
brackets to denote	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
denote inner product	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out the ways	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
make a prediction	0.00131781435256	0.0	0.0	3.16992500144	0.0000000000	False
prediction of classification	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
compute the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
function that outputs	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
written in terms	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
products between input	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
products in fact	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
write the entire	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
vector between input	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
input feature vectors	0.00310672274003	0.0	2.99833147942	3.16992500144	0.0000000000	False
set of features	0.00121211102925	0.0	0.0	1.58496250072	0.0000000000	False
four polynomial features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
call this mapping	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
ll let phi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
denote the mapping	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
higher dimensional set	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
product between phi	0.00636612354292	0.0	6.99721913237	7.92481250361	0.4415274463	False
corresponds to running	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
running a support	0.00381967412575	0.0	3.99833147942	0.0	0.0000000000	False
original one-dimensional input	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
one-dimensional input feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
fact sometimes phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
high degree polynomial	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
degree polynomial features	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
features sometimes phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
infinite dimensional vector	0.00268967291455	0.0	2.99833147942	3.16992500144	0.0000000000	False
vector of features	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
extremely high dimensional	0.00310672274003	0.0	3.99833147942	3.16992500144	0.0000000000	False
nt actually compute	0.0	0.0	0.0	0.0	0.0000000000	False
high dimensional feature	0.00724901972675	0.0	5.99610678532	7.92481250361	0.4769797422	False
dimensional feature vector	0.00828459397342	0.0	5.99555061179	11.094737505	0.5362318841	False
inefficient it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
important special cases	0.00381967412575	0.0	2.99833147942	4.75488750216	0.0000000000	False
call the kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vectors it turns	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
cases where computing	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
computationally very expensive	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
nt compute infinite	0.0	0.0	0.0	0.0	0.0000000000	False
compute infinite dimensional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
cases where phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
expensive to represent	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
compute a kernel	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vectors very inexpensively	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
lets you work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
work in feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
feature spaces phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
bit later today	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
examples of phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
constructing kernels explicitly	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
save on writing	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
equals x transpose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
transpose z squared	0.00381967412575	0.0	5.99833147942	4.75488750216	0.0000000000	False
mapping where phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
definition of phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
elements of phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
order to compute	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
length of phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
order n squared	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
compute the kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
function is defined	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
computed this kernel	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
kernel you find	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
raise your hand	0.000902178372964	0.0	0.0	3.16992500144	0.0000000000	False
describe a couple	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
couple of quick	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
kernel in order	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out to correspond	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
creating a feature	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
meaning the first	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
first order terms	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
control the relative	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
product between vectors	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vectors of length	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
length and square	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
square in order	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
examples of kernels	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
construct the feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
re implicitly working	0.0	0.0	0.0	1.58496250072	0.0000000000	False
high dimensional computing	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
dimensional computing space	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
set of attributes	0.00207114849336	0.0	0.0	3.16992500144	0.0000000000	False
vector of phi	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
feature vector phi	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
kernel is computing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt as rigorous	0.0	0.0	0.0	0.0	0.0000000000	False
pointing different directions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
small that intuition	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
thing to classify	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
learn the algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
similar and small	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt always true	0.0	0.0	0.0	0.0	0.0000000000	False
classify some brand	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
brand new thing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
classify or dna	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
answers the question	0.000658907176278	0.0	0.0	1.58496250072	0.0000000000	False
similar or dissimilar	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
exist some phi	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
kxz is equal	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kernel it turns	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
result that characterizes	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
result now suppose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
exist some function	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
set of points	0.000658907176278	0.0	0.0	1.58496250072	0.0000000000	False
define a matrix	0.0	0.0	0.0	1.58496250072	0.0000000000	False
apologize for overloading	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
nt enough alphabets	0.0	0.0	0.0	0.0	0.0000000000	False
find the kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
kernel function applied	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
definition of matrix	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
valid kernel function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
value for phi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two feature vectors	0.0	0.0	0.0	1.58496250072	0.0000000000	False
product the explicit	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
phi xi subscript	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vector just rearrange	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
sum of squares	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
transpose b equals	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
makes sense questions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
posisemidefinite it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
due to mercer	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
kernels it means	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
exists a phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kxz equals phi	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
necessarily a training	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
choose it holds	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
result i proved	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
show it turns	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
kernel a concrete	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
find an input	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
possibly be equal	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
examples of functions	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
fail to meet	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
meet the conditions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
tie this back	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose some function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out that function	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
function i wrote	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
similarity to galceans	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose some kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
choose x transpose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
vector to apply	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
apply a support	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
vector machine kernel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
problem it depends	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
two examples similar	0.0	0.0	0.0	1.58496250072	0.0000000000	False
formulation of support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vector machine algorithm	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
galcean kernel corresponds	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional nonetheless	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
working with infinite	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.00288566969728	0.0	5.9977753059	3.16992500144	0.4180790960	False
compute these things	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
represent these infinite	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
feature vectors explicitly	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
started off talking	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
talking about support	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
machines i started	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
wanted to start	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
start to develop	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
develop non-linear learning	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
non-linear learning algorithms	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
draw that slanted	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
one-dimensional input data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
takes your original	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
original input data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
data and maps	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
dimensional feature space	0.00360708712161	0.0	5.99721913237	4.75488750216	0.0000000000	False
case of galcean	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
draw two dimensions	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
infinite dimensional space	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
exponentially high dimensional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
high dimensional space	0.00310672274003	0.0	3.99833147942	3.16992500144	0.0000000000	False
classifier that separates	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
separates your data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
largest possible geometric	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
originally one dimensional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
higher dimensional space	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
vector machines output	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
machines output nonlinear	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
output nonlinear decision	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
nonlinear decision boundaries	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
solve complex optimization	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
complex optimization problems	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
optimization problems questions	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
sigmer is save	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
values of sigmer	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
sigmer and train	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
train an svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
hold out cross	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
out cross validation	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
cross validation set	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
algorithms we talked	0.00179311527637	0.0	0.0	1.58496250072	0.0000000000	False
locally linear aggressions	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
linear aggressions bandwidth	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
aggressions bandwidth parameter	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
number of parameters	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
ids by saving	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
data to test	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
model selection explicitly	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kind of separation	0.0	0.0	0.0	1.58496250072	0.0000000000	False
separation ? good	0.0	0.0	0.0	0.0	0.0000000000	False
svms that work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
tend linearly separated	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
separated by mapping	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
mapping a higher	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
address that work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
discussion of soft	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
soft margin svms	0.00509289883434	0.0	4.9977753059	3.16992500144	0.0000000000	False
run an svm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
algorithm that assumes	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
assumes the data	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
separable on data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
separable it turns	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
out this algorithm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
make it work	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
word about kernels	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
talked about kernels	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
context of support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
made support vector	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
powerful learning algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
end of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
ll actually give	0.0	0.0	0.0	1.58496250072	0.0000000000	False
give a couple	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
couple more examples	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
general than support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
derived a dual	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm in terms	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
algorithms and rewrite	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
rewrite in terms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
map the features	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
algorithm still work	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
work the idea	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
talk about non-linear	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
non-linear decision boundaries	0.00127322470858	1.0	0.0	1.58496250072	0.0000000000	False
norm soft margin	0.00381967412575	0.0	3.99833147942	0.0	0.0000000000	False
margin svm machine	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
machine only people	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
great at coming	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
linearly separable data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
separable data set	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
makes the data	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
data non-linearly separable	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nice data set	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
great decision boundary	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
boundary that separates	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
separate this data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
suspicious example skew	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
skew my entire	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
entire decision boundary	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
slightly modified formulation	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
svm optimization problem	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
prefer to choose	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose that original	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
original decision boundary	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
formulation our svm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
svm primal problem	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
one-half w squared	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
add these penalty	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
examples is separated	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
separated with functional	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
functional margin greater	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
margin is greater	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
implies you classified	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
classified it correctly	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
examples with functional	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
functional margin negative	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
allowing my algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to misclassify	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
encourage the algorithm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
sort of penalty	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
term that penalizes	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
penalizes setting cis	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization problem	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
problem it turns	0.00159584756954	0.0	0.0	0.0	0.0000000000	False
out that similar	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out the dual	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
denote the multipliers	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
set of constraints	0.00207114849336	0.0	0.0	3.16992500144	0.0000000000	False
optimization objective minus	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
objective minus sum	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
greater or equal	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
redivide the entire	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
dual changes compared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha are greater	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt very hard	0.0	0.0	0.0	0.0	0.0000000000	False
solution to constrain	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
constrain optimization problems	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
derive conversions conditions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
solve this optimization	0.00358623055274	0.0	7.9977753059	0.0	0.4180790960	False
alphas have converged	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem in terms	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
change the algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that lets	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
lets us handle	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
handle non-linearly separable	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
non-linearly separable data	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
stuff makes sense	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem we wrote	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
dual optimization problem	0.00381967412575	0.0	2.99833147942	3.16992500144	0.0000000000	False
problem with convergence	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
partly to give	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
excuse to talk	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm called coordinate	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
apply an algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
talk about coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
algorithm to describe	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
describe coordinate assent	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
maximize some function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
function of alpha	0.00621344548007	0.0	7.99666295884	7.92481250361	0.4605809129	False
coordinate assent algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
repeat until convergence	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
assent essentially holds	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
parameters except alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha i fixed	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
maximizes this function	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
function with respect	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
alpha i hat	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha one alpha	0.00509289883434	0.0	0.0	3.16992500144	0.0000000000	False
alpha i minus	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
fixed just optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
objective with respect	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
assent one picture	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
optimize a quadratic	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
call this alpha	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
alpha two axis	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
begin by minimizing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
respect to alpha	0.0127322470858	0.0	11.9944382647	15.8496250072	0.3195164076	False
minimize with respect	0.00207114849336	0.0	0.0	0.0	0.0000000000	False
back to alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
re always taking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
taking these axis-aligned	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
minimum it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
describe the algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
optimize with respect	0.00381967412575	0.0	2.99833147942	4.75488750216	0.0000000000	False
lot of parameters	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose which alphas	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
update next depending	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
sense to alternate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
higher dimensional parameters	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose to update	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
make faster progress	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
maximum it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out that coordinate	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
coordinate assent compared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
previously  compared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
lot more steps	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
advantage of coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
inexpensive to optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
method in order	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
order to converge	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
converge it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
easy to fix	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
parameters and optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
group of coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
assent with optimizing	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
modify this algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to solve	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
solve the svm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vector machine dual	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
machine dual optimization	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
reason the reason	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
change one alpha	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
alpha without violating	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
violating the constraint	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
due to john	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
colleague at microsoft	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
microsoft the smo	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
change two alphas	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sense the sequential	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sequential minimal optimization	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
term minimal refers	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choosing the smallest	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
number of alpha	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
outline the algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
select two alphas	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas to change	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
means a rule	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
rule of thumb	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
alpha ks fixed	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
fixed except alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
optimize w alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha with respect	0.00381967412575	0.0	3.99833147942	4.75488750216	0.0000000000	False
alpha j subject	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
constraints it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
out the key	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
chose to update	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
update and subject	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
running this algorithm	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
satisfied these convergence	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
smo algorithm works	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
number of iterations	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
iterations to converge	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
order to derive	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
derive that step	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
update in respect	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
two in general	0.0	0.0	0.0	1.58496250072	0.0000000000	False
make my notation	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
derive the derivation	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
derivation for alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
general completely analogous	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm with respect	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
respect to constraint	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem this means	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
means that alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
denote by zeta	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
values of alpha	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
two must lie	0.0	0.0	0.0	0.0	0.0000000000	False
box that ranges	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
constraint that alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
equal to zeta	0.00381967412575	0.0	5.99833147942	1.58496250072	0.0000000000	False
implies that alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
zeta minus alpha	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
optimize the objective	0.00254644941717	0.0	0.0	1.58496250072	0.0000000000	False
definition for alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
dimensional quadratic function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
form a alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alpha two squared	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
standard quadratic function	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
easy to optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
school or undergrad	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
optimize quadratic functions	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
value for alpha	0.0	0.0	0.0	0.0	0.0000000000	False
two the last	0.0	0.0	0.0	0.0	0.0000000000	False
solution must lie	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sort of quadratic	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
minimize the quadratic	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
value that lies	0.0	0.0	0.0	1.58496250072	0.0000000000	False
optimize your quadratic	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
clip your solution	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
inside the box	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
box that ll	0.0	0.0	0.0	0.0	0.0000000000	False
quadratic optimization problem	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
optimization problem subject	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
satisfying this box	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
constraint and lying	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
box having solved	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
solved the alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm very efficient	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
efficient you mentioned	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
understand that right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
run optimization algorithm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
respect the constraint	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
constraint that sum	0.00207114849336	0.0	0.0	1.58496250072	0.0000000000	False
talking about ascent	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
change just alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
four through alpha	0.0	0.0	0.0	0.0	0.0000000000	False
alpha m fixed	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt change alpha	0.0	0.0	0.0	0.0	0.0000000000	False
choose to change	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
two must satisfy	0.0	0.0	0.0	0.0	0.0000000000	False
satisfy that linear	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
satisfies the constraint	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
zeta was defined	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
validated the constraint	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
equal to sum	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
pair of alphas	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas to update	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
couple more words	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
select some alpha	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
procedure to optimize	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
nt actually talk	0.0	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
alpha ? exchanging	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas  optimizing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
translate it differently	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
metric of progress	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
true for coordinate	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
nt get worse	0.0	0.0	0.0	0.0	0.0000000000	False
alphas will converge	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
alphas may move	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
words on smo	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
platt s original	0.0	0.0	0.0	0.0	0.0000000000	False
original algorithm talked	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choosing which values	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
values or pairs	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
complicated to explain	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
explain in words	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
platt s paper	0.0	0.0	0.0	0.0	0.0000000000	False
easy to read	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
ll also posting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
posting a handout	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
update the parameter	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
compute the parameter	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problems to wrap	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
wrap up today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
couple of examples	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
examples of applications	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
applications of svms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	True
problem of handler	0.0	0.0	0.0	1.58496250072	0.0000000000	False
handler s integer	0.0	0.0	0.0	0.0	0.0000000000	False
recognition in handler	0.0	0.0	0.0	0.0	0.0000000000	False
array of pixels	0.000896557638184	0.0	0.0	1.58496250072	0.0000000000	False
combination of pixels	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
represents the character	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
pixels by ten	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
hundred dimensional feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
features of xb01	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
gray scale values	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for handler	0.0	0.0	0.0	0.0	0.0000000000	False
apply an svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
galcean kernel works	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
kernel and throwing	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
throwing an svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
svm gave performance	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
gave performance comparable	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
surprising because support	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
account any knowledge	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
representing the pixel	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
pixel intensity value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
means the performance	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
performance of svm	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
fairly esoteric objects	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
classify protein sequences	0.00254644941717	0.0	0.0	3.16992500144	0.0000000000	False
classes of proteins	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
suspect that biologists	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
bodies are made	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
sequences of amino	0.00254644941717	0.0	0.0	0.0	0.0000000000	False
denote amino acids	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
amino acid sequence	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
acid sequence represented	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
series of alphabets	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
assign this protein	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
type of protein	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
construct my feature	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
long protein sequences	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
write down aaaa	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
acids and count	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
representation for protein	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
protein this representation	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
applies no matter	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
matter how long	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
long my protein	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
160,000 dimensional feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
modern computer standards	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
represent these high	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
feature vectors imagine	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
modern day computers	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
big it turns	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
efficient dynamic programming	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
dynamic programming algorithm	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
compute inner products	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
apply this feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
ridiculously high feature	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
high feature vector	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
vector to classify	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
algorithm for finding	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
kind of reminiscent	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
choose a standard	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
research papers written	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
problem two last	0.0	0.0	0.0	0.0	0.0000000000	False
two last sentences	0.0	0.0	0.0	0.0	0.0000000000	False
wraps up svms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
shelf learning algorithms	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
lot of learning	0.000896557638184	0.0	0.0	0.0	0.0000000000	False
close this class	0.00127322470858	0.0	0.0	1.58496250072	0.0000000000	False
congrats you re	0.0	0.0	0.0	0.0	0.0000000000	False
apply learning algorithms	0.000797923784772	0.0	0.0	1.58496250072	0.0000000000	False
lot of problems	0.00103557424668	0.0	0.0	1.58496250072	0.0000000000	False
problems we re	0.0	0.0	0.0	0.0	0.0000000000	False
understand the learning	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
good morning	0.000300726124321	0.0	0.0	0.0	0.0000000000	False
quick reminder	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
project proposals	0.000961889899095	0.0	0.0	1.0	0.0000000000	False
proposals start	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
project ideas	0.000597705092123	0.0	0.0	1.0	0.0000000000	False
office hours	0.000597705092123	0.0	0.0	1.0	0.0000000000	False
lecture today	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
started today	0.0	0.0	0.0	0.0	0.0000000000	False
support vector	0.00767670318522	0.0	17.989432703	17.0	0.3262180974	False
vector machines	0.00767670318522	0.0	17.989432703	17.0	0.4135855546	False
smo algorithm	0.0084881647239	0.0	10.9944382647	9.0	0.3296213808	True
optimization problem	0.0101032433696	0.0	22.9872080089	22.0	0.4542974079	True
context optimization	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
training set	0.00120290449729	0.0	2.9977753059	3.0	0.0000000000	False
optimal margin	0.00138076566224	0.0	0.0	0.0	0.0000000000	False
margin classifier	0.00119541018425	0.0	0.0	0.0	0.0000000000	False
data set	0.00193506784966	0.0	5.99666295884	5.0	0.5285714286	False
geometric margin	0.00119541018425	0.0	0.0	1.0	0.0000000000	False
training examples	0.000645022616553	0.0	2.99833147942	2.0	0.0000000000	False
previous lecture	0.000373515548577	0.0	0.0	1.0	0.0000000000	False
primal optimization	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
angle brackets	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
hypothesis applied	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
threshold function	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
input vectors	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
entire algorithm	0.0010638983797	0.0	0.0	1.0	0.0000000000	False
input feature	0.00192377979819	0.0	3.9977753059	3.0	0.5285714286	False
feature vectors	0.00966397191874	0.0	14.9872080089	22.0	0.3894736842	False
high kernel	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
input attribute	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
real number	0.000601452248643	0.0	0.0	2.0	0.0000000000	False
living area	0.000480944949547	0.0	0.0	1.0	0.0000000000	False
richer set	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
polynomial features	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
mapping phi	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
original features	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
higher dimensional	0.00339526588956	0.0	1.9977753059	3.0	0.3523809524	False
dimensional set	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
features phi	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
learning algorithm	0.00224670247665	0.0	7.99555061179	7.0	0.5211267606	True
original one-dimensional	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
one-dimensional input	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
high dimensional	0.00896557638184	0.0	9.99165739711	13.0	0.3360858794	False
high degree	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
infinite dimensional	0.00395344305767	0.0	9.99499443826	8.0	0.3946666667	False
dimensional vector	0.00144283484864	0.0	2.99833147942	2.0	0.0000000000	False
dimensional feature	0.00625228434412	0.0	11.9927697442	11.0	0.3472924188	False
important special	0.00254644941717	0.0	2.99833147942	0.0	0.0000000000	False
special cases	0.00121211102925	0.0	2.99833147942	2.0	0.0000000000	False
kernel function	0.0084881647239	0.0	7.99443826474	9.0	0.2681159420	False
computing phi	0.00339526588956	0.0	6.9977753059	3.0	0.4180790960	False
feature spaces	0.00288566969728	0.0	5.99666295884	4.0	0.4180790960	False
spaces phi	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
concrete examples	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
constructing kernels	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
kernels explicitly	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
kernel corresponds	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
feature mapping	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
vector times	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
cool thing	0.000597705092123	0.0	0.0	1.0	0.0000000000	False
squared elements	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
phi exist	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
valid kernel	0.0118834306135	0.0	20.9916573971	14.0	0.3003246753	False
makes sense	0.000860327629225	0.0	1.9977753059	3.0	0.0000000000	False
quick generalizations	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
define kxz	0.0	0.0	0.0	1.0	0.0000000000	False
add root	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
cx1 root	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
cx2 root	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
first order	0.00138076566224	0.0	0.0	1.0	0.0000000000	False
order terms	0.00119541018425	0.0	0.0	0.0	0.0000000000	False
product terms	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
relative waiting	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
monomial terms	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
quadratic terms	0.000690382831119	0.0	0.0	1.0	0.0000000000	False
dqz features	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
monomials monomials	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
polynomial terms	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
dimensional computing	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
computing space	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
specific examples	0.0010638983797	0.0	0.0	1.0	0.0000000000	False
create kernels	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
machine-learning problem	0.000961889899095	0.0	0.0	2.0	0.0000000000	False
vector phi	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
partial intuition	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
rigorous intuition	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
learning problem	0.000346593711856	0.0	1.99833147942	3.0	0.0000000000	False
random thing	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
dna sequences	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
strange thing	0.000597705092123	0.0	0.0	1.0	0.0000000000	False
similar things	0.000531949189848	0.0	0.0	1.0	0.0000000000	False
good measure	0.00254644941717	0.0	3.99833147942	3.0	0.0000000000	False
specific problem	0.000690382831119	0.0	0.0	1.0	0.0000000000	False
sufficient conditions	0.00169763294478	0.0	0.0	2.0	0.0000000000	False
show part	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
function phi	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
holds true	0.00121211102925	0.0	2.99833147942	3.0	0.0000000000	False
overloading notation	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
kernel matrix	0.00254644941717	0.0	3.99833147942	2.0	0.0000000000	False
m-by-m matrix	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
function applied	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
matrix multiplication	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
rearrange sums	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
equals sum	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
sense questions	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
standard definitions	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
mercer kernels	0.00169763294478	1.0	0.0	1.0	0.0000000000	True
kxz equals	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
equals phi	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
transpose phi	0.00169763294478	0.0	0.0	2.0	0.0000000000	False
symmetric posisemidefinite	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
symmetry posisemidefinite	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
nt show	0.0	0.0	0.0	0.0	0.0000000000	False
galcean kernel	0.00424408236195	0.0	5.99721913237	4.0	0.5285714286	True
machine kernel	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
dual formulation	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
machine algorithm	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
dimensional nonetheless	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
finite amount	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
vectors explicitly	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
good idea	0.0	0.0	0.0	1.0	0.0000000000	False
non-linear learning	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
original data	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
input data	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
original input	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
pedagogical reasons	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
dimensional space	0.00336661464683	0.0	9.99610678532	6.0	0.1933797909	False
linear classifier	0.000531949189848	0.0	0.0	1.0	0.0000000000	False
original space	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
machines output	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
nonlinear decision	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
decision boundaries	0.00265974594924	0.0	3.99721913237	4.0	0.2948207171	False
entire process	0.000597705092123	0.0	0.0	1.0	0.0000000000	False
complex optimization	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
problems questions	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
choose sigmer	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
small amount	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
separate hold	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
out cross	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
cross validation	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
validation set	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
separate set	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
re testing	0.0	0.0	0.0	1.0	0.0000000000	False
linear aggressions	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
aggressions bandwidth	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
bandwidth parameter	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
choose ids	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
model selection	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
selection explicitly	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
good question	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
linearly separable	0.00836787128972	0.0	15.9905450501	16.0	0.4769797422	False
higher dimension	0.00169763294478	0.0	2.99610678532	6.0	0.0000000000	False
soft margin	0.00276153132447	0.0	4.9977753059	2.0	0.5285714286	False
margin svms	0.00339526588956	0.0	4.9977753059	2.0	0.0000000000	False
svm algorithm	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
final word	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
made support	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
powerful learning	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
choose kernels	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
linear algorithms	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
linear regression	0.000404037009748	0.0	0.0	1.0	0.0000000000	False
logistic regression	0.000373515548577	0.0	0.0	1.0	0.0000000000	False
theses algorithms	0.00084881647239	0.0	2.99833147942	3.0	0.0000000000	False
problem set	0.000373515548577	0.0	0.0	1.0	0.0000000000	False
non-linear decision	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
norm soft	0.00254644941717	0.0	3.99833147942	0.0	0.0000000000	False
svm machine	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
good names	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
separable data	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
non-linearly separable	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
nice data	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
great decision	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
entire decision	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
modified formulation	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
svm optimization	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
original decision	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
svm primal	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
primal problem	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
original problem	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
penalty terms	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
functional margin	0.00179311527637	0.0	5.99833147942	2.0	0.0000000000	False
margin greater	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
optimization objective	0.00298852546061	0.0	5.99721913237	4.0	0.4180790960	False
setting cis	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
convex optimization	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
construct alpha	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
objective minus	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
minus sum	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
alpha times	0.000531949189848	0.0	0.0	1.0	0.0000000000	False
entire dual	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
last lecture	0.0	0.0	0.0	1.0	0.0000000000	False
optimal solution	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
constrain optimization	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
derive conversions	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
conversions conditions	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
global optimum	0.0	0.0	0.0	1.0	0.0000000000	False
single outliers	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
stuff makes	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
last thing	0.0	0.0	0.0	1.0	0.0000000000	False
dual optimization	0.00254644941717	0.0	2.99833147942	2.0	0.0000000000	False
convergence criteria	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
efficient algorithm	0.0010638983797	0.0	0.0	1.0	0.0000000000	False
coordinate assent	0.0135810635582	1.0	9.99110122358	15.0	0.1975792097	True
simplest form	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
optimization algorithm	0.00138076566224	0.0	0.0	1.0	0.0000000000	False
assent algorithm	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
quadratic function	0.00483198595937	0.0	19.9938820912	10.0	0.1328068916	False
axis-aligned steps	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
alternating order	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
alpha two	0.0	0.0	43.9816462736	32.0	0.1598502304	False
fixed order	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
alphas update	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
dimensional parameters	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
faster progress	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
assent compared	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
chief advantage	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
basic form	0.000597705092123	0.0	0.0	1.0	0.0000000000	False
change alpha	0.00509289883434	0.0	4.99666295884	6.0	0.1933797909	False
john platt	0.00084881647239	0.0	1.99833147942	3.0	0.0000000000	False
sequential minimal	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
minimal optimization	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
term minimal	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
minimal refers	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
smallest number	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
key step	0.00138076566224	0.0	0.0	1.0	0.0000000000	False
algorithm works	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
large number	0.000245603368477	0.0	0.0	0.0	0.0000000000	False
update alpha	0.00169763294478	0.0	0.0	2.0	0.0000000000	False
board easier	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
completely analogous	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
bosk constraint	0.00169763294478	0.0	0.0	2.0	0.0000000000	False
draw alpha	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
zeta minus	0.00169763294478	0.0	0.0	0.0	0.0000000000	False
minus alpha	0.00119541018425	0.0	0.0	0.0	0.0000000000	False
earlier definition	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
dimensional quadratic	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
hold alpha	0.00169763294478	0.0	0.0	2.0	0.0000000000	False
standard quadratic	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
high school	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
optimal value	0.0	0.0	0.0	0.0	0.0000000000	False
last step	0.0	0.0	0.0	0.0	0.0000000000	False
ll give	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic optimization	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
problem subject	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
solution satisfying	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
box constraint	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
straight line	0.000373515548577	0.0	0.0	1.0	0.0000000000	False
solution lying	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
line segment	0.000690382831119	0.0	0.0	1.0	0.0000000000	False
dequadratic optimization	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
run optimization	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
linear constraint	0.00138076566224	0.0	0.0	1.0	0.0000000000	False
ascent suppose	0.00084881647239	1.0	0.0	0.0	0.0000000000	False
previous iteration	0.000690382831119	0.0	0.0	1.0	0.0000000000	False
defining zeta	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
basic outline	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
choosing alpha	0.000690382831119	0.0	0.0	1.0	0.0000000000	False
objective function	0.000961889899095	0.0	0.0	1.0	0.0000000000	False
change work	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
intervening iterations	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
final value	0.0	0.0	0.0	1.0	0.0000000000	False
original algorithm	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
algorithm talked	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
simplified version	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
process readings	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
integer recognition	0.00254644941717	0.0	3.99833147942	3.0	0.0000000000	False
pixel array	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
scanned image	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
zip code	0.000690382831119	0.0	0.0	1.0	0.0000000000	False
ten pixels	0.00339526588956	0.0	7.9977753059	2.0	0.0000000000	False
binary features	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
scale values	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
champion algorithm	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
polynomial kernel	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
kernel works	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
svm gave	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
gave performance	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
pixel intensity	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
intensity value	0.0	0.0	0.0	0.0	0.0000000000	False
careful development	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
esoteric objects	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
classify protein	0.00169763294478	0.0	0.0	1.0	0.0000000000	False
protein sequences	0.00414229698671	0.0	11.9966629588	5.0	0.4180790960	False
room cringe	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
amino acids	0.00418393564486	0.0	13.9961067853	6.0	0.1705069124	False
acid sequence	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
sequence represented	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
classes depending	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
long protein	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
100th position	0.00169763294478	0.0	0.0	2.0	0.0000000000	False
feature representation	0.00339526588956	0.0	7.9977753059	3.0	0.0000000000	False
idea write	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
subsequences occur	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
bajt occurs	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
sequences occur	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
long vector	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
representation applies	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
modern computer	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
computer standards	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
vectors imagine	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
modern day	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
day computers	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
efficient dynamic	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
dynamic programming	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
programming algorithm	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
high feature	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
finding subsequences	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
re interested	0.0	0.0	0.0	1.0	0.0000000000	False
cool kernel	0.00084881647239	0.0	0.0	1.0	0.0000000000	False
standard kernel	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
research papers	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
papers written	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
last sentences	0.0	0.0	0.0	0.0	0.0000000000	False
shelf learning	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
good	0.000149769233671	0.0	0.0	0.0	0.4197730956	False
morning	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
back	0.000254917197159	0.0	0.0	0.0	0.4769797422	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
homework	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
give	2.25761029398e-05	0.0	0.0	0.0	0.4977578475	False
end	5.86595166058e-05	0.0	0.0	0.0	0.5362318841	False
class	0.000159762778411	0.0	0.0	0.0	0.5211267606	False
quick	0.00022983356928	0.0	0.0	0.0	0.0000000000	False
reminder	0.000480944949547	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
project	0.000393813500312	0.0	0.0	0.0	0.0000000000	False
proposals	0.000373515548577	0.0	0.0	0.0	0.0000000000	False
start	0.0	0.0	0.0	0.0	0.3153409091	False
trickle	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
great	0.000282683566763	0.0	0.0	0.0	0.0000000000	False
due	0.000606055514623	0.0	0.0	0.0	0.0000000000	False
friday	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
meet	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
chat	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
ideas	0.000339889596212	0.0	0.0	0.0	0.3663366337	False
office	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
hours	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
immediately	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
lecture	0.000237446562321	0.0	0.0	0.0	0.0000000000	False
today	5.94528586277e-05	0.0	0.0	0.0	0.4415274463	False
questions	0.000175978549817	0.0	0.0	0.0	0.3888439774	False
wrap	0.000747031097154	0.0	0.0	0.0	0.5211267606	False
discussion	0.00010410869227	0.0	0.0	0.0	0.0000000000	False
support	0.00204327811941	0.0	0.0	0.0	0.3262180974	False
vector	0.008227712844	0.0	0.0	0.0	0.3193158638	False
machines	0.00152925629481	0.0	0.0	0.0	0.4280991736	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
talk	0.000171464299113	0.0	0.0	0.0	0.4190938511	False
kernels	0.0143433138461	1.0	0.0	0.0	0.2373129290	True
smo	0.00509289883434	0.0	0.0	0.0	0.3323353293	False
algorithm	0.00235619762432	0.0	0.0	0.0	0.2985184099	False
solving	0.00112896042351	0.0	0.0	0.0	0.4269230769	False
optimization	0.00786345866826	0.0	0.0	0.0	0.2702963473	False
problem	0.000234334542121	0.0	0.0	0.0	0.4425837321	False
posed	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.5285714286	False
recap	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
wrote	0.000430163814612	0.0	0.0	0.0	0.5285714286	False
context	0.000300726124321	0.0	0.0	0.0	0.0000000000	False
assuming	0.00013075459081	0.0	0.0	0.0	0.0000000000	False
data	0.00073490878069	0.0	0.0	0.0	0.2306858227	False
linearly	0.00303027757311	0.0	0.0	0.0	0.3004872767	False
separable	0.00177865603813	0.0	0.0	0.0	0.2619469027	False
assumption	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
fix	0.000905511829009	0.0	0.0	0.0	0.4605809129	False
training	0.00098241347391	0.0	0.0	0.0	0.3592233010	False
set	0.000234470798675	0.0	0.0	0.0	0.3744578313	False
find	0.00010558712989	0.0	0.0	0.0	0.5053110774	False
margin	0.00241599297968	0.0	0.0	0.0	0.4292343387	False
classifier	0.00182544576228	0.0	0.0	0.0	0.3828786453	False
maximizes	0.000842513428743	0.0	0.0	0.0	0.3752535497	False
geometric	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
examples	0.00101766084035	0.0	0.0	0.0	0.3744578313	False
previous	0.000143223497383	0.0	0.0	0.0	0.0000000000	False
derived	0.00130796153079	0.0	0.0	0.0	0.2740740741	False
dual	0.00636612354292	0.0	0.0	0.0	0.3814432990	False
primal	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
angle	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
brackets	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
denote	0.000804899403564	0.0	0.0	0.0	0.5606060606	False
product	0.0033202100397	0.0	0.0	0.0	0.3568340539	False
transpose	0.00280136661433	0.0	0.0	0.0	0.2889120250	False
worked	0.000449307701012	0.0	0.0	0.0	0.4451521585	False
out	0.0	0.0	0.0	0.0	0.3937991671	False
ways	7.91488541069e-05	0.0	0.0	0.0	0.4877589454	False
sum	0.00155873783655	0.0	0.0	0.0	0.2758906379	False
alpha	0.0266877158129	0.0	0.0	0.0	0.0838976902	False
make	0.000102878579468	0.0	0.0	0.0	0.4364351245	False
prediction	0.000262542333541	0.0	0.0	0.0	0.0000000000	False
classification	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
compute	0.00038644358108	0.0	0.0	0.0	0.2378503471	False
value	0.000282683566763	0.0	0.0	0.0	0.3828786453	False
hypothesis	0.000122801684239	0.0	0.0	0.0	0.0000000000	False
applied	0.000624652153622	0.0	0.0	0.0	0.5306388527	False
threshold	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
function	0.00109117584531	0.0	0.0	0.0	0.2388984056	False
outputs	0.000142292483051	0.0	0.0	0.0	0.0000000000	False
minus	0.000525152823737	0.0	0.0	0.0	0.3663366337	False
written	0.000169610140058	0.0	0.0	0.0	0.0000000000	False
terms	0.000222948219854	0.0	0.0	0.0	0.3952991453	False
input	0.000520543461352	0.0	0.0	0.0	0.3779795687	False
property	5.20543461352e-05	0.0	0.0	0.0	0.0000000000	False
turns	0.00166212593625	0.0	0.0	0.0	0.3708139819	False
dependers	0.000124036860136	0.0	0.0	0.0	0.4415274463	False
fact	0.00010697802405	0.0	0.0	0.0	0.5362318841	False
write	0.000343572125609	0.0	0.0	0.0	0.3380710660	False
entire	0.000159762778411	0.0	0.0	0.0	0.5441176471	False
explicitly	0.00121211102925	0.0	0.0	0.0	0.0000000000	False
referring	0.00010410869227	0.0	0.0	0.0	0.0000000000	False
feature	0.00348616583474	0.0	0.0	0.0	0.2621519196	False
high	0.00135177858898	0.0	0.0	0.0	0.3262180974	False
attribute	0.000721417424321	0.0	0.0	0.0	0.0000000000	False
real	9.54823315886e-05	0.0	0.0	0.0	0.0000000000	False
number	1.41100643374e-05	0.0	0.0	0.0	0.5285714286	False
living	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
area	9.40800352924e-05	0.0	0.0	0.0	0.0000000000	False
house	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
sold	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
months	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
map	0.00103488038822	0.0	0.0	0.0	0.2994849154	False
richer	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.4605809129	False
polynomial	0.000808074019497	0.0	0.0	0.0	0.4180790960	False
acutely	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
call	1.12880514699e-05	0.0	0.0	0.0	0.4839476813	False
phi	0.0125045686882	0.0	0.0	0.0	0.1418711656	False
original	0.000594594360797	0.0	0.0	0.0	0.2829226848	False
higher	0.000804417492482	0.0	0.0	0.0	0.3748191027	False
dimensional	0.00449340495329	0.0	0.0	0.0	0.2352554264	False
learning	0.000792792481063	0.0	0.0	0.0	0.5606060606	False
replace	0.000752786675572	0.0	0.0	0.0	0.2836801752	False
corresponds	0.000537704768265	0.0	0.0	0.0	0.4292343387	False
running	0.00017365160419	0.0	0.0	0.0	0.4769797422	False
one-dimensional	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
scenario	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
degree	0.000262542333541	0.0	0.0	0.0	0.0000000000	False
infinite	0.00110521515815	0.0	0.0	0.0	0.3486910995	False
extremely	0.000470400176462	0.0	0.0	0.0	0.3752535497	False
efficiently	0.0008790092429	0.0	0.0	0.0	0.3752535497	False
represent	0.000364380422946	0.0	0.0	0.0	0.5522388060	False
inefficient	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
important	0.000143223497383	0.0	0.0	0.0	0.0000000000	False
special	0.00026370277287	0.0	0.0	0.0	0.0000000000	False
cases	0.0	0.0	0.0	0.0	0.4605809129	False
expensive	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
impossible	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
nonetheless	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.2136398300	False
inexpensively	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
lets	0.000143223497383	0.0	0.0	0.0	0.4846297781	False
spaces	0.000918031262325	0.0	0.0	0.0	0.1686417502	False
bit	2.48073720272e-05	0.0	0.0	0.0	0.0000000000	False
concrete	0.000300726124321	0.0	0.0	0.0	0.0000000000	False
constructing	0.000470400176462	0.0	0.0	0.0	0.5362318841	False
illustrates	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
save	0.000560273322866	0.0	0.0	0.0	0.0000000000	False
equals	0.00126638166571	0.0	0.0	0.0	0.3189655172	False
squared	0.000924901139828	0.0	0.0	0.0	0.2836801752	False
right	0.0	0.0	0.0	0.0	0.5362318841	False
thing	0.0	0.0	0.0	0.0	0.2740740741	False
free	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
guess	0.000215081907306	0.0	0.0	0.0	0.0000000000	False
definition	0.000238705828971	0.0	0.0	0.0	0.5362318841	False
verify	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
elements	0.000673222925705	0.0	0.0	0.0	0.2479061977	False
multiply	0.000702094523952	0.0	0.0	0.0	0.4180790960	False
times	0.0	0.0	0.0	0.0	0.3894736842	False
cool	0.000393813500312	0.0	0.0	0.0	0.0000000000	False
order	0.000121577451165	0.0	0.0	0.0	0.2602579132	False
dimension	0.000693187423711	0.0	0.0	0.0	0.0000000000	False
pairs	0.000393813500312	0.0	0.0	0.0	0.0000000000	False
length	0.000322622860959	0.0	0.0	0.0	0.0000000000	False
defined	0.000169944798106	0.0	0.0	0.0	0.3385620915	False
exist	0.00052740554574	0.0	0.0	0.0	0.3992805755	False
valid	0.00343431458286	0.0	0.0	0.0	0.2291438980	False
raise	0.000188160070585	0.0	0.0	0.0	0.0000000000	False
hand	8.71697272067e-05	0.0	0.0	0.0	0.0000000000	False
sense	0.000124036860136	0.0	0.0	0.0	0.0000000000	False
describe	0.000402449701782	0.0	0.0	0.0	0.5362318841	False
couple	0.000736810105432	0.0	0.0	0.0	0.5441176471	False
generalizations	7.81569328916e-05	0.0	0.0	0.0	0.5441176471	False
kxz	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
add	0.00024480833662	0.0	0.0	0.0	0.4180790960	False
bottom	0.000122801684239	0.0	0.0	0.0	0.0000000000	False
root	0.000491206736955	0.0	0.0	0.0	0.2044198895	False
read	0.000208217384541	0.0	0.0	0.0	0.4180790960	False
cx1	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
cx2	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
cx3	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
creating	0.000152925629481	0.0	0.0	0.0	0.0000000000	False
monomials	0.00169763294478	0.0	0.0	0.0	0.0000000000	False
meaning	2.53981158072e-05	0.0	0.0	0.0	0.4135855546	False
first	0.0	0.0	0.0	0.0	0.0000000000	False
quadratic	0.00210508287025	0.0	0.0	0.0	0.1418400876	False
parameter	0.00122340503585	0.0	0.0	0.0	0.4916943522	False
control	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
relative	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
waiting	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
dqz	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
power	0.000198198120266	0.0	0.0	0.0	0.0000000000	False
grows	0.000131271166771	0.0	0.0	0.0	0.0000000000	False
exponentially	0.000300726124321	0.0	0.0	0.0	0.0000000000	False
implicitly	0.000961889899095	0.0	0.0	0.0	0.4180790960	False
plugging	0.000280837809581	0.0	0.0	0.0	0.0000000000	False
specific	9.58576670466e-05	0.0	0.0	0.0	0.0000000000	False
faced	0.000393813500312	0.0	0.0	0.0	0.0000000000	False
machine-learning	0.000439271450852	0.0	0.0	0.0	0.0000000000	False
intuition	0.000736810105432	0.0	0.0	0.0	0.2044198895	False
sort	0.000159762778411	0.0	0.0	0.0	0.4415274463	False
partial	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
rigorous	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
similar	0.000316595416428	0.0	0.0	0.0	0.3045267490	False
pointing	1.69320772048e-05	0.0	0.0	0.0	0.4415274463	False
direction	0.000344750353921	0.0	0.0	0.0	0.0000000000	False
large	0.000277020989374	0.0	0.0	0.0	0.0000000000	False
contrast	0.000262542333541	0.0	0.0	0.0	0.0000000000	False
dissimilar	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
small	5.42482303594e-05	0.0	0.0	0.0	0.0000000000	False
random	0.000107540953653	0.0	0.0	0.0	0.0000000000	False
decide	5.65367133527e-05	0.0	0.0	0.0	0.0000000000	False
true	0.00062190384688	0.0	0.0	0.0	0.3592233010	False
brand	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
dna	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
sequences	0.000726726440974	0.0	0.0	0.0	0.1964601770	False
strange	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
answers	4.77411657943e-05	0.0	0.0	0.0	0.0000000000	False
measure	0.000421256714371	0.0	0.0	0.0	0.0000000000	False
words	0.000435848636033	0.0	0.0	0.0	0.0000000000	False
understand	4.45896439708e-05	0.0	0.0	0.0	0.0000000000	False
result	0.000183606252465	0.0	0.0	0.0	0.0000000000	False
characterizes	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
sufficient	0.000262542333541	0.0	0.0	0.0	0.0000000000	False
conditions	0.000738349501526	0.0	0.0	0.0	0.3992805755	False
choose	0.00168218192429	0.0	0.0	0.0	0.3177914110	False
show	0.000124036860136	0.0	0.0	0.0	0.0000000000	False
part	5.7154766371e-06	0.0	0.0	0.0	0.0000000000	False
suppose	7.44221160815e-05	0.0	0.0	0.0	0.0000000000	False
holds	0.00079110831861	0.0	0.0	0.0	0.4542974079	False
matrix	0.00186757774289	0.0	0.0	0.0	0.2513207547	False
apologize	0.000797923784772	0.0	0.0	0.0	0.0000000000	False
overloading	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
notation	0.00017580184858	0.0	0.0	0.0	0.0000000000	False
alphabets	0.00121211102925	0.0	0.0	0.0	0.0000000000	False
m-by-m	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
subscript	0.000346593711856	0.0	0.0	0.0	0.0000000000	False
indimensional	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
multiplication	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
kij	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
explicit	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
rearrange	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
familiar	9.40800352924e-05	0.0	0.0	0.0	0.0000000000	False
greater	0.000611702517925	0.0	0.0	0.0	0.3946666667	False
minute	0.000107540953653	0.0	0.0	0.0	0.0000000000	False
steps	0.000223266348245	0.0	0.0	0.0	0.4769797422	False
buy	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
summarize	0.000300726124321	0.0	0.0	0.0	0.0000000000	False
standard	0.000305851258963	0.0	0.0	0.0	0.0000000000	False
posisemidefinite	0.00212204118097	0.0	0.0	0.0	0.0000000000	False
shown	6.1202084155e-05	0.0	0.0	0.0	0.0000000000	False
converse	0.000491206736955	0.0	0.0	0.0	0.5285714286	False
test	0.000430163814612	0.0	0.0	0.0	0.0000000000	False
theorem	0.000322511308277	0.0	0.0	0.0	0.0000000000	False
mercer	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
i.e	0.0	0.0	0.0	0.0	0.0000000000	False
necessarily	0.000107540953653	0.0	0.0	0.0	0.0000000000	False
capital	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
symmetric	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
proved	0.000188160070585	0.0	0.0	0.0	0.0000000000	False
symmetry	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
possibly	0.000107540953653	0.0	0.0	0.0	0.4180790960	False
fail	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
tie	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
svm	0.00690382831119	0.0	0.0	0.0	0.2904808636	False
galcean	0.00254644941717	0.0	0.0	0.0	0.5362318841	False
choice	7.11462415253e-05	0.0	0.0	0.0	0.0000000000	False
formulation	0.000693187423711	0.0	0.0	0.0	0.0000000000	False
finite	0.000131271166771	0.0	0.0	0.0	0.0000000000	False
amount	0.000164077667006	0.0	0.0	0.0	0.0000000000	False
wanted	0.000100612425445	0.0	0.0	0.0	0.4937094929	False
develop	0.000215081907306	0.0	0.0	0.0	0.0000000000	False
non-linear	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
picture	0.000260271730676	0.0	0.0	0.0	0.0000000000	False
mind	8.790092429e-05	0.0	0.0	0.0	0.0000000000	False
draw	0.000213438724576	0.0	0.0	0.0	0.0000000000	False
slanted	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
takes	8.4972399053e-05	0.0	0.0	0.0	0.4157303371	False
pedagogical	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
reasons	0.000178499820024	0.0	0.0	0.0	0.0000000000	False
infinity	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
largest	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
drew	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
linear	0.00052740554574	0.0	0.0	0.0	0.4605809129	False
nonlinear	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
decision	0.000614008421194	0.0	0.0	0.0	0.3262786596	False
boundaries	0.000751815310803	0.0	0.0	0.0	0.2948207171	False
process	6.39051113644e-05	0.0	0.0	0.0	0.0000000000	False
complex	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
sigmer	0.00169763294478	0.0	0.0	0.0	0.2886115445	False
thirds	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
cross	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
locally	0.000122801684239	0.0	0.0	0.0	0.0000000000	False
aggressions	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
bandwidth	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
ids	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
model	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
selection	0.000421256714371	0.0	0.0	0.0	0.0000000000	False
moving	0.00011872328116	0.0	0.0	0.0	0.0000000000	False
kind	3.51957099635e-05	0.0	0.0	0.0	0.0000000000	False
topic	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
tend	0.000131271166771	0.0	0.0	0.0	0.0000000000	False
address	0.00011491678464	0.0	0.0	0.0	0.0000000000	False
soft	0.0010638983797	0.0	0.0	0.0	0.5285714286	False
guys	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
hard	0.000368405052716	0.0	0.0	0.0	0.0000000000	False
change	0.000566482660353	0.0	0.0	0.0	0.2146171694	False
final	0.000264264160354	0.0	0.0	0.0	0.0000000000	False
made	0.00012240416831	0.0	0.0	0.0	0.0000000000	False
regression	0.000322511308277	0.0	0.0	0.0	0.0000000000	False
logistic	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
rewrite	0.000373515548577	0.0	0.0	0.0	0.0000000000	False
theses	0.000345191415559	0.0	0.0	0.0	0.3712374582	False
widely	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
quarter	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
kernalize	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
play	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
norm	0.000606055514623	0.0	0.0	0.0	0.0000000000	False
people	0.00012240416831	0.0	0.0	0.0	0.0000000000	False
coming	8.20388335029e-05	0.0	0.0	0.0	0.4197730956	False
names	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
non-linearly	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
nice	8.20388335029e-05	0.0	0.0	0.0	0.0000000000	False
outlier	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
slightly	0.000143223497383	0.0	0.0	0.0	0.0000000000	False
suspicious	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
skew	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
lot	0.000237446562321	0.0	0.0	0.0	0.5285714286	False
modified	0.000402449701782	0.0	0.0	0.0	0.4180790960	False
deal	0.000131271166771	0.0	0.0	0.0	0.0000000000	False
prefer	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
minimize	0.000704286978118	0.0	0.0	0.0	0.3385620915	False
one-half	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
adding	0.000188160070585	0.0	0.0	0.0	0.0000000000	False
penalty	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
cis	0.00169763294478	0.0	0.0	0.0	0.1933797909	False
demand	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
remember	7.91488541069e-05	0.0	0.0	0.0	0.0000000000	False
ago	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
implies	0.000215081907306	0.0	0.0	0.0	0.0000000000	False
correctly	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
misclassified	0.000531949189848	0.0	0.0	0.0	0.0000000000	False
larger	5.65367133527e-05	0.0	0.0	0.0	0.0000000000	False
negative	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
allowing	0.000186757774289	0.0	0.0	0.0	0.5362318841	False
encourage	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
objective	0.000688165332666	0.0	0.0	0.0	0.4769797422	False
penalizes	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
convex	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
constraints	0.00554549938969	0.0	0.0	0.0	0.2343007916	False
previously	0.000503062127227	0.0	0.0	0.0	0.0000000000	False
redivide	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
simplify	0.000393813500312	0.0	0.0	0.0	0.0000000000	False
simply	0.000393813500312	0.0	0.0	0.0	0.0000000000	False
compared	0.000574583923201	0.0	0.0	0.0	0.3752535497	False
home	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
essentially	4.96147440544e-05	0.0	0.0	0.0	0.0000000000	False
math	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
solution	0.00061530647003	0.0	0.0	0.0	0.2142266336	False
constrain	0.000439271450852	0.0	0.0	0.0	0.0000000000	False
converged	0.00141412953412	0.0	0.0	0.0	0.4415274463	False
global	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
optimum	0.0	0.0	0.0	0.0	0.0000000000	False
handle	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
single	5.65367133527e-05	0.0	0.0	0.0	0.0000000000	False
stuff	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
criteria	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
partly	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
excuse	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
coordinate	0.00384755959638	0.0	0.0	0.0	0.1837368094	False
assent	0.00679053177912	0.0	0.0	0.0	0.1975792097	False
simplest	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
form	5.42482303594e-05	0.0	0.0	0.0	0.0000000000	False
forget	0.000322511308277	0.0	0.0	0.0	0.0000000000	False
repeat	8.790092429e-05	0.0	0.0	0.0	0.0000000000	False
respect	0.00169344063526	0.0	0.0	0.0	0.2939099735	False
updated	0.00129049144384	0.0	0.0	0.0	0.3579595427	False
hat	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
fancy	0.000597705092123	0.0	0.0	0.0	0.0000000000	False
imagine	0.000201224850891	0.0	0.0	0.0	0.0000000000	False
contours	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
minimums	0.000280837809581	0.0	0.0	0.0	0.0000000000	False
axis	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
begin	6.1202084155e-05	0.0	0.0	0.0	0.0000000000	False
someplace	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
axis-aligned	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
modification	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
variations	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
alternating	0.000262542333541	0.0	0.0	0.0	0.0000000000	False
visit	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
progress	0.000606055514623	0.0	0.0	0.0	0.0000000000	False
faster	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
maximum	8.20388335029e-05	0.0	0.0	0.0	0.0000000000	False
newton	0.0	0.0	0.0	0.0	0.0000000000	False
method	0.000142292483051	0.0	0.0	0.0	0.0000000000	False
chief	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
advantage	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
iterations	0.00110521515815	0.0	0.0	0.0	0.4180790960	False
easy	0.000301837276336	0.0	0.0	0.0	0.0000000000	False
group	0.000150363062161	0.0	0.0	0.0	0.0000000000	False
quickly	0.000198198120266	0.0	0.0	0.0	0.0000000000	False
basic	2.34638066423e-05	0.0	0.0	0.0	0.0000000000	False
recall	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
violating	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
determined	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
john	0.00103557424668	0.0	0.0	0.0	0.0000000000	False
platt	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
colleague	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
microsoft	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
sequential	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
smallest	0.00011491678464	0.0	0.0	0.0	0.0000000000	False
outline	0.000439271450852	0.0	0.0	0.0	0.0000000000	False
rule	9.40800352924e-05	0.0	0.0	0.0	0.0000000000	False
thumb	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
subject	0.000806278270692	0.0	0.0	0.0	0.3262786596	False
key	0.000132132080177	0.0	0.0	0.0	0.0000000000	False
chose	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
satisfied	0.000491206736955	0.0	0.0	0.0	0.4180790960	False
epsilon	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
cheap	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
board	0.000245603368477	0.0	0.0	0.0	0.0000000000	False
easier	0.000131271166771	0.0	0.0	0.0	0.0000000000	False
completely	2.13956048101e-05	0.0	0.0	0.0	0.0000000000	False
analogous	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
zeta	0.00339526588956	0.0	0.0	0.0	0.2886115445	False
bosk	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
lie	0.000470400176462	0.0	0.0	0.0	0.3752535497	False
box	0.00112054664573	0.0	0.0	0.0	0.4180790960	False
ranges	0.000122801684239	0.0	0.0	0.0	0.0000000000	False
earlier	5.20543461352e-05	0.0	0.0	0.0	0.0000000000	False
expression	0.000215081907306	0.0	0.0	0.0	0.0000000000	False
view	9.40800352924e-05	0.0	0.0	0.0	0.0000000000	False
school	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
undergrad	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
line	0.000174339454413	0.0	0.0	0.0	0.3457943925	False
clip	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
inside	7.64628147407e-05	0.0	0.0	0.0	0.0000000000	False
straight	8.790092429e-05	0.0	0.0	0.0	0.0000000000	False
segment	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
dequadratic	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
loop	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
mentioned	0.000107540953653	0.0	0.0	0.0	0.0000000000	False
ascent	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
divided	7.64628147407e-05	0.0	0.0	0.0	0.0000000000	False
procedure	0.000188160070585	0.0	0.0	0.0	0.0000000000	False
exchanging	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
farther	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
translate	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
differently	5.7154766371e-06	0.0	0.0	0.0	0.4916943522	False
metric	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
care	0.000169610140058	0.0	0.0	0.0	0.0000000000	False
increase	0.00017580184858	0.0	0.0	0.0	0.0000000000	False
stay	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
worse	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
eventually	9.40800352924e-05	0.0	0.0	0.0	0.0000000000	False
intervening	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
closer	0.000346593711856	0.0	0.0	0.0	0.0000000000	False
conceptually	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
complicated	0.00017580184858	0.0	0.0	0.0	0.0000000000	False
explain	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
paper	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
pretty	0.000131271166771	0.0	0.0	0.0	0.0000000000	False
posting	0.000262542333541	0.0	0.0	0.0	0.0000000000	False
handout	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
homepage	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
version	0.000107540953653	0.0	0.0	0.0	0.0000000000	False
details	4.35848636033e-05	0.0	0.0	0.0	0.0000000000	False
difficult	0.000122801684239	0.0	0.0	0.0	0.0000000000	False
notes	5.65367133527e-05	0.0	0.0	0.0	0.0000000000	False
briefly	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
applications	5.65367133527e-05	0.0	0.0	0.0	0.0000000000	False
handler	0.0	0.0	0.0	0.0	0.0000000000	False
integer	0.000368405052716	0.0	0.0	0.0	0.0000000000	False
recognition	0.000797923784772	0.0	0.0	0.0	0.0000000000	False
pixel	0.00303027757311	0.0	0.0	0.0	0.1600471884	False
array	0.00022983356928	0.0	0.0	0.0	0.0000000000	False
scanned	0.000373515548577	0.0	0.0	0.0	0.0000000000	False
image	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
zip	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
code	7.11462415253e-05	0.0	0.0	0.0	0.0000000000	False
britain	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
combination	0.000229388444222	0.0	0.0	0.0	0.0000000000	False
character	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
ten	0.000226146853411	0.0	0.0	0.0	0.2044198895	False
hundred	0.000100612425445	0.0	0.0	0.0	0.0000000000	False
binary	8.790092429e-05	0.0	0.0	0.0	0.0000000000	False
xb01	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
gray	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
scale	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
dark	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
years	0.00017580184858	0.0	0.0	0.0	0.0000000000	False
neuronetwork	0.00127322470858	0.0	0.0	0.0	0.0000000000	False
champion	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
throwing	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
gave	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
performance	0.00010410869227	0.0	0.0	0.0	0.0000000000	False
surprising	0.000186757774289	0.0	0.0	0.0	0.0000000000	False
account	0.000122801684239	0.0	0.0	0.0	0.0000000000	False
knowledge	0.000173296855928	0.0	0.0	0.0	0.0000000000	False
intensity	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
shuffle	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
fairly	5.20543461352e-05	0.0	0.0	0.0	0.0000000000	False
esoteric	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
protein	0.00292572054416	0.0	0.0	0.0	0.2260692464	False
suspect	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
biologists	0.000690382831119	0.0	0.0	0.0	0.0000000000	False
room	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
cringe	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
amino	0.00209196782243	0.0	0.0	0.0	0.1640278657	False
acids	0.00186182216447	0.0	0.0	0.0	0.1705069124	False
bodies	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
series	0.000219635725426	0.0	0.0	0.0	0.0000000000	False
assign	8.790092429e-05	0.0	0.0	0.0	0.0000000000	False
type	6.1202084155e-05	0.0	0.0	0.0	0.0000000000	False
challenging	0.000265974594924	0.0	0.0	0.0	0.0000000000	False
long	0.000328155334012	0.0	0.0	0.0	0.0000000000	False
short	0.000322511308277	0.0	0.0	0.0	0.0000000000	False
100th	0.00084881647239	0.0	0.0	0.0	0.0000000000	False
position	7.91488541069e-05	0.0	0.0	0.0	0.0000000000	False
representation	0.00043950462145	0.0	0.0	0.0	0.0000000000	False
aaaa	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
aaab	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
aaac	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
aaaz	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
aaba	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
count	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
subsequences	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
occur	0.000322622860959	0.0	0.0	0.0	0.0000000000	False
bajt	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
put	3.61654869063e-05	0.0	0.0	0.0	0.0000000000	False
matter	7.64628147407e-05	0.0	0.0	0.0	0.0000000000	False
r20	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
160,000	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
modern	0.000404037009748	0.0	0.0	0.0	0.0000000000	False
1,000	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
store	9.40800352924e-05	0.0	0.0	0.0	0.0000000000	False
double	0.000201224850891	0.0	0.0	0.0	0.0000000000	False
day	8.20388335029e-05	0.0	0.0	0.0	0.0000000000	False
big	6.60660400886e-05	0.0	0.0	0.0	0.0000000000	False
dynamic	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
programming	5.65367133527e-05	0.0	0.0	0.0	0.0000000000	False
ridiculously	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
reminiscent	0.000345191415559	0.0	0.0	0.0	0.0000000000	False
interested	5.20543461352e-05	0.0	0.0	0.0	0.0000000000	False
research	0.000161255654138	0.0	0.0	0.0	0.0000000000	False
sentences	0.000202018504874	0.0	0.0	0.0	0.0000000000	False
effective	7.64628147407e-05	0.0	0.0	0.0	0.0000000000	False
shelf	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
close	2.83241330177e-05	0.0	0.0	0.0	0.0000000000	False
congrats	0.000424408236195	0.0	0.0	0.0	0.0000000000	False
qualified	0.000240472474774	0.0	0.0	0.0	0.0000000000	False
week	0.000122801684239	0.0	0.0	0.0	0.0000000000	False
poorly	0.000298852546061	0.0	0.0	0.0	0.0000000000	False
tools	0.00014041890479	0.0	0.0	0.0	0.0000000000	False
assume that your project	0.0	0.0	0.0	2.0	0.0000000000	False
working on your proposals	0.0	0.0	0.0	2.0	0.0000000000	False
working on your project	0.0	0.0	0.0	2.0	0.0000000000	False
session at the end	0.0	0.0	0.0	2.0	0.0000000000	False
end of the quarter	0.0	0.0	0.0	2.0	0.0000000000	False
start a new chapter	0.0	0.0	0.0	2.0	0.0000000000	False
talk about learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
learned about a lot	0.0	0.0	0.0	2.0	0.0000000000	False
lot of learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
powerful tools of machine	0.0	0.0	0.0	2.0	0.0000000000	False
tools of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
sort of well qualified	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to learn	0.0	0.0	0.0	2.0	0.0000000000	False
re going to carpentry	0.0	0.0	0.0	2.0	0.0000000000	False
carpentry school to learn	0.0	0.0	0.0	2.0	0.0000000000	False
tools if you learn	0.0	0.0	0.0	2.0	0.0000000000	False
walk in and pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick up a tool	0.0	0.0	0.0	2.0	0.0000000000	False
give you a sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense of the mastery	0.0	0.0	0.0	2.0	0.0000000000	False
mastery of the machine	0.0	0.0	0.0	2.0	0.0000000000	False
deeply about the properties	0.0	0.0	0.0	2.0	0.0000000000	False
properties of different machine	0.0	0.0	0.0	2.0	0.0000000000	False
common scenarios in machine	0.0	0.0	0.0	2.0	0.0000000000	False
scenarios in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
machine learning is someday	0.0	0.0	0.0	2.0	0.0000000000	False
ll be doing research	0.0	0.0	0.0	2.0	0.0000000000	False
research or a company	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms you learned	0.0	0.0	0.0	2.0	0.0000000000	False
people that really understand	0.0	0.0	0.0	2.0	0.0000000000	False
people that maybe read	0.0	0.0	0.0	2.0	0.0000000000	False
work through the math	0.0	0.0	0.0	2.0	0.0000000000	False
apply a support vector	0.0	0.0	0.0	2.0	0.0000000000	False
understand enough about support	0.0	0.0	0.0	2.0	0.0000000000	False
separates the great people	0.0	0.0	0.0	2.0	0.0000000000	False
great people in machine	0.0	0.0	0.0	2.0	0.0000000000	False
people in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning versus the people	0.0	0.0	0.0	2.0	0.0000000000	False
people that like read	0.0	0.0	0.0	2.0	0.0000000000	False
read the text book	0.0	0.0	0.0	2.0	0.0000000000	False
ll have just understood	0.0	0.0	0.0	2.0	0.0000000000	False
ll start to talk	0.0	0.0	0.0	2.0	0.0000000000	False
theoretical results of machine	0.0	0.0	0.0	2.0	0.0000000000	False
results of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning the next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
problems that the learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning theory will point	0.0	0.0	0.0	2.0	0.0000000000	False
first thing we re	0.0	0.0	0.0	0.0	0.0000000000	False
re gon na talk	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm we learned	0.0	0.0	0.0	2.0	0.0000000000	False
line through these datas	0.0	0.0	0.0	2.0	0.0000000000	False
structure in the data	0.0	0.0	0.0	4.0	0.0000000000	False
bias of the learning	0.0	0.0	0.0	4.0	0.0000000000	False
learning algorithm as representing	0.0	0.0	0.0	2.0	0.0000000000	False
infinite amount of training	0.0	0.0	0.0	4.0	0.0000000000	False
amount of training data	0.0	0.0	0.0	4.0	0.0000000000	False
tons of training data	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm would still fail	0.0	0.0	0.0	2.0	0.0000000000	False
fit the quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm with high bias	0.0	0.0	0.0	2.0	0.0000000000	False
dataset if you fit	0.0	0.0	0.0	2.0	0.0000000000	False
fourth of the polynomials	0.0	0.0	0.0	2.0	0.0000000000	False
polynomials into this dataset	0.0	0.0	0.0	2.0	0.0000000000	False
interpolate the five data	0.0	0.0	0.0	2.0	0.0000000000	False
model to the structure	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has a problem	0.0	0.0	0.0	2.0	0.0000000000	False
alternatively that this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has high variance	0.0	0.0	0.0	2.0	0.0000000000	False
overfitting a high variance	0.0	0.0	0.0	2.0	0.0000000000	False
patterns in the data	0.0	0.0	0.0	2.0	0.0000000000	False
dataset of housing prices	0.0	0.0	0.0	2.0	0.0000000000	False
happy medium of fitting	0.0	0.0	0.0	2.0	0.0000000000	False
fitting a quadratic function	0.0	0.0	0.0	2.0	0.0000000000	False
nt interpolate your data	0.0	0.0	0.0	0.0	0.0000000000	False
interpolate your data points	0.0	0.0	0.0	2.0	0.0000000000	False
multi-structure in your data	0.0	0.0	0.0	2.0	0.0000000000	False
model which under fits	0.0	0.0	0.0	2.0	0.0000000000	False
picture of classification problems	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative examples	0.0	0.0	0.0	2.0	0.0000000000	False
equals the sigmoid function	0.0	0.0	0.0	2.0	0.0000000000	False
applied to a tenth	0.0	0.0	0.0	2.0	0.0000000000	False
tenth of the polynomial	0.0	0.0	0.0	2.0	0.0000000000	False
boundary like this right	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative classes	0.0	0.0	0.0	2.0	0.0000000000	False
regression into this model	0.0	0.0	0.0	2.0	0.0000000000	False
problem of overfitting versus	0.0	0.0	0.0	2.0	0.0000000000	False
bias versus high variance	0.0	0.0	0.0	2.0	0.0000000000	False
formal model of machine	0.0	0.0	0.0	2.0	0.0000000000	False
model of machine learning	0.0	0.0	7.99783432593	8.0	0.0000000000	False
initial foray into learning	0.0	0.0	0.0	2.0	0.0000000000	False
foray into learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
talk about learning classification	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine lectures	0.0	0.0	0.0	2.0	0.0000000000	False
ll be a bit	0.0	0.0	0.0	2.0	0.0000000000	False
cleaner if i switch	0.0	0.0	0.0	2.0	0.0000000000	False
back to y equals	0.0	0.0	0.0	2.0	0.0000000000	False
model as a model	0.0	0.0	0.0	2.0	0.0000000000	False
forum as logistic regressions	0.0	0.0	0.0	2.0	0.0000000000	False
similar to logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
re going to force	0.0	0.0	0.0	2.0	0.0000000000	False
force the logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
involved in the probabilities	0.0	0.0	0.0	2.0	0.0000000000	False
re given a training	0.0	0.0	0.0	2.0	0.0000000000	False
set of m examples	0.0	0.0	0.0	4.0	0.0000000000	False
ranging from i equals	0.0	0.0	0.0	2.0	0.0000000000	False
assume that the training	0.0	0.0	0.0	2.0	0.0000000000	False
training example is xiyi	0.0	0.0	0.0	2.0	0.0000000000	False
xiyi i ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
identically and definitively distributed	0.0	0.0	0.0	2.0	0.0000000000	False
running a classification problem	0.0	0.0	0.0	2.0	0.0000000000	False
classification problem on houses	0.0	0.0	0.0	2.0	0.0000000000	False
features of the house	0.0	0.0	0.0	2.0	0.0000000000	False
house will be sold	0.0	0.0	0.0	2.0	0.0000000000	False
priority distribution over features	0.0	0.0	0.0	2.0	0.0000000000	False
assume that training examples	0.0	0.0	0.0	2.0	0.0000000000	False
training examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
examples we ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
iid from some probability	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to build	0.0	0.0	0.0	2.0	0.0000000000	False
build a spam classifier	0.0	0.0	0.0	2.0	0.0000000000	False
distribution of what emails	0.0	0.0	0.0	2.0	0.0000000000	False
simplify  to understand	0.0	0.0	0.0	2.0	0.0000000000	False
phenomena of bias invariance	0.0	0.0	0.0	2.0	0.0000000000	False
simplified model of machine	0.0	0.0	5.99837574445	6.0	0.0000000000	False
regression fits this parameters	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood but in order	0.0	0.0	0.0	2.0	0.0000000000	False
order to understand learning	0.0	0.0	0.0	2.0	0.0000000000	False
assume a simplified model	0.0	0.0	0.0	2.0	0.0000000000	False
error of a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis x subscript data	0.0	0.0	0.0	2.0	0.0000000000	False
data write this epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon hat of subscript	0.0	0.0	0.0	2.0	0.0000000000	False
hat of subscript data	0.0	0.0	0.0	2.0	0.0000000000	False
dependence on a training	0.0	0.0	0.0	2.0	0.0000000000	False
sum of indicator functions	0.0	0.0	0.0	2.0	0.0000000000	False
fraction of training examples	0.0	0.0	0.0	4.0	0.0000000000	False
training examples your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
examples your hypothesis classifies	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis classifies so defined	0.0	0.0	0.0	2.0	0.0000000000	False
defined as a training	0.0	0.0	0.0	2.0	0.0000000000	False
training error and training	0.0	0.0	0.0	2.0	0.0000000000	False
error and training error	0.0	0.0	0.0	2.0	0.0000000000	False
risk the simplified model	0.0	0.0	0.0	2.0	0.0000000000	False
minimize my training error	0.0	0.0	0.0	4.0	0.0000000000	False
minimizes your training error	0.0	0.0	0.0	2.0	0.0000000000	False
training error it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out that logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression and support	0.0	0.0	0.0	4.0	0.0000000000	False
regression and support vector	0.0	0.0	0.0	4.0	0.0000000000	False
formally viewed as approximation	0.0	0.0	0.0	2.0	0.0000000000	False
viewed as approximation cities	0.0	0.0	0.0	2.0	0.0000000000	False
solve this optimization problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem and logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
approximations to this nonconvex	0.0	0.0	0.0	2.0	0.0000000000	False
optimization problem by finding	0.0	0.0	0.0	2.0	0.0000000000	False
finding the convex approximation	0.0	0.0	0.0	2.0	0.0000000000	False
similar to what algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
definition of empirical risk	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm as not choosing	0.0	0.0	0.0	2.0	0.0000000000	False
define the hypothesis class	0.0	0.0	0.0	4.0	0.0000000000	False
class of all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
words as the class	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm is choosing	0.0	0.0	0.0	2.0	0.0000000000	False
mapping from the input	0.0	0.0	0.0	2.0	0.0000000000	False
class of all functions	0.0	0.0	0.0	4.0	0.0000000000	False
logistic regression can choose	0.0	0.0	0.0	2.0	0.0000000000	False
redefine empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
function into hypothesis class	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class of script	0.0	0.0	0.0	2.0	0.0000000000	False
script h that minimizes	0.0	0.0	0.0	2.0	0.0000000000	False
minimizes  that minimizes	0.0	0.0	0.0	2.0	0.0000000000	False
hand if it makes	0.0	0.0	0.0	2.0	0.0000000000	False
function from the class	0.0	0.0	0.0	2.0	0.0000000000	False
general case this set	0.0	0.0	0.0	2.0	0.0000000000	False
functions represented by viewer	0.0	0.0	0.0	2.0	0.0000000000	False
represented by viewer network	0.0	0.0	0.0	2.0	0.0000000000	False
functions the learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm wants to choose	0.0	0.0	0.0	2.0	0.0000000000	False
definition for empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
minimization will still apply	0.0	0.0	0.0	2.0	0.0000000000	False
understand whether empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
alex ? a function	0.0	0.0	0.0	2.0	0.0000000000	False
function that s defined	0.0	0.0	0.0	0.0	0.0000000000	False
question is h data	0.0	0.0	0.0	2.0	0.0000000000	False
purpose of this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
data is the class	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm or logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
mapping from the infa	0.0	0.0	0.0	2.0	0.0000000000	False
domain to the center	0.0	0.0	0.0	2.0	0.0000000000	False
center of class label	0.0	0.0	0.0	2.0	0.0000000000	False
perform empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
minimization over any hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
class for the purpose	0.0	0.0	0.0	2.0	0.0000000000	False
restrict myself to talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking about binary classification	0.0	0.0	0.0	2.0	0.0000000000	False
regression in other problem	0.0	0.0	0.0	2.0	0.0000000000	False
question ? yes cool	0.0	0.0	0.0	2.0	0.0000000000	False
right so i wan	0.0	0.0	0.0	2.0	0.0000000000	False
understand if empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
things we can prove	0.0	0.0	0.0	2.0	0.0000000000	False
care about training error	0.0	0.0	0.0	2.0	0.0000000000	False
predictions on the training	0.0	0.0	0.0	2.0	0.0000000000	False
goal the ultimate goal	0.0	0.0	0.0	2.0	0.0000000000	False
makes predictions on examples	0.0	0.0	0.0	2.0	0.0000000000	False
predicts prices or sale	0.0	0.0	0.0	2.0	0.0000000000	False
sale or no sale	0.0	0.0	0.0	2.0	0.0000000000	False
sale outcomes of houses	0.0	0.0	0.0	2.0	0.0000000000	False
care about is generalization	0.0	0.0	0.0	2.0	0.0000000000	False
defined as the probability	0.0	0.0	0.0	2.0	0.0000000000	False
terms of notational convention	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon hat training error	0.0	0.0	0.0	2.0	0.0000000000	False
error as an attempt	0.0	0.0	0.0	2.0	0.0000000000	False
attempt to approximate generalization	0.0	0.0	0.0	2.0	0.0000000000	False
things with the hats	0.0	0.0	0.0	2.0	0.0000000000	False
re using to estimate	0.0	0.0	0.0	2.0	0.0000000000	False
hat is a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis output by learning	0.0	0.0	0.0	2.0	0.0000000000	False
output by learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
estimate what the functions	0.0	0.0	0.0	2.0	0.0000000000	False
giving us low generalization	0.0	0.0	0.0	2.0	0.0000000000	False
care about in order	0.0	0.0	0.0	2.0	0.0000000000	False
prove our first learning	0.0	0.0	0.0	2.0	0.0000000000	False
first learning theory result	0.0	0.0	0.0	2.0	0.0000000000	False
first is the union	0.0	0.0	0.0	2.0	0.0000000000	False
events in a sense	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over the events	0.0	0.0	0.0	2.0	0.0000000000	False
sort of just set	0.0	0.0	0.0	2.0	0.0000000000	False
set notation for probability	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the probability	0.0	0.0	0.0	4.0	0.0000000000	False
ve seen venn diagrams	0.0	0.0	0.0	2.0	0.0000000000	False
diagrams depictions of probability	0.0	0.0	0.0	2.0	0.0000000000	False
great  the probability	0.0	0.0	0.0	2.0	0.0000000000	False
mass in the union	0.0	0.0	0.0	2.0	0.0000000000	False
things to the sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum of the masses	0.0	0.0	0.0	2.0	0.0000000000	False
turns out that depending	0.0	0.0	0.0	2.0	0.0000000000	False
axioms that probably varies	0.0	0.0	0.0	2.0	0.0000000000	False
written as an axiom	0.0	0.0	0.0	2.0	0.0000000000	False
avitivity are probably measured	0.0	0.0	0.0	2.0	0.0000000000	False
commonly called the union	0.0	0.0	0.0	2.0	0.0000000000	False
variables with mean phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi so the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability of zi equals	0.0	0.0	0.0	2.0	0.0000000000	False
iid for newly random	0.0	0.0	0.0	2.0	0.0000000000	False
equals one through mzi	0.0	0.0	0.0	2.0	0.0000000000	False
random variables by sort	0.0	0.0	0.0	2.0	0.0000000000	False
true value of phi	0.0	0.0	0.0	2.0	0.0000000000	False
holds  this lemma	0.0	0.0	0.0	2.0	0.0000000000	False
variables you will remember	0.0	0.0	0.0	2.0	0.0000000000	False
undergraduate probability or statistics	0.0	0.0	0.0	2.0	0.0000000000	False
probability or statistics class	0.0	0.0	0.0	2.0	0.0000000000	False
average all the things	0.0	0.0	0.0	2.0	0.0000000000	False
coins with bias phi	0.0	0.0	0.0	2.0	0.0000000000	False
observe these m benuve	0.0	0.0	0.0	2.0	0.0000000000	False
probability distribution of phi	0.0	0.0	0.0	2.0	0.0000000000	False
distribution function of phi	0.0	0.0	0.0	2.0	0.0000000000	False
phi hat will converse	0.0	0.0	0.0	2.0	0.0000000000	False
discreet set of values	0.0	0.0	0.0	2.0	0.0000000000	False
roughly to a gaussian	0.0	0.0	0.0	2.0	0.0000000000	False
put s one interval	0.0	0.0	0.0	2.0	0.0000000000	False
mass of the details	0.0	0.0	0.0	2.0	0.0000000000	False
probability that my value	0.0	0.0	0.0	2.0	0.0000000000	False
mass in these tails	0.0	0.0	0.0	2.0	0.0000000000	False
negative two gamma squared	0.0	0.0	10.9967514889	12.0	0.4408352668	False
side of the bound	0.0	0.0	0.0	2.0	0.0000000000	False
two e to negative	0.0	0.0	0.0	2.0	0.0000000000	False
gamma squared so balance	0.0	0.0	0.0	2.0	0.0000000000	False
probability that you make	0.0	0.0	0.0	2.0	0.0000000000	False
variable and the cool	0.0	0.0	0.0	2.0	0.0000000000	False
thing about this bound	0.0	0.0	0.0	2.0	0.0000000000	False
thing behind this bound	0.0	0.0	0.0	2.0	0.0000000000	False
fixed value of gamma	0.0	0.0	0.0	4.0	0.0000000000	False
size of your training	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian will actually shrink	0.0	0.0	0.0	2.0	0.0000000000	False
left in the tails	0.0	0.0	0.0	2.0	0.0000000000	False
tend  are sort	0.0	0.0	0.0	2.0	0.0000000000	False
works for any finer	0.0	0.0	0.0	2.0	0.0000000000	False
central limit theorem approximation	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon to help explain	0.0	0.0	0.0	2.0	0.0000000000	False
reference to central limit	0.0	0.0	0.0	2.0	0.0000000000	False
limit theorem all right	0.0	0.0	0.0	2.0	0.0000000000	False
right so lets start	0.0	0.0	0.0	2.0	0.0000000000	False
lets start to understand	0.0	0.0	0.0	2.0	0.0000000000	False
understand empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
studying empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
minimization for a case	0.0	0.0	0.0	2.0	0.0000000000	False
case of finite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
class of k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
function mapping from inputs	0.0	0.0	0.0	2.0	0.0000000000	False
whichever of these functions	0.0	0.0	0.0	2.0	0.0000000000	False
continuous infinitely large class	0.0	0.0	0.0	2.0	0.0000000000	False
large class of hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
prove the first row	0.0	0.0	0.0	2.0	0.0000000000	False
describe our first learning	0.0	0.0	0.0	2.0	0.0000000000	False
classes so empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
empirical risk minimization takes	0.0	0.0	0.0	2.0	0.0000000000	False
minimization takes the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
bound on the generalization	0.0	0.0	2.99837574445	6.0	0.0000000000	False
error of h hat	0.0	0.0	5.9967514889	12.0	0.4408352668	False
prove that somehow minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
step in this prove	0.0	0.0	0.0	2.0	0.0000000000	False
show that training error	0.0	0.0	0.0	2.0	0.0000000000	False
good approximation to generalization	0.0	0.0	0.0	2.0	0.0000000000	False
approximation to generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
show that this implies	0.0	0.0	0.0	2.0	0.0000000000	False
error of the hypothesis	0.0	0.0	1.99783432593	8.0	0.5277777778	False
hypothesis of empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
slightly notation heavy class	0.0	0.0	0.0	2.0	0.0000000000	False
notation heavy class round	0.0	0.0	0.0	2.0	0.0000000000	False
set of new symbols	0.0	0.0	0.0	2.0	0.0000000000	False
understand what the notation	0.0	0.0	0.0	2.0	0.0000000000	False
notation i was defining	0.0	0.0	0.0	2.0	0.0000000000	False
errors that give approximation	0.0	0.0	0.0	2.0	0.0000000000	False
give approximation generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
imply that minimizing training	0.0	0.0	0.0	2.0	0.0000000000	False
pretty well in terms	0.0	0.0	0.0	2.0	0.0000000000	False
terms of minimizing generalization	0.0	0.0	0.0	2.0	0.0000000000	False
give us a bound	0.0	0.0	0.0	2.0	0.0000000000	False
output by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
lets pick any hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
fixed hypothesis so pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick any one hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis misclassifies the ife	0.0	0.0	0.0	2.0	0.0000000000	False
ife example  excuse	0.0	0.0	0.0	2.0	0.0000000000	False
training set is drawn	0.0	0.0	0.0	2.0	0.0000000000	False
drawn randomly from sum	0.0	0.0	0.0	2.0	0.0000000000	False
randomly from sum distribution	0.0	0.0	0.0	2.0	0.0000000000	False
depending on what training	0.0	0.0	0.0	2.0	0.0000000000	False
training examples i ve	0.0	0.0	0.0	0.0	0.0000000000	False
out what the probability	0.0	0.0	0.0	2.0	0.0000000000	False
takes on the value	0.0	0.0	0.0	2.0	0.0000000000	False
sample my training set	0.0	0.0	0.0	2.0	0.0000000000	False
set iid from distribution	0.0	0.0	0.0	2.0	0.0000000000	False
chance that my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
error of my hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
error of this hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis raise your hand	0.0	0.0	0.0	2.0	0.0000000000	False
hand if that made	0.0	0.0	0.0	2.0	0.0000000000	False
examples i ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
ve drawn are iid	0.0	0.0	0.0	2.0	0.0000000000	False
training examples were drawn	0.0	0.0	0.0	2.0	0.0000000000	False
assumption if you read	0.0	0.0	0.0	2.0	0.0000000000	False
definition of training error	0.0	0.0	0.0	2.0	0.0000000000	False
average of my zis	0.0	0.0	0.0	2.0	0.0000000000	False
drawn from benuve distribution	0.0	0.0	0.0	2.0	0.0000000000	False
average of miid benuve	0.0	0.0	0.0	2.0	0.0000000000	False
miid benuve random variables	0.0	0.0	0.0	2.0	0.0000000000	False
probability that the difference	0.0	0.0	0.0	2.0	0.0000000000	False
training and generalization error	0.0	0.0	0.0	4.0	0.0000000000	False
large than this thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing on the right	0.0	0.0	0.0	4.0	0.0000000000	False
probability my training error	0.0	0.0	0.0	2.0	0.0000000000	False
bounded by this thing	0.0	0.0	0.0	2.0	0.0000000000	False
ve done is approve	0.0	0.0	0.0	2.0	0.0000000000	False
bound for one fixed	0.0	0.0	0.0	2.0	0.0000000000	False
prove is that training	0.0	0.0	0.0	2.0	0.0000000000	False
good estimate for generalization	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in my hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
board so in order	0.0	0.0	0.0	2.0	0.0000000000	False
define a random event	0.0	0.0	0.0	2.0	0.0000000000	False
gamma on a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
bound is the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability that there exists	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis in my class	0.0	0.0	0.0	4.0	0.0000000000	False
make a large error	0.0	0.0	7.99729290742	10.0	0.3259005146	False
error in my estimate	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of generalization error	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis one and make	0.0	0.0	0.0	2.0	0.0000000000	False
large error in estimating	0.0	0.0	0.0	4.0	0.0000000000	False
estimating the generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis two and make	0.0	0.0	0.0	2.0	0.0000000000	False
error in estimating generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error in this estimate	0.0	0.0	0.0	2.0	0.0000000000	False
make a small error	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error in taking	0.0	0.0	0.0	2.0	0.0000000000	False
minus on the right	0.0	0.0	0.0	2.0	0.0000000000	False
sign of the inequality	0.0	0.0	0.0	2.0	0.0000000000	False
sides the minus sign	0.0	0.0	0.0	2.0	0.0000000000	False
sign flips the sign	0.0	0.0	0.0	2.0	0.0000000000	False
sign of the equality	0.0	0.0	0.0	2.0	0.0000000000	False
probability  which abbreviates	0.0	0.0	0.0	2.0	0.0000000000	False
simultaneously for all hypotheses	0.0	0.0	0.0	4.0	0.0000000000	False
hypotheses in our class	0.0	0.0	0.0	2.0	0.0000000000	False
conversions  this sort	0.0	0.0	0.0	2.0	0.0000000000	False
alludes to the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that this shows	0.0	0.0	0.0	2.0	0.0000000000	False
simultaneously converge to epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
close to generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
fact that this converges	0.0	0.0	0.0	2.0	0.0000000000	False
converges for all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
value of gamma computed	0.0	0.0	0.0	4.0	0.0000000000	False
gamma computed ? right	0.0	0.0	0.0	2.0	0.0000000000	False
gamma is a constant	0.0	0.0	0.0	2.0	0.0000000000	False
constant imagine a gamma	0.0	0.0	0.0	2.0	0.0000000000	False
constant that we chose	0.0	0.0	0.0	2.0	0.0000000000	False
true for any fixed	0.0	0.0	0.0	2.0	0.0000000000	False
bound and then sort	0.0	0.0	0.0	2.0	0.0000000000	False
ll choose specific values	0.0	0.0	0.0	2.0	0.0000000000	False
specific values of gamma	0.0	0.0	0.0	2.0	0.0000000000	False
re proved this holds	0.0	0.0	0.0	2.0	0.0000000000	False
proved this holds true	0.0	0.0	0.0	2.0	0.0000000000	False
true for any value	0.0	0.0	0.0	2.0	0.0000000000	False
labs in the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
result wo nt work	0.0	0.0	0.0	0.0	0.0000000000	False
work in this present	0.0	0.0	0.0	2.0	0.0000000000	False
lecture to infinite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
talk concretely about algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
consequences of the understanding	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of these things	0.0	0.0	0.0	2.0	0.0000000000	False
hand if the things	0.0	0.0	0.0	2.0	0.0000000000	False
things i ve proved	0.0	0.0	0.0	0.0	0.0000000000	False
proved so far make	0.0	0.0	0.0	2.0	0.0000000000	False
sense ? okay cool	0.0	0.0	0.0	2.0	0.0000000000	False
great thanks all right	0.0	0.0	0.0	2.0	0.0000000000	False
couple of other forms	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a bound	0.0	0.0	0.0	2.0	0.0000000000	False
fix my training set	0.0	0.0	0.0	4.0	0.0000000000	False
set and then fix	0.0	0.0	0.0	2.0	0.0000000000	False
training set  fix	0.0	0.0	0.0	2.0	0.0000000000	False
probability that uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
probability of something happening	0.0	0.0	0.0	2.0	0.0000000000	False
value of this error	0.0	0.0	0.0	2.0	0.0000000000	False
two other equivalent forms	0.0	0.0	0.0	2.0	0.0000000000	False
forms of the bounds	0.0	0.0	0.0	2.0	0.0000000000	False
proved was given gamma	0.0	0.0	0.0	2.0	0.0000000000	False
probability of uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
gamma and the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability delta of making	0.0	0.0	0.0	2.0	0.0000000000	False
large a training set	0.0	0.0	4.99729290742	10.0	0.2883156297	False
give a uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
conversions bound with parameters	0.0	0.0	0.0	2.0	0.0000000000	False
bound with parameters gamma	0.0	0.0	0.0	2.0	0.0000000000	False
parameters gamma and delta	0.0	0.0	0.0	2.0	0.0000000000	False
form of this result	0.0	0.0	0.0	2.0	0.0000000000	False
long as your training	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that with probability	0.0	0.0	0.0	2.0	0.0000000000	False
error is within gamma	0.0	0.0	0.0	2.0	0.0000000000	False
gamma of generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
undergrad computer science classes	0.0	0.0	0.0	2.0	0.0000000000	False
heard of computational complexity	0.0	0.0	0.0	2.0	0.0000000000	False
sample complexity just means	0.0	0.0	0.0	2.0	0.0000000000	False
achieve a certain bound	0.0	0.0	0.0	2.0	0.0000000000	False
error and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out you can pose	0.0	0.0	0.0	2.0	0.0000000000	False
pose them in sort	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a form	0.0	0.0	0.0	2.0	0.0000000000	False
form of probability bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound or a sample	0.0	0.0	0.0	2.0	0.0000000000	False
find the sample complexity	0.0	0.0	0.0	2.0	0.0000000000	False
give a certain bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound on the errors	0.0	0.0	0.0	2.0	0.0000000000	False
errors and in fact	0.0	0.0	0.0	2.0	0.0000000000	False
complexity bounds often sort	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to achieve	0.0	0.0	0.0	2.0	0.0000000000	False
grows like the log	0.0	0.0	0.0	4.0	0.0000000000	False
log of k grows	0.0	0.0	0.0	2.0	0.0000000000	False
slowly as a function	0.0	0.0	0.0	2.0	0.0000000000	False
right  i learned	0.0	0.0	0.0	2.0	0.0000000000	False
purposes for all values	0.0	0.0	0.0	2.0	0.0000000000	False
fact that m sample	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
class quite a lot	0.0	0.0	0.0	2.0	0.0000000000	False
lot and the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of the training	0.0	0.0	0.0	2.0	0.0000000000	False
talk about infinite hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
classes the final form	0.0	0.0	0.0	2.0	0.0000000000	False
hold m and delta	0.0	0.0	0.0	2.0	0.0000000000	False
delta fixed and solved	0.0	0.0	0.0	2.0	0.0000000000	False
difference in the training	0.0	0.0	0.0	2.0	0.0000000000	False
result of the training	0.0	0.0	0.0	2.0	0.0000000000	False
essentially that uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
uniform conversions will hold	0.0	0.0	0.0	2.0	0.0000000000	False
true with high probability	0.0	0.0	0.0	2.0	0.0000000000	False
assume that uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon of h minus	0.0	0.0	0.0	2.0	0.0000000000	False
prove about the bound	0.0	0.0	0.0	2.0	0.0000000000	False
prove about the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
suppose this holds true	0.0	0.0	0.0	2.0	0.0000000000	False
hat was the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
selected by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
make one more definition	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense of minimizing generalization	0.0	0.0	0.0	2.0	0.0000000000	False
sort of makes sense	0.0	0.0	0.0	2.0	0.0000000000	False
makes sense to compare	0.0	0.0	0.0	2.0	0.0000000000	False
performance of our learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to the performance	0.0	0.0	0.0	2.0	0.0000000000	False
performance of h star	0.0	0.0	0.0	2.0	0.0000000000	False
class is a class	0.0	0.0	0.0	2.0	0.0000000000	False
hope that your learning	0.0	0.0	0.0	2.0	0.0000000000	False
result in three steps	0.0	0.0	0.0	2.0	0.0000000000	False
steps so the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
hat will then gamma	0.0	0.0	0.0	2.0	0.0000000000	False
chosen to minimize training	0.0	0.0	0.0	2.0	0.0000000000	False
nt be any hypothesis	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis with lower training	0.0	0.0	0.0	2.0	0.0000000000	False
error than h hat	0.0	0.0	0.0	2.0	0.0000000000	False
hat so the training	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the training	0.0	0.0	0.0	2.0	0.0000000000	False
error of h star	0.0	0.0	5.99783432593	8.0	0.0000000000	False
hypothesis that minimizes training	0.0	0.0	0.0	2.0	0.0000000000	False
training error h hat	0.0	0.0	0.0	2.0	0.0000000000	False
apply this uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
hat of h star	0.0	0.0	0.0	2.0	0.0000000000	False
star must be moving	0.0	0.0	0.0	4.0	0.0000000000	False
moving gamma of epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
epsilon of h star	0.0	0.0	1.99837574445	6.0	0.0000000000	False
gamma of the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error with estimate	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis  a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
training examples it misclassifies	0.0	0.0	0.0	2.0	0.0000000000	False
misclassifies ? and generalization	0.0	0.0	0.0	2.0	0.0000000000	False
hat is the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that s chosen	0.0	0.0	0.0	0.0	0.0000000000	False
chosen by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm that minimizes training	0.0	0.0	0.0	2.0	0.0000000000	False
defined as the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
out of all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in my class	0.0	0.0	0.0	2.0	0.0000000000	False
minimizes training error epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
tie all these things	0.0	0.0	0.0	2.0	0.0000000000	False
set of k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
fixed m and delta	0.0	0.0	0.0	4.0	0.0000000000	False
form of the theorem	0.0	0.0	0.0	2.0	0.0000000000	False
minimum over all hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
prove this we set	0.0	0.0	0.0	2.0	0.0000000000	False
two times the square	0.0	0.0	0.0	2.0	0.0000000000	False
times the square root	0.0	0.0	0.0	2.0	0.0000000000	False
root term to prove	0.0	0.0	0.0	2.0	0.0000000000	False
theorem we set gamma	0.0	0.0	0.0	2.0	0.0000000000	False
equal to that square	0.0	0.0	0.0	2.0	0.0000000000	False
great so set gamma	0.0	0.0	0.0	2.0	0.0000000000	False
gamma to that square	0.0	0.0	0.0	2.0	0.0000000000	False
board holds with probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability one minus delta	0.0	0.0	0.0	4.0	0.0000000000	False
minus delta right equation	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta this uniform	0.0	0.0	0.0	2.0	0.0000000000	False
delta this uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
star  i guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess and whenever uniform	0.0	0.0	0.0	2.0	0.0000000000	False
boards that this result	0.0	0.0	0.0	2.0	0.0000000000	False
two  generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
star plus two times	0.0	0.0	0.0	2.0	0.0000000000	False
theorem so this result	0.0	0.0	0.0	2.0	0.0000000000	False
result sort of helps	0.0	0.0	0.0	2.0	0.0000000000	False
helps us to quantify	0.0	0.0	0.0	2.0	0.0000000000	False
quantify a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit that bias variance	0.0	0.0	0.0	2.0	0.0000000000	False
tradeoff that i talked	0.0	0.0	0.0	2.0	0.0000000000	False
start of this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
functions and linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
functions and the subset	0.0	0.0	0.0	2.0	0.0000000000	False
subset of the class	0.0	0.0	0.0	2.0	0.0000000000	False
subset of h prime	0.0	0.0	0.0	2.0	0.0000000000	False
holds for infinite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
linear to quadratic functions	0.0	0.0	0.0	2.0	0.0000000000	False
quadratic functions then epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis in my hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
sense of generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
error  the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
function so by switching	0.0	0.0	0.0	2.0	0.0000000000	False
larger class of hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
term k will increase	0.0	0.0	0.0	2.0	0.0000000000	False
finding a better function	0.0	0.0	0.0	2.0	0.0000000000	False
sort of not fitting	0.0	0.0	0.0	2.0	0.0000000000	False
size of your hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
bias of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
variance in your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
fit this hypothesis class	0.0	0.0	0.0	2.0	0.0000000000	False
class to the data	0.0	0.0	0.0	2.0	0.0000000000	False
data and by switching	0.0	0.0	0.0	2.0	0.0000000000	False
increases and your bias	0.0	0.0	0.0	2.0	0.0000000000	False
decreases as a note	0.0	0.0	0.0	2.0	0.0000000000	False
statistics class you ve	0.0	0.0	0.0	0.0	0.0000000000	False
terms of squared error	0.0	0.0	0.0	2.0	0.0000000000	False
out that for classification	0.0	0.0	0.0	2.0	0.0000000000	False
universally accepted formal definition	0.0	0.0	0.0	2.0	0.0000000000	False
formal definition of bias	0.0	0.0	0.0	2.0	0.0000000000	False
variance for classification problems	0.0	0.0	0.0	2.0	0.0000000000	False
classification problems for regression	0.0	0.0	0.0	2.0	0.0000000000	False
problems for regression problems	0.0	0.0	0.0	2.0	0.0000000000	False
error definition for classification	0.0	0.0	0.0	2.0	0.0000000000	False
definition for classification problems	0.0	0.0	0.0	2.0	0.0000000000	False
classification problems it turns	0.0	0.0	0.0	2.0	0.0000000000	False
ve been several competing	0.0	0.0	0.0	2.0	0.0000000000	False
competing proposals for definitions	0.0	0.0	0.0	2.0	0.0000000000	False
definitions okay the cartoon	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon associated with intuition	0.0	0.0	0.0	2.0	0.0000000000	False
fixed training set size	0.0	0.0	0.0	2.0	0.0000000000	False
size m vertical axis	0.0	0.0	0.0	2.0	0.0000000000	False
axis i ll plot	0.0	0.0	0.0	0.0	0.0000000000	False
ll plot model complexity	0.0	0.0	0.0	2.0	0.0000000000	False
complexity and by model	0.0	0.0	0.0	2.0	0.0000000000	False
complexity i mean sort	0.0	0.0	0.0	2.0	0.0000000000	False
remember the bandwidth parameter	0.0	0.0	0.0	2.0	0.0000000000	False
parameter from locally weighted	0.0	0.0	0.0	2.0	0.0000000000	False
locally weighted linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
similar effect in controlling	0.0	0.0	0.0	2.0	0.0000000000	False
model is model complexity	0.0	0.0	0.0	2.0	0.0000000000	False
complexity polynomial i guess	0.0	0.0	0.0	2.0	0.0000000000	False
training error will tend	0.0	0.0	0.0	2.0	0.0000000000	False
complexity of your model	0.0	0.0	0.0	2.0	0.0000000000	False
fit your training set	0.0	0.0	0.0	2.0	0.0000000000	False
find that generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
regime on the left	0.0	0.0	0.0	2.0	0.0000000000	False
re underfitting the data	0.0	0.0	0.0	2.0	0.0000000000	False
bias and this regime	0.0	0.0	0.0	2.0	0.0000000000	False
regime on the right	0.0	0.0	0.0	2.0	0.0000000000	False
variance or you re	0.0	0.0	0.0	0.0	0.0000000000	False
re overfitting the data	0.0	0.0	0.0	2.0	0.0000000000	False
sort of intermediate complexity	0.0	0.0	0.0	2.0	0.0000000000	False
talk about the number	0.0	0.0	0.0	2.0	0.0000000000	False
automatically select model complexities	0.0	0.0	0.0	2.0	0.0000000000	False
area of minimized generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error the last thing	0.0	0.0	0.0	2.0	0.0000000000	False
back to the theorem	0.0	0.0	0.0	2.0	0.0000000000	False
out was an error	0.0	0.0	0.0	2.0	0.0000000000	False
last thing i wan	0.0	0.0	0.0	4.0	0.0000000000	False
wan na do today	0.0	0.0	0.0	2.0	0.0000000000	False
back to this theorem	0.0	0.0	0.0	2.0	0.0000000000	False
fix my error bound	0.0	0.0	0.0	2.0	0.0000000000	False
fix delta and solve	0.0	0.0	0.0	2.0	0.0000000000	False
fixed with k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
fixed then in order	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
choose with empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
two times gamma worse	0.0	0.0	0.0	2.0	0.0000000000	False
error i could obtain	0.0	0.0	0.0	2.0	0.0000000000	False
obtain with this hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hold true with probability	0.0	0.0	0.0	2.0	0.0000000000	False
solving for the error	0.0	0.0	0.0	2.0	0.0000000000	False
re going to convince	0.0	0.0	0.0	2.0	0.0000000000	False
set that term gamma	0.0	0.0	0.0	2.0	0.0000000000	False
term gamma and solve	0.0	0.0	0.0	2.0	0.0000000000	False
result really holds true	0.0	0.0	0.0	2.0	0.0000000000	False
theorem we ve proved	0.0	0.0	0.0	0.0	0.0000000000	False
proved in other words	0.0	0.0	0.0	2.0	0.0000000000	False
bounds in learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
learning theory it turns	0.0	0.0	0.0	2.0	0.0000000000	False
loose so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
bounds usually we re	0.0	0.0	0.0	0.0	0.0000000000	False
interested in the constants	0.0	0.0	0.0	2.0	0.0000000000	False
log k over delta	0.0	0.0	0.0	2.0	0.0000000000	False
size of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class is logarithmic	0.0	0.0	0.0	2.0	0.0000000000	False
cool so next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
start from this result	0.0	0.0	0.0	2.0	0.0000000000	False
generalize these to infinite	0.0	0.0	0.0	2.0	0.0000000000	False
classes and then talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about practical algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
practical algorithms for model	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms for model spectrum	0.0	0.0	0.0	2.0	0.0000000000	False
ll see you guys	0.0	0.0	0.0	2.0	0.0000000000	False
guys in a couple	0.0	0.0	0.0	2.0	0.0000000000	False
email back comments	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
slightly questionable aspects	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
today is start	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
talk about learning	0.00156245566001	0.0	0.0	1.58496250072	0.0000000000	False
guess eight lectures	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
lot of learning	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
tools of machine	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
powerful learning algorithms	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
sorts of problems	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hope you start	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
made an analogy	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
imagine you re	0.0	0.0	0.0	0.0	0.0000000000	False
school to learn	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
acquire a set	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set of tools	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
cut a piece	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
piece of wood	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
mastering the tools	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
machine learning tools	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
machine learning algorithms	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
scenarios in machine	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
learning is someday	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms you learned	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
apply logistic regression	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
support vector machines	0.00356024555418	0.0	4.9967514889	7.92481250361	0.4408352668	True
separates the people	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
compared to people	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
read the textbook	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
apply a support	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
modify the algorithm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
separates the great	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
people in machine	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
machine learning versus	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
versus the people	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
read the text	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
ll the math	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today  today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
start to talk	0.000548550025184	0.0	0.0	0.0	0.0000000000	False
results of machine	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms for sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
theory will point	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
apply learning algorithms	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
thing we re	0.0	0.0	0.0	0.0	0.0000000000	False
bias variance trade-off	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ordinary least squares	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
first learning algorithm	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
algorithm we learned	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
good model right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
underfit the data	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
failing to fit	0.00175559568851	0.0	0.0	3.16992500144	0.0000000000	False
fit the evident	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
evident quadratic structure	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
algorithm as representing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
representing the fact	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
amount of training	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
tons of training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fit the quadratic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithm with high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fit a fourth	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
problem  excuse	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
overfitting the data	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
algorithm has high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
intuition behind overfitting	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
overfitting a high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithm is fitting	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
fitting serious patterns	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fitting idiosyncratic properties	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
dataset of housing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
medium of fitting	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fitting a quadratic	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
interpolate your data	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
picture of classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
positive and negative	0.00109710005037	0.0	0.0	1.58496250072	0.0000000000	False
fit logistic regression	0.00141264461515	0.0	0.0	3.16992500144	0.0000000000	False
high order polynomial	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
equals the sigmoid	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sigmoid function applied	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
separate the positive	0.000645120039435	0.0	0.0	1.58496250072	0.0000000000	False
contrast you fit	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
understand this problem	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
problem of overfitting	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
overfitting versus underfitting	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bias versus high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
versus high variance	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
model of machine	0.00498633375858	0.0	7.99783432593	3.16992500144	0.4175824176	False
two twin problems	0.0	0.0	0.0	1.58496250072	0.0000000000	False
foray into learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
indicator z grading	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
apologies in advance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
advance for changing	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
changing the notation	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
vector machine lectures	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
learning theory lectures	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
forum as logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
similar to logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
force the logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
logistic regression algorithm	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
opt for labels	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
classifier to opt	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
notation for writing	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
writing a set	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
xiyi i ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve drawn iid	0.0	0.0	0.0	3.16992500144	0.0000000000	False
running a classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problem on houses	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
distribution over features	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
features of houses	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ll be sold	0.0	0.0	0.0	3.16992500144	0.0000000000	False
assume that training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
thing for spam	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
build a spam	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
understand or simplify	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
understand the phenomena	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
phenomena of bias	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
logistic regression fits	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fits this parameters	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
parameters the model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
maximizing the law	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
law of likelihood	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
order to understand	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
understand learning algorithms	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
assume a simplified	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
define training error	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis x subscript	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
subscript data write	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
write this epsilon	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hat of subscript	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
make the dependence	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
training set explicit	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hope the notation	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
notation is clear	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sum of indicator	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis correctly classifies	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fraction of training	0.00202781126965	0.0	0.0	0.0	0.0000000000	False
examples your hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
classifies so defined	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error and training	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
risk the simplified	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
empirical risk minimization	0.0192642070617	1.0	7.98971304819	28.529325013	0.3653846154	True
learning algorithm works	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
choose parameters data	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
minimize my training	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
ll prove properties	0.0	0.0	0.0	1.58496250072	0.0000000000	False
basic learning algorithm	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that minimizes	0.00202781126965	0.0	0.0	1.58496250072	0.0000000000	False
minimizes your training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error it turns	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
out that logistic	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
regression and support	0.00175559568851	0.0	0.0	0.0	0.0000000000	False
viewed as approximation	0.00202781126965	0.0	0.0	1.58496250072	0.0000000000	False
nonconvex optimization problem	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
hard to solve	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
solve this optimization	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
problem and logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problem by finding	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
finding the convex	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms like logistic	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
definition of empirical	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
choosing a set	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
set of parameters	0.00129024007887	0.0	0.0	3.16992500144	0.0000000000	False
choosing a function	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
define the hypothesis	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm is choosing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
specific linear classifier	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
vary the parameter	0.0	0.0	0.0	1.58496250072	0.0000000000	False
parameter s data	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis class script	0.00506952817413	0.0	2.99783432593	6.33985000288	0.5277777778	False
regression can choose	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
redefine empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
writing this choosing	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
function into hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class of script	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00220825242347	0.0	3.99729290742	6.33985000288	0.4408352668	False
algorithms as choosing	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
choosing from function	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
case this set	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class of functions	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
represented by viewer	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
functions the learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
definition for empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
understand whether empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
reasonable algorithm alex	0.0	0.0	0.0	1.58496250072	0.0000000000	False
data still defined	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
framework is general	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
mind a model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
algorithm or logistic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
set of functions	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
center of class	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
perform empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
purpose of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talking about binary	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
generalizes to regression	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
answer your question	0.0	0.0	0.0	1.58496250072	0.0000000000	False
cool all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
wan na understand	0.0	0.0	0.0	1.58496250072	0.0000000000	False
understand if empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt actually care	0.0	0.0	0.0	0.0	0.0000000000	False
care about training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt really care	0.0	0.0	0.0	0.0	0.0000000000	False
care about making	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
making accurate predictions	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
goal the ultimate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
makes  generalization	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
predictions on examples	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prices or sale	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
outcomes of houses	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
write as epsilon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
terms of notational	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
place a hat	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hat on top	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
attempt to estimate	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
epsilon hat training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hat training error	0.00124658343965	0.0	4.99783432593	4.75488750216	0.0000000000	False
attempt to approximate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
approximate generalization error	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
top are things	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
estimate other quantities	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
output by learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prove some things	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sense of giving	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
giving us low	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
low generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
order to prove	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
prove our first	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
first learning theory	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
learning theory result	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
state two lemmas	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
two or dot	0.0	0.0	0.0	1.58496250072	0.0000000000	False
means this sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
notation for probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
probability just means	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
two plus dot	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ve seen venn	0.0	0.0	0.0	0.0	0.0000000000	False
venn diagrams depictions	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
depictions of probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
surprising it turns	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
out that depending	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
define your axioms	0.0	0.0	0.0	1.58496250072	0.0000000000	False
axioms of probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
axiom so sigmas	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sigmas of avitivity	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
nt actually prove	0.0	0.0	0.0	0.0	0.0000000000	False
ll just state	0.0	0.0	0.0	1.58496250072	0.0000000000	False
equal to phi	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
observe m iid	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
newly random variables	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
phi hat means	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
semper my equals	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
benuve random variables	0.00997266751716	0.0	7.99566865187	11.094737505	0.0000000000	False
variables by sort	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of taking	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
taking its average	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gamma be fixed	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
probability your estimate	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
estimate of phi	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
value of phi	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two gamma squared	0.0	0.0	10.9962100704	1.58496250072	0.4408352668	False
statement of fact	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
draw a cartoon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
cartoon to describe	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
guess so lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
real number line	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
probability or statistics	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
central limit theorem	0.00608343380895	0.0	4.9967514889	7.92481250361	0.2342786683	True
toss m coins	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
coins with bias	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
distribution of phi	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
cumulative distribution function	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
function of phi	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
hat will converse	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gaussian technically phi	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set of values	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
pick a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of gamma	0.00124658343965	0.0	4.99621007038	9.50977500433	0.2883156297	False
words the probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
total probability mass	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
negative two gamma	0.00997266751716	0.0	10.9967514889	0.0	0.3986013986	False
right hand side	0.0	0.0	6.99783432593	6.33985000288	0.0000000000	False
squared so balance	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
balance the probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
make a mistake	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
mistake in estimating	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
increase the size	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
toss a coin	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gaussian will shrink	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
shrink the worth	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
probability mass left	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
tails to decrease	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
familiar with tend	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of asymptotic	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
limit theorem approximation	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
explain the intuition	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
theorem just holds	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
reference to central	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
theorem all right	0.0	0.0	0.0	0.0	0.0000000000	False
right so lets	0.0	0.0	0.0	0.0	0.0000000000	False
start to understand	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
understand empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
begin with studying	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
studying empirical risk	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
start with studying	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
studying the case	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
case of finite	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
finite hypothesis classes	0.00304171690448	0.0	5.99566865187	12.6797000058	0.0000000000	False
mapping from inputs	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
inputs to outputs	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
lowest training error	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
continuous infinitely large	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
infinitely large class	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class of hypotheses	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
prove the first	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
describe our first	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
first learning theorem	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ll later generalize	0.0	0.0	0.0	1.58496250072	0.0000000000	False
classes so empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
risk minimization takes	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
takes the hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prove a bound	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
hat all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minimizing training error	0.00608343380895	0.0	3.9967514889	7.92481250361	0.3986013986	False
show that training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
approximation to generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
implies a bound	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis of empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class i guess	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
slightly notation heavy	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
notation heavy class	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
heavy class round	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt quite remember	0.0	0.0	0.0	0.0	0.0000000000	False
empirical risk strategy	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
show training errors	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
errors that give	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
give approximation generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
imply that minimizing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
terms of minimizing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
minimizing generalization error	0.00498633375858	0.0	3.99783432593	6.33985000288	0.0000000000	False
output by empirical	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
idea so lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
pick any hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis so pick	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
misclassifies the ife	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis was classified	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set is drawn	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
randomly from sum	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sum distribution scripts	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
examples i ve	0.0	0.0	0.0	0.0	0.0000000000	False
sample my training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
training set iid	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
iid from distribution	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis will misclassify	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
drawn are iid	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
iid random variables	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
examples were drawn	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
definition of training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
average of miid	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
drawn from benuve	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
miid benuve random	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
add the probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
difference between training	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
training and generalization	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
greater than gamma	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
set is large	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
probability my training	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
approve this bound	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
estimate for generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
order to show	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
define a random	0.0	0.0	0.0	0.0	0.0000000000	False
exists some hypothesis	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
make a large	0.00623291719823	0.0	7.99729290742	0.0	0.3259005146	False
estimate of generalization	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
exists a hypothesis	0.00373975031894	0.0	5.99837574445	4.75488750216	0.0000000000	False
holds the chance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
chance there exists	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
error in estimating	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
estimating the generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
two and make	0.0	0.0	0.0	0.0	0.0000000000	False
estimating generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
minus both sides	0.00373975031894	0.0	5.99837574445	4.75488750216	0.0000000000	False
exist for hypothesis	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
make a small	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
error in taking	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
taking one minus	0.00124658343965	0.0	5.99837574445	4.75488750216	0.0000000000	False
sides the minus	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
minus sign flips	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
flips the sign	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
probability one minus	0.00373975031894	0.0	2.99837574445	1.58496250072	0.0000000000	False
gamma of epsilon	0.00249316687929	0.0	0.0	1.58496250072	0.0000000000	False
give this result	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
uniform conversions result	0.00498633375858	1.0	2.99783432593	6.33985000288	0.0000000000	False
term uniform conversions	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of alludes	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
converge to epsilon	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
close to generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
term uniform refers	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
clean a couple	0.000877797844255	0.0	0.0	1.58496250072	0.0000000000	False
couple more boards	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
computed ? right	0.0	0.0	0.0	0.0	0.0000000000	False
imagine a gamma	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
chose in advance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound that holds	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
sort of develop	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
develop this result	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
ll choose specific	0.0	0.0	0.0	0.0	0.0000000000	False
choose specific values	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll just imagine	0.0	0.0	0.0	1.58496250072	0.0000000000	False
proved this holds	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gamma any questions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
phase is infinite	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
lecture to infinite	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
infinite hypothesis classes	0.00506952817413	1.0	4.99729290742	7.92481250361	0.0000000000	False
concretely about algorithms	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
things i ve	0.0	0.0	0.0	0.0	0.0000000000	False
uniform conversions bound	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
bound and rewrite	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound on probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
suppose i fix	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fix my training	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
set  fix	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fix my threshold	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
error threshold gamma	0.00124658343965	0.0	0.0	3.16992500144	0.0000000000	False
probability that uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
uniform conversions holds	0.00498633375858	0.0	2.99783432593	6.33985000288	0.0000000000	False
parameters of interest	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
training set size	0.00438898922128	0.0	3.99729290742	6.33985000288	0.3259005146	False
two other equivalent	0.0	0.0	0.0	0.0	0.0000000000	False
probability of uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
delta of making	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
large a training	0.00747950063787	0.0	5.9967514889	1.58496250072	0.2602739726	False
order to give	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
give a bound	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
give a uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
bound with parameters	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gamma and delta	0.0	0.0	0.0	0.0	0.0000000000	False
training set assigns	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
greater than equal	0.000645120039435	0.0	0.0	1.58496250072	0.0000000000	False
gamma of generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sample complexity bound	0.00498633375858	0.0	3.99783432593	6.33985000288	0.0000000000	False
undergrad computer science	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
computer science classes	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
heard of computational	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
complexity just means	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
means how large	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
large a sample	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sample of examples	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
order to achieve	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound and error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
theorems we write	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
form of probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
personally often find	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
find the sample	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
easy to interpret	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bounds often sort	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
machine learning problem	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
slowest growing functions	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
true so log	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sample complexity grows	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
increase this number	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
number of hypotheses	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
talk about infinite	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
classes the final	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fixed and solved	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
solved for gamma	0.00202781126965	0.0	0.0	3.16992500144	0.0000000000	False
training generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gamma and plugging	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
plugging the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
essentially that uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
conversions will hold	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
true with high	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
assume that uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
suppose this holds	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
selected by empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
define h star	0.0	0.0	0.0	1.58496250072	0.0000000000	False
smallest generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sense of minimizing	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of makes	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
sense to compare	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
compare the performance	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
linear decision boundaries	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
nt be separated	0.0	0.0	0.0	0.0	0.0000000000	False
prove this result	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis i chose	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
number these equations	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hat and epsilon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hat was chosen	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
chosen to minimize	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis with lower	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
lower training error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that minimizes	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error h hat	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
apply this uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
error with estimate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
examples it misclassifies	0.0	0.0	0.0	0.0	0.0000000000	False
chosen by empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
talk about empirical	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
hat is defined	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
training error epsilon	0.00249316687929	0.0	0.0	0.0	0.0000000000	False
member of typical	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
delta be fixed	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
error bound form	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hypotheses in set	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set h epsilon	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
gamma to equal	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
times the square	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
square root term	0.00373975031894	0.0	2.99837574445	4.75488750216	0.0000000000	False
term to prove	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
prove this theorem	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
theorem we set	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
great so set	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
previous board holds	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
holds with probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
minus delta right	0.0	0.0	0.0	0.0	0.0000000000	False
delta right equation	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
set gamma equal	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
delta this uniform	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
call this equation	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
equation  star	0.0	0.0	0.0	1.58496250072	0.0000000000	False
two  generalization	0.0	0.0	0.0	0.0	0.0000000000	False
two times gamma	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of helps	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bit that bias	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
bias variance tradeoff	0.00304171690448	0.0	3.99837574445	4.75488750216	0.0000000000	True
functions and linear	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
class h prime	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
features so lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
linear hypothesis class	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
quadratic hypothesis class	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
larger hypothesis class	0.00373975031894	0.0	2.99837574445	4.75488750216	0.0000000000	False
holds for infinite	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
switch from linear	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
linear to quadratic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
functions then epsilon	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sense of generalization	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
lowest generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
lower generalization error	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
complex hypothesis class	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
increase by switching	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
term will increase	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
hope for finding	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
risk of sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fitting my model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
accurately also increases	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fit a hypothesis	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fit this hypothesis	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
note of warning	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
class you ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve seen definitions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
definitions of bias	0.00373975031894	0.0	4.99837574445	3.16992500144	0.0000000000	False
bias and variance	0.00351119137702	0.0	6.99783432593	6.33985000288	0.0000000000	False
defined in terms	0.000781227830005	0.0	0.0	1.58496250072	0.0000000000	False
terms of squared	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
universally accepted formal	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
accepted formal definition	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
variance for classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problems for regression	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
square error definition	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
definition for classification	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
problems it turns	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
out there ve	0.0	0.0	0.0	0.0	0.0000000000	False
proposals for definitions	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
fixed training set	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
size m vertical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll plot model	0.0	0.0	0.0	0.0	0.0000000000	False
plot model complexity	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of degree	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
degree of polynomial	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
remember the bandwidth	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
locally weighted linear	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
weighted linear regression	0.00101390563483	0.0	0.0	0.0	0.0000000000	False
effect in controlling	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
controlling how complex	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
complex your model	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
model is model	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
model complexity polynomial	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
polynomial i guess	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error will tend	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
increase the complexity	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
complete your model	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fit your training	0.000877797844255	0.0	0.0	0.0	0.0000000000	False
find that generalization	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
model of sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of intermediate	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll actually talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
number of algorithms	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
automatically select model	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
select model complexities	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
area of minimized	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
error the last	0.0	0.0	0.0	0.0	0.0000000000	False
theorem i wrote	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
error bound theorem	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
delta where probability	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
bound on gamma	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
thing i wan	0.0	0.0	5.99783432593	3.16992500144	0.0000000000	False
theorem and write	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
out a corollary	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
fix my error	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
delta and solve	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
delta and gamma	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
order to guarantee	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis i choose	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
choose with empirical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
times gamma worse	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
hypothesis class lets	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
true with probability	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
sort of solving	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
set that term	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
gamma and solve	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
home and sort	0.00101390563483	0.0	0.0	1.58496250072	0.0000000000	False
sort of convince	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
result really holds	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
theorem we ve	0.0	0.0	0.0	0.0	0.0000000000	False
formula we wrote	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
wrote and solve	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
back and convince	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
prove these bounds	0.00249316687929	0.0	0.0	3.16992500144	0.0000000000	False
bounds in learning	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
theory it turns	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
constants are sort	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
sort of loose	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
class is logarithmic	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
ll actually start	0.0	0.0	0.0	1.58496250072	0.0000000000	False
result again remember	0.00124658343965	0.0	0.0	1.58496250072	0.0000000000	False
talk about practical	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
algorithms for model	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
good morning	0.000294433656463	0.0	0.0	1.0	0.0000000000	False
quick announcement	0.00043008002629	0.0	0.0	1.0	0.0000000000	False
first things	0.000675073424372	0.0	1.99837574445	3.0	0.0000000000	False
project proposals	0.000941763076769	0.0	0.0	2.0	0.0000000000	False
back comments	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
questionable aspects	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
exciting proposals	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
proposal session	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
exciting event	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
learning theory	0.00376705230707	1.0	6.99566865187	7.0	0.4408352668	True
learning algorithms	0.0057741912846	0.0	13.9886302112	20.0	0.3486238532	True
powerful tools	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
machine learning	0.00474699407224	0.0	14.9935029778	11.0	0.3937823834	False
powerful learning	0.00135187417977	0.0	0.0	0.0	0.0000000000	False
first lecture	0.000520818553337	0.0	0.0	1.0	0.0000000000	False
carpentry school	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
small part	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
tool box	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
essential part	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
good carpenter	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
learning tools	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
common scenarios	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
logistic regression	0.00548550025184	0.0	12.9918787223	14.0	0.4679802956	True
support vector	0.00237349703612	0.0	4.9967514889	4.0	0.4596774194	False
vector machines	0.00237349703612	0.0	4.9967514889	4.0	0.4408352668	False
bizarre reason	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
great people	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
learning versus	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
text book	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
theoretical results	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
practical advice	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
apply learning	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
first homework	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
bias variance	0.00270374835953	0.0	3.99783432593	3.0	0.5277777778	True
variance trade-off	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
first learning	0.00202781126965	0.0	1.99837574445	2.0	0.0000000000	False
straight line	0.00036570001679	0.0	0.0	1.0	0.0000000000	False
good model	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
model right	0.0	0.0	0.0	0.0	0.0000000000	False
high bias	0.00234079425135	0.0	3.99783432593	3.0	0.0000000000	False
quadratic structure	0.00135187417977	0.0	0.0	1.0	0.0000000000	False
infinite amount	0.00117039712567	0.0	0.0	0.0	0.0000000000	False
training data	0.00158233135741	0.0	2.99783432593	3.0	0.4175824176	False
quadratic function	0.00258048015774	0.0	3.9967514889	5.0	0.4175824176	False
opposite problem	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
data points	0.000941763076769	0.0	0.0	1.0	0.0000000000	False
great model	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
high variance	0.00234079425135	0.0	5.99783432593	3.0	0.0000000000	False
idiosyncratic properties	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
specific dataset	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
housing prices	0.000470881538384	0.0	0.0	0.0	0.0000000000	False
happy medium	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
simple model	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
classification problems	0.00215040013145	0.0	5.99729290742	4.0	0.0000000000	False
training set	0.00647754044219	0.0	9.98808879264	21.0	0.3885480573	False
negative examples	0.00043008002629	0.0	0.0	0.0	0.0000000000	False
high order	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
sigmoid function	0.00104163710667	0.0	0.0	1.0	0.0000000000	False
function applied	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
decision boundary	0.00156245566001	0.0	3.99837574445	2.0	0.0000000000	False
negative classes	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
linear features	0.00166211125286	0.0	0.0	2.0	0.0000000000	False
quadratic features	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
overfitting versus	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
versus underfitting	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
formal model	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
twin problems	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
initial foray	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
learning classification	0.00083105562643	1.0	0.0	1.0	0.0000000000	False
data transpose	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
learning classifier	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
machine lectures	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
equals minus	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
theory lectures	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
bit cleaner	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
original notation	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
model forum	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
regression algorithm	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
examples ranging	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
sum distribution	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
priority distribution	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
training examples	0.00221034101286	0.0	5.99512723335	9.0	0.3770672547	False
probability distributions	0.00118674851806	0.0	1.99837574445	2.0	0.0000000000	False
spam classifier	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
bias invariance	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
simplified model	0.00249316687929	0.0	5.99837574445	2.0	0.0000000000	False
regression fits	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
understand learning	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
define training	0.0	0.0	0.0	0.0	0.0000000000	False
training error	0.0210671482621	0.0	18.9805089334	35.0	0.3343741130	True
subscript data	0.00415527813215	0.0	3.99729290742	4.0	0.0000000000	False
data write	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
set explicit	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
indicator functions	0.00086016005258	0.0	0.0	1.0	0.0000000000	False
hypothesis classifies	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
empirical risk	0.0135187417977	0.0	7.98917162967	19.0	0.4042553191	False
risk minimization	0.0128428047078	0.0	7.98971304819	16.0	0.3653846154	False
algorithm works	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
choose parameters	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
parameters data	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
prove properties	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
basic learning	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
approximation cities	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
nonconvex optimization	0.00166211125286	0.0	0.0	0.0	0.0000000000	False
optimization problem	0.00129024007887	0.0	2.99837574445	2.0	0.0000000000	False
convex approximation	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
prove today	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
hypothesis class	0.0187263540108	0.0	23.982133189	31.0	0.3054662379	False
linear classifiers	0.00208327421335	0.0	3.99783432593	3.0	0.0000000000	True
specific linear	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
function mapping	0.00249316687929	0.0	0.0	1.0	0.0000000000	False
input domain	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
class zero-one	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
class script	0.00675937089883	0.0	6.99512723335	5.0	0.5036818851	False
redefine empirical	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
makes sense	0.000842325920971	0.0	5.9967514889	6.0	0.0000000000	False
previous formulation	0.0	0.0	0.0	1.0	0.0000000000	False
general case	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
functions represented	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
viewer network	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
reasonable algorithm	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
algorithm alex	0.0	0.0	0.0	0.0	0.0000000000	False
phase transpose	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
visectron algorithm	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
infa domain	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
class label	0.000470881538384	0.0	0.0	0.0	0.0000000000	False
binary classification	0.00083105562643	1.0	0.0	0.0	0.0000000000	False
accurate predictions	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
ultimate goal	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
makes predictions	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
predicts prices	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
sale outcomes	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
generalization error	0.0304171690448	0.0	33.9756361668	44.0	0.3754116356	True
distribution scripts	0.00337968544942	0.0	3.99837574445	2.0	0.0000000000	False
hypothesis mislabels	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
notational convention	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
approximate generalization	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
hypothesis output	0.00117039712567	0.0	0.0	1.0	0.0000000000	False
low generalization	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
theory result	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
union vowel	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
probabilistic event	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
necessarily independent	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
current distribution	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
union symbol	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
set notation	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
events occurring	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
venn diagrams	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
diagrams depictions	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
total mass	0.00166211125286	0.0	0.0	2.0	0.0000000000	False
individual sets	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
union balance	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
hufting inequality	0.00581738938501	0.0	9.99621007038	7.0	0.4175824176	False
random variables	0.00373275649167	0.0	9.99404439632	9.0	0.2945736434	False
newly random	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
define phi	0.0	0.0	0.0	2.0	0.0000000000	False
benuve random	0.00664844501144	0.0	7.99566865187	5.0	0.3937823834	False
true value	0.0	0.0	0.0	1.0	0.0000000000	False
gamma squared	0.00675937089883	0.0	10.9945858148	6.0	0.4188976378	False
theorem holds	0.00166211125286	0.0	0.0	2.0	0.0000000000	False
holds true	0.00356024555418	0.0	5.99512723335	8.0	0.3986013986	False
real number	0.000294433656463	0.0	0.0	0.0	0.0000000000	False
number line	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
undergraduate probability	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
statistics class	0.00104163710667	0.0	0.0	2.0	0.0000000000	False
central limit	0.0040556225393	0.0	4.9967514889	4.0	0.1932203390	False
limit theorem	0.00473155962918	0.0	4.9967514889	4.0	0.2342786683	False
gaussian distribution	0.00043008002629	0.0	0.0	1.0	0.0000000000	False
bias phi	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
gaussian lets	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
cumulative distribution	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
distribution function	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
discreet set	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
interval gamma	0.00166211125286	0.0	0.0	2.0	0.0000000000	False
probability mass	0.00202781126965	0.0	3.99837574445	2.0	0.0000000000	False
total probability	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
right hand	0.0	0.0	6.99783432593	0.0	0.4175824176	False
hand side	0.00172032010516	0.0	6.99783432593	0.0	0.0000000000	False
cool thing	0.000585198562837	0.0	0.0	1.0	0.0000000000	False
interesting thing	0.000395582839353	0.0	0.0	1.0	0.0000000000	False
fixed value	0.0	0.0	1.99837574445	1.0	0.0000000000	False
mass left	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
finer value	0.0	0.0	0.0	1.0	0.0000000000	False
bound holds	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
theorem approximation	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
lets start	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
finite hypothesis	0.00202781126965	0.0	5.99566865187	4.0	0.0000000000	False
hypotheses right	0.0	0.0	0.0	1.0	0.0000000000	False
lowest training	0.00135187417977	0.0	0.0	0.0	0.0000000000	False
large class	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
first row	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
learning theorem	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
minimization takes	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
minimizing training	0.0040556225393	0.0	3.9967514889	5.0	0.3986013986	False
first step	0.000315763001837	0.0	0.0	1.0	0.0000000000	False
good approximation	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
slightly notation	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
heavy class	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
class round	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
large set	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
risk strategy	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
show training	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
give approximation	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
minimizing generalization	0.00332422250572	0.0	3.99783432593	3.0	0.4175824176	False
lets pick	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
notice lets	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
fixed hypothesis	0.00332422250572	0.0	5.99783432593	3.0	0.0000000000	False
hypothesis misclassifies	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
set iid	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
hypothesis raise	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
made sense	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
cool great	0.000941763076769	0.0	0.0	2.0	0.0000000000	False
iid random	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
benuve distribution	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
miid benuve	0.00166211125286	0.0	0.0	0.0	0.0000000000	False
high probability	0.00135187417977	0.0	0.0	1.0	0.0000000000	False
tricky part	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
good estimate	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
random event	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
previous board	0.00197791419677	0.0	3.99729290742	4.0	0.3259005146	False
pretty small	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
large error	0.00415527813215	0.0	7.99729290742	2.0	0.3259005146	False
estimating generalization	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
union bound	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
small error	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
inequality flipped	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
minus sign	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
sign flips	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
uniform conversions	0.0081112450786	0.0	10.9929615593	12.0	0.3725490196	True
conversions result	0.00332422250572	0.0	2.99783432593	0.0	0.0000000000	False
term uniform	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
epsilon hats	0.01163477877	0.0	9.99242014077	13.0	0.4018126888	False
uniform refers	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
gamma computed	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
constant imagine	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
specific values	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
hypothesis phase	0.00166211125286	0.0	0.0	2.0	0.0000000000	False
simple result	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
present form	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
infinite hypothesis	0.00337968544942	0.0	4.99729290742	3.0	0.5205479452	False
conversions bound	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
error threshold	0.00135187417977	0.0	0.0	0.0	0.0000000000	False
threshold gamma	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
conversions holds	0.00332422250572	0.0	2.99783432593	0.0	0.0000000000	False
set size	0.00292599281418	0.0	3.99729290742	2.0	0.3259005146	False
equivalent forms	0.00249316687929	0.0	2.99837574445	2.0	0.0000000000	False
probability delta	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
parameters gamma	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
set delta	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
set assigns	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
minus delta	0.00468158850269	0.0	6.99566865187	7.0	0.5428571429	False
sample complexity	0.0040556225393	0.0	6.9967514889	5.0	0.1932203390	False
complexity bound	0.00332422250572	0.0	3.99783432593	2.0	0.0000000000	False
undergrad computer	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
computer science	0.000731400033579	0.0	0.0	1.0	0.0000000000	False
science classes	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
computational complexity	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
probability bound	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
give guidance	0.00166211125286	0.0	0.0	2.0	0.0000000000	False
learning problem	0.000339341499243	0.0	0.0	0.0	0.0000000000	False
growing functions	0.00166211125286	0.0	0.0	0.0	0.0000000000	False
carnegie mellon	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
practical purposes	0.000520818553337	0.0	0.0	1.0	0.0000000000	False
complexity grows	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
final form	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
error bound	0.00337968544942	0.0	6.99729290742	4.0	0.4408352668	False
delta fixed	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
training generalization	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
minus epsilon	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
hypothesis selected	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
smallest generalization	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
linear decision	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
linear functions	0.00158233135741	0.0	2.99783432593	4.0	0.0000000000	False
lower training	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
final step	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
moving gamma	0.00166211125286	0.0	0.0	1.0	0.0000000000	False
original gamma	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
error epsilon	0.00135187417977	0.0	0.0	0.0	0.0000000000	False
finite set	0.00043008002629	0.0	0.0	1.0	0.0000000000	False
bound form	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
set gamma	0.00332422250572	0.0	3.99783432593	3.0	0.2945736434	False
square root	0.00202781126965	0.0	2.99837574445	1.0	0.0000000000	False
root term	0.00249316687929	0.0	2.99837574445	1.0	0.0000000000	False
board holds	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
delta right	0.0	0.0	0.0	0.0	0.0000000000	False
right equation	0.0	0.0	0.0	0.0	0.0000000000	False
result holds	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
times gamma	0.00135187417977	0.0	0.0	1.0	0.0000000000	False
result sort	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
variance tradeoff	0.00202781126965	0.0	3.99837574445	0.0	0.0000000000	False
linear regression	0.000791165678706	0.0	0.0	1.0	0.0000000000	False
linear hypothesis	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
quadratic hypothesis	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
larger hypothesis	0.00249316687929	0.0	2.99837574445	0.0	0.0000000000	False
tradeoffs involved	0.0	0.0	0.0	1.0	0.0000000000	False
similar holds	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
hypothesis function	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
lowest generalization	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
lower generalization	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
complex hypothesis	0.00166211125286	0.0	0.0	0.0	0.0000000000	False
first term	0.00175559568851	0.0	2.99837574445	3.0	0.0000000000	False
larger class	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
variance increases	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
bias decreases	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
squared error	0.00135187417977	0.0	0.0	1.0	0.0000000000	False
formal definition	0.00104163710667	0.0	0.0	1.0	0.0000000000	False
regression problems	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
error definition	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
competing proposals	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
intuitive definitions	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
fixed training	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
vertical axis	0.000470881538384	0.0	0.0	0.0	0.0000000000	False
horizontal axis	0.00043008002629	0.0	0.0	1.0	0.0000000000	False
plot model	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
model complexity	0.00270374835953	0.0	7.99783432593	3.0	0.0000000000	False
bandwidth parameter	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
similar effect	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
complexity polynomial	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
intermediate complexity	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
select model	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
last thing	0.0	0.0	0.0	1.0	0.0000000000	False
bound theorem	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
fix gamma	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
fix delta	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
gamma worse	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
class lets	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
easy part	0.00166211125286	0.0	0.0	2.0	0.0000000000	False
term gamma	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
ve proved	0.0	0.0	0.0	2.0	0.0000000000	False
true fact	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
grading equals	0.00083105562643	0.0	0.0	1.0	0.0000000000	False
key step	0.000675937089883	0.0	0.0	1.0	0.0000000000	False
practical algorithms	0.00083105562643	1.0	0.0	0.0	0.0000000000	False
model spectrum	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
right	0.0	0.0	0.0	0.0	0.4340101523	False
good	0.000104739589397	0.0	0.0	0.0	0.5352112676	False
morning	0.000147216828232	0.0	0.0	0.0	0.0000000000	False
quick	0.000112512237395	0.0	0.0	0.0	0.0000000000	False
announcement	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
first	0.0	0.0	0.0	0.0	0.3461807989	False
things	0.0	0.0	0.0	0.0	0.4526375496	False
project	0.000514097665544	0.0	0.0	0.0	0.0000000000	False
proposals	0.00109710005037	0.0	0.0	0.0	0.2945736434	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
read	0.000254825740563	0.0	0.0	0.0	0.4408352668	False
two	0.0	0.0	0.0	0.0	0.3454545455	False
email	0.000274961489743	0.0	0.0	0.0	0.0000000000	False
back	0.000305046190327	0.0	0.0	0.0	0.4367816092	False
comments	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
slightly	9.34844356495e-05	0.0	0.0	0.0	0.0000000000	False
questionable	8.04049545061e-05	0.0	0.0	0.0	0.3741209564	False
aspects	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
hear	0.000128524416386	0.0	0.0	0.0	0.0000000000	False
today	0.000101865491523	0.0	0.0	0.0	0.4279279279	False
safely	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
assume	0.000341383065037	0.0	0.0	0.0	0.3937823834	False
start	0.0	0.0	0.0	0.0	0.3013215859	False
working	0.000146635425156	0.0	0.0	0.0	0.4188976378	False
exciting	0.000470881538384	0.0	0.0	0.0	0.0000000000	False
friday	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
session	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
end	1.14864220723e-05	0.0	0.0	0.0	0.0000000000	False
quarter	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
event	0.00182850008395	0.0	0.0	0.0	0.2279348757	False
chapter	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
talk	8.9534153429e-05	0.0	0.0	0.0	0.5635593220	False
learning	0.00323418289569	0.0	0.0	0.0	0.2287625418	False
theory	0.00108208936263	0.0	0.0	0.0	0.4596774194	False
previous	0.000327195524773	0.0	0.0	0.0	0.3518518519	False
guess	0.000842325920971	0.0	0.0	0.0	0.5352112676	False
lectures	0.000736180876988	0.0	0.0	0.0	0.3817351598	False
lot	7.74927238934e-05	0.0	0.0	0.0	0.0000000000	False
algorithms	0.00129325985751	0.0	0.0	0.0	0.3514450867	False
hope	0.00109984595897	0.0	0.0	0.0	0.4188976378	False
understand	0.000189178769971	0.0	0.0	0.0	0.4253731343	False
powerful	0.000194050973741	0.0	0.0	0.0	0.0000000000	False
tools	0.000687403724357	0.0	0.0	0.0	0.2945736434	False
machine	0.00134753198183	0.0	0.0	0.0	0.2814814815	False
sort	0.000719531367466	0.0	0.0	0.0	0.4860465116	False
qualified	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
industry	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
apply	0.000407721184901	0.0	0.0	0.0	0.4596774194	False
problems	0.000100725922608	0.0	0.0	0.0	0.4253731343	False
fact	0.000167583343035	0.0	0.0	0.0	0.4903225806	False
remember	0.000193731809734	0.0	0.0	0.0	0.5205479452	False
made	0.000119842953196	0.0	0.0	0.0	0.0000000000	False
analogy	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
carpenter	0.00135187417977	0.0	0.0	0.0	0.0000000000	False
imagine	0.000295521558459	0.0	0.0	0.0	0.0000000000	False
carpentry	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
school	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
small	0.000106226253921	0.0	0.0	0.0	0.4408352668	False
part	2.79794229465e-05	0.0	0.0	0.0	0.4175824176	False
acquire	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
set	0.000340095812814	0.0	0.0	0.0	0.4205803171	False
walk	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
pick	0.000492535930764	0.0	0.0	0.0	0.4408352668	False
box	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
cut	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
piece	6.96575599582e-05	0.0	0.0	0.0	0.0000000000	False
wood	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
rip	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
jig	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
keyhole	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
mastering	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
essential	4.85765928696e-05	0.0	0.0	0.0	0.0000000000	False
give	3.03926080893e-05	0.0	0.0	0.0	0.2853841710	False
sense	0.000291459557218	0.0	0.0	0.0	0.4529801325	False
mastery	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
deeply	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
properties	0.000203860592451	0.0	0.0	0.0	0.5277777778	False
turns	0.000658688153094	0.0	0.0	0.0	0.4539249147	False
out	0.0	0.0	0.0	0.0	0.4526375496	False
common	9.85071861529e-05	0.0	0.0	0.0	0.0000000000	False
scenarios	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
someday	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
research	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
company	0.000147216828232	0.0	0.0	0.0	0.0000000000	False
logistic	0.00236822251378	0.0	0.0	0.0	0.4401544402	False
regression	0.00299974851745	0.0	0.0	0.0	0.4956521739	False
support	0.000631744440728	0.0	0.0	0.0	0.4596774194	False
vector	0.000721392908418	0.0	0.0	0.0	0.3518518519	False
bayes	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
bizarre	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
reason	0.000104858907366	0.0	0.0	0.0	0.5277777778	False
separates	0.000348287799791	0.0	0.0	0.0	0.3259005146	False
people	0.00029960738299	0.0	0.0	0.0	0.1704035874	False
compared	0.000225024474791	0.0	0.0	0.0	0.0000000000	False
textbook	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
math	0.000315763001837	0.0	0.0	0.0	0.0000000000	False
decisions	0.000480928605612	0.0	0.0	0.0	0.5277777778	False
wanted	9.85071861529e-05	0.0	0.0	0.0	0.3822407215	False
modify	9.85071861529e-05	0.0	0.0	0.0	0.0000000000	False
great	0.000332122351015	0.0	0.0	0.0	0.0000000000	False
versus	0.000509012248865	0.0	0.0	0.0	0.0000000000	False
text	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
book	8.60616635938e-05	0.0	0.0	0.0	0.0000000000	False
understood	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
theoretical	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
results	0.00101866510217	0.0	0.0	0.0	0.4675963905	False
week	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
fixing	0.00216715809536	0.0	0.0	0.0	0.3247863248	False
point	8.28889311526e-06	0.0	0.0	0.0	0.0000000000	False
focused	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
practical	0.000240966697936	0.0	0.0	0.0	0.0000000000	False
advice	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
homework	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
alluded	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
previously	0.000197014372306	0.0	0.0	0.0	0.0000000000	False
bias	0.00447337461465	0.0	0.0	0.0	0.2310030395	False
variance	0.00301056018403	0.0	0.0	0.0	0.3405017921	False
trade-off	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
ordinary	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
squares	0.00111452095933	0.0	0.0	0.0	0.3972125436	False
straight	8.60616635938e-05	0.0	0.0	0.0	0.0000000000	False
line	8.53457662592e-05	0.0	0.0	0.0	0.0000000000	False
datas	0.000875951229958	0.0	0.0	0.0	0.3253424658	False
model	0.00236417246767	0.0	0.0	0.0	0.2261904762	False
underfit	0.00135187417977	0.0	0.0	0.0	0.0000000000	False
high	0.00076623315954	0.0	0.0	0.0	0.3569598634	False
failing	0.000395582839353	0.0	0.0	0.0	0.0000000000	False
fit	0.00206221117307	0.0	0.0	0.0	0.2552783109	False
evident	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
quadratic	0.00161938511055	0.0	0.0	0.0	0.2204176334	False
structure	0.000152895444338	0.0	0.0	0.0	0.0000000000	False
prefaces	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
formally	0.000526453700607	0.0	0.0	0.0	0.4408352668	False
representing	0.000101930296225	0.0	0.0	0.0	0.0000000000	False
infinite	0.00132255366543	0.0	0.0	0.0	0.4367816092	False
amount	0.00016064446529	0.0	0.0	0.0	0.0000000000	False
training	0.00889717920383	0.0	0.0	0.0	0.2721641502	False
tons	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
function	0.000837916715176	0.0	0.0	0.0	0.3156688628	False
opposite	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
dataset	0.00117039712567	0.0	0.0	0.0	0.0000000000	False
fourth	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
polynomials	0.00118674851806	0.0	0.0	0.0	0.0000000000	False
interpolate	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
excuse	0.000687403724357	0.0	0.0	0.0	0.5352112676	False
overfitting	0.00146299640709	0.0	0.0	0.0	0.4175824176	False
alternatively	0.000128524416386	0.0	0.0	0.0	0.0000000000	False
intuition	0.000721392908418	0.0	0.0	0.0	0.4408352668	False
patterns	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
idiosyncratic	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
specific	9.38519174955e-05	0.0	0.0	0.0	0.0000000000	False
housing	0.00101802449773	0.0	0.0	0.0	0.3259005146	False
prices	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
happy	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
medium	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
perfectly	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
captures	0.000128524416386	0.0	0.0	0.0	0.0000000000	False
multi-structure	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
simple	4.18958357588e-05	0.0	0.0	0.0	0.0000000000	False
picture	0.000101930296225	0.0	0.0	0.0	0.0000000000	False
classification	0.00103051779762	0.0	0.0	0.0	0.4408352668	False
lets	0.000467422178248	0.0	0.0	0.0	0.3815261044	False
positive	7.74927238934e-05	0.0	0.0	0.0	0.0000000000	False
negative	0.000985071861529	0.0	0.0	0.0	0.3941908714	False
examples	0.000664244702029	0.0	0.0	0.0	0.3762376238	False
order	6.80191625628e-05	0.0	0.0	0.0	0.5588235294	False
equals	0.00108489813451	0.0	0.0	0.0	0.4040961008	False
sigmoid	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
tenth	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
boundary	0.000441650484695	0.0	0.0	0.0	0.0000000000	False
classes	0.0020021742399	0.0	0.0	0.0	0.2366011476	False
contrast	0.000128524416386	0.0	0.0	0.0	0.0000000000	False
linear	0.0013769866175	0.0	0.0	0.0	0.2611683849	False
features	0.000417945359749	0.0	0.0	0.0	0.0000000000	False
explicitly	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
posing	0.000470881538384	0.0	0.0	0.0	0.0000000000	False
prove	0.00294756740314	0.0	0.0	0.0	0.4402716740	False
twin	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
initial	5.9921476598e-05	0.0	0.0	0.0	0.0000000000	False
foray	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
transpose	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
classifier	0.00137480744871	0.0	0.0	0.0	0.4188976378	False
indicator	0.000208972679874	0.0	0.0	0.0	0.0000000000	False
grading	0.000548550025184	0.0	0.0	0.0	0.0000000000	False
apologies	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
advance	0.000395582839353	0.0	0.0	0.0	0.0000000000	False
changing	2.77314718479e-05	0.0	0.0	0.0	0.0000000000	False
notation	0.000946678299532	0.0	0.0	0.0	0.4903225806	False
minus	0.000747875485196	0.0	0.0	0.0	0.2794117647	False
bit	4.85765928696e-05	0.0	0.0	0.0	0.0000000000	False
cleaner	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
switch	0.00120232151403	0.0	0.0	0.0	0.1629502573	False
zero-one	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
original	0.000129367315827	0.0	0.0	0.0	0.0000000000	False
forum	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
similar	0.000154985447787	0.0	0.0	0.0	0.5277777778	False
force	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
opt	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
labels	0.000473644502756	0.0	0.0	0.0	0.0000000000	False
involved	0.000112512237395	0.0	0.0	0.0	0.0000000000	False
probabilities	0.00694031848485	0.0	0.0	0.0	0.2914772727	False
usual	0.000147216828232	0.0	0.0	0.0	0.2832800852	False
writing	0.000230156883495	0.0	0.0	0.0	0.4102060844	False
ranging	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
xiyi	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
drawn	0.000675073424372	0.0	0.0	0.0	0.3986013986	False
iid	0.00204819496993	0.0	0.0	0.0	0.3082271147	False
sum	0.000321288930581	0.0	0.0	0.0	0.5277777778	False
distribution	0.00168768356093	0.0	0.0	0.0	0.3507692308	False
scripts	0.00375803697385	0.0	0.0	0.0	0.5205479452	False
identically	0.000257048832772	0.0	0.0	0.0	0.0000000000	False
definitively	0.000654391049547	0.0	0.0	0.0	0.4529801325	False
running	2.42882964348e-05	0.0	0.0	0.0	0.0000000000	False
sold	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
months	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
priority	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
spam	0.000645120039435	0.0	0.0	0.0	0.0000000000	False
build	9.21114813481e-05	0.0	0.0	0.0	0.0000000000	False
simplify	0.000514097665544	0.0	0.0	0.0	0.3454545455	False
phenomena	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
invariance	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
parameters	0.000748628878797	0.0	0.0	0.0	0.4367816092	False
maximizing	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
law	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
likelihood	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
define	0.000221851774783	0.0	0.0	0.0	0.3762376238	False
error	0.0145744659949	0.0	0.0	0.0	0.2978000189	False
hypothesis	0.0103399650207	0.0	0.0	0.0	0.2657342657	False
subscript	0.00118769524735	0.0	0.0	0.0	0.3379923761	False
epsilon	0.00516096031548	0.0	0.0	0.0	0.2968750000	False
hat	0.00903168055209	0.0	0.0	0.0	0.2500000000	False
make	0.000117513576376	0.0	0.0	0.0	0.4167101828	False
dependence	0.000121441482174	0.0	0.0	0.0	0.5277777778	False
explicit	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
clear	5.53537251691e-05	0.0	0.0	0.0	0.0000000000	False
correctly	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
ife	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
divide	7.48628878797e-05	0.0	0.0	0.0	0.0000000000	False
fraction	0.000274961489743	0.0	0.0	0.0	0.0000000000	False
risk	0.0057290040867	1.0	0.0	0.0	0.4167101828	False
empirical	0.00585198562837	0.0	0.0	0.0	0.4042553191	False
minimization	0.00325073714304	0.0	0.0	0.0	0.3387815750	False
choose	0.000823491766677	0.0	0.0	0.0	0.2454492073	False
basic	1.14864220723e-05	0.0	0.0	0.0	0.0000000000	False
viewed	0.000184222962696	0.0	0.0	0.0	0.0000000000	False
approximation	0.00127995005876	0.0	0.0	0.0	0.3741209564	False
cities	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
nonconvex	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
optimization	0.000412442234614	0.0	0.0	0.0	0.0000000000	False
hard	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
solve	0.000921114813481	0.0	0.0	0.0	0.2996845426	False
finding	6.89185324338e-05	0.0	0.0	0.0	0.5428571429	False
convex	0.000169670749622	0.0	0.0	0.0	0.0000000000	False
rewrite	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
equivalent	0.000848353748108	0.0	0.0	0.0	0.3259005146	False
hypotheses	0.00468736698003	0.0	0.0	0.0	0.4718242598	False
words	0.000298710181907	0.0	0.0	0.0	0.5277777778	False
mapping	0.000368445925392	0.0	0.0	0.0	0.5277777778	False
input	0.000101930296225	0.0	0.0	0.0	0.0000000000	False
domain	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
vary	0.000473644502756	0.0	0.0	0.0	0.0000000000	False
redefine	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
raise	0.000460557406741	0.0	0.0	0.0	0.4408352668	False
hand	0.000384055948166	0.0	0.0	0.0	0.4529801325	False
formulation	0.0	0.0	0.0	0.0	0.0000000000	False
cool	0.000899670914703	0.0	0.0	0.0	0.0000000000	False
development	0.000210581480243	0.0	0.0	0.0	0.0000000000	False
general	0.000459129347299	0.0	0.0	0.0	0.3654535169	False
case	0.0	0.0	0.0	0.0	0.4175824176	False
viewer	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
network	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
alex	0.0	0.0	0.0	0.0	0.0000000000	False
phase	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
answers	0.000186968871299	0.0	0.0	0.0	0.0000000000	False
framework	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
purpose	0.000388101947482	0.0	0.0	0.0	0.3747534517	False
mind	8.60616635938e-05	0.0	0.0	0.0	0.0000000000	False
visectron	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
board	0.00108208936263	0.0	0.0	0.0	0.3518518519	False
infa	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
center	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
perform	0.000152895444338	0.0	0.0	0.0	0.0000000000	False
restrict	0.000147216828232	0.0	0.0	0.0	0.0000000000	False
binary	8.60616635938e-05	0.0	0.0	0.0	0.0000000000	False
wan	0.0	0.0	0.0	0.0	0.0000000000	False
care	0.000221414900676	0.0	0.0	0.0	0.3454545455	False
accurate	0.000339341499243	0.0	0.0	0.0	0.0000000000	False
predictions	0.000385573249158	0.0	0.0	0.0	0.0000000000	False
ultimate	0.000395582839353	0.0	0.0	0.0	0.0000000000	False
goal	0.000315763001837	0.0	0.0	0.0	0.0000000000	False
sale	0.000470881538384	0.0	0.0	0.0	0.0000000000	False
outcomes	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
sample	0.00157881500919	0.0	0.0	0.0	0.2111111111	False
mislabels	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
terms	0.000261939835344	0.0	0.0	0.0	0.2378716745	False
convention	0.000337536712186	0.0	0.0	0.0	0.0000000000	False
place	5.53537251691e-05	0.0	0.0	0.0	0.0000000000	False
top	0.000110707450338	0.0	0.0	0.0	0.0000000000	False
means	2.48666793458e-05	0.0	0.0	0.0	0.3917525773	False
attempt	0.000791165678706	0.0	0.0	0.0	0.3454545455	False
estimate	0.00254506124432	0.0	0.0	0.0	0.2995270625	False
quantities	9.85071861529e-05	0.0	0.0	0.0	0.0000000000	False
output	0.000208972679874	0.0	0.0	0.0	0.0000000000	False
low	0.000128524416386	0.0	0.0	0.0	0.0000000000	False
state	0.000240464302806	0.0	0.0	0.0	0.0000000000	False
lemmas	0.00124658343965	0.0	0.0	0.0	0.0000000000	False
union	0.00164808538435	0.0	0.0	0.0	0.3379923761	False
vowel	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
probabilistic	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
necessarily	0.000105290740121	0.0	0.0	0.0	0.0000000000	False
independent	0.000368445925392	0.0	0.0	0.0	0.0000000000	False
current	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
assumption	0.000294433656463	0.0	0.0	0.0	0.0000000000	False
dot	0.000631744440728	0.0	0.0	0.0	0.1461538462	False
symbol	0.000473644502756	0.0	0.0	0.0	0.0000000000	False
occurring	0.000105290740121	0.0	0.0	0.0	0.0000000000	False
venn	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
diagrams	0.000169670749622	0.0	0.0	0.0	0.0000000000	False
depictions	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
cryptic	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
ignore	0.000274961489743	0.0	0.0	0.0	0.0000000000	False
total	0.000194050973741	0.0	0.0	0.0	0.0000000000	False
mass	0.00141264461515	0.0	0.0	0.0	0.2394957983	False
individual	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
surprising	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
axioms	0.000706322307576	0.0	0.0	0.0	0.0000000000	False
written	5.53537251691e-05	0.0	0.0	0.0	0.0000000000	False
sigmas	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
avitivity	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
measured	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
commonly	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
balance	0.00043008002629	0.0	0.0	0.0	0.0000000000	False
call	5.52592874351e-06	0.0	0.0	0.0	0.3140495868	False
hufting	0.00290869469251	0.0	0.0	0.0	0.3741209564	False
inequality	0.00208327421335	0.0	0.0	0.0	0.4408352668	False
random	0.00126348888146	0.0	0.0	0.0	0.3313953488	False
variables	0.000659136242578	0.0	0.0	0.0	0.2945736434	False
phi	0.0030607299995	0.0	0.0	0.0	0.1646317448	False
observe	0.000274961489743	0.0	0.0	0.0	0.0000000000	False
newly	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
semper	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
mzi	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
benuve	0.00373975031894	0.0	0.0	0.0	0.3479145473	False
taking	0.000110925887392	0.0	0.0	0.0	0.4208469055	False
average	0.00101802449773	0.0	0.0	0.0	0.3747534517	False
gamma	0.0106807366625	0.0	0.0	0.0	0.2732958099	False
true	0.000774952152367	0.0	0.0	0.0	0.4115523466	False
value	0.000276768625845	0.0	0.0	0.0	0.2814814815	False
bounded	0.0046268789899	0.0	0.0	0.0	0.3494512014	False
theorem	0.00378915602205	0.0	0.0	0.0	0.2395964691	False
holds	0.00206547992625	0.0	0.0	0.0	0.3534883721	False
statement	8.60616635938e-05	0.0	0.0	0.0	0.0000000000	False
draw	0.000139315119916	0.0	0.0	0.0	0.0000000000	False
cartoon	0.000988957098383	0.0	0.0	0.0	0.5277777778	False
describe	0.000197014372306	0.0	0.0	0.0	0.0000000000	False
real	4.67422178248e-05	0.0	0.0	0.0	0.0000000000	False
number	1.38148218588e-05	0.0	0.0	0.0	0.4408352668	False
undergraduate	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
statistics	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
central	0.00129024007887	0.0	0.0	0.0	0.1932203390	False
limit	0.000675073424372	0.0	0.0	0.0	0.1932203390	False
tend	0.000385573249158	0.0	0.0	0.0	0.0000000000	False
gaussian	0.00118674851806	0.0	0.0	0.0	0.3454545455	False
toss	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
coins	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
roughly	0.000240464302806	0.0	0.0	0.0	0.0000000000	False
cumulative	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
converse	0.00168325011964	0.0	0.0	0.0	0.4018126888	False
technically	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
discreet	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
factions	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
entity	0.000169670749622	0.0	0.0	0.0	0.0000000000	False
put	3.54087513069e-05	0.0	0.0	0.0	0.0000000000	False
interval	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
details	4.26728831296e-05	0.0	0.0	0.0	0.0000000000	False
tails	0.000520818553337	0.0	0.0	0.0	0.0000000000	False
side	0.000356756036789	0.0	0.0	0.0	0.4175824176	False
mistake	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
interesting	0.000203860592451	0.0	0.0	0.0	0.0000000000	False
exponentially	0.000294433656463	0.0	0.0	0.0	0.0000000000	False
increase	0.00068849330875	0.0	0.0	0.0	0.4408352668	False
size	0.000498183526522	0.0	0.0	0.0	0.3584905660	False
worth	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
shrink	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
root	0.000480928605612	0.0	0.0	0.0	0.2945736434	False
left	0.000104858907366	0.0	0.0	0.0	0.0000000000	False
decrease	0.000339341499243	0.0	0.0	0.0	0.0000000000	False
quickly	6.46836579137e-05	0.0	0.0	0.0	0.0000000000	False
important	0.000140226653474	0.0	0.0	0.0	0.0000000000	False
version	0.000210581480243	0.0	0.0	0.0	0.0000000000	False
familiar	9.21114813481e-05	0.0	0.0	0.0	0.0000000000	False
asymptotic	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
finer	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
explain	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
reference	0.000101930296225	0.0	0.0	0.0	0.0000000000	False
begin	0.000179764429794	0.0	0.0	0.0	0.0000000000	False
studying	0.000197014372306	0.0	0.0	0.0	0.0000000000	False
finite	0.000514097665544	0.0	0.0	0.0	0.5277777778	False
whichever	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
lowest	0.000706322307576	0.0	0.0	0.0	0.0000000000	False
large	0.000736180876988	0.0	0.0	0.0	0.2639967307	False
continuous	3.87463619467e-05	0.0	0.0	0.0	0.0000000000	False
row	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
strategy	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
step	0.000145729778609	0.0	0.0	0.0	0.5205479452	False
show	0.000194306371478	0.0	0.0	0.0	0.4367816092	False
implies	0.000315872220364	0.0	0.0	0.0	0.0000000000	False
realized	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
heavy	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
round	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
introducing	0.000210581480243	0.0	0.0	0.0	0.0000000000	False
pretty	0.000257048832772	0.0	0.0	0.0	0.0000000000	False
idea	2.77314718479e-05	0.0	0.0	0.0	0.0000000000	False
notice	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
misclassifies	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
randomly	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
zis	0.00168984272471	0.0	0.0	0.0	0.1431997259	False
figure	5.9921476598e-05	0.0	0.0	0.0	0.0000000000	False
chance	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
miid	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
add	5.9921476598e-05	0.0	0.0	0.0	0.0000000000	False
difference	1.67876537679e-05	0.0	0.0	0.0	0.4758497317	False
greater	0.000224588663639	0.0	0.0	0.0	0.0000000000	False
tricky	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
approve	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
exists	0.000430308317969	0.0	0.0	0.0	0.2883156297	False
equation	0.000788057489223	0.0	0.0	0.0	0.2832800852	False
sign	0.000412442234614	0.0	0.0	0.0	0.0000000000	False
flipped	0.000585198562837	0.0	0.0	0.0	0.0000000000	False
shown	0.000119842953196	0.0	0.0	0.0	0.0000000000	False
abbreviates	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
simultaneously	0.000781227830005	0.0	0.0	0.0	0.0000000000	False
instance	3.87463619467e-05	0.0	0.0	0.0	0.0000000000	False
uniform	0.0023753904947	0.0	0.0	0.0	0.3427835052	False
converge	0.000395582839353	0.0	0.0	0.0	0.0000000000	False
close	5.54629436958e-05	0.0	0.0	0.0	0.0000000000	False
clean	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
couple	0.000240464302806	0.0	0.0	0.0	0.0000000000	False
computed	7.27610653733e-05	0.0	0.0	0.0	0.3259005146	False
constant	0.000299451551519	0.0	0.0	0.0	0.0000000000	False
chose	0.000315763001837	0.0	0.0	0.0	0.0000000000	False
labs	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
present	8.03222326452e-05	0.0	0.0	0.0	0.0000000000	False
form	0.000177043756535	0.0	0.0	0.0	0.3040000000	False
factors	0.0	0.0	0.0	0.0	0.0000000000	False
concretely	0.000147216828232	0.0	0.0	0.0	0.0000000000	False
consequences	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
suppose	4.85765928696e-05	0.0	0.0	0.0	0.0000000000	False
threshold	0.000706322307576	0.0	0.0	0.0	0.0000000000	False
formula	0.000588867312926	0.0	0.0	0.0	0.4175824176	False
happening	2.77314718479e-05	0.0	0.0	0.0	0.0000000000	False
delta	0.0033624541345	0.0	0.0	0.0	0.2880242547	False
long	0.00016064446529	0.0	0.0	0.0	0.0000000000	False
assigns	8.60616635938e-05	0.0	0.0	0.0	0.0000000000	False
guarantee	0.000548550025184	0.0	0.0	0.0	0.0000000000	False
complexity	0.0016746221646	0.0	0.0	0.0	0.2112013681	False
undergrad	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
science	0.000315763001837	0.0	0.0	0.0	0.0000000000	False
heard	0.000339341499243	0.0	0.0	0.0	0.0000000000	False
achieve	0.000548550025184	0.0	0.0	0.0	0.0000000000	False
personally	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
easy	0.000295521558459	0.0	0.0	0.0	0.0000000000	False
interpret	0.000147216828232	0.0	0.0	0.0	0.0000000000	False
guidance	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
note	0.000110707450338	0.0	0.0	0.0	0.0000000000	False
grows	0.000771146498317	0.0	0.0	0.0	0.1932203390	False
log	0.00068849330875	0.0	0.0	0.0	0.1638940234	False
extremely	9.21114813481e-05	0.0	0.0	0.0	0.0000000000	False
slowly	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
slowest	0.00083105562643	0.0	0.0	0.0	0.0000000000	False
colleague	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
andrew	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
moore	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
carnegie	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
mellon	0.000337968544942	0.0	0.0	0.0	0.0000000000	False
final	0.000129367315827	0.0	0.0	0.0	0.0000000000	False
plugging	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
proof	0.000257048832772	0.0	0.0	0.0	0.0000000000	False
execute	0.000147216828232	0.0	0.0	0.0	0.0000000000	False
selected	0.000274961489743	0.0	0.0	0.0	0.0000000000	False
star	0.00221034101286	0.0	0.0	0.0	0.3479145473	False
smallest	0.000112512237395	0.0	0.0	0.0	0.0000000000	False
bad	0.000105290740121	0.0	0.0	0.0	0.0000000000	False
chosen	0.000240464302806	0.0	0.0	0.0	0.0000000000	False
lower	0.000210581480243	0.0	0.0	0.0	0.0000000000	False
moving	7.74927238934e-05	0.0	0.0	0.0	0.0000000000	False
member	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
typical	8.03222326452e-05	0.0	0.0	0.0	0.0000000000	False
family	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
tie	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
minimum	0.000274961489743	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.0000000000	False
wait	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
helps	0.000137480744871	0.0	0.0	0.0	0.5277777778	False
quantify	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
tradeoff	0.00146299640709	0.0	0.0	0.0	0.4175824176	False
prime	0.000548550025184	0.0	0.0	0.0	0.0000000000	False
subset	0.00036570001679	0.0	0.0	0.0	0.0000000000	False
larger	0.000221414900676	0.0	0.0	0.0	0.2945736434	False
pay	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
illustrated	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
speaking	0.000294433656463	0.0	0.0	0.0	0.0000000000	False
loosely	0.00086016005258	0.0	0.0	0.0	0.0000000000	False
warning	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
universally	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
accepted	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
competing	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
informal	6.96575599582e-05	0.0	0.0	0.0	0.0000000000	False
plot	0.000412442234614	0.0	0.0	0.0	0.0000000000	False
vertical	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
axis	0.000315763001837	0.0	0.0	0.0	0.0000000000	False
horizontal	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
degree	0.000128524416386	0.0	0.0	0.0	0.0000000000	False
bandwidth	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
locally	0.000120232151403	0.0	0.0	0.0	0.0000000000	False
weighted	0.000235440769192	0.0	0.0	0.0	0.0000000000	False
effect	7.48628878797e-05	0.0	0.0	0.0	0.0000000000	False
controlling	9.85071861529e-05	0.0	0.0	0.0	0.0000000000	False
complete	2.09479178794e-05	0.0	0.0	0.0	0.0000000000	False
regime	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
intermediate	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
preferable	0.000182850008395	0.0	0.0	0.0	0.0000000000	False
automatically	0.000137480744871	0.0	0.0	0.0	0.0000000000	False
area	9.21114813481e-05	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.0000000000	False
wrote	0.000315872220364	0.0	0.0	0.0	0.0000000000	False
corollary	0.000675937089883	0.0	0.0	0.0	0.0000000000	False
worse	0.000197791419677	0.0	0.0	0.0	0.0000000000	False
obtain	9.21114813481e-05	0.0	0.0	0.0	0.0000000000	False
suffices	0.000292599281418	0.0	0.0	0.0	0.0000000000	False
convince	0.000941763076769	0.0	0.0	0.0	0.2550335570	False
home	0.000157881500919	0.0	0.0	0.0	0.0000000000	False
logically	0.000225024474791	0.0	0.0	0.0	0.0000000000	False
follow	5.9921476598e-05	0.0	0.0	0.0	0.0000000000	False
sounds	0.000215040013145	0.0	0.0	0.0	0.0000000000	False
plausible	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
big	6.46836579137e-05	0.0	0.0	0.0	0.0000000000	False
key	6.46836579137e-05	0.0	0.0	0.0	0.0000000000	False
logarithmic	0.000260409276668	0.0	0.0	0.0	0.0000000000	False
spectrum	0.000415527813215	0.0	0.0	0.0	0.0000000000	False
guys	9.85071861529e-05	0.0	0.0	0.0	0.0000000000	False
couple of quick announcements	0.0	0.0	0.0	2.0	0.0000000000	False
ve all been graded	0.0	0.0	0.0	2.0	0.0000000000	False
end of lecture today	0.0	0.0	0.0	4.0	0.0000000000	False
today if you re	0.0	0.0	0.0	0.0	0.0000000000	False
re an sepd student	0.0	0.0	2.9985	6.0	0.0000000000	False
submitted your problem set	0.0	0.0	0.0	2.0	0.0000000000	False
copy of your homework	0.0	0.0	0.0	2.0	0.0000000000	False
late hand in box	0.0	0.0	0.0	4.0	0.0000000000	False
classroom at the end	0.0	0.0	0.0	2.0	0.0000000000	False
pick up and homework	0.0	0.0	0.0	2.0	0.0000000000	False
nt picked up today	0.0	0.0	0.0	0.0	0.0000000000	False
basement of the gates	0.0	0.0	0.0	2.0	0.0000000000	False
end of class today	0.0	0.0	0.0	2.0	0.0000000000	False
posted on the web	0.0	0.0	0.0	2.0	0.0000000000	False
posted online last week	0.0	0.0	0.0	2.0	0.0000000000	False
week so do make	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you download	0.0	0.0	0.0	2.0	0.0000000000	False
sort of personally gratifying	0.0	0.0	0.0	2.0	0.0000000000	False
people in this class	0.0	0.0	0.0	2.0	0.0000000000	False
late on monday night	0.0	0.0	0.0	2.0	0.0000000000	False
announcement just a reminder	0.0	0.0	0.0	2.0	0.0000000000	False
midterm for this class	0.0	0.0	0.0	2.0	0.0000000000	False
p.m so the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
guess so the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
bring but no laptops	0.0	0.0	0.0	2.0	0.0000000000	False
laptops and computers sepd	0.0	0.0	0.0	2.0	0.0000000000	False
live in the bay	0.0	0.0	0.0	2.0	0.0000000000	False
person on the evening	0.0	0.0	0.0	2.0	0.0000000000	False
november if you re	0.0	0.0	0.0	0.0	0.0000000000	False
live outside the bay	0.0	0.0	0.0	4.0	0.0000000000	False
nt drive to stanford	0.0	0.0	0.0	0.0	0.0000000000	False
usual class mailing address	0.0	0.0	0.0	2.0	0.0000000000	False
midterm because you live	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you email	0.0	0.0	0.0	2.0	0.0000000000	False
arrangements for the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
taking this via sepd	0.0	0.0	0.0	2.0	0.0000000000	False
equal or greater importance	0.0	0.0	0.0	2.0	0.0000000000	False
midterm of another class	0.0	0.0	0.0	2.0	0.0000000000	False
usual staff mailing address	0.0	0.0	0.0	2.0	0.0000000000	False
showing up in person	0.0	0.0	0.0	2.0	0.0000000000	False
person for the midterm	0.0	0.0	0.0	2.0	0.0000000000	False
midterm okay any questions	0.0	0.0	0.0	2.0	0.0000000000	False
lecture s technical material	0.0	0.0	0.0	0.0	0.0000000000	False
week s discussion section	0.0	0.0	0.0	0.0	0.0000000000	False
talking about convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
last week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
discussion section they discussed	0.0	0.0	0.0	2.0	0.0000000000	False
discussed total convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization and this week	0.0	0.0	0.0	2.0	0.0000000000	False
week they ll wrap	0.0	0.0	0.0	0.0	0.0000000000	False
wrap up the material	0.0	0.0	0.0	2.0	0.0000000000	False
present on convex optimization	0.0	0.0	0.0	2.0	0.0000000000	False
today in this lecture	0.0	0.0	0.0	2.0	0.0000000000	False
talk a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit more about learning	0.0	0.0	0.0	2.0	0.0000000000	False
talk about vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
building on the issues	0.0	0.0	0.0	2.0	0.0000000000	False
issues of bias variance	0.0	0.0	0.0	2.0	0.0000000000	False
tradeoffs of under fitting	0.0	0.0	0.0	2.0	0.0000000000	False
fitting and over fitting	0.0	0.0	0.0	2.0	0.0000000000	False
talk about model selection	0.0	0.0	3.9985	6.0	0.0000000000	False
algorithms for automatically making	0.0	0.0	0.0	2.0	0.0000000000	False
decisions for this bias	0.0	0.0	0.0	2.0	0.0000000000	False
previous lecture and depending	0.0	0.0	0.0	2.0	0.0000000000	False
set of k hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that this holds	0.0	0.0	2.9985	6.0	0.0000000000	False
minus delta it suffices	0.0	0.0	0.0	2.0	0.0000000000	False
talked about empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
simplified modern machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class of script	0.0	0.0	0.0	2.0	0.0000000000	False
empirical risk minimization-learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
attains the smallest error	0.0	0.0	0.0	2.0	0.0000000000	False
error on the training	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error ; right	0.0	0.0	0.0	2.0	0.0000000000	False
probability of a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
distribution as the training	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error of the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
output by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
class plus two times	0.0	0.0	0.0	2.0	0.0000000000	False
times gamma two times	0.0	0.0	0.0	2.0	0.0000000000	False
two times this error	0.0	0.0	0.0	2.0	0.0000000000	False
times this error threshold	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta we show	0.0	0.0	0.0	2.0	0.0000000000	False
show that it suffices	0.0	0.0	0.0	2.0	0.0000000000	False
suffices for your training	0.0	0.0	0.0	2.0	0.0000000000	False
two gamma square log	0.0	0.0	0.0	2.0	0.0000000000	False
two k over delta	0.0	0.0	0.0	2.0	0.0000000000	False
size of your hypothesis	0.0	0.0	0.0	4.0	0.0000000000	False
bound in the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of training examples	0.0	0.0	9.994	24.0	0.3925233645	False
case of infinite hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
script h is sort	0.0	0.0	0.0	2.0	0.0000000000	False
model like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
parameterized by real numbers	0.0	0.0	0.0	2.0	0.0000000000	False
first going to give	0.0	0.0	0.0	2.0	0.0000000000	False
argument that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
sort of formally broken	0.0	0.0	0.0	2.0	0.0000000000	False
formally broken just sort	0.0	0.0	0.0	2.0	0.0000000000	False
proof is somewhat involved	0.0	0.0	0.0	2.0	0.0000000000	False
apply this result analyzing	0.0	0.0	0.0	2.0	0.0000000000	False
result analyzing logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
script h is parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
re applying logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression to find	0.0	0.0	0.0	2.0	0.0000000000	False
find the linear position	0.0	0.0	0.0	2.0	0.0000000000	False
endless one real numbers	0.0	0.0	0.0	2.0	0.0000000000	False
class is really represented	0.0	0.0	0.0	2.0	0.0000000000	False
represented in a computer	0.0	0.0	0.0	2.0	0.0000000000	False
double position floating point	0.0	0.0	0.0	2.0	0.0000000000	False
position floating point numbers	0.0	0.0	0.0	2.0	0.0000000000	False
real number is represented	0.0	0.0	0.0	2.0	0.0000000000	False
64-bit representation ; right	0.0	0.0	0.0	2.0	0.0000000000	False
times d bits computers	0.0	0.0	0.0	2.0	0.0000000000	False
computers ca nt represent	0.0	0.0	0.0	0.0	0.0000000000	False
nt represent real numbers	0.0	0.0	0.0	0.0	0.0000000000	False
numbers they only represent	0.0	0.0	0.0	2.0	0.0000000000	False
represent used to speed	0.0	0.0	0.0	2.0	0.0000000000	False
class in your computer	0.0	0.0	0.0	2.0	0.0000000000	False
number of possible values	0.0	0.0	0.0	2.0	0.0000000000	False
ways you can flip	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee that a hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
returned by empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in your hypotheses	0.0	0.0	0.0	4.0	0.0000000000	False
sort of error bound	0.0	0.0	0.0	2.0	0.0000000000	False
intuition that this conveys	0.0	0.0	0.0	2.0	0.0000000000	False
linear in the number	0.0	0.0	3.9985	6.0	0.0000000000	False
parameters of your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
order of something linear	0.0	0.0	0.0	2.0	0.0000000000	False
sense that it relies	0.0	0.0	0.0	2.0	0.0000000000	False
representation of 14-point numbers	0.0	0.0	0.0	2.0	0.0000000000	False
right way to show	0.0	0.0	0.0	4.0	0.0000000000	False
formally ; all right	0.0	0.0	0.0	2.0	0.0000000000	False
turns out the right	0.0	0.0	0.0	2.0	0.0000000000	False
involves a much longer	0.0	0.0	0.0	2.0	0.0000000000	False
longer because the proof	0.0	0.0	0.0	2.0	0.0000000000	False
proof is extremely involved	0.0	0.0	0.0	2.0	0.0000000000	False
prove it farther proof	0.0	0.0	0.0	2.0	0.0000000000	False
proof be a source	0.0	0.0	0.0	2.0	0.0000000000	False
source of learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis classes this definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition given a set	0.0	0.0	0.0	2.0	0.0000000000	False
set of d points	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class h shatters	0.0	0.0	0.0	2.0	0.0000000000	False
informal way of thinking	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class has shattered	0.0	0.0	0.0	2.0	0.0000000000	False
associate these d points	0.0	0.0	0.0	2.0	0.0000000000	False
points with any caught	0.0	0.0	0.0	2.0	0.0000000000	False
caught set of labels	0.0	0.0	0.0	2.0	0.0000000000	False
labels y ; right	0.0	0.0	0.0	2.0	0.0000000000	False
labels those d examples	0.0	0.0	0.0	2.0	0.0000000000	False
points you can choose	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class h classed	0.0	0.0	0.0	2.0	0.0000000000	False
classed all linear classifiers	0.0	0.0	0.0	2.0	0.0000000000	False
find a linear classifier	0.0	0.0	0.0	2.0	0.0000000000	False
linear classifier that attains	0.0	0.0	0.0	2.0	0.0000000000	False
attains zero training error	0.0	0.0	0.0	2.0	0.0000000000	False
labelings of this set	0.0	0.0	0.0	2.0	0.0000000000	False
set of two points	0.0	0.0	0.0	2.0	0.0000000000	False
class script h shatters	0.0	0.0	0.0	2.0	0.0000000000	False
set of three points	0.0	0.0	0.0	4.0	0.0000000000	False
hypothesis in the hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class that labels	0.0	0.0	0.0	2.0	0.0000000000	False
labels these examples correctly	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class also shatters	0.0	0.0	0.0	2.0	0.0000000000	False
terminology h can realize	0.0	0.0	0.0	2.0	0.0000000000	False
give it any set	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that perfectly separates	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative examples	0.0	0.0	0.0	2.0	0.0000000000	False
set of four points	0.0	0.0	2.9985	6.0	0.0000000000	False
labelings we can choose	0.0	0.0	0.0	2.0	0.0000000000	False
boundary that can realize	0.0	0.0	0.0	2.0	0.0000000000	False
points that the class	0.0	0.0	0.0	2.0	0.0000000000	False
linear classifiers can shatter	0.0	0.0	0.0	2.0	0.0000000000	False
dimension these two people	0.0	0.0	0.0	2.0	0.0000000000	False
vapnik and chervonenkis dimension	0.0	0.0	0.0	2.0	0.0000000000	False
set that is shattered	0.0	0.0	0.0	2.0	0.0000000000	False
shattered by this set	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class can shatter	0.0	0.0	0.0	2.0	0.0000000000	False
shatter arbitrarily large sets	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the set	0.0	0.0	0.0	2.0	0.0000000000	False
set s of size	0.0	0.0	0.0	2.0	0.0000000000	False
absolutely so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
exists some other set	0.0	0.0	0.0	2.0	0.0000000000	False
size three being shattered	0.0	0.0	0.0	2.0	0.0000000000	False
four that can shatter	0.0	0.0	0.0	2.0	0.0000000000	False
nt shatter this set	0.0	0.0	0.0	0.0	0.0000000000	False
shatter and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out this result	0.0	0.0	0.0	2.0	0.0000000000	False
out this result holds	0.0	0.0	0.0	2.0	0.0000000000	False
dimensions the vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the class	0.0	0.0	0.0	4.0	0.0000000000	False
class of linear classifiers	0.0	0.0	2.9985	6.0	0.0000000000	False
classifiers in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
dimension in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
arguably the best-known result	0.0	0.0	0.0	2.0	0.0000000000	False
probability of one minus	0.0	0.0	0.0	4.0	0.0000000000	False
formula on the right	0.0	0.0	0.0	2.0	0.0000000000	False
right looks a bit	0.0	0.0	0.0	2.0	0.0000000000	False
out the essential aspects	0.0	0.0	0.0	2.0	0.0000000000	False
key to this result	0.0	0.0	0.0	2.0	0.0000000000	False
class with vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
vapnik and chervonenkis show	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta you enjoy	0.0	0.0	0.0	2.0	0.0000000000	False
sort of uniform conversions	0.0	0.0	0.0	2.0	0.0000000000	False
hypotheses in your hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
error of h minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus the training error	0.0	0.0	0.0	2.0	0.0000000000	False
two things is bounded	0.0	0.0	0.0	2.0	0.0000000000	False
re probably one minus	0.0	0.0	0.0	2.0	0.0000000000	False
step to this step	0.0	0.0	0.0	4.0	0.0000000000	False
previous lecture we proved	0.0	0.0	0.0	2.0	0.0000000000	False
implies that it appears	0.0	0.0	0.0	2.0	0.0000000000	False
showed that if generalization	0.0	0.0	0.0	2.0	0.0000000000	False
generalization error and training	0.0	0.0	0.0	2.0	0.0000000000	False
error and training error	0.0	0.0	0.0	2.0	0.0000000000	False
error of the hypotheses	0.0	0.0	0.0	4.0	0.0000000000	False
times the best generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error plus two times	0.0	0.0	0.0	2.0	0.0000000000	False
notation so that formula	0.0	0.0	0.0	2.0	0.0000000000	False
minus delta we re	0.0	0.0	0.0	0.0	0.0000000000	False
put gamma and delta	0.0	0.0	0.0	2.0	0.0000000000	False
subscript error to denote	0.0	0.0	0.0	2.0	0.0000000000	False
treat gamma and delta	0.0	0.0	0.0	2.0	0.0000000000	False
absorb turns that depend	0.0	0.0	0.0	2.0	0.0000000000	False
dimension and hypotheses class	0.0	0.0	0.0	2.0	0.0000000000	False
empirical risk minimization algorithms	0.0	0.0	0.0	4.0	0.0000000000	False
algorithms in other words	0.0	0.0	0.0	2.0	0.0000000000	False
training error the intuition	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the hypotheses	0.0	0.0	0.0	2.0	0.0000000000	False
shows that sample complexity	0.0	0.0	0.0	2.0	0.0000000000	False
complexity is upper bounded	0.0	0.0	0.0	4.0	0.0000000000	False
model and logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression linear classification	0.0	0.0	0.0	2.0	0.0000000000	False
classification in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
regression in any dimensions	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of your model	0.0	0.0	0.0	4.0	0.0000000000	False
fit in those models	0.0	0.0	0.0	2.0	0.0000000000	False
parameters in your model	0.0	0.0	0.0	2.0	0.0000000000	False
source of not learning	0.0	0.0	0.0	2.0	0.0000000000	False
result shows the sample	0.0	0.0	0.0	2.0	0.0000000000	False
shows the sample complexity	0.0	0.0	0.0	2.0	0.0000000000	False
bounded by vc dimension	0.0	0.0	0.0	4.0	0.0000000000	False
worse case some complexity	0.0	0.0	0.0	2.0	0.0000000000	False
perfectly nasty learning problem	0.0	0.0	0.0	2.0	0.0000000000	False
bound so i guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess in the worse	0.0	0.0	0.0	2.0	0.0000000000	False
complexity in the number	0.0	0.0	0.0	2.0	0.0000000000	False
bounded and lower bounded	0.0	0.0	0.0	2.0	0.0000000000	False
proof of this assume	0.0	0.0	0.0	2.0	0.0000000000	False
entirety of the theorem	0.0	0.0	0.0	2.0	0.0000000000	False
theorem this is true	0.0	0.0	0.0	2.0	0.0000000000	False
out in the proof	0.0	0.0	0.0	2.0	0.0000000000	False
reconstruction called an epsilon	0.0	0.0	0.0	2.0	0.0000000000	False
working through this proof	0.0	0.0	0.0	2.0	0.0000000000	False
start reading the book	0.0	0.0	0.0	2.0	0.0000000000	False
thought i would inflict	0.0	0.0	0.0	2.0	0.0000000000	False
couple of loose ends	0.0	0.0	0.0	4.0	0.0000000000	False
mention a few things	0.0	0.0	0.0	2.0	0.0000000000	False
feel a little bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit like random facts	0.0	0.0	0.0	2.0	0.0000000000	False
proved for an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
minimizes 0-1 training error	0.0	0.0	0.0	2.0	0.0000000000	False
error so one question	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on support vector	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature space	0.0	0.0	0.0	2.0	0.0000000000	False
infinite so it turns	0.0	0.0	0.0	2.0	0.0000000000	False
out that the class	0.0	0.0	0.0	2.0	0.0000000000	False
class of linear separators	0.0	0.0	0.0	2.0	0.0000000000	False
separators with large margin	0.0	0.0	0.0	4.0	0.0000000000	False
give you a set	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class will comprise	0.0	0.0	0.0	2.0	0.0000000000	False
comprise only the linear	0.0	0.0	0.0	2.0	0.0000000000	False
nt allow a point	0.0	0.0	0.0	0.0	0.0000000000	False
point that comes closer	0.0	0.0	0.0	2.0	0.0000000000	False
nt allow that line	0.0	0.0	0.0	0.0	0.0000000000	False
data points all lie	0.0	0.0	0.0	2.0	0.0000000000	False
lie within some sphere	0.0	0.0	0.0	2.0	0.0000000000	False
data with a margin	0.0	0.0	0.0	2.0	0.0000000000	False
equal to r squared	0.0	0.0	0.0	2.0	0.0000000000	False
squared over four gamma	0.0	0.0	0.0	2.0	0.0000000000	False
symbol ; it means	0.0	0.0	0.0	2.0	0.0000000000	False
turns out you prove	0.0	0.0	0.0	2.0	0.0000000000	False
things about this result	0.0	0.0	0.0	2.0	0.0000000000	False
talk about but turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns they can prove	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers with large margins	0.0	0.0	0.0	2.0	0.0000000000	False
margins is actually bounded	0.0	0.0	0.0	2.0	0.0000000000	False
bounded the surprising thing	0.0	0.0	0.0	2.0	0.0000000000	False
bound on vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dependents on the dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dimension of the points	0.0	0.0	0.0	2.0	0.0000000000	False
data points x combine	0.0	0.0	0.0	2.0	0.0000000000	False
long as you restrict	0.0	0.0	0.0	2.0	0.0000000000	False
attention to the class	0.0	0.0	0.0	2.0	0.0000000000	False
class of your separators	0.0	0.0	0.0	2.0	0.0000000000	False
find a large margin	0.0	0.0	0.0	2.0	0.0000000000	False
examples with large margin	0.0	0.0	0.0	2.0	0.0000000000	False
automatically trying to find	0.0	0.0	0.0	2.0	0.0000000000	False
find a hypothesis class	0.0	0.0	0.0	2.0	0.0000000000	False
constantly infinite dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
equal to some equals	0.0	0.0	0.0	2.0	0.0000000000	False
tie empirical risk minimization	0.0	0.0	0.0	2.0	0.0000000000	False
strongly to the source	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms we ve talked	0.0	0.0	0.0	0.0	0.0000000000	False
talked about it turns	0.0	0.0	0.0	2.0	0.0000000000	False
minimization so that view	0.0	0.0	0.0	2.0	0.0000000000	False
training example your training	0.0	0.0	0.0	2.0	0.0000000000	False
value of this data	0.0	0.0	0.0	2.0	0.0000000000	False
guess if your training	0.0	0.0	0.0	2.0	0.0000000000	False
subscript x not equals	0.0	0.0	0.0	2.0	0.0000000000	False
minimize this step function	0.0	0.0	0.0	4.0	0.0000000000	False
step function ; right	0.0	0.0	0.0	2.0	0.0000000000	False
correct classification on setting	0.0	0.0	0.0	2.0	0.0000000000	False
turns out this step	0.0	0.0	0.0	2.0	0.0000000000	False
out this step function	0.0	0.0	0.0	2.0	0.0000000000	False
classifiers minimizing the training	0.0	0.0	0.0	2.0	0.0000000000	False
minimizing the training error	0.0	0.0	0.0	2.0	0.0000000000	False
error is an empty	0.0	0.0	0.0	2.0	0.0000000000	False
heart problem it turns	0.0	0.0	0.0	2.0	0.0000000000	False
machines can be viewed	0.0	0.0	0.0	2.0	0.0000000000	False
approximation for this problem	0.0	0.0	0.0	2.0	0.0000000000	False
out that logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
ll be a function	0.0	0.0	0.0	2.0	0.0000000000	False
approximation to this step	0.0	0.0	0.0	2.0	0.0000000000	False
approximate empirical risk minimization	0.0	0.0	0.0	4.0	0.0000000000	False
line above this curve	0.0	0.0	0.0	2.0	0.0000000000	False
problem you can find	0.0	0.0	0.0	2.0	0.0000000000	False
find the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
parameters for logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
viewed as approximated dysfunction	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine turns	0.0	0.0	0.0	2.0	0.0000000000	False
approximate this step function	0.0	0.0	0.0	2.0	0.0000000000	False
two over different approximation	0.0	0.0	0.0	2.0	0.0000000000	False
linear that our results	0.0	0.0	0.0	2.0	0.0000000000	False
regression and the support	0.0	0.0	0.0	2.0	0.0000000000	False
machine as different approximations	0.0	0.0	0.0	2.0	0.0000000000	False
developed even though svm	0.0	0.0	0.0	2.0	0.0000000000	False
due to empirical risk	0.0	0.0	0.0	2.0	0.0000000000	False
last of the loose	0.0	0.0	0.0	2.0	0.0000000000	False
move on to talk	0.0	0.0	0.0	2.0	0.0000000000	False
theory that we started	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
important not to choose	0.0	0.0	0.0	2.0	0.0000000000	False
simple or too complex	0.0	0.0	0.0	2.0	0.0000000000	False
choose a linear function	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis with high bias	0.0	0.0	0.0	2.0	0.0000000000	False
generalize well so model	0.0	0.0	0.0	2.0	0.0000000000	False
model selection algorithms provide	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms provide a class	0.0	0.0	0.0	2.0	0.0000000000	False
methods to automatically trade	0.0	0.0	0.0	2.0	0.0000000000	False
trade make these tradeoffs	0.0	0.0	0.0	2.0	0.0000000000	False
last time of generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error ? i drew	0.0	0.0	0.0	2.0	0.0000000000	False
x-axis was model complexity	0.0	0.0	0.0	2.0	0.0000000000	False
number of the degree	0.0	0.0	0.0	2.0	0.0000000000	False
polynomial ; the regression	0.0	0.0	0.0	2.0	0.0000000000	False
polynomial to five data	0.0	0.0	0.0	2.0	0.0000000000	False
selection in the abstract	0.0	0.0	0.0	2.0	0.0000000000	False
abstract ; all right	0.0	0.0	0.0	2.0	0.0000000000	False
right ? some examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples of model selection	0.0	0.0	0.0	4.0	0.0000000000	False
selection problems will include	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to choose	0.0	0.0	7.998	8.0	0.0000000000	False
right ? what degree	0.0	0.0	0.0	2.0	0.0000000000	False
parameter in locally awaited	0.0	0.0	0.0	2.0	0.0000000000	False
locally awaited linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
local way to regression	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective ; right	0.0	0.0	0.0	2.0	0.0000000000	False
penalize in this class	0.0	0.0	0.0	2.0	0.0000000000	False
specific examples of model	0.0	0.0	0.0	2.0	0.0000000000	False
method for semantically choosing	0.0	0.0	0.0	2.0	0.0000000000	False
finite set of models	0.0	0.0	0.0	2.0	0.0000000000	False
bandwidth parameter and discretize	0.0	0.0	0.0	2.0	0.0000000000	False
discrete of the values	0.0	0.0	0.0	2.0	0.0000000000	False
select an appropriate model	0.0	0.0	0.0	2.0	0.0000000000	False
model ; all right	0.0	0.0	0.0	2.0	0.0000000000	False
laughing that i asked	0.0	0.0	0.0	2.0	0.0000000000	False
terrible idea to choose	0.0	0.0	0.0	2.0	0.0000000000	False
complex model ; right	0.0	0.0	0.0	2.0	0.0000000000	False
choose a 10th degree	0.0	0.0	0.0	2.0	0.0000000000	False
fits the training set	0.0	0.0	0.0	2.0	0.0000000000	False
selection in a training	0.0	0.0	0.0	2.0	0.0000000000	False
set several standard procedures	0.0	0.0	0.0	2.0	0.0000000000	False
hold out cross validation	0.0	0.0	9.994	24.0	0.3559322034	False
teach a training set	0.0	0.0	0.0	2.0	0.0000000000	False
randomly split the training	0.0	0.0	0.0	2.0	0.0000000000	False
split the training set	0.0	0.0	0.0	2.0	0.0000000000	False
set into two subsets	0.0	0.0	0.0	2.0	0.0000000000	False
two subsets we call	0.0	0.0	0.0	2.0	0.0000000000	False
call it the training	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation subset	0.0	0.0	0.0	4.0	0.0000000000	False
model on just trading	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation set	0.0	0.0	0.0	4.0	0.0000000000	False
set and you pick	0.0	0.0	0.0	2.0	0.0000000000	False
error on the hold	0.0	0.0	0.0	2.0	0.0000000000	False
percent of the data	0.0	0.0	2.998	8.0	0.0000000000	False
smallest hold out cross	0.0	0.0	0.0	2.0	0.0000000000	False
out cross validation error	0.0	0.0	0.0	4.0	0.0000000000	False
error on your hold	0.0	0.0	0.0	2.0	0.0000000000	False
model that you selected	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that was trained	0.0	0.0	0.0	2.0	0.0000000000	False
percent of your data	0.0	0.0	3.998	8.0	0.0000000000	False
cross validation does sort	0.0	0.0	0.0	2.0	0.0000000000	False
working with a company	0.0	0.0	0.0	2.0	0.0000000000	False
acquired at great cost	0.0	0.0	0.0	2.0	0.0000000000	False
great cost ; right	0.0	0.0	0.0	2.0	0.0000000000	False
acquired by medical experiments	0.0	0.0	0.0	2.0	0.0000000000	False
represents a sick man	0.0	0.0	0.0	2.0	0.0000000000	False
sick man in amounts	0.0	0.0	0.0	2.0	0.0000000000	False
amounts of physical human	0.0	0.0	0.0	2.0	0.0000000000	False
couple of other variations	0.0	0.0	0.0	2.0	0.0000000000	False
variations on hold out	0.0	0.0	0.0	2.0	0.0000000000	False
cross validation that makes	0.0	0.0	0.0	2.0	0.0000000000	False
train on k minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one pieces test	0.0	0.0	0.0	2.0	0.0000000000	False
test on the remaining	0.0	0.0	0.0	4.0	0.0000000000	False
out i will hold	0.0	0.0	0.0	2.0	0.0000000000	False
train on the remaining	0.0	0.0	0.0	2.0	0.0000000000	False
remove the third piece	0.0	0.0	0.0	2.0	0.0000000000	False
estimate of the generalization	0.0	0.0	0.0	2.0	0.0000000000	False
error of my model	0.0	0.0	0.0	2.0	0.0000000000	False
selected on the entirety	0.0	0.0	0.0	2.0	0.0000000000	False
entirety of your training	0.0	0.0	0.0	2.0	0.0000000000	False
set so i drew	0.0	0.0	0.0	2.0	0.0000000000	False
validation and the advantage	0.0	0.0	0.0	2.0	0.0000000000	False
hold out cross option	0.0	0.0	0.0	2.0	0.0000000000	False
data into ten pieces	0.0	0.0	0.0	2.0	0.0000000000	False
out in simple hold	0.0	0.0	0.0	2.0	0.0000000000	False
simple hold out cross	0.0	0.0	0.0	4.0	0.0000000000	False
split is fairly common	0.0	0.0	0.0	4.0	0.0000000000	False
common choice the disadvantage	0.0	0.0	0.0	2.0	0.0000000000	False
disadvantage of k-fold cross	0.0	0.0	0.0	2.0	0.0000000000	False
train your model ten	0.0	0.0	0.0	2.0	0.0000000000	False
ten times per model	0.0	0.0	0.0	2.0	0.0000000000	False
expensive but k equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals ten works great	0.0	0.0	0.0	2.0	0.0000000000	False
examples and this procedure	0.0	0.0	0.0	2.0	0.0000000000	False
procedure is called leave	0.0	0.0	0.0	2.0	0.0000000000	False
leave one out cross	0.0	0.0	2.998	8.0	0.4158415842	False
out the first training	0.0	0.0	0.0	2.0	0.0000000000	False
train on the rest	0.0	0.0	0.0	4.0	0.0000000000	False
out the second training	0.0	0.0	0.0	2.0	0.0000000000	False
data than k-fold cross	0.0	0.0	0.0	2.0	0.0000000000	False
leave one example out	0.0	0.0	0.0	2.0	0.0000000000	False
run your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm on m minus	0.0	0.0	0.0	2.0	0.0000000000	False
minus one training examples	0.0	0.0	0.0	2.0	0.0000000000	False
re extremely data scarce	0.0	0.0	0.0	2.0	0.0000000000	False
validation is maybe preferred	0.0	0.0	0.0	2.0	0.0000000000	False
proved that the difference	0.0	0.0	0.0	2.0	0.0000000000	False
examples in your training	0.0	0.0	0.0	2.0	0.0000000000	False
set and vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
dimension so maybe examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples into different groups	0.0	0.0	0.0	2.0	0.0000000000	False
compute the training error	0.0	0.0	0.0	2.0	0.0000000000	False
people in structure risk	0.0	0.0	0.0	2.0	0.0000000000	False
risk minimization that propose	0.0	0.0	0.0	2.0	0.0000000000	False
questions for cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
points do you sort	0.0	0.0	0.0	2.0	0.0000000000	False
re proving learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
proving learning theory bounds	0.0	0.0	0.0	2.0	0.0000000000	False
loose because you re	0.0	0.0	0.0	0.0	0.0000000000	False
re sort of proving	0.0	0.0	0.0	2.0	0.0000000000	False
proving the worse case	0.0	0.0	0.0	2.0	0.0000000000	False
worse case upper bound	0.0	0.0	0.0	2.0	0.0000000000	False
upper bound that holds	0.0	0.0	0.0	2.0	0.0000000000	False
bounds that i proved	0.0	0.0	0.0	2.0	0.0000000000	False
right ? that holds	0.0	0.0	0.0	2.0	0.0000000000	False
absolutely any probability distribution	0.0	0.0	0.0	4.0	0.0000000000	False
probability distribution over training	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over training examples	0.0	0.0	0.0	2.0	0.0000000000	False
assume the training examples	0.0	0.0	0.0	2.0	0.0000000000	False
training examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
examples we ve drawn	0.0	0.0	0.0	0.0	0.0000000000	False
iid from some distribution	0.0	0.0	0.0	2.0	0.0000000000	False
probability distribution over script	0.0	0.0	0.0	2.0	0.0000000000	False
script d and chances	0.0	0.0	0.0	2.0	0.0000000000	False
houses and their prices	0.0	0.0	0.0	2.0	0.0000000000	False
plug in the constants	0.0	0.0	0.0	2.0	0.0000000000	False
constants of learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
numbers take logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression you have ten	0.0	0.0	0.0	2.0	0.0000000000	False
probability how many training	0.0	0.0	0.0	2.0	0.0000000000	False
plug in actual constants	0.0	0.0	0.0	2.0	0.0000000000	False
constants into the text	0.0	0.0	0.0	2.0	0.0000000000	False
text for learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
estimates with the number	0.0	0.0	0.0	2.0	0.0000000000	False
training examples to fit	0.0	0.0	0.0	2.0	0.0000000000	False
examples to fit ten	0.0	0.0	0.0	2.0	0.0000000000	False
write papers on learning	0.0	0.0	0.0	2.0	0.0000000000	False
papers on learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
ignore the constant factors	0.0	0.0	0.0	2.0	0.0000000000	False
factors because the bounds	0.0	0.0	0.0	2.0	0.0000000000	False
bounds to give guidelines	0.0	0.0	0.0	2.0	0.0000000000	False
linearly in the number	0.0	0.0	0.0	2.0	0.0000000000	False
shape of the bounds	0.0	0.0	0.0	2.0	0.0000000000	False
fact that the number	0.0	0.0	0.0	2.0	0.0000000000	False
training examples the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that some complexity	0.0	0.0	0.0	2.0	0.0000000000	False
magnitude of the bound	0.0	0.0	0.0	2.0	0.0000000000	False
looser than will hold	0.0	0.0	0.0	2.0	0.0000000000	False
problem you are working	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to fit	0.0	0.0	0.0	2.0	0.0000000000	False
fit a logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
training examples is ten	0.0	0.0	0.0	2.0	0.0000000000	False
examples is ten times	0.0	0.0	0.0	2.0	0.0000000000	False
ten times your number	0.0	0.0	0.0	2.0	0.0000000000	False
examples is like tiny	0.0	0.0	0.0	2.0	0.0000000000	False
tiny times the number	0.0	0.0	0.0	2.0	0.0000000000	False
bounds in cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
validation do we assume	0.0	0.0	0.0	2.0	0.0000000000	False
convention we usually split	0.0	0.0	0.0	2.0	0.0000000000	False
split the train testers	0.0	0.0	0.0	2.0	0.0000000000	False
randomly one more thing	0.0	0.0	0.0	2.0	0.0000000000	False
talk about for model	0.0	0.0	0.0	2.0	0.0000000000	False
special case of model	0.0	0.0	0.0	2.0	0.0000000000	False
case of model selections	0.0	0.0	0.0	2.0	0.0000000000	False
high dimensional feature space	0.0	0.0	0.0	2.0	0.0000000000	False
classification and i wan	0.0	0.0	0.0	2.0	0.0000000000	False
talk about this text	0.0	0.0	0.0	2.0	0.0000000000	False
classification example that spam	0.0	0.0	0.0	2.0	0.0000000000	False
30,000 or 50,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
depending on what learning	0.0	0.0	0.0	2.0	0.0000000000	False
risk of over fitting	0.0	0.0	3.9985	6.0	0.0000000000	False
variance of your learning	0.0	0.0	0.0	2.0	0.0000000000	False
specific case of text	0.0	0.0	0.0	2.0	0.0000000000	False
case of text classification	0.0	0.0	0.0	4.0	0.0000000000	False
number of relevant features	0.0	0.0	0.0	2.0	0.0000000000	False
smaller number of features	0.0	0.0	0.0	2.0	0.0000000000	False
relevant to the learning	0.0	0.0	0.0	2.0	0.0000000000	False
word buy or viagra	0.0	0.0	0.0	2.0	0.0000000000	False
non-spam so in feature	0.0	0.0	0.0	2.0	0.0000000000	False
subset of the features	0.0	0.0	0.0	2.0	0.0000000000	False
give ourselves a simpler	0.0	0.0	0.0	2.0	0.0000000000	False
simpler learning a simpler	0.0	0.0	0.0	2.0	0.0000000000	False
learning a simpler hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis class to choose	0.0	0.0	0.0	2.0	0.0000000000	False
space so in feature	0.0	0.0	0.0	2.0	0.0000000000	False
searcheristics sort of simple	0.0	0.0	0.0	2.0	0.0000000000	False
sort of simple search	0.0	0.0	0.0	2.0	0.0000000000	False
search through this space	0.0	0.0	0.0	2.0	0.0000000000	False
find a good subset	0.0	0.0	0.0	2.0	0.0000000000	False
good subset of features	0.0	0.0	0.0	2.0	0.0000000000	False
enumerate all possible feature	0.0	0.0	0.0	2.0	0.0000000000	False
initialize the sets script	0.0	0.0	0.0	2.0	0.0000000000	False
repeat for i equals	0.0	0.0	0.0	2.0	0.0000000000	False
model using cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
validation and by cross	0.0	0.0	0.0	2.0	0.0000000000	False
validation or k-fold cross	0.0	0.0	0.0	2.0	0.0000000000	False
cross validation or leave	0.0	0.0	0.0	2.0	0.0000000000	False
equal to f union	0.0	0.0	0.0	2.0	0.0000000000	False
follow through the empty	0.0	0.0	0.0	2.0	0.0000000000	False
empty set of features	0.0	0.0	0.0	2.0	0.0000000000	False
feature to your set	0.0	0.0	0.0	4.0	0.0000000000	False
set then you train	0.0	0.0	0.0	2.0	0.0000000000	False
single feature to add	0.0	0.0	0.0	2.0	0.0000000000	False
add to your set	0.0	0.0	0.0	2.0	0.0000000000	False
script f in step	0.0	0.0	0.0	2.0	0.0000000000	False
feature or best model	0.0	0.0	0.0	2.0	0.0000000000	False
model according to hold	0.0	0.0	0.0	2.0	0.0000000000	False
feature addition that results	0.0	0.0	0.0	2.0	0.0000000000	False
lowest hold out cross	0.0	0.0	0.0	2.0	0.0000000000	False
lowest cross validation error	0.0	0.0	0.0	4.0	0.0000000000	False
added all the features	0.0	0.0	0.0	2.0	0.0000000000	False
entire set of features	0.0	0.0	0.0	4.0	0.0000000000	False
exceeded some threshold number	0.0	0.0	0.0	2.0	0.0000000000	False
threshold number of features	0.0	0.0	0.0	2.0	0.0000000000	False
re fitting logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
features added to set	0.0	0.0	0.0	2.0	0.0000000000	False
output of best hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
training lots of hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
testing them using cross	0.0	0.0	0.0	2.0	0.0000000000	False
output best hypothesis found	0.0	0.0	0.0	2.0	0.0000000000	False
selection and the term	0.0	0.0	0.0	2.0	0.0000000000	False
fact that this feature	0.0	0.0	0.0	2.0	0.0000000000	False
described is a forward	0.0	0.0	0.0	2.0	0.0000000000	False
selection or forward search	0.0	0.0	0.0	2.0	0.0000000000	False
software that you write	0.0	0.0	0.0	2.0	0.0000000000	False
wraps around your learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense that to perform	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to train	0.0	0.0	0.0	2.0	0.0000000000	False
wrapper model feature selection	0.0	1.0	0.0	4.0	0.0000000000	True
re performing the search	0.0	0.0	0.0	2.0	0.0000000000	False
performing the search process	0.0	0.0	0.0	2.0	0.0000000000	False
repeatedly training your learning	0.0	0.0	0.0	2.0	0.0000000000	False
training your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
backward search or backward	0.0	0.0	0.0	4.0	0.0000000000	False
search or backward selection	0.0	0.0	0.0	4.0	0.0000000000	False
start with f equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals the entire set	0.0	0.0	0.0	2.0	0.0000000000	False
nt even make sense	0.0	0.0	0.0	0.0	0.0000000000	False
make sense to initialize	0.0	0.0	0.0	4.0	0.0000000000	False
set of all features	0.0	0.0	0.0	2.0	0.0000000000	False
examples and 10,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
emails and 10,000 training	0.0	0.0	0.0	2.0	0.0000000000	False
10,000 training 10,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
10,000 features in email	0.0	0.0	0.0	2.0	0.0000000000	False
training examples then depending	0.0	0.0	0.0	2.0	0.0000000000	False
depending on the learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm you re	0.0	0.0	0.0	0.0	0.0000000000	False
model feature selection algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
feature selection algorithms tend	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms tend to work	0.0	0.0	0.0	2.0	0.0000000000	False
re computationally very expensive	0.0	0.0	0.0	2.0	0.0000000000	False
right so forward search	0.0	0.0	0.0	2.0	0.0000000000	False
forward search and backward	0.0	0.0	0.0	2.0	0.0000000000	False
search and backward search	0.0	0.0	0.0	2.0	0.0000000000	False
guarantee they ll find	0.0	0.0	0.0	0.0	0.0000000000	False
find the best subset	0.0	0.0	0.0	4.0	0.0000000000	False
features it actually turns	0.0	0.0	0.0	2.0	0.0000000000	False
formulizations of the feature	0.0	0.0	0.0	2.0	0.0000000000	False
problems it actually turns	0.0	0.0	0.0	2.0	0.0000000000	False
features but in practice	0.0	0.0	0.0	2.0	0.0000000000	False
forward selection backward selection	0.0	0.0	0.0	2.0	0.0000000000	False
selection backward selection work	0.0	0.0	0.0	2.0	0.0000000000	False
envision other search algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms where you sort	0.0	0.0	0.0	2.0	0.0000000000	False
search through the space	0.0	0.0	0.0	2.0	0.0000000000	False
end possible feature subsets	0.0	0.0	0.0	2.0	0.0000000000	False
selection tends to work	0.0	0.0	0.0	2.0	0.0000000000	False
computationally but for problems	0.0	0.0	0.0	2.0	0.0000000000	False
problems such as text	0.0	0.0	0.0	2.0	0.0000000000	False
text classification it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out for text	0.0	0.0	0.0	2.0	0.0000000000	False
out for text classification	0.0	0.0	0.0	2.0	0.0000000000	False
easily have 50,000 features	0.0	0.0	0.0	2.0	0.0000000000	False
50,000 features forward selection	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms that will give	0.0	0.0	0.0	2.0	0.0000000000	False
sense of generalization error	0.0	0.0	0.0	2.0	0.0000000000	False
error so you tend	0.0	0.0	0.0	2.0	0.0000000000	False
computationally much less expensive	0.0	0.0	0.0	2.0	0.0000000000	False
filter feature selection methods	0.0	0.0	0.0	2.0	0.0000000000	False
feature i will compute	0.0	0.0	0.0	2.0	0.0000000000	False
compute some rough estimate	0.0	0.0	0.0	2.0	0.0000000000	False
rough estimate or compute	0.0	0.0	0.0	2.0	0.0000000000	False
top k most correlated	0.0	0.0	0.0	2.0	0.0000000000	False
ideas in problem sets	0.0	0.0	0.0	2.0	0.0000000000	False
major information between feature	0.0	0.0	0.0	2.0	0.0000000000	False
write out the definition	0.0	0.0	0.0	2.0	0.0000000000	False
values of y times	0.0	0.0	0.0	2.0	0.0000000000	False
times the distribution times	0.0	0.0	0.0	2.0	0.0000000000	False
estimate from your training	0.0	0.0	0.0	2.0	0.0000000000	False
estimate from the training	0.0	0.0	0.0	2.0	0.0000000000	False
standard information theoretic measure	0.0	0.0	0.0	2.0	0.0000000000	False
class in information theory	0.0	0.0	0.0	2.0	0.0000000000	False
concepts of mutual information	0.0	0.0	0.0	2.0	0.0000000000	False
information is a measure	0.0	0.0	0.0	2.0	0.0000000000	False
distribution and this distribution	0.0	0.0	0.0	2.0	0.0000000000	False
non-independent in other words	0.0	0.0	0.0	2.0	0.0000000000	False
divergence will be large	0.0	0.0	0.0	2.0	0.0000000000	False
non-independent then that means	0.0	0.0	0.0	2.0	0.0000000000	False
information and this measure	0.0	0.0	0.0	2.0	0.0000000000	False
correlation or major information	0.0	0.0	0.0	2.0	0.0000000000	False
meaning that you compute	0.0	0.0	0.0	2.0	0.0000000000	False
features of mutual information	0.0	0.0	0.0	2.0	0.0000000000	False
include in your learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm the k features	0.0	0.0	0.0	2.0	0.0000000000	False
correlation with the label	0.0	0.0	0.0	2.0	0.0000000000	False
largest mutual information label	0.0	0.0	0.0	2.0	0.0000000000	False
sort them in decreasing	0.0	0.0	0.0	2.0	0.0000000000	False
order of mutual information	0.0	0.0	0.0	2.0	0.0000000000	False
decide how many features	0.0	0.0	0.0	2.0	0.0000000000	False
features includes using cross	0.0	0.0	0.0	2.0	0.0000000000	False
includes using cross validation	0.0	0.0	0.0	2.0	0.0000000000	False
choose this by hand	0.0	0.0	0.0	2.0	0.0000000000	False
great so next lecture	0.0	0.0	0.0	2.0	0.0000000000	False
lecture i ll continue	0.0	0.0	0.0	0.0	0.0000000000	False
continue i ll wrap	0.0	0.0	0.0	0.0	0.0000000000	False
couple of quick	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
submissions they ve	0.0	0.0	0.0	0.0	0.0000000000	False
end of lecture	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
re an sepd	0.0	0.0	2.9985	0.0	0.0000000000	False
submitted your problem	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hand in box	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
picked up today	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
access after hours	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
end of class	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
homework by fax	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
posted online last	0.0	0.0	0.0	0.0	0.0000000000	False
online last week	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
guys actually understood	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class for working	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
working as graders	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
late on monday	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class is scheduled	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
8th of november	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
laptops and computers	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
computers sepd students	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
person to stanford	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
midterm in person	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
drive to stanford	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
usual class mailing	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class mailing address	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
cs229qa @ cs.stanford.edu	0.0	0.0	0.0	1.58496250072	0.0000000000	False
attend the midterm	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
make alternate arrangements	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
regular stanford students	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
event of sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
equal or greater	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class that conflicts	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
usual staff mailing	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
staff mailing address	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
ll be showing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lecture s technical	0.0	0.0	0.0	0.0	0.0000000000	False
week s discussion	0.0	0.0	0.0	0.0	0.0000000000	False
talking about convex	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
section they discussed	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
discussed total convex	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
total convex optimization	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
present on convex	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
lecture is talk	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension and building	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
issues of bias	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bias variance tradeoffs	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
talk about model	0.00284796479574	0.0	3.9985	0.0	0.0000000000	False
model selection algorithms	0.0023343564589	1.0	0.0	1.58496250072	0.0000000000	False
automatically making decisions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
started to talk	0.000513608336833	0.0	0.0	1.58496250072	0.0000000000	False
lecture and depending	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
week s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
lecture to recap	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
result we proved	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
finite hypothesis class	0.000949321598579	0.0	4.998	6.33985000288	0.0000000000	False
gamma and delta	0.00466871291781	0.0	5.998	4.75488750216	0.2937062937	False
order to guarantee	0.00474660799289	0.0	3.9975	7.92481250361	0.5316455696	False
delta it suffices	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
greater and equal	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
learning dropped constants	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
talked about empirical	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
empirical risk minimization	0.00949321598579	1.0	6.9945	15.8496250072	0.5316455696	True
simplified modern machine	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
modern machine learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class of script	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
empirical risk minimization-learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
risk minimization-learning algorithm	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
chooses the hypothesis	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that attains	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
attains the smallest	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
denoted generalization error	0.0	0.0	0.0	1.58496250072	0.0000000000	False
error ; right	0.0	0.0	0.0	0.0	0.0000000000	False
hypothesis h misclassifying	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis h output	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
output by empirical	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
two times gamma	0.0	0.0	0.0	3.16992500144	0.0000000000	False
gamma two times	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times this error	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
holds a probability	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
delta we show	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
training set size	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
greater than equal	0.000604027008112	0.0	0.0	1.58496250072	0.0000000000	False
two gamma square	0.0	0.0	0.0	0.0	0.0000000000	False
gamma square log	0.00189864319716	0.0	0.0	1.58496250072	0.0000000000	False
number of training	0.00877757961247	0.0	9.994	0.0	0.3925233645	False
order to give	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
give a guarantee	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sample complexity result	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
case of infinite	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
infinite hypothesis classes	0.00284796479574	0.0	3.9985	4.75488750216	0.0000000000	False
model like logistic	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
parameterized by real	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
give an argument	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
broken just sort	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
technically somewhat broken	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
conveys useful intuition	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
apply this result	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
result analyzing logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
analyzing logistic regression	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
linear division boundaries	0.000949321598579	0.0	0.0	3.16992500144	0.0000000000	False
re applying logistic	0.0	0.0	0.0	0.0	0.0000000000	False
applying logistic regression	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
regression to find	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
find the linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
linear position boundary	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
parameterized by endless	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
endless one real	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bits to represent	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
represent real numbers	0.00350153468835	0.0	5.9985	4.75488750216	0.0000000000	False
normal standard computer	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
double position floating	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
position floating point	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
floating point numbers	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
number is represented	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
representation ; right	0.0	0.0	0.0	0.0	0.0000000000	False
64-bit floating point	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
times d bits	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
nt represent real	0.0	0.0	0.0	0.0	0.0000000000	False
number of ways	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of guarantee	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
great and equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
returned by empirical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
give that sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of error	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
error bound guarantee	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
number of parameters	0.00585171974165	0.0	7.9955	14.2646625065	0.3500000000	False
representation of 14-point	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
outline the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the right	0.0	0.0	0.0	0.0	0.0000000000	False
state the result	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
prove it farther	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
source of learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
learning theory balance	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
classes this definition	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class h shatters	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shatters the set	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
realize any labeling	0.00350153468835	0.0	3.9985	4.75488750216	0.0000000000	False
class has shattered	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set of labels	0.00350153468835	0.0	3.9985	3.16992500144	0.0000000000	False
choose any set	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis class shatters	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that labels	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
comprising two points	0.0	0.0	0.0	1.58496250072	0.0000000000	False
four possible labelings	0.0	0.0	0.0	1.58496250072	0.0000000000	False
labelings that computes	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose to label	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
label both positive	0.0	0.0	0.0	1.58496250072	0.0000000000	False
class h classed	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classed all linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of find	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
find a linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classifier that attains	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
attains zero training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hypothesis class script	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
script h shatters	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shatters this set	0.00700306937671	0.0	5.997	9.50977500433	0.3730017762	False
larger example suppose	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
suppose my set	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
points ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
find the hypothesis	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
class that labels	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
labels these examples	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class also shatters	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set s right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
find a hypothesis	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
separates the positive	0.000604027008112	0.0	0.0	1.58496250072	0.0000000000	False
positive and negative	0.000513608336833	0.0	0.0	0.0	0.0000000000	False
set ? suppose	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lots of labels	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
realize some labelings	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
realize this labeling	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
classifiers can shatter	0.0	0.0	0.0	0.0	0.0000000000	False
vapnik and chervonenkis	0.00350153468835	0.0	2.9985	3.16992500144	0.0000000000	False
class can shatter	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shatter arbitrarily large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
arbitrarily large sets	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
dimension is infinite	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
kind of good	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
set is equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
nt really prove	0.0	0.0	0.0	0.0	0.0000000000	False
sets of size	0.00583589114726	0.0	4.9975	7.92481250361	0.2335928810	False
choose a set	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
definition no right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose my set	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
lapping three points	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out this result	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
result holds true	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class of linear	0.00379728639431	0.0	2.998	3.16992500144	0.5250000000	False
dimensions is equal	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimensional feature space	0.00198399239271	0.0	2.9985	3.16992500144	0.0000000000	False
arguably the best-known	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re in probability	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out the essential	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
delta you enjoy	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
enjoy this sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of uniform	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
uniform conversions results	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
things is bounded	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
step ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lecture we proved	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
error and training	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
hypotheses you pick	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
two gamma times	0.0	0.0	0.0	1.58496250072	0.0000000000	False
constants in front	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
slightly more complicated	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
delta we re	0.0	0.0	0.0	0.0	0.0000000000	False
write m equals	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
error to denote	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
delta as constants	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
turns that depend	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
depend on gamma	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
guarantee this holds	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension and hypotheses	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
risk minimization algorithms	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
minimize training error	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
error the intuition	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
shows that sample	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
complexity is upper	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
reasonable hypothesis classes	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
dimension is sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
parameters you model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model and logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
logistic regression linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
regression linear classification	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
dimensions logistic regression	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimensions is endless	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
endless one parameters	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sense of low	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
low other polynomial	0.0	0.0	0.0	1.58496250072	0.0000000000	False
dimension is enormous	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
strange and degenerate	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
things it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
shows the sample	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
find it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
case some complexity	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
perfectly nasty learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
nasty learning problem	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
prove this bound	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bounded and lower	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
assume any sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of finites	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ve actually stated	0.0	0.0	0.0	1.58496250072	0.0000000000	False
stated the entirety	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
true it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
someway that sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of proof	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
clever to prove	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
reading the book	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
book that led	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
understand this proof	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
tie a couple	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
couple of loose	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
bit like random	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bound was proved	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
algorithm that minimizes	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
minimizes 0-1 training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
0-1 training error	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
support vector machines	0.00333346406681	0.0	7.9965	9.50977500433	0.3500000000	True
nt over fit	0.0	0.0	0.0	0.0	0.0000000000	False
sequel of remember	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
remember our discussion	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
discussion on support	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
map the features	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
features in infinite	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional feature	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
separators with large	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
low vc dimension	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension i wan	0.0	0.0	0.0	1.58496250072	0.0000000000	False
understand the details	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
informally it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
set of points	0.000604027008112	0.0	0.0	1.58496250072	0.0000000000	False
lines that separate	0.00146292993541	0.0	0.0	3.16992500144	0.0000000000	False
separate these points	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class will comprise	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
boundaries that separate	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
separate the points	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
points it turns	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
points all lie	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sphere of radius	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
separators is separate	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
separate to data	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
four gamma squared	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out you prove	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classifiers with large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bounded the surprising	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
points x combine	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
combine an infinite	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
infinite dimensional space	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
dimension is bounded	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
find a large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
large margin separator	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
find the line	0.00116717822945	0.0	0.0	3.16992500144	0.0000000000	False
separates your positive	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
examples with large	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class with small	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
small vc dimension	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
finite dimensional spaces	0.000949321598579	0.0	0.0	3.16992500144	0.0000000000	False
constantly infinite dimensional	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
infinite dimensional vectors	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
squared is equal	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
insures that conversions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
tie empirical risk	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
source of algorithms	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
draw a function	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
equals data transpose	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
positive or negative	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
negative and depending	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
right or wrong	0.0	0.0	0.0	1.58496250072	0.0000000000	False
part of indicator	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
indicator h subscript	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose parameters data	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
minimize this step	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
function ; right	0.0	0.0	0.0	0.0	0.0000000000	False
classification on setting	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
setting your training	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out this step	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
linear classifiers minimizing	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
minimizing the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
empty heart problem	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
problem it turns	0.000731464967706	0.0	0.0	0.0	0.0000000000	False
out that logistic	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
tying to minimize	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
minimize the minus	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
plot the minus	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
approximate empirical risk	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
hard optimization problem	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
convex optimization problem	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
find the maximum	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
parameters for logistic	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
viewed as approximated	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
vector machine turns	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
approximate this step	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of linear	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
theory we developed	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
nt exactly due	0.0	0.0	0.0	0.0	0.0000000000	False
due to empirical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
completely appropriate intuitions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
intuitions for svm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
regression are reasonable	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
check for questions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
started to develop	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
sort of wrapped	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
trade-off between bias	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bias and variance	0.000821883638985	0.0	0.0	3.16992500144	0.0000000000	False
choose a hypothesis	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
data has sort	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose a linear	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
hypothesis with high	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
ll also fail	0.0	0.0	0.0	1.58496250072	0.0000000000	False
fail to fit	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
fit the data	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
fail to generalize	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
selection algorithms provide	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
provide a class	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class of methods	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
automatically trade make	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
make these tradeoffs	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
tradeoffs between bias	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
variance ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
remember the cartoon	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
cartoon i drew	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
drew this last	0.0	0.0	0.0	1.58496250072	0.0000000000	False
x-axis was model	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
meaning the number	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
simple a model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
high generalization error	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
complex a model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
re over fitting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
examples of model	0.00189864319716	0.0	0.0	1.58496250072	0.0000000000	False
model selection problems	0.00466871291781	0.0	7.998	6.33985000288	0.0000000000	False
problems will include	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
choose the degree	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choose the parameter	0.00132266159514	0.0	0.0	3.16992500144	0.0000000000	False
locally awaited linear	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
awaited linear regression	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of local	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
objective ; right	0.0	0.0	0.0	0.0	0.0000000000	False
parameter c controls	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
controls the tradeoff	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
large margin versus	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
set of models	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
parameter and discretize	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
range of values	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
re training set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lowest training error	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
fit ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
idea to choose	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
choose a model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
end up choosing	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
model ; right	0.0	0.0	0.0	0.0	0.0000000000	False
choose a 10th	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
10th degree polynomial	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fits the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set several standard	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hold out cross	0.0123411807815	0.0	9.9935	15.8496250072	0.2956145100	False
out cross validation	0.0151891455773	0.0	9.992	19.0195500087	0.3903345725	False
teach a training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
split the training	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
subsets we call	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
call it subset	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
cross validation subset	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
train each model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
cross validation set	0.00189864319716	0.0	0.0	0.0	0.0000000000	False
pick the model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
data then test	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
cross validation error	0.00466871291781	0.0	2.998	3.16992500144	0.0000000000	False
output the hypothesis	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
chosen the degree	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
back and retrain	0.00350153468835	0.0	0.0	3.16992500144	0.0000000000	False
retrain the model	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
validation does sort	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sort of work	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
company or application	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
acquired at great	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
cost ; right	0.0	0.0	0.0	0.0	0.0000000000	False
data is acquired	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
acquired by medical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
training example represents	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
represents a sick	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
man in amounts	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
amounts of physical	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
physical human pain	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
select my model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model if people	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
variations on hold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validation that makes	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
slightly more efficient	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
k-fold cross validation	0.00700306937671	1.0	4.997	9.50977500433	0.0000000000	True
draw this box	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
note the entirety	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ll then divide	0.0	0.0	0.0	1.58496250072	0.0000000000	False
minus one pieces	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
remaining one test	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
guess ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll just hold	0.0	0.0	0.0	1.58496250072	0.0000000000	False
remaining pieces test	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model you selected	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
drew five pieces	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fairly common choice	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fold cross validation	0.00116717822945	0.0	5.9965	11.094737505	0.0000000000	False
out cross option	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
switch the data	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
data into ten	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re only holding	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out in simple	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
commonly k equals	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
choice the disadvantage	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
disadvantage of k-fold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validate your model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
train your model	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
model ten times	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
times per model	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
computationally more expensive	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
equals ten works	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
ten works great	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set k equals	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out the first	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
data than k-fold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
computationally very expensive	0.00284796479574	0.0	1.9985	3.16992500144	0.0000000000	False
run your learning	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
minus one training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
lot of times	0.000513608336833	0.0	0.0	1.58496250072	0.0000000000	False
re extremely data	0.0	0.0	0.0	0.0	0.0000000000	False
extremely data scarce	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
generalized by number	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
number of examples	0.00146292993541	0.0	0.0	3.16992500144	0.0000000000	False
compute the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
people in structure	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
structure risk minimization	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
minimization that propose	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
questions for cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
marginal ? right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
re proving learning	0.0	0.0	0.0	0.0	0.0000000000	False
proving learning theory	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
learning theory bounds	0.00583589114726	0.0	9.9975	6.33985000288	0.0000000000	False
sort of proving	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
proving the worse	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
worse case upper	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
case upper bound	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bound that holds	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
absolutely any probability	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
distribution over training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
examples ; right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
assume the training	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
examples we ve	0.0	0.0	0.0	0.0	0.0000000000	False
bounds i proved	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
proved hold true	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
distribution over script	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
real life distribution	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
constants of learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
extremely large numbers	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
numbers take logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
logistic regression logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
regression logistic regression	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
plug in actual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
text for learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
extremely pessimistic estimates	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ridiculously large numbers	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
10,000 training examples	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
examples to fit	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
fit ten parameters	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
papers on learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
absolutely just ignore	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ignore the constant	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bounds to give	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
model to choose	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
gross x dimension	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
dimension in number	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bounds the fact	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
examples the fact	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
complexity is linear	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bound will tend	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
answer your question	0.0	0.0	0.0	1.58496250072	0.0000000000	False
question ? uh-huh	0.0	0.0	0.0	1.58496250072	0.0000000000	False
rule of thumb	0.00164376727797	0.0	0.0	3.16992500144	0.0000000000	False
fit a logistic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
logistic regression model	0.000731464967706	0.0	0.0	1.58496250072	0.0000000000	False
examples is ten	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times your number	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times the number	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
perfectly fine fitting	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
fitting that model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sorts of intuitions	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
bounds in cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
assume these examples	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
train testers randomly	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
case of model	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
feature selection problem	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
high dimensional feature	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
wan na talk	0.0	0.0	0.0	1.58496250072	0.0000000000	False
spam versus non-spam	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
reduce the number	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
number of features	0.00181208102434	0.0	3.9985	3.16992500144	0.0000000000	False
reduce the variance	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
reduce the risk	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
case of text	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
number of relevant	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
email is spam	0.00189864319716	0.0	0.0	3.16992500144	0.0000000000	False
spam or non-spam	0.00350153468835	0.0	5.9985	4.75488750216	0.0000000000	False
english function words	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
non-spam so words	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
words in contrast	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
buy or viagra	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
spam and non-spam	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
stanford or machine-learning	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
select a subset	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
specific learning problem	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
learning a simpler	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
simpler hypothesis class	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
class to choose	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
50,000 features originally	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
included or excluded	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
sort of simple	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
simple search algorithms	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
subsets of features	0.00466871291781	0.0	7.997	7.92481250361	0.0000000000	False
find a good	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
large a number	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
number to enumerate	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
forward search algorithm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
forward selection algorithm	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	True
ll just write	0.0	0.0	0.0	3.16992500144	0.0000000000	False
write it out	0.00164376727797	0.0	0.0	3.16992500144	0.0000000000	False
out my writing	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
out will make	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
starts with initialize	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
initialize the sets	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
evaluate the model	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
model using cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validation or k-fold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
validation or leave	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
set of features	0.00111115468894	0.0	10.9955	12.6797000058	0.0000000000	False
adding that feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
feature to add	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
add that feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
single feature addition	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
addition that results	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
lowest cross validation	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
adding one feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
exceeded some threshold	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re fitting logistic	0.0	0.0	0.0	0.0	0.0000000000	False
fitting logistic regression	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
added to set	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
learning this algorithm	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
lots of hypothesis	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
output best hypothesis	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
hypothesis you ve	0.0	0.0	0.0	0.0	0.0000000000	False
wrapper feature selection	0.0023343564589	1.0	0.0	3.16992500144	0.0000000000	True
feature selection algorithm	0.00246565091695	0.0	2.9985	3.16992500144	0.0000000000	True
piece of software	0.000821883638985	0.0	0.0	1.58496250072	0.0000000000	False
write that wraps	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
perform forward selection	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to train	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
wrapper model feature	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
model feature selection	0.0023343564589	0.0	0.0	1.58496250072	0.0000000000	False
performing the search	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
re repeatedly training	0.0	0.0	0.0	1.58496250072	0.0000000000	False
training your learning	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
search or backward	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
equals the entire	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
nt even make	0.0	0.0	0.0	0.0	0.0000000000	False
sense to initialize	0.0023343564589	0.0	0.0	0.0	0.0000000000	False
training 10,000 features	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
features in email	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
examples then depending	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
algorithm you re	0.0	0.0	0.0	0.0	0.0000000000	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
selection algorithms tend	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
tend to work	0.000949321598579	0.0	0.0	1.58496250072	0.0000000000	False
class of algorithms	0.00164376727797	0.0	0.0	3.16992500144	0.0000000000	False
re actually right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
search and backward	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
forward selection backward	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
selection backward selection	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
backward selection work	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
envision other search	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
methods to search	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
end possible feature	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
classification it turns	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
out for text	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
50,000 features forward	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
features forward selection	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
sense of generalization	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
tend to learn	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
learn the hypothesis	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
hypothesis that works	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
filter feature selection	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
feature selection methods	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
compute some measure	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
compute some rough	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
estimate or compute	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
compute the correlation	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
pick the top	0.0023343564589	0.0	0.0	3.16992500144	0.0000000000	False
features i guess	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
ideas in problem	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
information between feature	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
out the definition	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
times the distribution	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
standard information theoretic	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
information theoretic measure	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
class in information	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
concepts of mutual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
two probability distributions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll have large	0.0	0.0	0.0	1.58496250072	0.0000000000	False
large mutual information	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
measure of information	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
chosen some measure	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
measure like correlation	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
correlation or major	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
top k features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features ; meaning	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features of mutual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
largest mutual information	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
mutual information label	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
order of mutual	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
top one feature	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
top two features	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
top three features	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
includes using cross	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
bayesian model selection	0.00116717822945	0.0	0.0	1.58496250072	0.0000000000	False
quick announcements	0.000402684672075	0.0	0.0	0.0	0.0000000000	False
problem set	0.00205443334733	0.0	3.997	5.0	0.2937062937	False
lecture today	0.000975286623608	0.0	0.0	0.0	0.0000000000	False
sepd student	0.00311247527854	0.0	3.998	2.0	0.0000000000	False
sepd career	0.00155623763927	0.0	0.0	2.0	0.0000000000	False
hard copy	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
late hand	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
gates building	0.0	0.0	0.0	1.0	0.0000000000	False
class today	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
web page	0.00109584485198	0.0	0.0	2.0	0.0000000000	False
posted online	0.00044088719838	0.0	0.0	0.0	0.0000000000	False
last week	0.0	0.0	0.0	2.0	0.0000000000	False
homework solutions	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
monday night	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
open book	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
open notes	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
computers sepd	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
bay area	0.0023343564589	0.0	2.9985	3.0	0.0000000000	False
usual class	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
class mailing	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
mailing address	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
alternate arrangements	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
regular stanford	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
stanford students	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
greater importance	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
usual staff	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
staff mailing	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
technical material	0.00054792242599	0.0	0.0	1.0	0.0000000000	False
discussion section	0.000805369344149	0.0	0.0	2.0	0.0000000000	False
convex optimization	0.00195057324722	1.0	2.998	3.0	0.0000000000	False
total convex	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
learning theory	0.00352709758704	0.0	9.996	7.0	0.3134328358	True
bias variance	0.00126576213144	0.0	0.0	1.0	0.0000000000	False
variance tradeoffs	0.00126576213144	0.0	0.0	0.0	0.0000000000	False
previous lecture	0.00171202778944	0.0	2.9975	4.0	0.0000000000	False
model selection	0.00633936305345	1.0	15.9935	11.0	0.2495049505	True
selection algorithms	0.00328753455594	0.0	3.997	5.0	0.4384133612	False
making decisions	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
finite hypothesis	0.000632881065719	0.0	4.998	0.0	0.0000000000	False
hypothesis class	0.0153418279277	0.0	22.986	27.0	0.3637795276	False
fixed parameters	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
re probability	0.0	0.0	5.996	7.0	0.0000000000	False
minus delta	0.00383545698193	0.0	6.9965	7.0	0.0000000000	False
big-o notations	0.00311247527854	0.0	3.998	4.0	0.0000000000	False
dropped constants	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
notation means	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
empirical risk	0.00696169172291	0.0	6.9945	9.0	0.4757981462	False
risk minimization	0.00696169172291	0.0	6.994	10.0	0.5384615385	False
modern machine	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
machine learning	0.000370384896312	0.0	0.0	0.0	0.0000000000	False
minimization-learning algorithm	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
smallest error	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
training set	0.00385950238129	0.0	13.993	13.0	0.2818791946	False
denoted generalization	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
generalization error	0.00886033492007	0.0	9.992	15.0	0.2601238685	True
times gamma	0.00126576213144	0.0	0.0	1.0	0.0000000000	False
error threshold	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
set size	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
square log	0.00109584485198	0.0	0.0	1.0	0.0000000000	False
complexity result	0.0023343564589	0.0	5.9985	2.0	0.0000000000	False
training examples	0.00650428777823	0.0	23.9835	32.0	0.3871743487	False
sample complexity	0.00253152426288	0.0	5.998	3.0	0.5250000000	False
infinite hypothesis	0.00189864319716	0.0	3.9985	1.0	0.0000000000	False
set script	0.00379728639431	0.0	4.997	5.0	0.3134328358	False
specific functions	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
logistic regression	0.006163300042	0.0	11.9905	18.0	0.3471074380	False
real numbers	0.00220542993216	0.0	15.9955	8.0	0.0000000000	False
correct argument	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
broken argument	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
result analyzing	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
linear division	0.00126576213144	0.0	0.0	0.0	0.0000000000	False
division boundaries	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
linear position	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
position boundary	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
computer computers	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
normal standard	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
standard computer	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
double position	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
position floating	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
floating point	0.00189864319716	0.0	5.9985	2.0	0.0000000000	False
point numbers	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
64-bit representation	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
64-bit floating	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
bits computers	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
speed things	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
computer representation	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
gamma square	0.00189864319716	0.0	5.998	3.0	0.0000000000	False
hypotheses class	0.00155623763927	0.0	3.9985	2.0	0.0000000000	False
result suggests	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
error bound	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
bound guarantee	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
roughly right	0.0	0.0	0.0	2.0	0.0000000000	False
14-point numbers	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
theory balance	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
caught set	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
class shatters	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
shattering means	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
linear classifiers	0.00536407642984	0.0	7.9945	10.0	0.4056189640	True
training error	0.00493130183391	0.0	6.9955	8.0	0.4384133612	False
class script	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
examples correctly	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
negative examples	0.000402684672075	0.0	1.9985	2.0	0.0000000000	False
chervonenkis dimension	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
larger set	0.00054792242599	0.0	0.0	1.0	0.0000000000	False
large sets	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
result holds	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
dimensional feature	0.00132266159514	0.0	2.9985	2.0	0.0000000000	False
feature space	0.00132266159514	0.0	2.9985	2.0	0.0000000000	False
best-known result	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
bit complicated	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
essential aspects	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
chervonenkis show	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
uniform conversions	0.00126576213144	0.0	0.0	1.0	0.0000000000	False
conversions results	0.0	0.0	0.0	0.0	0.0000000000	False
complicated formula	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
proved earlier	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
gamma times	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
put gamma	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
subscript error	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
treat gamma	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
absorb turns	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
learning algorithm	0.00283191609975	0.0	5.994	12.0	0.4483985765	False
minimization algorithms	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
minimize training	0.00126576213144	0.0	0.0	0.0	0.0000000000	False
reasonable hypothesis	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
regression linear	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
linear classification	0.000778118819634	0.0	9.994	11.0	0.0000000000	False
takeaway intuition	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
strange examples	0.00155623763927	0.0	0.0	2.0	0.0000000000	False
result shows	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
worse case	0.0023343564589	0.0	3.9985	2.0	0.0000000000	False
nasty learning	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
learning problem	0.00127090412938	0.0	4.9975	4.0	0.0000000000	False
step reconstruction	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
epsilon net	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
ph.d student	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
solid week	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
start reading	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
loose ends	0.0023343564589	0.0	3.9985	1.0	0.0000000000	False
random facts	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
support vector	0.00259269427418	0.0	7.9965	4.0	0.3360000000	False
vector machines	0.00222230937787	0.0	7.9965	4.0	0.3500000000	False
infinite dimensional	0.00201342336037	0.0	3.9975	4.0	0.2937062937	False
linear separators	0.00126576213144	0.0	0.0	1.0	0.0000000000	False
large margin	0.00700306937671	0.0	8.996	7.0	0.3360000000	False
data points	0.00176354879352	0.0	3.998	3.0	0.0000000000	False
funny symbol	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
ceiling symbol	0.0	0.0	0.0	1.0	0.0000000000	False
strange things	0.00054792242599	0.0	0.0	1.0	0.0000000000	False
surprising thing	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
dimensional space	0.000881774396761	0.0	0.0	1.0	0.0000000000	False
restrict attention	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
margin separator	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
fit alex	0.0	0.0	0.0	1.0	0.0000000000	False
finite dimensional	0.000632881065719	0.0	4.997	4.0	0.0000000000	False
dimensional vectors	0.00044088719838	0.0	0.0	1.0	0.0000000000	False
equals data	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
data transpose	0.00253152426288	0.0	3.998	3.0	0.2038834951	False
right suppose	0.0	0.0	0.0	1.0	0.0000000000	False
choose parameters	0.000975286623608	0.0	0.0	0.0	0.0000000000	False
parameters data	0.000975286623608	0.0	0.0	0.0	0.0000000000	False
step function	0.00189864319716	0.0	7.997	5.0	0.3134328358	False
correct classification	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
indicator function	0.000402684672075	0.0	0.0	1.0	0.0000000000	False
non-convex function	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
classifiers minimizing	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
empty heart	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
heart problem	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
convex approximation	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
maximize likelihood	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
logged likelihood	0.000881774396761	0.0	0.0	2.0	0.0000000000	False
rough approximation	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
hard optimization	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
optimization problem	0.000805369344149	0.0	0.0	1.0	0.0000000000	False
maximum likelihood	0.000370384896312	0.0	0.0	0.0	0.0000000000	False
approximated dysfunction	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
machine turns	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
linear function	0.000740769792624	0.0	0.0	1.0	0.0000000000	False
hinge class	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
high-level message	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
quadratic structure	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
high bias	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
high variance	0.00054792242599	0.0	0.0	1.0	0.0000000000	False
algorithms provide	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
trade make	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
model complexity	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
regression function	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
high generalization	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
selection problems	0.00466871291781	0.0	7.997	4.0	0.2937062937	False
bandwidth parameter	0.000975286623608	0.0	0.0	1.0	0.0000000000	False
linear regression	0.000370384896312	0.0	0.0	0.0	0.0000000000	False
soft margin	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
optimization objective	0.0	0.0	0.0	0.0	0.0000000000	False
margin versus	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
specific examples	0.000487643311804	0.0	0.0	0.0	0.0000000000	False
finite set	0.000402684672075	0.0	0.0	0.0	0.0000000000	False
quadratic classifier	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
lowest training	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
terrible idea	0.00126576213144	0.0	0.0	1.0	0.0000000000	False
right cool	0.0	0.0	0.0	1.0	0.0000000000	False
complex model	0.0	0.0	0.0	0.0	0.0000000000	False
10th degree	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
standard procedures	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
out cross	0.0107589781172	0.0	9.9915	13.0	0.3200358584	False
cross validation	0.020252194103	0.0	17.983	31.0	0.3485477178	True
validation subset	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
trading subset	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
validation set	0.00126576213144	0.0	0.0	0.0	0.0000000000	False
lowest error	0.00155623763927	0.0	0.0	2.0	0.0000000000	False
straightforward procedure	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
smallest hold	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
validation error	0.00311247527854	0.0	2.998	2.0	0.0000000000	False
hypothesis trained	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
machine-learning applications	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
great cost	0.0	0.0	0.0	0.0	0.0000000000	False
medical experiments	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
sick man	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
physical human	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
human pain	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
data set	0.000295649444465	0.0	0.0	1.0	0.0000000000	False
k-fold cross	0.00466871291781	0.0	4.997	4.0	0.3962264151	False
ve drawn	0.0	0.0	0.0	2.0	0.0000000000	False
pieces test	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
remaining piece	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
error measures	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
common choice	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
fold cross	0.000778118819634	0.0	5.9965	0.0	0.0000000000	False
cross option	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
ten pieces	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
standard hold	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
simple hold	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
fairly common	0.00164376727797	0.0	2.9985	2.0	0.0000000000	False
computationally expensive	0.00126576213144	0.0	0.0	2.0	0.0000000000	False
model ten	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
ten times	0.00146292993541	0.0	3.9985	2.0	0.0000000000	False
equals ten	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
ten works	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
works great	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
first training	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
extremely data	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
data scarce	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
dimension bounds	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
loose bounds	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
structure risk	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
proving learning	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
theory bounds	0.00389059409817	0.0	9.9975	2.0	0.0000000000	False
re sort	0.0	0.0	0.0	0.0	0.0000000000	False
case upper	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
upper bound	0.00176354879352	0.0	5.998	3.0	0.5250000000	False
holds true	0.00185192448156	0.0	7.9975	4.0	0.3245749614	False
probability distribution	0.00148153958525	0.0	3.998	3.0	0.3442622951	False
distribution script	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
real life	0.000487643311804	0.0	0.0	0.0	0.0000000000	False
life distribution	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
large numbers	0.000450294284794	0.0	0.0	1.0	0.0000000000	False
ten parameters	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
percent probability	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
actual constants	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
pessimistic estimates	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
write papers	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
constant factors	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
give guidelines	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
quadratic parameters	0.0	0.0	0.0	1.0	0.0000000000	False
actual magnitude	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
regression model	0.00044088719838	0.0	0.0	0.0	0.0000000000	False
good shape	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
tiny times	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
train testers	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
testers randomly	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
special case	0.000370384896312	0.0	0.0	0.0	0.0000000000	False
feature selection	0.00602714668589	0.0	11.9945	10.0	0.3360000000	True
machine-learning problems	0.00044088719838	0.0	0.0	1.0	0.0000000000	False
high dimensional	0.00109584485198	0.0	0.0	1.0	0.0000000000	False
text classification	0.00383545698193	0.0	7.9965	6.0	0.3442622951	False
spam versus	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
versus non-spam	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
early examples	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
real risk	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
specific case	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
small number	0.000402684672075	0.0	0.0	1.0	0.0000000000	False
relevant features	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
english words	0.00155623763927	0.0	0.0	2.0	0.0000000000	False
english function	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
function words	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
smaller number	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
word buy	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
word stanford	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
specific learning	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
simpler learning	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
simpler hypothesis	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
features originally	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
huge space	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
searcheristics sort	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
simple search	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
search algorithms	0.00126576213144	0.0	3.9985	2.0	0.0000000000	False
good subset	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
feature subsets	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
forward search	0.0023343564589	0.0	3.9985	2.0	0.0000000000	False
forward selection	0.00622495055707	0.0	9.996	7.0	0.4384133612	False
empty set	0.00109584485198	0.0	0.0	1.0	0.0000000000	False
adding feature	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
feature found	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
single feature	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
feature addition	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
lowest hold	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
lowest cross	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
entire set	0.00109584485198	0.0	0.0	1.0	0.0000000000	False
threshold number	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
features added	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
hypothesis found	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
training lots	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
entire procedure	0.000632881065719	0.0	0.0	1.0	0.0000000000	False
wrapper feature	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
term wrapper	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
wrapper model	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
model feature	0.00155623763927	0.0	0.0	1.0	0.0000000000	False
search process	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
backward search	0.0023343564589	1.0	3.9985	2.0	0.0000000000	False
backward selection	0.0023343564589	0.0	3.9985	2.0	0.0000000000	False
delete features	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
makes sense	0.000788671215895	0.0	3.998	4.0	0.0000000000	False
algorithms tend	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
main disadvantage	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
selection backward	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
selection work	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
features forward	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
filter feature	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
selection methods	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
basic idea	0.000370384896312	0.0	0.0	1.0	0.0000000000	False
simple heuristics	0.0	0.0	0.0	1.0	0.0000000000	False
rough estimate	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
class label	0.00044088719838	0.0	0.0	1.0	0.0000000000	False
correlated features	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
informative measure	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
major information	0.00389059409817	1.0	9.9975	4.0	0.4158415842	False
distribution times	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
joint distribution	0.000975286623608	0.0	0.0	2.0	0.0000000000	False
training data	0.000740769792624	0.0	0.0	2.0	0.0000000000	False
standard information	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
theoretic measure	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
standard measure	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
k-l divergence	0.00389059409817	1.0	9.9975	5.0	0.0000000000	False
information theory	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
mutual information	0.00544683173744	1.0	13.9965	6.0	0.2872777018	True
formal measure	0.00155623763927	0.0	0.0	2.0	0.0000000000	False
large mutual	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
good feature	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
compute correlation	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
largest correlation	0.000778118819634	0.0	0.0	1.0	0.0000000000	False
largest mutual	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
information label	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
decreasing order	0.000487643311804	0.0	0.0	1.0	0.0000000000	False
features includes	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
cool great	0.00044088719838	0.0	0.0	1.0	0.0000000000	False
bayesian model	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
couple	0.000450294284794	0.0	0.0	0.0	0.4158415842	False
quick	0.000105345402368	0.0	0.0	0.0	0.0000000000	False
announcements	0.000295649444465	0.0	0.0	0.0	0.0000000000	False
first	0.0	0.0	0.0	0.0	0.4384133612	False
problem	0.000130985910358	0.0	0.0	0.0	0.3962264151	False
set	0.00059706055771	0.0	0.0	0.0	0.2226402189	False
submissions	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
graded	0.000342405557889	0.0	0.0	0.0	0.0000000000	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
return	0.000368929794719	0.0	0.0	0.0	0.2937062937	False
end	0.000107547568423	0.0	0.0	0.0	0.3716814159	False
lecture	0.000362782856698	0.0	0.0	0.0	0.4565217391	False
today	8.17515735452e-05	0.0	0.0	0.0	0.3245749614	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
sepd	0.00272341586872	0.0	0.0	0.0	0.2608695652	False
student	0.000564057790756	0.0	0.0	0.0	0.4384133612	False
submitted	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
faxing	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
career	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
handed	0.000159818776963	0.0	0.0	0.0	0.2937062937	False
hard	0.000225147142397	0.0	0.0	0.0	0.0000000000	False
copy	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
homework	0.000555577344468	0.0	0.0	0.0	0.2937062937	False
person	0.00101316214079	0.0	0.0	0.0	0.3738872404	False
late	0.000476589048518	0.0	0.0	0.0	0.0000000000	False
box	0.000513608336833	0.0	0.0	0.0	0.0000000000	False
classroom	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
pick	0.000922324486797	0.0	0.0	0.0	0.3903345725	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
leave	0.00064463747515	1.0	0.0	0.0	0.3559322034	False
basement	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
gates	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
building	8.62441392151e-05	0.0	0.0	0.0	0.0000000000	False
access	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
hours	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.4855491329	False
class	0.001493853114	0.0	0.0	0.0	0.3982359427	False
posted	0.000240675266473	0.0	0.0	0.0	0.0000000000	False
web	0.000342405557889	0.0	0.0	0.0	0.0000000000	False
page	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
online	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.4565217391	False
week	0.000562867855992	0.0	0.0	0.0	0.3716814159	False
make	6.81126733861e-05	0.0	0.0	0.0	0.3471074380	False
download	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
instructor	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
sort	0.000820154650826	0.0	0.0	0.0	0.4565217391	False
gratifying	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
solutions	8.05796843937e-05	0.0	0.0	0.0	0.0000000000	False
hey	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
guys	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
understood	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
cool	0.000481350532946	0.0	0.0	0.0	0.0000000000	False
people	0.000280522910611	0.0	0.0	0.0	0.5250000000	False
working	0.000215749288944	0.0	0.0	0.0	0.3777596075	False
graders	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
stayed	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
monday	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
night	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
big	6.05634207203e-05	0.0	0.0	0.0	0.0000000000	False
reminder	0.00044088719838	0.0	0.0	0.0	0.0000000000	False
midterm	0.00246565091695	0.0	0.0	0.0	0.2270270270	False
scheduled	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
8th	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
november	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
p.m	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
two	0.0	0.0	0.0	0.0	0.3337408313	False
guess	0.000887255117882	0.0	0.0	0.0	0.5526315789	False
open	0.00027567874152	0.0	0.0	0.0	0.0000000000	False
book	0.000161159368787	0.0	0.0	0.0	0.0000000000	False
notes	0.000103655577126	0.0	0.0	0.0	0.0000000000	False
bring	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
laptops	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
computers	0.000327006294181	0.0	0.0	0.0	0.2818791946	False
live	0.000413518112281	0.0	0.0	0.0	0.0000000000	False
bay	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
area	0.000258732417645	0.0	0.0	0.0	0.0000000000	False
stanford	0.000881774396761	0.0	0.0	0.0	0.4158415842	False
evening	0.00022044359919	0.0	0.0	0.0	0.4719101124	False
drive	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
email	0.000901064213558	0.0	0.0	0.0	0.3716814159	False
usual	0.00027567874152	0.0	0.0	0.0	0.4719101124	False
mailing	0.000402684672075	0.0	0.0	0.0	0.0000000000	False
address	0.000316036207104	0.0	0.0	0.0	0.0000000000	False
cs229qa	0.0	0.0	0.0	0.0	0.0000000000	False
cs.stanford.edu	0.0	0.0	0.0	0.0	0.0000000000	False
physically	0.00025744691816	0.0	0.0	0.0	0.0000000000	False
attend	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
wednesday	0.000731464967706	0.0	0.0	0.0	0.0000000000	False
alternate	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
arrangements	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
regular	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
taking	2.59650250293e-05	0.0	0.0	0.0	0.3745637844	False
conflict	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
event	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
equal	0.00105207028442	0.0	0.0	0.0	0.3719083969	False
greater	0.000280377005335	0.0	0.0	0.0	0.5250000000	False
importance	0.000175059277402	0.0	0.0	0.0	0.5250000000	False
staff	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
hear	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
assume	0.000239728165445	0.0	0.0	0.0	0.5384615385	False
showing	0.00022741173938	0.0	0.0	0.0	0.5097087379	False
questions	8.60380547387e-05	0.0	0.0	0.0	0.5600000000	False
back	0.000155790150176	0.0	0.0	0.0	0.4384133612	False
technical	0.000342405557889	0.0	0.0	0.0	0.0000000000	False
material	0.00025744691816	0.0	0.0	0.0	0.0000000000	False
discussion	0.000238593781395	0.0	0.0	0.0	0.3245749614	False
section	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
talking	8.38309826291e-05	0.0	0.0	0.0	0.3818181818	False
convex	0.000794315080863	0.0	0.0	0.0	0.2872777018	False
optimization	0.000772340754479	0.0	0.0	0.0	0.0000000000	False
total	6.05634207203e-05	0.0	0.0	0.0	0.0000000000	False
wrap	0.000684811115778	0.0	0.0	0.0	0.5250000000	False
present	7.5205845275e-05	0.0	0.0	0.0	0.0000000000	False
bit	0.00022741173938	0.0	0.0	0.0	0.4855491329	False
learning	0.00169577578017	0.0	0.0	0.0	0.3925233645	False
theory	0.00157602999678	0.0	0.0	0.0	0.3162650602	False
dimension	0.00619565763073	0.0	0.0	0.0	0.2470588235	False
issues	7.5205845275e-05	0.0	0.0	0.0	0.0000000000	False
bias	0.00110221799595	0.0	0.0	0.0	0.4158415842	False
variance	0.00100671168019	0.0	0.0	0.0	0.0000000000	False
tradeoffs	0.00109584485198	0.0	0.0	0.0	0.5250000000	False
fitting	0.00218829880436	0.0	0.0	0.0	0.4757981462	False
previous	0.000218824096752	0.0	0.0	0.0	0.3245749614	False
model	0.00415046019059	0.0	0.0	0.0	0.2943237561	False
selection	0.00514893836319	0.0	0.0	0.0	0.2737146995	False
algorithms	0.000916342711491	0.0	0.0	0.0	0.3515232675	False
automatically	0.000386170377239	0.0	0.0	0.0	0.0000000000	False
decisions	0.000112573571198	0.0	0.0	0.0	0.0000000000	False
started	0.0	0.0	0.0	0.0	0.5316455696	False
depending	0.000136447043628	0.0	0.0	0.0	0.5384615385	False
bayesian	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
recap	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
result	0.000953777896077	0.0	0.0	0.0	0.4093567251	False
proved	0.00155239450587	0.0	0.0	0.0	0.3767810026	False
finite	0.000601688166183	0.0	0.0	0.0	0.4384133612	False
hypothesis	0.00529095784633	0.0	0.0	0.0	0.3086722195	False
hypotheses	0.00219439490312	0.0	0.0	0.0	0.2809364548	False
suppose	0.000136447043628	0.0	0.0	0.0	0.5316455696	False
fixed	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
parameters	0.00161216778068	0.0	0.0	0.0	0.2862010221	False
gamma	0.00259269427418	0.0	0.0	0.0	0.3088235294	False
delta	0.00240750182603	0.0	0.0	0.0	0.2818791946	False
order	0.000127372918978	0.0	0.0	0.0	0.3206106870	False
guarantee	0.00188323056839	0.0	0.0	0.0	0.3738872404	False
holds	0.00225623116302	0.0	0.0	0.0	0.2684735362	False
probability	0.00168472686531	0.0	0.0	0.0	0.3521341463	False
minus	0.000525177832205	0.0	0.0	0.0	0.2818791946	False
suffices	0.00164376727797	0.0	0.0	0.0	0.3962264151	False
big-o	0.00194529704909	0.0	0.0	0.0	0.4384133612	False
notations	0.000402898421969	0.0	0.0	0.0	0.0000000000	False
dropped	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
constants	0.000420565508003	0.0	0.0	0.0	0.4158415842	False
write	0.00018234301282	0.0	0.0	0.0	0.4757981462	False
quickly	0.000121126841441	0.0	0.0	0.0	0.0000000000	False
means	2.84566514923e-05	0.0	0.0	0.0	0.4579858884	False
empirical	0.00301357334294	0.0	0.0	0.0	0.4757981462	False
risk	0.00365732483853	0.0	0.0	0.0	0.4895104895	False
minimization	0.00175241652492	0.0	0.0	0.0	0.4065524944	False
simplified	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
modern	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
machine	0.000490659759336	0.0	0.0	0.0	0.3716814159	False
script	0.00222230937787	0.0	0.0	0.0	0.3925233645	False
minimization-learning	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
chooses	0.00168226203201	0.0	0.0	0.0	0.3313893654	False
attains	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
smallest	0.000210690804736	0.0	0.0	0.0	0.0000000000	False
error	0.00482437797661	0.0	0.0	0.0	0.2736463716	False
training	0.00878073855348	0.0	0.0	0.0	0.2716417910	False
symbol	0.000295649444465	0.0	0.0	0.0	0.0000000000	False
epsilon	0.000402684672075	0.0	0.0	0.0	0.0000000000	False
denoted	0.000184464897359	0.0	0.0	0.0	0.0000000000	False
generalization	0.000167176956159	0.0	0.0	0.0	0.2392803598	False
right	0.0	0.0	0.0	0.0	0.3821543880	False
misclassifying	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
drawn	0.000316036207104	0.0	0.0	0.0	0.0000000000	False
distribution	0.00158018103552	0.0	0.0	0.0	0.1772151899	False
output	0.000326102469013	0.0	0.0	0.0	0.3730017762	False
times	0.0	0.0	0.0	0.0	0.4468085106	False
threshold	0.00044088719838	0.0	0.0	0.0	0.0000000000	False
size	0.000570105674196	0.0	0.0	0.0	0.1742738589	False
square	0.000391322962816	0.0	0.0	0.0	0.4384133612	False
log	0.000402898421969	0.0	0.0	0.0	0.3730017762	False
complexity	0.00119902183284	0.0	0.0	0.0	0.4379146919	False
bound	0.00373046663033	0.0	0.0	0.0	0.3021582734	False
number	0.000111239637652	0.0	0.0	0.0	0.2869774920	False
examples	0.00181397259971	0.0	0.0	0.0	0.3071951012	False
give	2.84566514923e-05	0.0	0.0	0.0	0.4772727273	False
sample	0.00059129888893	0.0	0.0	0.0	0.5250000000	False
infinite	0.00123830928318	0.0	0.0	0.0	0.2495049505	False
specific	0.000146456187648	0.0	0.0	0.0	0.5316455696	False
functions	0.000254976432388	0.0	0.0	0.0	0.2210526316	False
logistic	0.00280866972242	0.0	0.0	0.0	0.2904987259	False
regression	0.00310431916688	0.0	0.0	0.0	0.3750000000	False
parameterized	0.00100671168019	0.0	0.0	0.0	0.2335928810	False
real	0.000481413012855	0.0	0.0	0.0	0.1799766264	False
argument	0.000476589048518	0.0	0.0	0.0	0.0000000000	False
formally	0.000591503411921	0.0	0.0	0.0	0.4158415842	False
broken	0.00126576213144	0.0	0.0	0.0	0.4158415842	False
conveys	0.000370384896312	0.0	0.0	0.0	0.0000000000	False
intuition	0.00123830928318	0.0	0.0	0.0	0.4483985765	False
correct	0.000130440987605	0.0	0.0	0.0	0.0000000000	False
full	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
proof	0.00144405159884	0.0	0.0	0.0	0.1742738589	False
involved	0.000316036207104	0.0	0.0	0.0	0.0000000000	False
apply	9.5437512558e-05	0.0	0.0	0.0	0.0000000000	False
analyzing	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
linear	0.00241739053181	0.0	0.0	0.0	0.3920180238	False
division	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
boundaries	0.000413518112281	0.0	0.0	0.0	0.0000000000	False
endless	0.00126576213144	0.0	0.0	0.0	0.4158415842	False
find	0.000161321352635	0.0	0.0	0.0	0.4329896907	False
position	0.000399061142367	0.0	0.0	0.0	0.4329896907	False
represented	0.000334031293953	0.0	0.0	0.0	0.1634241245	False
normal	0.000181690262161	0.0	0.0	0.0	0.0000000000	False
standard	0.000350471256669	0.0	0.0	0.0	0.4384133612	False
double	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
floating	0.000731464967706	0.0	0.0	0.0	0.0000000000	False
point	6.72611762545e-05	0.0	0.0	0.0	0.2961918195	False
64-bit	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
representation	0.000161159368787	0.0	0.0	0.0	0.0000000000	False
routinely	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
speed	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
things	0.0	0.0	0.0	0.0	0.4855491329	False
flip	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
values	0.000310966731379	0.0	0.0	0.0	0.4158415842	False
power	6.05634207203e-05	0.0	0.0	0.0	0.0000000000	False
ways	7.25565713395e-05	0.0	0.0	0.0	0.3881700555	False
plug	0.000386170377239	0.0	0.0	0.0	0.0000000000	False
equation	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
great	0.000207311154253	0.0	0.0	0.0	0.0000000000	False
clear	5.18277885632e-05	0.0	0.0	0.0	0.0000000000	False
suggests	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
words	0.000559365719372	0.0	0.0	0.0	0.1135135135	False
roughly	0.000562867855992	0.0	0.0	0.0	0.0000000000	False
slightly	0.000131294458051	0.0	0.0	0.0	0.0000000000	False
sense	0.000181929391504	0.0	0.0	0.0	0.3716814159	False
relies	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
14-point	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
outline	0.000201342336037	0.0	0.0	0.0	0.0000000000	False
turns	0.00130601828411	0.0	0.0	0.0	0.3490304709	False
out	0.0	0.0	0.0	0.0	0.3825968729	False
longer	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
extremely	0.000431220696076	0.0	0.0	0.0	0.3245749614	False
state	0.000225147142397	0.0	0.0	0.0	0.0000000000	False
farther	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
source	0.000443474166698	0.0	0.0	0.0	0.0000000000	False
balance	0.000201342336037	0.0	0.0	0.0	0.0000000000	False
definition	0.000218824096752	0.0	0.0	0.0	0.0000000000	False
shatters	0.00661400996689	0.0	0.0	0.0	0.2473498233	False
realize	0.000675441427191	0.0	0.0	0.0	0.2872777018	False
labeling	0.00339996861135	0.0	0.0	0.0	0.1993670886	False
informal	0.00143485086366	0.0	0.0	0.0	0.1907560780	False
thinking	0.00012872345908	0.0	0.0	0.0	0.4483985765	False
associate	9.85839019869e-05	0.0	0.0	0.0	0.0000000000	False
caught	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
perfectly	0.000513608336833	0.0	0.0	0.0	0.0000000000	False
illustrate	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
classifiers	0.00154468150896	0.0	0.0	0.0	0.4056189640	False
comprising	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.3360000000	False
negative	0.000737859589438	0.0	0.0	0.0	0.4158415842	False
larger	0.000103655577126	0.0	0.0	0.0	0.0000000000	False
correctly	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
terminology	0.000201342336037	0.0	0.0	0.0	0.0000000000	False
separates	0.000586984444224	0.0	0.0	0.0	0.2641509434	False
lots	0.000145113142679	0.0	0.0	0.0	0.4158415842	False
instance	3.62782856698e-05	0.0	0.0	0.0	0.0000000000	False
vapnik	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
chervonenkis	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
arbitrarily	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
large	0.000507895999377	0.0	0.0	0.0	0.3613500993	False
kind	2.15095136847e-05	0.0	0.0	0.0	0.0000000000	False
good	9.80678586109e-05	0.0	0.0	0.0	0.5316455696	False
absolutely	0.000421381609472	0.0	0.0	0.0	0.0000000000	False
exists	8.05796843937e-05	0.0	0.0	0.0	0.0000000000	False
lapping	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
place	5.18277885632e-05	0.0	0.0	0.0	0.0000000000	False
true	0.000362794519943	0.0	0.0	0.0	0.3245749614	False
dimensional	0.00115851113172	0.0	0.0	0.0	0.3613500993	False
feature	0.00463065505999	0.0	0.0	0.0	0.2000866176	False
space	0.000448836656978	0.0	0.0	0.0	0.5316455696	False
wan	0.0	0.0	0.0	0.0	0.5316455696	False
arguably	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
best-known	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
formula	0.000413518112281	0.0	0.0	0.0	0.0000000000	False
complicated	0.000322318737575	0.0	0.0	0.0	0.0000000000	False
worry	0.000181690262161	0.0	0.0	0.0	0.0000000000	False
essential	2.2741173938e-05	0.0	0.0	0.0	0.0000000000	False
aspects	0.000112573571198	0.0	0.0	0.0	0.0000000000	False
key	6.05634207203e-05	0.0	0.0	0.0	0.0000000000	False
enjoy	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
uniform	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
conversions	0.000450294284794	0.0	0.0	0.0	0.0000000000	False
difference	1.04788728286e-05	0.0	0.0	0.0	0.3088235294	False
step	0.000250152913318	0.0	0.0	0.0	0.2957746479	False
earlier	4.7718756279e-05	0.0	0.0	0.0	0.0000000000	False
remember	0.000108834857009	0.0	0.0	0.0	0.0000000000	False
implies	9.85839019869e-05	0.0	0.0	0.0	0.0000000000	False
appears	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
close	5.19300500586e-05	0.0	0.0	0.0	0.0000000000	False
front	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
absorbed	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
rewrite	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
corollary	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
put	1.65766375291e-05	0.0	0.0	0.0	0.0000000000	False
subscript	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
treat	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
conclude	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
upper	0.000684811115778	0.0	0.0	0.0	0.5250000000	False
reasonable	9.81795762312e-05	0.0	0.0	0.0	0.0000000000	False
similar	3.62782856698e-05	0.0	0.0	0.0	0.0000000000	False
classification	0.00124055433684	0.0	0.0	0.0	0.3730017762	False
low	0.000240675266473	0.0	0.0	0.0	0.0000000000	False
polynomial	0.000740769792624	0.0	0.0	0.0	0.5250000000	False
takeaway	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
strange	0.000740769792624	0.0	0.0	0.0	0.2937062937	False
enormous	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
fall	0.000105345402368	0.0	0.0	0.0	0.0000000000	False
regime	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
degenerate	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
unusual	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
worse	0.000740769792624	0.0	0.0	0.0	0.4158415842	False
lower	0.000197167803974	0.0	0.0	0.0	0.0000000000	False
nasty	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
entirety	0.000821883638985	0.0	0.0	0.0	0.0000000000	False
theorem	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
reconstruction	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
net	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
clever	0.000731464967706	0.0	0.0	0.0	0.0000000000	False
assumption	0.00027567874152	0.0	0.0	0.0	0.0000000000	False
someway	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
one-step	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
needed	0.0	0.0	0.0	0.0	0.4200000000	False
ph.d	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
solid	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
wake	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
office	0.000201342336037	0.0	0.0	0.0	0.0000000000	False
a.m	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
reading	9.5437512558e-05	0.0	0.0	0.0	0.0000000000	False
led	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
home	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
day	7.5205845275e-05	0.0	0.0	0.0	0.0000000000	False
left	3.27265254104e-05	0.0	0.0	0.0	0.0000000000	False
understand	2.72505245151e-05	0.0	0.0	0.0	0.0000000000	False
thought	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
inflict	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
tie	0.000740769792624	0.0	0.0	0.0	0.4158415842	False
loose	0.00120805401622	0.0	0.0	0.0	0.4384133612	False
mention	0.000197167803974	0.0	0.0	0.0	0.0000000000	False
feel	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
random	9.85839019869e-05	0.0	0.0	0.0	0.0000000000	False
facts	7.84542868887e-05	0.0	0.0	0.0	0.0000000000	False
strong	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
0-1	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
support	0.000690087313908	0.0	0.0	0.0	0.3360000000	False
vector	0.000900588569587	0.0	0.0	0.0	0.3360000000	False
svm	0.0	0.0	0.0	0.0	0.2937062937	False
sequel	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
kernels	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
map	8.62441392151e-05	0.0	0.0	0.0	0.0000000000	False
margin	0.00261745036849	0.0	0.0	0.0	0.2811929397	False
details	3.99546942409e-05	0.0	0.0	0.0	0.0000000000	False
lines	0.000199773471204	0.0	0.0	0.0	0.3730017762	False
closer	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
data	0.000966610838474	0.0	0.0	0.0	0.2763157895	False
lie	8.62441392151e-05	0.0	0.0	0.0	0.0000000000	False
sphere	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
radius	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
funny	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
rounding	0.00044088719838	0.0	0.0	0.0	0.0000000000	False
ceiling	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
deliberately	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
surprising	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
combine	7.00942513338e-05	0.0	0.0	0.0	0.0000000000	False
long	7.5205845275e-05	0.0	0.0	0.0	0.0000000000	False
restrict	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
attention	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
small	3.31532750581e-05	0.0	0.0	0.0	0.0000000000	False
alex	0.0	0.0	0.0	0.0	0.0000000000	False
defined	2.59650250293e-05	0.0	0.0	0.0	0.0000000000	False
constantly	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
appoint	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
crosstalk	0.00155623763927	0.0	0.0	0.0	0.0000000000	False
insures	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
strongly	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
view	0.000258732417645	0.0	0.0	0.0	0.4158415842	False
focus	0.000201342336037	0.0	0.0	0.0	0.0000000000	False
draw	0.00026088197521	0.0	0.0	0.0	0.5250000000	False
jumps	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
indicator	0.00026088197521	0.0	0.0	0.0	0.3442622951	False
transpose	0.000684811115778	0.0	0.0	0.0	0.2038834951	False
wrong	0.000105345402368	0.0	0.0	0.0	0.0000000000	False
part	1.04788728286e-05	0.0	0.0	0.0	0.0000000000	False
non-convex	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
empty	0.000450294284794	0.0	0.0	0.0	0.4158415842	False
heart	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
approximation	0.00171202778944	0.0	0.0	0.0	0.2015355086	False
maximize	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
likelihood	0.000684811115778	0.0	0.0	0.0	0.0000000000	False
plot	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
drew	0.000684811115778	0.0	0.0	0.0	0.4158415842	False
rough	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
curve	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
maximum	7.5205845275e-05	0.0	0.0	0.0	0.0000000000	False
dysfunction	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
hinge	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
developed	0.000295751705961	0.0	0.0	0.0	0.0000000000	False
due	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
completely	3.92271434443e-05	0.0	0.0	0.0	0.0000000000	False
high-level	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
message	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
move	3.62782856698e-05	0.0	0.0	0.0	0.0000000000	False
check	6.05634207203e-05	0.0	0.0	0.0	0.0000000000	False
trade-off	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
simple	0.000137295002055	0.0	0.0	0.0	0.3962264151	False
quadratic	0.000413518112281	0.0	0.0	0.0	0.0000000000	False
structure	9.5437512558e-05	0.0	0.0	0.0	0.0000000000	False
high	0.000391322962816	0.0	0.0	0.0	0.2386363636	False
fail	0.000370384896312	0.0	0.0	0.0	0.0000000000	False
provide	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
methods	0.000326102469013	0.0	0.0	0.0	0.5250000000	False
trade	0.000487643311804	0.0	0.0	0.0	0.0000000000	False
cartoon	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
x-axis	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
degree	0.000601688166183	0.0	0.0	0.0	0.4384133612	False
14-degree	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
abstract	0.0	0.0	0.0	0.0	0.0000000000	False
include	0.0003008233811	0.0	0.0	0.0	0.4158415842	False
run	4.54823478759e-05	0.0	0.0	0.0	0.0000000000	False
bandwidth	0.00044088719838	0.0	0.0	0.0	0.0000000000	False
locally	0.000225147142397	0.0	0.0	0.0	0.0000000000	False
awaited	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
soft	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
objective	0.0	0.0	0.0	0.0	0.0000000000	False
controls	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
versus	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
penalize	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
semantically	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
discretize	0.000402684672075	0.0	0.0	0.0	0.0000000000	False
range	0.000112573571198	0.0	0.0	0.0	0.0000000000	False
lowest	0.00132266159514	0.0	0.0	0.0	0.3962264151	False
terrible	0.000402684672075	0.0	0.0	0.0	0.0000000000	False
idea	0.000155790150176	0.0	0.0	0.0	0.4565217391	False
laughing	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
asked	0.000112573571198	0.0	0.0	0.0	0.5250000000	False
10th	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
procedures	0.000431220696076	0.0	0.0	0.0	0.0000000000	False
cross	0.00322813570379	0.0	0.0	0.0	0.2557856273	False
validation	0.00611135078915	0.0	0.0	0.0	0.3460979157	False
teach	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
randomly	0.000443474166698	0.0	0.0	0.0	0.0000000000	False
split	0.00120805401622	0.0	0.0	0.0	0.3962264151	False
subsets	0.00239683890522	0.0	0.0	0.0	0.3903345725	False
call	5.17393663497e-06	0.0	0.0	0.0	0.4579858884	False
test	0.000985839019869	0.0	0.0	0.0	0.3620689655	False
straightforward	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
commonly	0.00100671168019	0.0	0.0	0.0	0.4158415842	False
percent	0.00147824722233	0.0	0.0	0.0	0.2015355086	False
chose	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
optionally	0.000295649444465	0.0	0.0	0.0	0.0000000000	False
retrain	0.000949321598579	0.0	0.0	0.0	0.0000000000	False
versions	0.000197167803974	0.0	0.0	0.0	0.0000000000	False
chosen	0.000225147142397	0.0	0.0	0.0	0.0000000000	False
entire	0.000117164950118	0.0	0.0	0.0	0.5250000000	False
straight	0.0	0.0	0.0	0.0	0.0000000000	False
company	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
application	0.000103655577126	0.0	0.0	0.0	0.0000000000	False
machine-learning	0.000604027008112	0.0	0.0	0.0	0.0000000000	False
painfully	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
acquired	0.00044088719838	0.0	0.0	0.0	0.0000000000	False
cost	0.0	0.0	0.0	0.0	0.0000000000	False
medical	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
experiments	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
sick	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
man	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
amounts	7.5205845275e-05	0.0	0.0	0.0	0.0000000000	False
human	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
unhappiness	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
variations	0.000295649444465	0.0	0.0	0.0	0.0000000000	False
efficient	8.05796843937e-05	0.0	0.0	0.0	0.0000000000	False
k-fold	0.0023343564589	0.0	0.0	0.0	0.3962264151	False
imagine	0.000184464897359	0.0	0.0	0.0	0.0000000000	False
divide	7.00942513338e-05	0.0	0.0	0.0	0.0000000000	False
pieces	0.000717425431829	0.0	0.0	0.0	0.3962264151	False
repeatedly	0.000684811115778	0.0	0.0	0.0	0.4158415842	False
remaining	0.000450294284794	0.0	0.0	0.0	0.3442622951	False
average	0.000317726032345	0.0	0.0	0.0	0.0000000000	False
remove	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
measures	0.00141595804988	0.0	0.0	0.0	0.2551076753	False
estimate	0.000794315080863	0.0	0.0	0.0	0.4384133612	False
easier	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
common	0.000461162243399	0.0	0.0	0.0	0.0000000000	False
fairly	0.000143156268837	0.0	0.0	0.0	0.0000000000	False
choice	0.000130440987605	0.0	0.0	0.0	0.0000000000	False
fold	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
advantage	0.000147824722233	0.0	0.0	0.0	0.0000000000	False
switch	0.000112573571198	0.0	0.0	0.0	0.0000000000	False
ten	0.000362794519943	0.0	0.0	0.0	0.3360000000	False
disadvantage	0.000402684672075	0.0	0.0	0.0	0.0000000000	False
expensive	0.00148153958525	0.0	0.0	0.0	0.0000000000	False
finally	0.000181690262161	0.0	0.0	0.0	0.0000000000	False
rest	0.000184464897359	0.0	0.0	0.0	0.0000000000	False
effective	7.00942513338e-05	0.0	0.0	0.0	0.0000000000	False
typically	7.5205845275e-05	0.0	0.0	0.0	0.0000000000	False
scarce	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
preferred	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
groups	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
practice	0.00015041169055	0.0	0.0	0.0	0.0000000000	False
tend	0.000722025799419	0.0	0.0	0.0	0.3162650602	False
propose	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
spend	0.000112573571198	0.0	0.0	0.0	0.0000000000	False
analytically	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
bad	0.000197167803974	0.0	0.0	0.0	0.0000000000	False
iid	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
chances	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
life	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
houses	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
prices	0.000171202778944	0.0	0.0	0.0	0.0000000000	False
actual	0.00015041169055	0.0	0.0	0.0	0.4184690158	False
text	0.00118259777786	0.0	0.0	0.0	0.3268482490	False
pessimistic	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
ridiculously	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
10,000	0.00126576213144	0.0	0.0	0.0	0.2937062937	False
papers	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
ignore	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
factors	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
attempts	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
guidelines	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
gross	0.000632881065719	0.0	0.0	0.0	0.0000000000	False
linearly	0.000185192448156	0.0	0.0	0.0	0.0000000000	False
shape	0.000240675266473	0.0	0.0	0.0	0.0000000000	False
magnitude	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
looser	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
answer	4.37648193504e-05	0.0	0.0	0.0	0.0000000000	False
uh-huh	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
rule	0.00017248827843	0.0	0.0	0.0	0.0000000000	False
thumb	0.00054792242599	0.0	0.0	0.0	0.0000000000	False
tiny	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
convention	0.000105345402368	0.0	0.0	0.0	0.0000000000	False
testers	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
special	8.05796843937e-05	0.0	0.0	0.0	0.0000000000	False
spam	0.00100671168019	0.0	0.0	0.0	0.2335928810	False
non-spam	0.00136980606497	0.0	0.0	0.0	0.0000000000	False
easily	0.000197167803974	0.0	0.0	0.0	0.0000000000	False
30,000	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
50,000	0.00121910827951	0.0	0.0	0.0	0.3245749614	False
early	0.00013783937076	0.0	0.0	0.0	0.0000000000	False
reduce	0.000421381609472	0.0	0.0	0.0	0.2937062937	False
relevant	0.000555577344468	0.0	0.0	0.0	0.0000000000	False
english	0.000661330797571	0.0	0.0	0.0	0.0000000000	False
contrast	0.000240675266473	0.0	0.0	0.0	0.0000000000	False
smaller	6.52204938026e-05	0.0	0.0	0.0	0.0000000000	False
buy	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
viagra	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
telling	7.5205845275e-05	0.0	0.0	0.0	0.3134328358	False
simpler	0.00025744691816	0.0	0.0	0.0	0.0000000000	False
originally	6.05634207203e-05	0.0	0.0	0.0	0.0000000000	False
excluded	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
possibilities	9.85839019869e-05	0.0	0.0	0.0	0.3559322034	False
huge	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
searcheristics	0.000778118819634	0.0	0.0	0.0	0.0000000000	False
search	0.00101455693548	0.0	0.0	0.0	0.2974504249	False
enumerate	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
forward	0.00151623307836	0.0	0.0	0.0	0.2675159236	False
pretty	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
initialize	0.000168313746367	0.0	0.0	0.0	0.0000000000	False
repeat	8.05796843937e-05	0.0	0.0	0.0	0.0000000000	False
adding	0.000431220696076	0.0	0.0	0.0	0.3245749614	False
evaluate	0.000225147142397	0.0	0.0	0.0	0.0000000000	False
flavors	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
union	0.00022044359919	0.0	0.0	0.0	0.0000000000	False
found	0.000161159368787	0.0	0.0	0.0	0.0000000000	False
follow	5.61045821222e-05	0.0	0.0	0.0	0.0000000000	False
basically	2.15095136847e-05	0.0	0.0	0.0	0.0000000000	False
figure	5.61045821222e-05	0.0	0.0	0.0	0.0000000000	False
single	0.000103655577126	0.0	0.0	0.0	0.0000000000	False
add	0.000112209164244	0.0	0.0	0.0	0.0000000000	False
addition	6.52204938026e-05	0.0	0.0	0.0	0.0000000000	False
terminate	0.000413518112281	0.0	0.0	0.0	0.0000000000	False
exceeded	0.000389059409817	0.0	0.0	0.0	0.0000000000	False
stop	8.62441392151e-05	0.0	0.0	0.0	0.0000000000	False
incidence	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
wrapper	0.00194529704909	0.0	0.0	0.0	0.3245749614	False
term	1.36252622575e-05	0.0	0.0	0.0	0.0000000000	False
described	0.0	0.0	0.0	0.0	0.0000000000	False
software	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
perform	9.5437512558e-05	0.0	0.0	0.0	0.0000000000	False
process	2.92912375295e-05	0.0	0.0	0.0	0.0000000000	False
backward	0.00189864319716	0.0	0.0	0.0	0.2592592593	False
delete	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
happen	2.59650250293e-05	0.0	0.0	0.0	0.0000000000	False
main	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
formulizations	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
envision	0.00031644053286	0.0	0.0	0.0	0.0000000000	False
afford	0.000243821655902	0.0	0.0	0.0	0.0000000000	False
filter	0.000273961212995	0.0	0.0	0.0	0.0000000000	False
heuristics	0.0	0.0	0.0	0.0	0.0000000000	False
correlation	0.00189864319716	0.0	0.0	0.0	0.2592592593	False
top	0.000259138942816	0.0	0.0	0.0	0.2335928810	False
major	0.000689196853801	0.0	0.0	0.0	0.3245749614	False
briefly	9.22324486797e-05	0.0	0.0	0.0	0.0000000000	False
joint	0.000370384896312	0.0	0.0	0.0	0.0000000000	False
theoretic	0.000201342336037	0.0	0.0	0.0	0.0000000000	False
k-l	0.00194529704909	0.0	0.0	0.0	0.1700404858	False
divergence	0.00194529704909	0.0	0.0	0.0	0.0000000000	False
concepts	0.000105345402368	0.0	0.0	0.0	0.0000000000	False
mutual	0.00191772849096	0.0	0.0	0.0	0.2270270270	False
independent	8.62441392151e-05	0.0	0.0	0.0	0.0000000000	False
identical	0.000120337633237	0.0	0.0	0.0	0.0000000000	False
non-independent	0.00116717822945	0.0	0.0	0.0	0.0000000000	False
highly	0.000201342336037	0.0	0.0	0.0	0.0000000000	False
play	0.00012872345908	0.0	0.0	0.0	0.0000000000	False
largest	0.000295649444465	0.0	0.0	0.0	0.0000000000	False
decreasing	0.000158863016173	0.0	0.0	0.0	0.0000000000	False
decide	5.18277885632e-05	0.0	0.0	0.0	0.0000000000	False
continue	3.62782856698e-05	0.0	0.0	0.0	0.0000000000	False
good morning welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
today is actually wrap	0.0	0.0	0.0	2.0	0.0000000000	False
wrap up our discussion	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
learning theory and sort	0.0	0.0	0.0	2.0	0.0000000000	False
talking about bayesian statistics	0.0	0.0	0.0	4.0	0.0000000000	False
bayesian statistics and regularization	0.0	0.0	0.0	4.0	0.0000000000	False
applying machine learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms to problems	0.0	0.0	0.0	2.0	0.0000000000	False
project or other problems	0.0	0.0	0.0	2.0	0.0000000000	False
graduate from this class	0.0	0.0	0.0	2.0	0.0000000000	False
regularization so you remember	0.0	0.0	0.0	2.0	0.0000000000	False
remember from last week	0.0	0.0	0.0	2.0	0.0000000000	False
talk about learning theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory and we learned	0.0	0.0	0.0	2.0	0.0000000000	False
variance and i guess	0.0	0.0	0.0	2.0	0.0000000000	False
lecture talking about algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms for model selection	0.0	0.0	0.0	2.0	0.0000000000	False
selection and for feature	0.0	0.0	0.0	2.0	0.0000000000	False
feature selection we talked	0.0	0.0	0.0	2.0	0.0000000000	False
talked about cross-validation right	0.0	0.0	0.0	2.0	0.0000000000	False
previous lecture were ways	0.0	0.0	0.0	2.0	0.0000000000	False
selection algorithms we talked	0.0	0.0	0.0	2.0	0.0000000000	False
fit and thereby reduce	0.0	0.0	0.0	2.0	0.0000000000	False
feature selection algorithms choose	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms choose a subset	0.0	0.0	0.0	2.0	0.0000000000	False
subset of the features	0.0	0.0	0.0	2.0	0.0000000000	False
today is to talk	0.0	0.0	0.0	2.0	0.0000000000	False
first model we learned	0.0	0.0	0.0	2.0	0.0000000000	False
parameters via maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
choose the parameters theta	0.0	0.0	0.0	2.0	0.0000000000	False
parameters theta that maximized	0.0	0.0	0.0	4.0	0.0000000000	False
probability of the data	0.0	0.0	0.0	4.0	0.0000000000	False
philosophical view behind writing	0.0	0.0	0.0	2.0	0.0000000000	False
true parameter theta out	0.0	0.0	0.0	2.0	0.0000000000	False
out there that generated	0.0	0.0	0.0	2.0	0.0000000000	False
parameter theta that govern	0.0	0.0	0.0	2.0	0.0000000000	False
theta that govern housing	0.0	0.0	0.0	2.0	0.0000000000	False
estimating the unknown value	0.0	0.0	0.0	2.0	0.0000000000	False
unknown value for theta	0.0	0.0	0.0	2.0	0.0000000000	False
procedure called maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
maximum likelihood for estimating	0.0	0.0	0.0	2.0	0.0000000000	False
frequencies procedure the alternative	0.0	0.0	0.0	2.0	0.0000000000	False
frequency school of statistics	0.0	0.0	0.0	2.0	0.0000000000	False
nt know what theta	0.0	0.0	0.0	0.0	0.0000000000	False
matrix given by tau	0.0	0.0	0.0	2.0	0.0000000000	False
denote my training set	0.0	0.0	0.0	2.0	0.0000000000	False
theta represents my beliefs	0.0	0.0	0.0	2.0	0.0000000000	False
absence of any data	0.0	0.0	0.0	2.0	0.0000000000	False
theta it probably represents	0.0	0.0	0.0	2.0	0.0000000000	False
sort of bayesian procedure	0.0	0.0	0.0	2.0	0.0000000000	False
posterior probability by parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters given my training	0.0	0.0	0.0	4.0	0.0000000000	False
board so my posterior	0.0	0.0	0.0	2.0	0.0000000000	False
posterior on my parameters	0.0	0.0	0.0	2.0	0.0000000000	False
rule let s call	0.0	0.0	0.0	0.0	0.0000000000	False
posterior and this distribution	0.0	0.0	0.0	2.0	0.0000000000	False
beliefs about what theta	0.0	0.0	0.0	2.0	0.0000000000	False
ve seen the training	0.0	0.0	0.0	2.0	0.0000000000	False
make a new prediction	0.0	0.0	0.0	2.0	0.0000000000	False
prediction on the price	0.0	0.0	0.0	2.0	0.0000000000	False
size of the house	0.0	0.0	0.0	2.0	0.0000000000	False
features of the house	0.0	0.0	0.0	2.0	0.0000000000	False
integral over my parameters	0.0	0.0	0.0	2.0	0.0000000000	False
times the posterior distribution	0.0	0.0	0.0	2.0	0.0000000000	False
posterior distribution of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta given the training	0.0	0.0	0.0	2.0	0.0000000000	False
input x in training	0.0	0.0	0.0	2.0	0.0000000000	False
integrate over y times	0.0	0.0	0.0	2.0	0.0000000000	False
respect to your posterior	0.0	0.0	0.0	2.0	0.0000000000	False
theta because this formula	0.0	0.0	0.0	2.0	0.0000000000	False
property of y conditioned	0.0	0.0	0.0	2.0	0.0000000000	False
conditioned on the values	0.0	0.0	0.0	2.0	0.0000000000	False
values of the random	0.0	0.0	0.0	2.0	0.0000000000	False
variables x and theta	0.0	0.0	0.0	2.0	0.0000000000	False
longer writing semicolon theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta as a random	0.0	0.0	0.0	2.0	0.0000000000	False
check are there questions	0.0	0.0	0.0	2.0	0.0000000000	False
make this more concrete	0.0	0.0	0.0	2.0	0.0000000000	False
steps in the computation	0.0	0.0	0.0	2.0	0.0000000000	False
difficult to compute integrals	0.0	0.0	0.0	2.0	0.0000000000	False
computing a full posterior	0.0	0.0	0.0	2.0	0.0000000000	False
quantity on the right-hand	0.0	0.0	0.0	4.0	0.0000000000	False
side and just maximize	0.0	0.0	0.0	2.0	0.0000000000	False
computing the full posterior	0.0	0.0	0.0	2.0	0.0000000000	False
maximum a posteriori estimate	0.0	0.0	0.0	2.0	0.0000000000	False
posteriori estimate of theta	0.0	0.0	0.0	2.0	0.0000000000	False
probable value of theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta onto your posterior	0.0	0.0	0.0	2.0	0.0000000000	False
max chi of theta	0.0	0.0	0.0	2.0	0.0000000000	False
map value of theta	0.0	0.0	0.0	2.0	0.0000000000	False
vector you d choose	0.0	0.0	0.0	0.0	0.0000000000	False
standard maximum likelihood estimation	0.0	0.0	0.0	2.0	0.0000000000	False
choosing the maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood value for theta	0.0	0.0	0.0	2.0	0.0000000000	False
times this other quantity	0.0	0.0	0.0	2.0	0.0000000000	False
centered around the point	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on feature selection	0.0	0.0	0.0	2.0	0.0000000000	False
reminiscent of feature selection	0.0	0.0	0.0	2.0	0.0000000000	False
points and you fit	0.0	0.0	0.0	2.0	0.0000000000	False
mind if you fit	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood estimation all right	0.0	0.0	0.0	2.0	0.0000000000	False
right ? in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
sort of bayesian regularization	0.0	0.0	5.99890789953	6.0	0.0000000000	False
sort of a smoother	0.0	0.0	0.0	2.0	0.0000000000	False
smoother and smoother fit	0.0	0.0	0.0	2.0	0.0000000000	False
fit to the data	0.0	0.0	0.0	2.0	0.0000000000	False
data as you decrease	0.0	0.0	0.0	2.0	0.0000000000	False
re driving the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
practice it s sort	0.0	0.0	0.0	0.0	0.0000000000	False
fitting a large number	0.0	0.0	0.0	2.0	0.0000000000	False
large number of parameters	0.0	0.0	0.0	2.0	0.0000000000	False
last piece of intuition	0.0	0.0	0.0	2.0	0.0000000000	False
ideas more in problem	0.0	0.0	0.0	2.0	0.0000000000	False
online later this week	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood tries to minimize	0.0	0.0	0.0	2.0	0.0000000000	False
right ? whereas maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out to be minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
add this prior term	0.0	0.0	0.0	2.0	0.0000000000	False
out that the authorization	0.0	0.0	0.0	2.0	0.0000000000	False
authorization objective you end	0.0	0.0	0.0	2.0	0.0000000000	False
end up optimizing turns	0.0	0.0	0.0	2.0	0.0000000000	False
add an extra term	0.0	0.0	0.0	2.0	0.0000000000	False
penalizes your parameter theta	0.0	0.0	0.0	2.0	0.0000000000	False
theta as being large	0.0	0.0	0.0	2.0	0.0000000000	False
similar to maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
expect that you tend	0.0	0.0	0.0	2.0	0.0000000000	False
parameters has the effect	0.0	0.0	0.0	2.0	0.0000000000	False
sense when you play	0.0	0.0	0.0	2.0	0.0000000000	False
play with these ideas	0.0	0.0	0.0	2.0	0.0000000000	False
models like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression and linear regression	0.0	0.0	0.0	2.0	0.0000000000	False
generalized in your models	0.0	0.0	0.0	2.0	0.0000000000	False
sorts of smoothing effects	0.0	0.0	0.0	2.0	0.0000000000	False
smoothing effects all right	0.0	0.0	0.0	2.0	0.0000000000	False
effects all right cool	0.0	0.0	0.0	2.0	0.0000000000	False
out that for problems	0.0	0.0	0.0	2.0	0.0000000000	False
problems like text classification	0.0	0.0	0.0	2.0	0.0000000000	False
features or 50,000 features	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm like logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
right ? so imagine	0.0	0.0	0.0	2.0	0.0000000000	False
imagine trying to build	0.0	0.0	0.0	2.0	0.0000000000	False
build a spam classifier	0.0	0.0	0.0	2.0	0.0000000000	False
effective text classification algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm with this sort	0.0	0.0	0.0	2.0	0.0000000000	False
pick and to pick	0.0	0.0	0.0	2.0	0.0000000000	False
pick either tau squared	0.0	0.0	0.0	4.0	0.0000000000	False
tau squared or lambda	0.0	0.0	0.0	4.0	0.0000000000	False
relation is lambda equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals one over tau	0.0	0.0	0.0	2.0	0.0000000000	False
cool so all right	0.0	0.0	0.0	2.0	0.0000000000	False
methods for preventing overfitting	0.0	0.0	0.0	2.0	0.0000000000	False
minutes talking about online	0.0	0.0	0.0	2.0	0.0000000000	False
talking about online learning	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a digression	0.0	0.0	0.0	2.0	0.0000000000	False
re designing the syllabus	0.0	0.0	0.0	2.0	0.0000000000	False
syllabus of a class	0.0	0.0	0.0	2.0	0.0000000000	False
good place to fit	0.0	0.0	0.0	2.0	0.0000000000	False
disjointed from the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the class	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
algorithms we ve talked	0.0	0.0	0.0	0.0	0.0000000000	False
re given a training	0.0	0.0	0.0	2.0	0.0000000000	False
run your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm on the training	0.0	0.0	0.0	2.0	0.0000000000	False
learning setting called online	0.0	0.0	0.0	2.0	0.0000000000	False
setting called online learning	0.0	0.0	0.0	2.0	0.0000000000	False
problem sees all right	0.0	0.0	0.0	2.0	0.0000000000	False
first gon na give	0.0	0.0	0.0	4.0	0.0000000000	False
make a guess right	0.0	0.0	0.0	2.0	0.0000000000	False
right ? you guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess we ll call	0.0	0.0	0.0	0.0	0.0000000000	False
ll call your guess	0.0	0.0	0.0	2.0	0.0000000000	False
ve made your prediction	0.0	0.0	0.0	2.0	0.0000000000	False
show you x two	0.0	0.0	0.0	2.0	0.0000000000	False
slightly more educated guess	0.0	0.0	0.0	2.0	0.0000000000	False
educated guess and call	0.0	0.0	0.0	2.0	0.0000000000	False
ve made your guess	0.0	0.0	0.0	2.0	0.0000000000	False
reveal the true label	0.0	0.0	0.0	2.0	0.0000000000	False
lot of machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
machine learning and batch	0.0	0.0	0.0	2.0	0.0000000000	False
learning and batch learning	0.0	0.0	0.0	2.0	0.0000000000	False
user likes or dislikes	0.0	0.0	0.0	2.0	0.0000000000	False
examples so in online	0.0	0.0	0.0	2.0	0.0000000000	False
learning what you care	0.0	0.0	0.0	2.0	0.0000000000	False
sum from i equals	0.0	0.0	0.0	2.0	0.0000000000	False
sequence of m examples	0.0	0.0	0.0	2.0	0.0000000000	False
total number of mistakes	0.0	0.0	0.0	2.0	0.0000000000	False
make on a sequence	0.0	0.0	0.0	2.0	0.0000000000	False
finish all the learning	0.0	0.0	0.0	2.0	0.0000000000	False
apply to this setting	0.0	0.0	0.0	2.0	0.0000000000	False
re asked to make	0.0	0.0	0.0	2.0	0.0000000000	False
asked to make prediction	0.0	0.0	0.0	2.0	0.0000000000	False
prediction on y hat	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm and run	0.0	0.0	0.0	2.0	0.0000000000	False
run the learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
previous to being asked	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to make	0.0	0.0	0.0	2.0	0.0000000000	False
remember the perceptron algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
initial the parameter theta	0.0	0.0	0.0	2.0	0.0000000000	False
ve see this reel	0.0	0.0	0.0	2.0	0.0000000000	False
standard perceptron learning rule	0.0	0.0	0.0	2.0	0.0000000000	False
run one-step stochastic gradient	0.0	0.0	0.0	2.0	0.0000000000	False
one-step stochastic gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
reason i ve put	0.0	0.0	0.0	0.0	0.0000000000	False
sort of learning theorysection	0.0	0.0	0.0	2.0	0.0000000000	False
theorysection of this class	0.0	0.0	0.0	2.0	0.0000000000	False
prove fairly amazing results	0.0	0.0	0.0	2.0	0.0000000000	False
online error using algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
main lecture to prove	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature vectors	0.0	0.0	0.0	2.0	0.0000000000	False
infinite feature dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
vectors may use kernel	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative examples	0.0	0.0	3.99854386604	8.0	0.0000000000	False
negative examples are separated	0.0	0.0	0.0	2.0	0.0000000000	False
separated by a margin	0.0	0.0	0.0	2.0	0.0000000000	False
margin down there separating	0.0	0.0	0.0	2.0	0.0000000000	False
prove that perceptron algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
perceptron algorithm will converge	0.0	0.0	0.0	2.0	0.0000000000	False
converge to a hypothesis	0.0	0.0	0.0	2.0	0.0000000000	False
hypothesis that perfectly separates	0.0	0.0	0.0	2.0	0.0000000000	False
finite number of examples	0.0	0.0	0.0	2.0	0.0000000000	False
ll converge to digital	0.0	0.0	0.0	2.0	0.0000000000	False
boundary that perfectly separates	0.0	0.0	0.0	2.0	0.0000000000	False
sort of other things	0.0	0.0	0.0	2.0	0.0000000000	False
notes that i posted	0.0	0.0	0.0	2.0	0.0000000000	False
online for the purposes	0.0	0.0	0.0	2.0	0.0000000000	False
purposes of this class	0.0	0.0	0.0	2.0	0.0000000000	False
proof of this result	0.0	0.0	0.0	2.0	0.0000000000	False
specifically in the problem	0.0	0.0	0.0	2.0	0.0000000000	False
svms can have bounded	0.0	0.0	0.0	2.0	0.0000000000	False
prove learning theory results	0.0	0.0	0.0	2.0	0.0000000000	False
infinite dimensional feature spaces	0.0	0.0	0.0	2.0	0.0000000000	False
read in like half	0.0	0.0	0.0	2.0	0.0000000000	False
bound is actually proved	0.0	0.0	0.0	2.0	0.0000000000	False
based on stochastic gradient	0.0	0.0	0.0	2.0	0.0000000000	False
switch to powerpoint slides	0.0	0.0	0.0	2.0	0.0000000000	False
spend most of today	0.0	0.0	0.0	2.0	0.0000000000	False
today s lecture sort	0.0	0.0	0.0	0.0	0.0000000000	False
lecture sort of talking	0.0	0.0	0.0	2.0	0.0000000000	False
applying different machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
tools known to humankind	0.0	0.0	0.0	2.0	0.0000000000	False
humankind in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
give you some advice	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you re	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms to work	0.0	0.0	0.0	2.0	0.0000000000	False
work well in problems	0.0	0.0	0.0	2.0	0.0000000000	False
conceptually most difficult material	0.0	0.0	0.0	2.0	0.0000000000	False
material in this class	0.0	0.0	0.0	2.0	0.0000000000	False
good machine learning people	0.0	0.0	0.0	2.0	0.0000000000	False
learning people will agree	0.0	0.0	0.0	2.0	0.0000000000	False
advice for doing machine	0.0	0.0	0.0	2.0	0.0000000000	False
work if you work	0.0	0.0	0.0	2.0	0.0000000000	False
work in the company	0.0	0.0	0.0	2.0	0.0000000000	False
product or you re	0.0	0.0	0.0	0.0	0.0000000000	False
learning system to work	0.0	0.0	0.0	2.0	0.0000000000	False
advice if you goal	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to invent	0.0	0.0	2.99890789953	6.0	0.0000000000	False
invent a new machine	0.0	0.0	0.0	2.0	0.0000000000	False
make machine learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
machine learning algorithm work	0.0	0.0	0.0	2.0	0.0000000000	False
deploy a working system	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics for debugging learning	0.0	0.0	0.0	2.0	0.0000000000	False
talk briefly about error	0.0	0.0	0.0	2.0	0.0000000000	False
briefly about error analyses	0.0	0.0	0.0	2.0	0.0000000000	False
analyses and ablative analysis	0.0	0.0	0.0	4.0	0.0000000000	False
talk about just advice	0.0	0.0	0.0	2.0	0.0000000000	False
problem and one theme	0.0	0.0	0.0	2.0	0.0000000000	False
turns out you ve	0.0	0.0	0.0	0.0	0.0000000000	False
out you ve heard	0.0	0.0	0.0	0.0	0.0000000000	False
ve heard about premature	0.0	0.0	0.0	2.0	0.0000000000	False
heard about premature optimization	0.0	0.0	0.0	2.0	0.0000000000	False
over-designs from the start	0.0	0.0	0.0	2.0	0.0000000000	False
writing piece of code	0.0	0.0	0.0	2.0	0.0000000000	False
code and they choose	0.0	0.0	0.0	2.0	0.0000000000	False
subroutine to optimize heavily	0.0	0.0	0.0	2.0	0.0000000000	False
guilty of premature optimization	0.0	0.0	0.0	2.0	0.0000000000	False
code to run faster	0.0	0.0	0.0	2.0	0.0000000000	False
faster and we choose	0.0	0.0	0.0	2.0	0.0000000000	False
choose probably a piece	0.0	0.0	0.0	2.0	0.0000000000	False
code and we implement	0.0	0.0	0.0	2.0	0.0000000000	False
quickly and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
bottleneck in the code	0.0	0.0	0.0	2.0	0.0000000000	False
call that premature optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization and in undergraduate	0.0	0.0	0.0	2.0	0.0000000000	False
premature optimization and people	0.0	0.0	0.0	2.0	0.0000000000	False
right ? and turns	0.0	0.0	0.0	2.0	0.0000000000	False
thing happens in building	0.0	0.0	0.0	2.0	0.0000000000	False
systems that many people	0.0	0.0	0.0	2.0	0.0000000000	False
part of a machine	0.0	0.0	0.0	2.0	0.0000000000	False
system and that turns	0.0	0.0	0.0	2.0	0.0000000000	False
first talk about debugging	0.0	0.0	0.0	2.0	0.0000000000	False
talk about debugging learning	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms as a motivating	0.0	0.0	0.0	2.0	0.0000000000	False
build an anti-spam system	0.0	0.0	1.99890789953	6.0	0.0000000000	False
chosen a small set	0.0	0.0	0.0	2.0	0.0000000000	False
implement bayesian logistic regression	0.0	0.0	0.0	4.0	0.0000000000	False
additional lambda squared term	0.0	0.0	0.0	2.0	0.0000000000	False
term and we re	0.0	0.0	0.0	0.0	0.0000000000	False
maximizing rather than minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
minus lambda theta square	0.0	0.0	0.0	2.0	0.0000000000	False
squared so the question	0.0	0.0	0.0	2.0	0.0000000000	False
bayesian logistic regression algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ways you could improve	0.0	0.0	0.0	2.0	0.0000000000	False
ll try to improve	0.0	0.0	0.0	2.0	0.0000000000	False
examples maybe you suspect	0.0	0.0	0.0	2.0	0.0000000000	False
smaller set of features	0.0	0.0	0.0	4.0	0.0000000000	False
figure out better features	0.0	0.0	0.0	2.0	0.0000000000	False
emails or whatever right	0.0	0.0	0.0	2.0	0.0000000000	False
suspect that gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
gradient descent a bit	0.0	0.0	0.0	2.0	0.0000000000	False
descent a bit longer	0.0	0.0	0.0	2.0	0.0000000000	False
run gradient descent longer	0.0	0.0	0.0	2.0	0.0000000000	False
remember hearing from class	0.0	0.0	0.0	2.0	0.0000000000	False
class that maybe newton	0.0	0.0	0.0	2.0	0.0000000000	False
newton s method converges	0.0	0.0	0.0	0.0	0.0000000000	False
improve a learning system	0.0	0.0	0.0	2.0	0.0000000000	False
picking ways to improve	0.0	0.0	0.0	2.0	0.0000000000	False
improve the learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm and picking	0.0	0.0	0.0	2.0	0.0000000000	False
work in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
largely largely a matter	0.0	0.0	0.0	2.0	0.0000000000	False
fixing what the problem	0.0	0.0	0.0	2.0	0.0000000000	False
fix very different problems	0.0	0.0	0.0	2.0	0.0000000000	False
save yourself a lot	0.0	0.0	0.0	2.0	0.0000000000	False
industry and in research	0.0	0.0	0.0	2.0	0.0000000000	False
change a learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
randomly there are lots	0.0	0.0	0.0	2.0	0.0000000000	False
things that obviously improve	0.0	0.0	0.0	2.0	0.0000000000	False
improve your learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
good ones that run	0.0	0.0	0.0	2.0	0.0000000000	False
figure out the problem	0.0	0.0	0.0	4.0	0.0000000000	False
bayesian logistic regression test	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression test error	0.0	0.0	0.0	2.0	0.0000000000	False
problem is either overfitting	0.0	0.0	0.0	2.0	0.0000000000	False
forget forget the tables	0.0	0.0	0.0	2.0	0.0000000000	False
forget the tables suppose	0.0	0.0	0.0	2.0	0.0000000000	False
tables suppose you suspect	0.0	0.0	0.0	2.0	0.0000000000	False
bias or high variance	0.0	0.0	5.99854386604	8.0	0.0000000000	False
features classified as spam	0.0	0.0	0.0	2.0	0.0000000000	False
out whether the problem	0.0	0.0	0.0	2.0	0.0000000000	False
high variance ? right	0.0	0.0	0.0	2.0	0.0000000000	False
problem is high bias	0.0	0.0	0.0	2.0	0.0000000000	False
variance if you remember	0.0	0.0	0.0	2.0	0.0000000000	False
previously for high variance	0.0	0.0	0.0	2.0	0.0000000000	False
high variance the training	0.0	0.0	0.0	2.0	0.0000000000	False
variance the training error	0.0	0.0	0.0	2.0	0.0000000000	False
lower than the test	0.0	0.0	0.0	2.0	0.0000000000	False
test error all right	0.0	0.0	0.0	2.0	0.0000000000	False
re fitting your training	0.0	0.0	0.0	2.0	0.0000000000	False
fitting your training set	0.0	0.0	0.0	4.0	0.0000000000	False
data points all right	0.0	0.0	0.0	2.0	0.0000000000	False
fitting the data set	0.0	0.0	0.0	2.0	0.0000000000	False
lower than your test	0.0	0.0	0.0	2.0	0.0000000000	False
error and in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
fitting a linear function	0.0	0.0	0.0	2.0	0.0000000000	False
curve for high variance	0.0	0.0	0.0	2.0	0.0000000000	False
plotting the training set	0.0	0.0	0.0	2.0	0.0000000000	False
notice as the training	0.0	0.0	0.0	2.0	0.0000000000	False
increase the training set	0.0	0.0	0.0	2.0	0.0000000000	False
extrapolate the green curve	0.0	0.0	0.0	2.0	0.0000000000	False
set error will decrease	0.0	0.0	0.0	2.0	0.0000000000	False
right ? another thing	0.0	0.0	0.0	2.0	0.0000000000	False
line is the desired	0.0	0.0	0.0	2.0	0.0000000000	False
desired performance you re	0.0	0.0	0.0	0.0	0.0000000000	False
re trying to reach	0.0	0.0	0.0	2.0	0.0000000000	False
out that your training	0.0	0.0	0.0	2.0	0.0000000000	False
error will actually grow	0.0	0.0	0.0	4.0	0.0000000000	False
grow as a function	0.0	0.0	3.99890789953	6.0	0.0000000000	False
function of the training	0.0	0.0	0.0	2.0	0.0000000000	False
larger your training set	0.0	0.0	0.0	2.0	0.0000000000	False
training set perfectly right	0.0	0.0	0.0	2.0	0.0000000000	False
function of your training	0.0	0.0	0.0	4.0	0.0000000000	False
set size because smart	0.0	0.0	0.0	2.0	0.0000000000	False
size because smart training	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostic for high variance	0.0	0.0	0.0	2.0	0.0000000000	False
training versus test error	0.0	0.0	0.0	2.0	0.0000000000	False
case of high variance	0.0	0.0	0.0	2.0	0.0000000000	False
curve for test error	0.0	0.0	0.0	2.0	0.0000000000	False
test error has flattened	0.0	0.0	0.0	2.0	0.0000000000	False
property of high bias	0.0	0.0	0.0	2.0	0.0000000000	False
hold out test set	0.0	0.0	0.0	2.0	0.0000000000	False
out test set error	0.0	0.0	0.0	2.0	0.0000000000	False
error if you find	0.0	0.0	0.0	2.0	0.0000000000	False
right ? in fact	0.0	0.0	0.0	2.0	0.0000000000	False
level of desired performance	0.0	0.0	0.0	4.0	0.0000000000	False
reduce your training error	0.0	0.0	0.0	2.0	0.0000000000	False
desired level of performance	0.0	0.0	0.0	2.0	0.0000000000	False
level of performance right	0.0	0.0	0.0	2.0	0.0000000000	False
green curve on test	0.0	0.0	0.0	2.0	0.0000000000	False
curve on test error	0.0	0.0	0.0	2.0	0.0000000000	False
personally tend to find	0.0	0.0	0.0	2.0	0.0000000000	False
problem or a variance	0.0	0.0	0.0	2.0	0.0000000000	False
training and test error	0.0	0.0	0.0	4.0	0.0000000000	False
back to the list	0.0	0.0	0.0	2.0	0.0000000000	False
high variance all right	0.0	0.0	0.0	2.0	0.0000000000	False
larger set of features	0.0	0.0	0.0	2.0	0.0000000000	False
features or adding email	0.0	0.0	0.0	2.0	0.0000000000	False
nt have enough features	0.0	0.0	0.0	0.0	0.0000000000	False
people working on machine	0.0	0.0	0.0	2.0	0.0000000000	False
working on machine learning	0.0	0.0	0.0	4.0	0.0000000000	False
ll build a learning	0.0	0.0	0.0	2.0	0.0000000000	False
build a learning system	0.0	0.0	0.0	2.0	0.0000000000	False
money and effort collecting	0.0	0.0	0.0	2.0	0.0000000000	False
effort collecting more training	0.0	0.0	0.0	2.0	0.0000000000	False
collecting more training data	0.0	0.0	0.0	2.0	0.0000000000	False
months or six months	0.0	0.0	0.0	2.0	0.0000000000	False
silicon valley and companies	0.0	0.0	0.0	2.0	0.0000000000	False
people building various machine	0.0	0.0	0.0	2.0	0.0000000000	False
building various machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
people spending six months	0.0	0.0	0.0	2.0	0.0000000000	False
spending six months working	0.0	0.0	0.0	2.0	0.0000000000	False
months working on fixing	0.0	0.0	0.0	2.0	0.0000000000	False
fixing a learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
told them six months	0.0	0.0	0.0	2.0	0.0000000000	False
nt possibly have helped	0.0	0.0	0.0	0.0	0.0000000000	False
easily spend six months	0.0	0.0	0.0	2.0	0.0000000000	False
months trying to invent	0.0	0.0	0.0	2.0	0.0000000000	False
depressing you could ve	0.0	0.0	0.0	0.0	0.0000000000	False
told you six months	0.0	0.0	0.0	2.0	0.0000000000	False
two of these solutions	0.0	0.0	0.0	2.0	0.0000000000	False
save yourself many months	0.0	0.0	0.0	2.0	0.0000000000	False
months of fruitless effort	0.0	0.0	0.0	2.0	0.0000000000	False
four at the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
great so bias versus	0.0	0.0	0.0	2.0	0.0000000000	False
variance is one thing	0.0	0.0	0.0	2.0	0.0000000000	False
out your own diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
out what s wrong	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm is nt working	0.0	0.0	0.0	0.0	0.0000000000	False
construct your own tests	0.0	0.0	0.0	2.0	0.0000000000	False
difference training and test	0.0	0.0	0.0	2.0	0.0000000000	False
construct your own diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
illustrate another common question	0.0	0.0	0.0	2.0	0.0000000000	False
percent error on spam	0.0	0.0	0.0	4.0	0.0000000000	False
error on spam mail	0.0	0.0	0.0	2.0	0.0000000000	False
percent error non-spam mail	0.0	0.0	0.0	2.0	0.0000000000	False
error non-spam mail right	0.0	0.0	0.0	2.0	0.0000000000	False
percent of your spam	0.0	0.0	0.0	2.0	0.0000000000	False
percent of all spam	0.0	0.0	0.0	2.0	0.0000000000	False
percent of the email	0.0	0.0	0.0	2.0	0.0000000000	False
email from your friends	0.0	0.0	0.0	2.0	0.0000000000	False
machine using a linear	0.0	0.0	0.0	2.0	0.0000000000	False
percent error on non-spam	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to build	0.0	0.0	0.0	2.0	0.0000000000	False
regression to your customers	0.0	0.0	0.0	2.0	0.0000000000	False
retrain overnight every day	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression just runs	0.0	0.0	0.0	2.0	0.0000000000	False
out well so question	0.0	0.0	0.0	2.0	0.0000000000	False
problem with logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
iterations and it turns	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing j of theta	0.0	0.0	0.0	4.0	0.0000000000	False
objective as a function	0.0	0.0	0.0	2.0	0.0000000000	False
function of the number	0.0	0.0	0.0	2.0	0.0000000000	False
curve has already flattened	0.0	0.0	0.0	2.0	0.0000000000	False
flattened out all right	0.0	0.0	0.0	2.0	0.0000000000	False
run this ten times	0.0	0.0	0.0	4.0	0.0000000000	False
logistic regression is converged	0.0	0.0	0.0	4.0	0.0000000000	False
curve the other question	0.0	0.0	0.0	2.0	0.0000000000	False
thing you might suspect	0.0	0.0	0.0	2.0	0.0000000000	False
suspect is a problem	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing the right function	0.0	0.0	0.0	2.0	0.0000000000	False
sum over your examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples of some weights	0.0	0.0	0.0	2.0	0.0000000000	False
non-spam than for spam	0.0	0.0	0.0	2.0	0.0000000000	False
mail because you care	0.0	0.0	0.0	2.0	0.0000000000	False
predictions correct for spam	0.0	0.0	0.0	2.0	0.0000000000	False
correct for spam email	0.0	0.0	0.0	2.0	0.0000000000	False
theta is the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
sort of maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
function to be optimizing	0.0	0.0	0.0	2.0	0.0000000000	False
switching to support vector	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine optimization	0.0	0.0	0.0	2.0	0.0000000000	False
vector machine optimization objective	0.0	0.0	0.0	2.0	0.0000000000	False
out is the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
problem with the optimization	0.0	0.0	0.0	4.0	0.0000000000	False
optimization objective i chose	0.0	0.0	0.0	2.0	0.0000000000	False
outperforms bayesian logistic regression	0.0	0.0	0.0	4.0	0.0000000000	False
deploy bayesian logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression to your problem	0.0	0.0	0.0	2.0	0.0000000000	False
learned by an svm	0.0	0.0	0.0	2.0	0.0000000000	False
ll let theta subscript	0.0	0.0	0.0	2.0	0.0000000000	False
blr be the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
regression so the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
optimization objective you care	0.0	0.0	0.0	2.0	0.0000000000	False
criteria that i talked	0.0	0.0	0.0	2.0	0.0000000000	False
support vector machine outperforms	0.0	0.0	0.0	2.0	0.0000000000	False
regression tries to optimize	0.0	0.0	0.0	2.0	0.0000000000	False
optimize an optimization objective	0.0	0.0	0.0	2.0	0.0000000000	False
less-than j of blr	0.0	0.0	0.0	2.0	0.0000000000	False
weighted accuracy of support	0.0	0.0	0.0	2.0	0.0000000000	False
accuracy of support vector	0.0	0.0	0.0	2.0	0.0000000000	False
bigger than this weighted	0.0	0.0	0.0	2.0	0.0000000000	False
regression so in order	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing the wrong objective	0.0	0.0	0.0	2.0	0.0000000000	False
check if this equality	0.0	0.0	0.0	2.0	0.0000000000	False
copied over in case	0.0	0.0	0.0	2.0	0.0000000000	False
maximize j of theta	0.0	0.0	5.99890789953	6.0	0.0000000000	False
regression so this means	0.0	0.0	0.0	2.0	0.0000000000	False
value of theta output	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression actually fails	0.0	0.0	0.0	2.0	0.0000000000	False
support back to machine	0.0	0.0	5.99890789953	6.0	0.0000000000	False
optimization algorithm the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm the optimization algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has nt converged	0.0	0.0	0.0	0.0	0.0000000000	False
converged the other case	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression actually attains	0.0	0.0	0.0	2.0	0.0000000000	False
attains the higher value	0.0	0.0	0.0	2.0	0.0000000000	False
value for the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
worse on your optimization	0.0	0.0	0.0	4.0	0.0000000000	False
maximizing your weighted accuracy	0.0	0.0	0.0	2.0	0.0000000000	False
objective to be maximizing	0.0	0.0	0.0	2.0	0.0000000000	False
nt a good objective	0.0	0.0	0.0	0.0	0.0000000000	False
objective to be choosing	0.0	0.0	0.0	2.0	0.0000000000	False
choosing if you care	0.0	0.0	0.0	2.0	0.0000000000	False
care about the weighted	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this made	0.0	0.0	0.0	2.0	0.0000000000	False
made sense ? cool	0.0	0.0	0.0	2.0	0.0000000000	False
good so that tells	0.0	0.0	0.0	2.0	0.0000000000	False
descent for more iterations	0.0	0.0	0.0	2.0	0.0000000000	False
fixes the optimization algorithm	0.0	0.0	5.99890789953	6.0	0.0000000000	False
method fixes the optimization	0.0	0.0	0.0	2.0	0.0000000000	False
times norm of data	0.0	0.0	0.0	2.0	0.0000000000	False
norm of data squared	0.0	0.0	0.0	2.0	0.0000000000	False
fixes the optimization objective	0.0	0.0	5.99890789953	6.0	0.0000000000	False
optimization objective and changing	0.0	0.0	0.0	2.0	0.0000000000	False
changing to an svm	0.0	0.0	0.0	2.0	0.0000000000	False
objective and be working	0.0	0.0	0.0	2.0	0.0000000000	False
pattern that the problem	0.0	0.0	0.0	2.0	0.0000000000	False
iterations of gradient descent	0.0	0.0	0.0	2.0	0.0000000000	False
descent like trying newton	0.0	0.0	0.0	2.0	0.0000000000	False
method and trying conjugate	0.0	0.0	0.0	2.0	0.0000000000	False
nt going to fix	0.0	0.0	0.0	0.0	0.0000000000	False
fixing your optimization algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
optimization algorithm or fixing	0.0	0.0	0.0	2.0	0.0000000000	False
work on flying helicopters	0.0	0.0	0.0	2.0	0.0000000000	False
draws on reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
close to the end	0.0	0.0	0.0	2.0	0.0000000000	False
ve talked about reinforcement	0.0	0.0	0.0	2.0	0.0000000000	False
talked about reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning in the class	0.0	0.0	0.0	2.0	0.0000000000	False
understand it more deeply	0.0	0.0	0.0	2.0	0.0000000000	False
machine-learning algorithm to design	0.0	0.0	0.0	2.0	0.0000000000	False
step was you build	0.0	0.0	0.0	2.0	0.0000000000	False
simulator for a helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
screenshot of our simulator	0.0	0.0	0.0	2.0	0.0000000000	False
choose a cost function	0.0	0.0	0.0	2.0	0.0000000000	False
ll call it cost	0.0	0.0	0.0	2.0	0.0000000000	False
call it cost function	0.0	0.0	0.0	2.0	0.0000000000	False
error in your helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
run a reinforcement-learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learn about rl algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
run reinforcement learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm in your simulator	0.0	0.0	0.0	2.0	0.0000000000	False
minimize this cost function	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the squared error	0.0	0.0	0.0	2.0	0.0000000000	False
re controlling your helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm will output	0.0	0.0	0.0	2.0	0.0000000000	False
run this learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
set of controller parameters	0.0	0.0	0.0	2.0	0.0000000000	False
capture the aerodynamic effects	0.0	0.0	0.0	2.0	0.0000000000	False
aerodynamic effects more accurately	0.0	0.0	0.0	2.0	0.0000000000	False
airflow and the turbulence	0.0	0.0	0.0	2.0	0.0000000000	False
affects around the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
modify the cost function	0.0	0.0	0.0	2.0	0.0000000000	False
function maybe your square	0.0	0.0	0.0	2.0	0.0000000000	False
error is nt cutting	0.0	0.0	0.0	0.0	0.0000000000	False
reasoning that i wanted	0.0	0.0	0.0	2.0	0.0000000000	False
reinforcement-learning algorithm does poorly	0.0	0.0	0.0	2.0	0.0000000000	False
things hold true suppose	0.0	0.0	0.0	2.0	0.0000000000	False
true suppose the contrary	0.0	0.0	0.0	2.0	0.0000000000	False
suppose that the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
model of our helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
suppose that the reinforcement	0.0	0.0	0.0	2.0	0.0000000000	False
correctly controls the helicopter	0.0	0.0	0.0	4.0	0.0000000000	False
run a learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm in simulation	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm can crash	0.0	0.0	0.0	2.0	0.0000000000	False
assume our reinforcement-learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
reinforcement-learning algorithm correctly controls	0.0	0.0	0.0	2.0	0.0000000000	False
minimize the cost function	0.0	0.0	3.99854386604	8.0	0.2914572864	False
function j of theta	0.0	0.0	0.0	4.0	0.0000000000	False
minimizing j of theta	0.0	0.0	2.99890789953	6.0	0.0000000000	False
theta does indeed correspond	0.0	0.0	0.0	2.0	0.0000000000	False
means that the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
fact that the learning	0.0	0.0	0.0	2.0	0.0000000000	False
flies well in simulation	0.0	0.0	0.0	2.0	0.0000000000	False
simulator of the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
tells me the problem	0.0	0.0	0.0	4.0	0.0000000000	False
right ? my simulator	0.0	0.0	0.0	2.0	0.0000000000	False
simulator predicts the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
spend out efforts improving	0.0	0.0	0.0	2.0	0.0000000000	False
efforts improving the accuracy	0.0	0.0	0.0	2.0	0.0000000000	False
accuracy of our simulator	0.0	0.0	0.0	2.0	0.0000000000	False
write theta subscript human	0.0	0.0	0.0	2.0	0.0000000000	False
control policy all right	0.0	0.0	0.0	2.0	0.0000000000	False
human pilot s flight	0.0	0.0	0.0	0.0	0.0000000000	False
optimizing this objective function	0.0	0.0	0.0	2.0	0.0000000000	False
good human pilot attains	0.0	0.0	0.0	2.0	0.0000000000	False
pilot attains a worse	0.0	0.0	0.0	2.0	0.0000000000	False
attains a worse value	0.0	0.0	0.0	2.0	0.0000000000	False
value on my optimization	0.0	0.0	0.0	2.0	0.0000000000	False
attains a lower value	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm s not managing	0.0	0.0	0.0	0.0	0.0000000000	False
theta and that tells	0.0	0.0	0.0	2.0	0.0000000000	False
attains a larger value	0.0	0.0	0.0	4.0	0.0000000000	False
larger value for theta	0.0	0.0	0.0	2.0	0.0000000000	False
value for theta excuse	0.0	0.0	0.0	2.0	0.0000000000	False
larger mean squared error	0.0	0.0	0.0	2.0	0.0000000000	False
error for the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
worse on my cost	0.0	0.0	0.0	2.0	0.0000000000	False
cost function but flies	0.0	0.0	0.0	2.0	0.0000000000	False
cost function it means	0.0	0.0	0.0	2.0	0.0000000000	False
cost function my learning	0.0	0.0	0.0	2.0	0.0000000000	False
function my learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
job minimizing the cost	0.0	0.0	0.0	2.0	0.0000000000	False
pilot so that tells	0.0	0.0	0.0	2.0	0.0000000000	False
tells you that minimizing	0.0	0.0	0.0	2.0	0.0000000000	False
function does nt correspond	0.0	0.0	0.0	0.0	0.0000000000	False
change j of theta	0.0	0.0	0.0	2.0	0.0000000000	False
work often reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms just work	0.0	0.0	0.0	2.0	0.0000000000	False
focusing on the simulator	0.0	0.0	0.0	2.0	0.0000000000	False
changing the cost function	0.0	0.0	0.0	2.0	0.0000000000	False
changing the reinforcement learning	0.0	0.0	0.0	2.0	0.0000000000	False
building a better simulator	0.0	0.0	0.0	2.0	0.0000000000	False
simulator for your helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
helicopter but it turns	0.0	0.0	0.0	2.0	0.0000000000	False
turns out that modeling	0.0	0.0	0.0	2.0	0.0000000000	False
out that modeling helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
active area of research	0.0	0.0	0.0	2.0	0.0000000000	False
research there are people	0.0	0.0	0.0	2.0	0.0000000000	False
writing entire phd theses	0.0	0.0	0.0	2.0	0.0000000000	False
write a phd thesis	0.0	0.0	0.0	2.0	0.0000000000	False
phd thesis and build	0.0	0.0	0.0	2.0	0.0000000000	False
fixing the wrong problem	0.0	0.0	0.0	2.0	0.0000000000	False
out what s happening	0.0	0.0	0.0	0.0	0.0000000000	False
happening in an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ve described are sort	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
learning algorithm is working	0.0	0.0	0.0	2.0	0.0000000000	False
good idea to run	0.0	0.0	0.0	2.0	0.0000000000	False
idea to run diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
understand your application problem	0.0	0.0	0.0	2.0	0.0000000000	False
high-paying job to apply	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms to some application	0.0	0.0	0.0	2.0	0.0000000000	False
specific important machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
important machine learning application	0.0	0.0	0.0	2.0	0.0000000000	False
application for many months	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of what works	0.0	0.0	0.0	2.0	0.0000000000	False
nt work your problem	0.0	0.0	0.0	0.0	0.0000000000	False
work your problem sort	0.0	0.0	0.0	2.0	0.0000000000	False
problem sort of right	0.0	0.0	0.0	2.0	0.0000000000	False
companies with important machine	0.0	0.0	0.0	2.0	0.0000000000	False
important machine learning problems	0.0	0.0	0.0	2.0	0.0000000000	False
months or for years	0.0	0.0	0.0	2.0	0.0000000000	False
important problem using learning	0.0	0.0	0.0	2.0	0.0000000000	False
problem using learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of the problem	0.0	0.0	0.0	4.0	0.0000000000	False
understanding of these problems	0.0	0.0	0.0	2.0	0.0000000000	False
valley companies that outsource	0.0	0.0	0.0	2.0	0.0000000000	False
outsource their machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
company in silicon valley	0.0	0.0	0.0	2.0	0.0000000000	False
firm in new york	0.0	0.0	0.0	2.0	0.0000000000	False
run all their learning	0.0	0.0	0.0	2.0	0.0000000000	False
understanding of your data	0.0	0.0	0.0	2.0	0.0000000000	False
nt maintain that expertise	0.0	0.0	0.0	0.0	0.0000000000	False
problem you really care	0.0	0.0	0.0	2.0	0.0000000000	False
problem that you build	0.0	0.0	0.0	2.0	0.0000000000	False
build up over months	0.0	0.0	0.0	2.0	0.0000000000	False
ll be really valuable	0.0	0.0	0.0	2.0	0.0000000000	False
reason for running diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
right ? so diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics and error analyses	0.0	0.0	0.0	2.0	0.0000000000	False
insight about the problem	0.0	0.0	0.0	2.0	0.0000000000	False
justify your research claims	0.0	0.0	0.0	2.0	0.0000000000	False
writing a research paper	0.0	0.0	0.0	4.0	0.0000000000	False
helicopter and it flies,or	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on error analysis	0.0	0.0	0.0	2.0	0.0000000000	False
good machine learning practice	0.0	0.0	0.0	2.0	0.0000000000	False
understanding what your sources	0.0	0.0	0.0	2.0	0.0000000000	False
wrong with the helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
flown so many times	0.0	0.0	0.0	2.0	0.0000000000	False
helicopter is actually building	0.0	0.0	0.0	2.0	0.0000000000	False
building an accurate simulator	0.0	0.0	0.0	2.0	0.0000000000	False
simulator of a helicopter	0.0	0.0	0.0	2.0	0.0000000000	False
helicopter is very hard	0.0	0.0	0.0	2.0	0.0000000000	False
out what is working	0.0	0.0	0.0	2.0	0.0000000000	False
working in your algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
working and we re	0.0	0.0	0.0	0.0	0.0000000000	False
re gon na talk	0.0	0.0	0.0	2.0	0.0000000000	False
sort of ia systems	0.0	0.0	0.0	2.0	0.0000000000	False
combine many different components	0.0	0.0	0.0	2.0	0.0000000000	False
components into a pipeline	0.0	0.0	0.0	2.0	0.0000000000	False
sort of a contrived	0.0	0.0	0.0	2.0	0.0000000000	False
dissimilar in many ways	0.0	0.0	0.0	2.0	0.0000000000	False
actual machine learning systems	0.0	0.0	0.0	2.0	0.0000000000	False
recognize people from images	0.0	0.0	0.0	2.0	0.0000000000	False
input in camera image	0.0	0.0	0.0	2.0	0.0000000000	False
run a face detection	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithm to detect	0.0	0.0	0.0	4.0	0.0000000000	False
algorithm to detect people	0.0	0.0	0.0	2.0	0.0000000000	False
detect people s faces	0.0	0.0	0.0	0.0	0.0000000000	False
people s faces right	0.0	0.0	0.0	0.0	0.0000000000	False
identity of the person	0.0	0.0	0.0	2.0	0.0000000000	False
segment of the eyes	0.0	0.0	0.0	2.0	0.0000000000	False
segment of the nose	0.0	0.0	0.0	2.0	0.0000000000	False
friend after she sees	0.0	0.0	0.0	2.0	0.0000000000	False
found all these features	0.0	0.0	0.0	2.0	0.0000000000	False
feed all the features	0.0	0.0	0.0	2.0	0.0000000000	False
regression or soft match	0.0	0.0	0.0	2.0	0.0000000000	False
identity of this person	0.0	0.0	0.0	2.0	0.0000000000	False
long complicated pipeline combining	0.0	0.0	0.0	2.0	0.0000000000	False
pipeline combining many machine	0.0	0.0	0.0	2.0	0.0000000000	False
combining many machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
error can be attributed	0.0	0.0	0.0	2.0	0.0000000000	False
typical error analysis procedure	0.0	0.0	0.0	2.0	0.0000000000	False
ground-truth for each component	0.0	0.0	0.0	2.0	0.0000000000	False
figure on the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
accuracy of the system	0.0	0.0	0.0	2.0	0.0000000000	False
implement my correct background	0.0	0.0	0.0	2.0	0.0000000000	False
correct background versus foreground	0.0	0.0	0.0	2.0	0.0000000000	False
giving that ground-truth data	0.0	0.0	0.0	2.0	0.0000000000	False
data in the test	0.0	0.0	0.0	2.0	0.0000000000	False
assume our accuracy increases	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm where the face	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm s accuracy increases	0.0	0.0	0.0	0.0	0.0000000000	False
components and just give	0.0	0.0	0.0	2.0	0.0000000000	False
out where the nose	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to figure	0.0	0.0	0.0	0.0	0.0000000000	False
giving it the correct	0.0	0.0	0.0	2.0	0.0000000000	False
output label and end	0.0	0.0	0.0	2.0	0.0000000000	False
giving the ground-truth labels	0.0	0.0	0.0	2.0	0.0000000000	False
components could help boost	0.0	0.0	0.0	2.0	0.0000000000	False
boost your final performance	0.0	0.0	0.0	2.0	0.0000000000	False
added the face detection	0.0	0.0	0.0	2.0	0.0000000000	False
percent whereas in contrast	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to improve	0.0	0.0	0.0	2.0	0.0000000000	False
improve your background subtraction	0.0	0.0	0.0	2.0	0.0000000000	False
larger potential for gains	0.0	0.0	0.0	2.0	0.0000000000	False
easily choose to spend	0.0	0.0	0.0	2.0	0.0000000000	False
right ? and choosing	0.0	0.0	0.0	2.0	0.0000000000	False
choosing the right piece	0.0	0.0	0.0	2.0	0.0000000000	False
sort of diagnostic tells	0.0	0.0	0.0	2.0	0.0000000000	False
sort of another type	0.0	0.0	0.0	2.0	0.0000000000	False
analyses that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
talked about the error	0.0	0.0	0.0	2.0	0.0000000000	False
analysis i just talked	0.0	0.0	0.0	2.0	0.0000000000	False
current performance and perfect	0.0	0.0	0.0	2.0	0.0000000000	False
performance and perfect performance	0.0	0.0	0.0	2.0	0.0000000000	False
sort of ablative analysis	0.0	0.0	0.0	2.0	0.0000000000	False
analysis tries to explain	0.0	0.0	0.0	2.0	0.0000000000	False
difference between some baselines	0.0	0.0	0.0	2.0	0.0000000000	False
suppose you ve built	0.0	0.0	0.0	0.0	0.0000000000	False
anti-spam classifier for adding	0.0	0.0	0.0	2.0	0.0000000000	False
classifier for adding lots	0.0	0.0	0.0	2.0	0.0000000000	False
adding lots of clever	0.0	0.0	0.0	2.0	0.0000000000	False
lots of clever features	0.0	0.0	0.0	2.0	0.0000000000	False
logistic regression algorithm right	0.0	0.0	0.0	2.0	0.0000000000	False
added features for spam	0.0	0.0	0.0	2.0	0.0000000000	False
features for spam correction	0.0	0.0	0.0	2.0	0.0000000000	False
email text parser features	0.0	0.0	0.0	2.0	0.0000000000	False
features for embedded images	0.0	0.0	0.0	2.0	0.0000000000	False
research paper and claim	0.0	0.0	0.0	2.0	0.0000000000	False
made the big difference	0.0	0.0	0.0	2.0	0.0000000000	False
figure out what accounts	0.0	0.0	0.0	2.0	0.0000000000	False
accounts for your improvement	0.0	0.0	0.0	2.0	0.0000000000	False
ll instead remove components	0.0	0.0	0.0	2.0	0.0000000000	False
ll remove the sender	0.0	0.0	0.0	2.0	0.0000000000	False
remove the sender host	0.0	0.0	0.0	4.0	0.0000000000	False
occurred when you remove	0.0	0.0	0.0	2.0	0.0000000000	False
remove the text parser	0.0	0.0	0.0	2.0	0.0000000000	False
make a credible case	0.0	0.0	0.0	2.0	0.0000000000	False
made the biggest difference	0.0	0.0	0.0	2.0	0.0000000000	False
features on this line	0.0	0.0	0.0	2.0	0.0000000000	False
means that in case	0.0	0.0	0.0	2.0	0.0000000000	False
rid of the sender	0.0	0.0	0.0	2.0	0.0000000000	False
host features to speed	0.0	0.0	0.0	2.0	0.0000000000	False
good candidate for elimination	0.0	0.0	0.0	2.0	0.0000000000	False
shuffle around the order	0.0	0.0	0.0	2.0	0.0000000000	False
things ? the answer	0.0	0.0	0.0	2.0	0.0000000000	False
result so in practice	0.0	0.0	0.0	2.0	0.0000000000	False
fairly natural of ordering	0.0	0.0	0.0	2.0	0.0000000000	False
ordering for both types	0.0	0.0	0.0	2.0	0.0000000000	False
add things or remove	0.0	0.0	0.0	2.0	0.0000000000	False
things or remove things	0.0	0.0	0.0	2.0	0.0000000000	False
formulas that are constants	0.0	0.0	0.0	2.0	0.0000000000	False
feel free to invent	0.0	0.0	0.0	2.0	0.0000000000	False
system and just remove	0.0	0.0	0.0	2.0	0.0000000000	False
talk about is sort	0.0	0.0	0.0	2.0	0.0000000000	False
started on a learning	0.0	0.0	0.0	2.0	0.0000000000	False
broad to get started	0.0	0.0	0.0	2.0	0.0000000000	False
started on learning problem	0.0	0.0	0.0	2.0	0.0000000000	False
carefully design your system	0.0	0.0	0.0	2.0	0.0000000000	False
designing exactly the right	0.0	0.0	0.0	2.0	0.0000000000	False
collecting the right data	0.0	0.0	0.0	2.0	0.0000000000	False
implement it and hope	0.0	0.0	0.0	2.0	0.0000000000	False
right ? the benefit	0.0	0.0	0.0	2.0	0.0000000000	False
benefit of this sort	0.0	0.0	0.0	2.0	0.0000000000	False
contribute to basic research	0.0	0.0	0.0	2.0	0.0000000000	False
basic research in machine	0.0	0.0	0.0	2.0	0.0000000000	False
research in machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
invent new machine learning	0.0	0.0	0.0	4.0	0.0000000000	False
slowing down and thinking	0.0	0.0	0.0	2.0	0.0000000000	False
deeply about the problem	0.0	0.0	0.0	4.0	0.0000000000	False
sort of the right	0.0	0.0	0.0	2.0	0.0000000000	False
deeply about a problem	0.0	0.0	0.0	2.0	0.0000000000	False
error analyses and diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
wrong and you fix	0.0	0.0	0.0	2.0	0.0000000000	False
working much more quickly	0.0	0.0	0.0	2.0	0.0000000000	False
working in a company	0.0	0.0	0.0	4.0	0.0000000000	False
first product to market	0.0	0.0	0.0	2.0	0.0000000000	False
hack and then fixing	0.0	0.0	0.0	2.0	0.0000000000	False
quickly and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
parts of a system	0.0	0.0	0.0	2.0	0.0000000000	False
lot of time focusing	0.0	0.0	0.0	2.0	0.0000000000	False
right ? for identifying	0.0	0.0	0.0	2.0	0.0000000000	False
big complicated learning system	0.0	0.0	0.0	2.0	0.0000000000	False
obvious at the outset	0.0	0.0	0.0	2.0	0.0000000000	False
components you should spend	0.0	0.0	0.0	2.0	0.0000000000	False
lots of time working	0.0	0.0	0.0	2.0	0.0000000000	False
nt know that preprocessing	0.0	0.0	0.0	0.0	0.0000000000	False
nt the right component	0.0	0.0	0.0	0.0	0.0000000000	False
spent three months working	0.0	0.0	0.0	2.0	0.0000000000	False
working on better background	0.0	0.0	0.0	2.0	0.0000000000	False
out what really works	0.0	0.0	0.0	2.0	0.0000000000	False
quickly and you find	0.0	0.0	0.0	2.0	0.0000000000	False
find out what parts	0.0	0.0	0.0	4.0	0.0000000000	False
hard parts to implement	0.0	0.0	0.0	2.0	0.0000000000	False
parts are hard parts	0.0	0.0	0.0	2.0	0.0000000000	False
parts that could make	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to build	0.0	0.0	0.0	4.0	0.0000000000	False
build a people recognition	0.0	0.0	0.0	2.0	0.0000000000	False
prototyped a few systems	0.0	0.0	0.0	2.0	0.0000000000	False
first system you re	0.0	0.0	0.0	0.0	0.0000000000	False
system you re designing	0.0	0.0	0.0	0.0	0.0000000000	False
concrete piece of advice	0.0	0.0	0.0	2.0	0.0000000000	False
applies to your projects	0.0	0.0	0.0	2.0	0.0000000000	False
build a working application	0.0	0.0	0.0	2.0	0.0000000000	False
system like this step	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to predict	0.0	0.0	0.0	2.0	0.0000000000	False
predict and just plot	0.0	0.0	0.0	2.0	0.0000000000	False
negative ? i thought	0.0	0.0	0.0	2.0	0.0000000000	False
wrong with this dataset	0.0	0.0	0.0	2.0	0.0000000000	False
wrong with your data	0.0	0.0	0.0	2.0	0.0000000000	False
out just by plotting	0.0	0.0	0.0	2.0	0.0000000000	False
find out be implementing	0.0	0.0	0.0	2.0	0.0000000000	False
big complicated learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms on it plotting	0.0	0.0	0.0	2.0	0.0000000000	False
plotting the data sounds	0.0	0.0	0.0	2.0	0.0000000000	False
lots of us give	0.0	0.0	0.0	2.0	0.0000000000	False
advice if your goal	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms all right	0.0	0.0	0.0	2.0	0.0000000000	False
lying around so give	0.0	0.0	0.0	2.0	0.0000000000	False
give me a learning	0.0	0.0	0.0	2.0	0.0000000000	False
complicated than logistic regression	0.0	0.0	0.0	2.0	0.0000000000	False
regression on it first	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to hack	0.0	0.0	0.0	0.0	0.0000000000	False
follow this specifically shoot	0.0	0.0	0.0	2.0	0.0000000000	False
premature optimization of code	0.0	0.0	0.0	2.0	0.0000000000	False
people will prematurely optimize	0.0	0.0	0.0	2.0	0.0000000000	False
prematurely optimize one component	0.0	0.0	0.0	2.0	0.0000000000	False
big complicated machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
complicated machine learning system	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon that highly influenced	0.0	0.0	0.0	2.0	0.0000000000	False
influenced my own thinking	0.0	0.0	0.0	2.0	0.0000000000	False
thinking it was based	0.0	0.0	0.0	2.0	0.0000000000	False
based on a paper	0.0	0.0	0.0	2.0	0.0000000000	False
paper written by christos	0.0	0.0	0.0	2.0	0.0000000000	False
written by christos papadimitriou	0.0	0.0	0.0	2.0	0.0000000000	False
developmental progress of research	0.0	0.0	0.0	2.0	0.0000000000	False
build a mail delivery	0.0	0.0	0.0	2.0	0.0000000000	False
ve drawn a circle	0.0	0.0	0.0	2.0	0.0000000000	False
nt have to deliver	0.0	0.0	0.0	0.0	0.0000000000	False
wander around indoor environments	0.0	0.0	0.0	2.0	0.0000000000	False
robot to manipulate objects	0.0	0.0	0.0	2.0	0.0000000000	False
manipulate objects and pickup	0.0	0.0	0.0	2.0	0.0000000000	False
objects and pickup envelopes	0.0	0.0	0.0	2.0	0.0000000000	False
build those two components	0.0	0.0	0.0	2.0	0.0000000000	False
two components in order	0.0	0.0	0.0	2.0	0.0000000000	False
drawing those two components	0.0	0.0	0.0	2.0	0.0000000000	False
components and little arrows	0.0	0.0	0.0	2.0	0.0000000000	False
obstacle avoidance is needed	0.0	0.0	0.0	2.0	0.0000000000	False
build your mail delivery	0.0	0.0	0.0	2.0	0.0000000000	False
robot well for obstacle	0.0	0.0	0.0	2.0	0.0000000000	False
robot that can navigate	0.0	0.0	0.0	2.0	0.0000000000	False
obstacles now we re	0.0	0.0	0.0	0.0	0.0000000000	False
computer vision to detect	0.0	0.0	0.0	2.0	0.0000000000	False
evening this is lighting	0.0	0.0	0.0	2.0	0.0000000000	False
lighting causes the color	0.0	0.0	0.0	2.0	0.0000000000	False
colors of an object	0.0	0.0	0.0	2.0	0.0000000000	False
right ? because lighting	0.0	0.0	0.0	2.0	0.0000000000	False
represented by three-dimensional vectors	0.0	0.0	0.0	2.0	0.0000000000	False
learn when two colors	0.0	0.0	0.0	2.0	0.0000000000	False
appearance of two colors	0.0	0.0	0.0	2.0	0.0000000000	False
geometry of 3d manifolds	0.0	0.0	0.0	4.0	0.0000000000	False
manifolds because that helps	0.0	0.0	0.0	2.0	0.0000000000	False
build a sound theory	0.0	0.0	0.0	2.0	0.0000000000	False
develop our 3d similarity	0.0	0.0	0.0	2.0	0.0000000000	False
understand the fundamental aspects	0.0	0.0	0.0	2.0	0.0000000000	False
aspects of this problem	0.0	0.0	0.0	2.0	0.0000000000	False
complexity of non-riemannian geometries	0.0	0.0	0.0	2.0	0.0000000000	False
eventually you re proving	0.0	0.0	0.0	0.0	0.0000000000	False
re proving convergence bounds	0.0	0.0	0.0	2.0	0.0000000000	False
convergence bounds for sampled	0.0	0.0	5.99890789953	6.0	0.0000000000	False
sampled of non-monotonic logic	0.0	0.0	0.0	2.0	0.0000000000	False
chances are that link	0.0	0.0	0.0	2.0	0.0000000000	False
link is nt real	0.0	0.0	0.0	0.0	0.0000000000	False
nt real color variance	0.0	0.0	0.0	0.0	0.0000000000	False
variance just barely helped	0.0	0.0	0.0	2.0	0.0000000000	False
barely helped object recognition	0.0	0.0	0.0	2.0	0.0000000000	False
learning and that link	0.0	0.0	0.0	2.0	0.0000000000	False
thought in your head	0.0	0.0	0.0	2.0	0.0000000000	False
written on differential geometry	0.0	0.0	0.0	2.0	0.0000000000	False
written because some guy	0.0	0.0	0.0	2.0	0.0000000000	False
ll help 3d similarity	0.0	0.0	0.0	2.0	0.0000000000	False
friend of mine told	0.0	0.0	0.0	2.0	0.0000000000	False
told me that color	0.0	0.0	0.0	2.0	0.0000000000	False
working on color invariance	0.0	0.0	0.0	2.0	0.0000000000	False
mine that his thing	0.0	0.0	0.0	2.0	0.0000000000	False
ll tell a friend	0.0	0.0	0.0	2.0	0.0000000000	False
re working on convergence	0.0	0.0	0.0	2.0	0.0000000000	False
working on convergence bound	0.0	0.0	0.0	2.0	0.0000000000	False
day of your mail	0.0	0.0	0.0	2.0	0.0000000000	False
theory of vc dimension	0.0	0.0	0.0	2.0	0.0000000000	False
impact on many applications	0.0	0.0	0.0	2.0	0.0000000000	False
dramatically advanced data machine	0.0	0.0	0.0	2.0	0.0000000000	False
advanced data machine learning	0.0	0.0	0.0	2.0	0.0000000000	False
mind are you working	0.0	0.0	0.0	2.0	0.0000000000	False
relevance to some application	0.0	0.0	0.0	2.0	0.0000000000	False
work on an application	0.0	0.0	0.0	2.0	0.0000000000	False
link from the theory	0.0	0.0	0.0	2.0	0.0000000000	False
theory i m working	0.0	0.0	0.0	0.0	0.0000000000	False
back to an application	0.0	0.0	0.0	2.0	0.0000000000	False
working on will relate	0.0	0.0	0.0	2.0	0.0000000000	False
relate to an application	0.0	0.0	0.0	2.0	0.0000000000	False
personally see a link	0.0	0.0	0.0	2.0	0.0000000000	False
back just to summarize	0.0	0.0	0.0	2.0	0.0000000000	False
coming up with diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostics for learning algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
learning algorithms and making	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms and making progress	0.0	0.0	0.0	2.0	0.0000000000	False
tests on your learning	0.0	0.0	0.0	2.0	0.0000000000	False
spent implementing those tests	0.0	0.0	0.0	2.0	0.0000000000	False
out what to work	0.0	0.0	0.0	2.0	0.0000000000	False
talked about error analyses	0.0	0.0	0.0	2.0	0.0000000000	False
analyses and ablative analyses	0.0	0.0	2.99890789953	6.0	0.0000000000	False
approaches and the risks	0.0	0.0	0.0	2.0	0.0000000000	False
minutes for your questions	0.0	0.0	0.0	2.0	0.0000000000	False
morning welcome back	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
discussion on learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theory and sort	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
start by talking	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
talking about bayesian	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
statistics and regularization	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
today s lecture	0.0	0.0	0.0	0.0	0.0000000000	False
applying machine learning	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
machine learning algorithms	0.00480916103251	0.0	6.99672369858	12.6797000058	0.4321907601	True
algorithms to problems	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
start the talk	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remember from last	0.0	0.0	0.0	0.0	0.0000000000	False
started to talk	0.000375202171673	0.0	0.0	1.58496250072	0.0000000000	False
talk about learning	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
learned about bias	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
bias and variance	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
previous lecture talking	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
talking about algorithms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithms for model	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
selection we talked	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
talked about cross-validation	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
methods we talked	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lecture were ways	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
simply the model	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
feature selection algorithms	0.00120080810257	0.0	0.0	1.58496250072	0.0000000000	False
algorithms we talked	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
eliminate a number	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
number of features	0.000441254997125	0.0	0.0	1.58496250072	0.0000000000	False
reduce the number	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
number of parameters	0.00106870245167	0.0	0.0	1.58496250072	0.0000000000	False
reduce overfitting right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
selection algorithms choose	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose a subset	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
method called regularization	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
linear regression model	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
model we learned	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose the parameters	0.00096623334805	0.0	0.0	1.58496250072	0.0000000000	False
parameters via maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta that maximized	0.00120080810257	0.0	0.0	0.0	0.0000000000	False
maximized the probability	0.00138700055999	0.0	0.0	3.16992500144	0.0000000000	False
data we observe	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
give this sort	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
sort of procedure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
common frequencies procedure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
school of statistics	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
view behind writing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
true parameter theta	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
theta that govern	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
govern housing prices	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
value of theta	0.0	0.0	7.99672369858	12.6797000058	0.3493975904	False
procedure for estimating	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
estimating the value	0.0	0.0	0.0	3.16992500144	0.0000000000	False
estimating the unknown	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
value for theta	0.0	0.0	2.99854386604	4.75488750216	0.0000000000	False
random variable right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
procedure called maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
likelihood for estimating	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
procedure the alternative	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
put a prior	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
prior on theta	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
bayesian school students	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
represent our uncertainty	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
uncertainty over theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
denote my training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
represents my beliefs	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
sort of bayesian	0.00341059733663	0.0	6.99854386604	3.16992500144	0.4113475177	False
calculate the probability	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
probability by parameters	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bayes  rule	0.0	0.0	0.0	0.0	0.0000000000	False
call it posterior	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
distribution now represents	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
estimate the price	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
theta and times	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
times the posterior	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
distribution of theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
started to write	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
longer writing semicolon	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing semicolon theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing comma theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
concrete it turns	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
computation are difficult	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
one-dimensional parameter vector	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
difficult to compute	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
high dimensional spaces	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
hard to compute	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
compute the posterior	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
posterior in theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
compute this integral	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
integral if theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
bayesian logistic regression	0.0170529866832	0.0	28.9927193302	30.1142875137	0.3036649215	False
computing a full	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
full posterior distribution	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
chi of theta	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
maximize this quantity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
computing the full	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum a posteriori	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
estimate of theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
ont max chi	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
make a prediction	0.00220627498562	0.0	4.99817983254	7.92481250361	0.3411764706	False
theta in place	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
standard maximum likelihood	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood estimation	0.00132376499137	0.0	3.99890789953	3.16992500144	0.0000000000	True
choosing the maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
re instead maximizing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
prior is theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
theta being gaussian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
mass is close	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
remember our discussion	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
discussion on feature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
eliminate a feature	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
feature from consideration	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
setting the source	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
source and value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
prior that drives	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
reminiscent of feature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
guess in pictures	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit a fourth-order	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit very high	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
estimation all right	0.0	0.0	0.0	0.0	0.0000000000	False
apply this sort	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
fit a higher-order	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
smoother and smoother	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
driving the parameters	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
closer and closer	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of hard	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
tau becomes smaller	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
smaller and smaller	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
curves you tend	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
tend to fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit your data	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
fitting a large	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
piece of intuition	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
set of ideas	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ll post online	0.0	0.0	0.0	1.58496250072	0.0000000000	False
week i guess	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
linear regression turns	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
add this prior	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
objective you end	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
end up optimizing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
add an extra	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
penalizes your parameter	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
similar to maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
kind of hard	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
strengthening the parameters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
effect of keeping	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
keeping the functions	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
functions you fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
make more sense	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
ideas a bit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
common for models	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
models like logistic	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
regression and linear	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sorts of smoothing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
effects all right	0.0	0.0	0.0	0.0	0.0000000000	False
problems like text	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm like logistic	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
prone to overfitting	0.00255794800248	0.0	3.99890789953	4.75488750216	0.0000000000	False
build a spam	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
effective text classification	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
text classification algorithm	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bayesian regularization alex	0.0	0.0	0.0	1.58496250072	0.0000000000	False
pick either tau	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
squared or lambda	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
relation is lambda	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
methods for preventing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
talking about online	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
designing the syllabus	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
place to fit	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithms we ve	0.0	0.0	0.0	0.0	0.0000000000	False
batch learning algorithms	0.000852649334158	1.0	0.0	1.58496250072	0.0000000000	False
run your learning	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
setting called online	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
process of learning	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sees all right	0.0	0.0	0.0	0.0	0.0000000000	False
make a guess	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
call your guess	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
made your prediction	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
first one right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
slightly more educated	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
guess and call	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
made your guess	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reveal the true	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
make your guess	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lot of machine	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
learning and batch	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
re making predictions	0.0	0.0	0.0	3.16992500144	0.0000000000	False
setting your website	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
start making predictions	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
likes or dislikes	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
total online error	0.00255794800248	0.0	3.99890789953	4.75488750216	0.0000000000	True
number of mistakes	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
mistakes you make	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sequence of examples	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
setting one thing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
asked to make	0.00138700055999	0.0	0.0	1.58496250072	0.0000000000	False
algorithm and run	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
run the learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
examples you ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve seen previous	0.0	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to make	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
stochastic gradient descent	0.00255794800248	0.0	2.99890789953	3.16992500144	0.0000000000	False
remember the perceptron	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
initial the parameter	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
update the parameters	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
reel a lot	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lot of times	0.00187601085836	0.0	2.99817983254	6.33985000288	0.4113475177	False
standard perceptron learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
perceptron learning rule	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
run one-step stochastic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
one-step stochastic gradient	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reason i ve	0.0	0.0	0.0	0.0	0.0000000000	False
sort of learning	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
prove fairly amazing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fairly amazing results	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error using algorithms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lecture to prove	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
infinite dimensional feature	0.00096623334805	0.0	0.0	1.58496250072	0.0000000000	False
dimensional feature vectors	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
simple vector machines	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
infinite feature dimensional	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
feature dimensional vectors	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
extremely high dimensional	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
positive and negative	0.00150080868669	0.0	3.99854386604	0.0	0.2027972028	False
examples are separated	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
infinite dimensional space	0.0016030536775	0.0	2.99890789953	4.75488750216	0.0000000000	False
separating the positive	0.00132376499137	0.0	2.99890789953	4.75488750216	0.0000000000	False
prove that perceptron	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm will converge	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
number of examples	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
converge to digital	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
class  syllabus	0.0	0.0	0.0	0.0	0.0000000000	False
nt be asked	0.0	0.0	0.0	0.0	0.0000000000	False
bounded vc dimension	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
prove learning theory	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
learning theory results	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
dimensional feature spaces	0.000483116674025	0.0	0.0	0.0	0.0000000000	False
sort of read	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
half an hour	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hour and understand	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lecture notes online	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
online learning setting	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
based on stochastic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
majority of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
switch to powerpoint	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sort of talking	0.00138700055999	0.0	0.0	1.58496250072	0.0000000000	False
talking about advice	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
advice for applying	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
applying different machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
humankind in machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine learning right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is give	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
tool it turns	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
machine learning tool	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
two different people	0.0	0.0	0.0	1.58496250072	0.0000000000	False
people to apply	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
person will sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithms to work	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
rest of today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
conceptually most difficult	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
class to understand	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
understand all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ll say today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
today is debatable	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
good machine learning	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
machine learning people	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
people will agree	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
focusing on today	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
today is advice	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
stuff to work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
deliver a product	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
building a system	0.00138700055999	0.0	0.0	3.16992500144	0.0000000000	False
machine learning system	0.00511589600495	0.0	3.99781579905	7.92481250361	0.0000000000	True
system to work	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
nt great advice	0.0	0.0	0.0	0.0	0.0000000000	False
make machine learning	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
learning algorithm work	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
deploy a working	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
diagnostics for debugging	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
debugging learning algorithms	0.00170529866832	1.0	0.0	3.16992500144	0.0000000000	False
briefly about error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
analyses and ablative	0.00255794800248	0.0	2.99890789953	1.58496250072	0.0000000000	False
out you ve	0.0	0.0	0.0	0.0	0.0000000000	False
heard about premature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
piece of code	0.00144935002207	0.0	2.99890789953	3.16992500144	0.0000000000	False
choose a subroutine	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
subroutine to optimize	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
write the subroutine	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
guilty of premature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
code to run	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
run really quickly	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt the bottleneck	0.0	0.0	0.0	0.0	0.0000000000	False
call that premature	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
undergraduate programming classes	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimization and people	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
building machine-learning systems	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
premature statistical optimization	0.00255794800248	1.0	3.99890789953	4.75488750216	0.0000000000	True
heavily optimize part	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
talk about debugging	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
build an anti-spam	0.00255794800248	0.0	1.99890789953	0.0	0.0000000000	False
ve carefully chosen	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
chosen a small	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implement bayesian logistic	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
implement gradient descent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
percent test error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
additional lambda squared	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lambda squared term	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
minus lambda theta	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lambda theta square	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
implemented your bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
logistic regression algorithm	0.00180121215386	0.0	1.99890789953	3.16992500144	0.0000000000	False
unacceptably high error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improve this algorithm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improve the algorithm.well	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
set of features	0.00121758436085	0.0	1.99890789953	3.16992500144	0.0000000000	False
suspect your features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out better features	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
finding spam emails	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
suspect that gradient	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt quite converged	0.0	0.0	0.0	0.0	0.0000000000	False
running gradient descent	0.00180121215386	0.0	3.99890789953	3.16992500144	0.0000000000	False
descent a bit	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
gradient descent longer	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
hearing from class	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
newton s method	0.0	0.0	0.0	0.0	0.0000000000	False
tune the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value for lambda	0.0	0.0	3.99890789953	4.75488750216	0.0000000000	False
svm might work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
listed eight things	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hundreds of ways	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ways to improve	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
improve a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
improve the learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm and picking	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
largely a matter	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
matter of luck	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
end up fixing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improvements all fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
people in industry	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
change a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
learning algorithm randomly	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
lots of things	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
improve your learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
run various diagnostics	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostics to figure	0.00426324667079	0.0	1.99817983254	7.92481250361	0.4321907601	False
out the problem	0.000852649334158	0.0	2.99817983254	4.75488750216	0.0000000000	False
logistic regression test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
regression test error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
suppose you suspected	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
suspected the problem	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
two few features	0.0	0.0	0.0	1.58496250072	0.0000000000	False
features that classify	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
classify as spam	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
wrote that wrong	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
forget the tables	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bias or high	0.00341059733663	0.0	5.99854386604	0.0	0.2914572864	False
nt make sense	0.0	0.0	0.0	0.0	0.0000000000	False
variance ? right	0.0	0.0	0.0	0.0	0.0000000000	False
problem is high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
remember the cartoon	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
previously for high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
high variance problems	0.00426324667079	0.0	5.99817983254	7.92481250361	0.5178571429	False
variance the training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error all right	0.0	0.0	0.0	0.0	0.0000000000	False
fitting your training	0.00120080810257	0.0	0.0	1.58496250072	0.0000000000	False
tenth order polynomial	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
points all right	0.0	0.0	0.0	0.0	0.0000000000	False
re just fitting	0.0	0.0	0.0	1.58496250072	0.0000000000	False
fitting the data	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
data is quadratic	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fitting a linear	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt even fitting	0.0	0.0	0.0	0.0	0.0000000000	False
typical learning curve	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
curve for high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
plotting the training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training set size	0.00360242430772	0.0	9.99781579905	9.50977500433	0.2914572864	False
plotting the error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
test set error	0.00255794800248	0.0	3.99890789953	3.16992500144	0.0000000000	False
sort of suggests	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
increase the training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
extrapolate the green	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error will decrease	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
red horizontal line	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
performance you re	0.0	0.0	0.0	0.0	0.0000000000	False
thing to plot	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
training error right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
larger your training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training set perfectly	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
set perfectly right	0.0	0.0	0.0	0.0	0.0000000000	False
size because smart	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
smart training sets	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
easy to fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
10,000 data points	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
harder to fit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fit that perfectly	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
perfectly all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
diagnostic for high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training versus test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
versus test error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
close that gap	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
case of high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
curve for test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error has flattened	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
extrapolate this curve	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
property of high	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
plot training errors	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hold out test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out test set	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error is high	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
training error grows	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
level of desired	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
reduce your training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
level of performance	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
training error sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
curve on test	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
tend to find	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
diagnostic i tend	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
training and test	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
re very close	0.0	0.0	0.0	1.58496250072	0.0000000000	False
list of fixes	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fix high variance	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
variance all right	0.0	0.0	0.0	0.0	0.0000000000	False
features or adding	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
adding email features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
solutions that fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fix high bias	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
working on machine	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
machine learning problems	0.00277400111999	0.0	3.99854386604	4.75488750216	0.0000000000	False
training examples helps	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
build a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
money and effort	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
collecting more training	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
high bias problem	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
spend three months	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
valley and companies	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
building various machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
spending six months	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
working on fixing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fixing a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
possibly have helped	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
invent new features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
solutions and save	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
months of fruitless	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
great so bias	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bias versus variance	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
ingenuity to figure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
wrong all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
ingenuity to construct	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
slightly more contrived	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
illustrate another common	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
applying learning algorithms	0.000534351225834	0.0	0.0	1.58496250072	0.0000000000	False
error on spam	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
percent error non-spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error non-spam mail	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
non-spam mail right	0.0	0.0	0.0	0.0	0.0000000000	False
error on non-spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
deploy logistic regression	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
overnight every day	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
regression just runs	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
problem with logistic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
optimizing your objective	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
number of iterations	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
out all right	0.0	0.0	0.0	0.0	0.0000000000	False
curves a lot	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run this ten	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
regression is converged	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
optimizing the right	0.0	0.0	0.0	0.0	0.0000000000	False
weighted accuracy function	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
higher for non-spam	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correct for spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
optimizes a quantity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of maximum	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
maximum likelihood thing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
right optimization function	0.0	0.0	0.0	1.58496250072	0.0000000000	False
change the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
lambda to change	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
change this parameter	0.0	0.0	0.0	1.58496250072	0.0000000000	False
switching to support	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
support vector machine	0.00121758436085	0.0	5.99890789953	3.16992500144	0.0000000000	True
vector machine optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine optimization objective	0.0	0.0	0.0	0.0	0.0000000000	False
optimization algorithm converging	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
objective i chose	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reiterate the story	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
svm outperforms bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
outperforms bayesian logistic	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
deploy bayesian logistic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theta subscript svm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ll let theta	0.0	0.0	0.0	0.0	0.0000000000	False
theta subscript blr	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
learned by bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
objective you care	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
weighted accuracy criteria	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
vector machine outperforms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine outperforms bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
accuracy for bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimize an optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
denoted j theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostic i choose	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
svm is bigger-than	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
bigger-than or less-than	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
accuracy of support	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
accuracy of bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out whether bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimizing the wrong	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
wrong objective function	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
two equations copied	0.0	0.0	0.0	1.58496250072	0.0000000000	False
svm is greater	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
definition of bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means that theta	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
theta the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
output that bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
regression actually fails	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fails to maximize	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
back to machine	0.00255794800248	0.0	5.99890789953	0.0	0.0000000000	False
machine actually returned	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
returned the value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt actually maximize	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm the optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
means that bayesian	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
regression actually attains	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
attains the higher	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine the support	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
weighted accuracy measure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
weighted accuracy objective	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means that maximizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt really correspond	0.0	0.0	0.0	0.0	0.0000000000	False
maximizing your weighted	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
wrong optimization objective	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt a good	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.000302084064114	0.0	0.0	1.58496250072	0.0000000000	False
sense ? cool	0.0	0.0	0.0	0.0	0.0000000000	False
iterations that fixes	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fixes the optimization	0.00511589600495	0.0	11.9978157991	6.33985000288	0.1912087912	False
lambda times norm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
norm of data	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
objective and changing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
harder and harder	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
harder to fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
iterations of gradient	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
crazy optimization algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fix the problem	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
sorts of diagnostics	0.00426324667079	0.0	2.99817983254	6.33985000288	0.5178571429	False
fixing your optimization	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm or fixing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
work on flying	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
draws on reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
diagnostic we re	0.0	0.0	0.0	0.0	0.0000000000	False
talked about reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
back and redo	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
redo this exact	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fly autonomous helicopters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to design	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
design the controller	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
controller for helicopter	0.0	0.0	0.0	1.58496250072	0.0000000000	False
build a simulator	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fly a helicopter	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
helicopter in simulation	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
choose a cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
call it cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
expected squared error	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
helicopter s position	0.0	0.0	0.0	0.0	0.0000000000	False
run a reinforcement-learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
weeks you run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run reinforcement learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
reinforcement learning algorithm	0.00554800223997	0.0	7.99708773207	11.094737505	0.4113475177	False
minimize this cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
minimize the squared	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
controlling your helicopter	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm will output	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
output some parameters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
denoting theta subscript	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fly your helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
suppose you run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run this learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out a set	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
set of controller	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
improve the simulator	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt that accurate	0.0	0.0	0.0	0.0	0.0000000000	False
capture the aerodynamic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
effects more accurately	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
capture the airflow	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
helicopter more accurately	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
modify the cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt just optimizing	0.0	0.0	0.0	0.0	0.0000000000	False
optimizing square area	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
wanted to experiment	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm does poorly	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
poorly well suppose	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things hold true	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
hold true suppose	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
suppose the contrary	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
simulator is accurate	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
controls the helicopter	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
tend to run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run a learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm in simulation	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm can crash	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
crash a helicopter	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
assume our reinforcement-learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm correctly controls	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
minimize the cost	0.00341059733663	0.0	3.99854386604	3.16992500144	0.2914572864	False
suppose that minimizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correspond to accurate	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correct autonomous flight	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things held true	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
real helicopter right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
learning control parameters	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of means	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
assumptions is wrong	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
learning algorithm flies	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
predicts the helicopter	0.0	0.0	0.0	0.0	0.0000000000	False
helicopter s controller	0.0	0.0	0.0	0.0	0.0000000000	False
spend out efforts	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out efforts improving	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
improving the accuracy	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
write theta subscript	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theta subscript human	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human control policy	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
policy all right	0.0	0.0	0.0	0.0	0.0000000000	False
fly the helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means squared error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
pilot s flight	0.0	0.0	0.0	0.0	0.0000000000	False
terms of optimizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
optimizing this objective	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human does worse	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
good human pilot	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human pilot attains	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
attains a worse	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
human actually attains	0.00255794800248	0.0	2.99890789953	4.75488750216	0.0000000000	False
attains a lower	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
managing to minimize	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
attains a larger	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
larger mean squared	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
function but flies	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
means the problem	0.0	0.0	0.0	1.58496250072	0.0000000000	False
function it means	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
means oh excuse	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
means that minimizing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
function my learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
correspond to good	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
good autonomous flight	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
reinforcement learning problems	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
work often reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithms just work	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
changing the cost	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
changing the reinforcement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
spend two years	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out that modeling	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
modeling helicopter aerodynamics	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
area of research	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing entire phd	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
entire phd theses	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out and spend	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
spend six years	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
years and write	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
write a phd	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
thesis and build	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fixing the wrong	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
described are sort	0.0	0.0	0.0	0.0	0.0000000000	False
specific learning problem	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
algorithm is working	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
idea to run	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
couple of reasons	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
understand your application	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
graduate from stanford	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
amazingly high-paying job	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
job to apply	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
apply machine-learning algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
significant economic interest	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
specific important machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
important machine learning	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
machine learning application	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
work your problem	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of right	0.0	0.0	0.0	0.0	0.0000000000	False
companies with important	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
years on end	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
problem using learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
personal intuitive understanding	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort i talked	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
problems it turns	0.000534351225834	0.0	0.0	1.58496250072	0.0000000000	False
silicon valley companies	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
companies that outsource	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
outsource their machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
re a company	0.0	0.0	0.0	1.58496250072	0.0000000000	False
company in silicon	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
hire a firm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
york to run	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
maintain that expertise	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
knowledge is outsourced	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
reason for running	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing research papers	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostics and error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
justify your research	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
writing a research	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
algorithm that works	0.00138700055999	0.0	0.0	3.16992500144	0.0000000000	False
works i built	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
built this helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
justification that shows	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
thing that fixed	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
fixed this problem,and	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
made it work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
discussion on error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine learning practice	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sources of errors	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
call error analyses	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
times the thing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
difficult a helicopter	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
building an accurate	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
two specific examples	0.0	0.0	0.0	1.58496250072	0.0000000000	False
actual machine learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
people from images	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
input in camera	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
preprocess the image	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
image and remove	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove the background	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
run a face	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
face detection algorithm	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm to detect	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
people s faces	0.0	0.0	0.0	0.0	0.0000000000	False
recognize the identity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
detect the mouth	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
regression or soft	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
soft match regression	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
long complicated pipeline	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
complicated pipeline combining	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
combining many machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
machine learning components	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
typical error analysis	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
error analysis procedure	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
ll repeatedly plug	0.0	0.0	0.0	1.58496250072	0.0000000000	False
bottom left bottom	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
percent of error	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
ll actually code	0.0	0.0	0.0	1.58496250072	0.0000000000	False
implement my correct	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
correct background removal	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
give my algorithm	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
correct background versus	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
background versus foreground	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
color that blue	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
blue to denote	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
giving that ground-truth	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
assume our accuracy	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
algorithm the ground-truth	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
face detection output	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithm s accuracy	0.0	0.0	0.0	0.0	0.0000000000	False
nose segmentation algorithm	0.0	0.0	0.0	1.58496250072	0.0000000000	False
figure that out	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
end up giving	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
correct output label	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
label and end	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
giving the ground-truth	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
boost your final	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
added the face	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
face detection ground-truth	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
percent accuracy right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
boost my accuracy	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostic also tells	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
improve the system	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
improve your background	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
potential for gains	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose to spend	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
months on right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choosing the right	0.0	0.0	0.0	0.0	0.0000000000	False
piece is critical	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
type of analyses	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
explain the difference	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
performance and perfect	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sort of ablative	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
suppose you ve	0.0	0.0	0.0	0.0	0.0000000000	False
good anti-spam classifier	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
classifier for adding	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
lots of clever	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
regression algorithm right	0.0	0.0	0.0	0.0	0.0000000000	False
features for spam	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sender host features	0.00341059733663	0.0	3.99854386604	6.33985000288	0.0000000000	False
email header features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
email text parser	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
text parser features	0.00255794800248	0.0	2.99890789953	3.16992500144	0.0000000000	False
javascript parser features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
features for embedded	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
preview the system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
components actually contribute	0.0	0.0	0.0	1.58496250072	0.0000000000	False
paper and claim	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
piece that made	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
made the big	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
document that claim	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
claim and justify	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
simple logistic regression	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out what accounts	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
ll instead remove	0.0	0.0	0.0	0.0	0.0000000000	False
rates so start	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove spelling correction	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove the sender	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
biggest drop occurred	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
remove the text	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
make a credible	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
made the biggest	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
features to speed	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
speed up computational	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
candidate for elimination	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
drop those features	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
address the question	0.000600404051286	0.0	0.0	1.58496250072	0.0000000000	False
natural of ordering	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fairly natural ordering	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things or remove	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
choose one ordering	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
analyses as sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
sort of formulas	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
free to invent	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
started on learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
problem the first	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
design your system	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
spend a long	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
long time designing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
collecting the right	0.0	0.0	0.0	0.0	0.0000000000	False
right data set	0.0	0.0	0.0	1.58496250072	0.0000000000	False
designing the right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
right algorithmic structure	0.0	0.0	0.0	1.58496250072	0.0000000000	False
hope it works	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
works all right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
sort of approach	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
elegant learning algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
contribute to basic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
research in machine	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
invent new machine	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
process of slowing	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
problem and invent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
invent new solutions	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
solutions second sort	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
input something quick	0.000852649334158	0.0	0.0	3.16992500144	0.0000000000	False
quick and dirty	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
run error analyses	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
analyses and diagnostics	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
fix those errors	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
errors the benefit	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
type of approach	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
end up working	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
product that wins	0.0	0.0	0.0	1.58496250072	0.0000000000	False
product to market	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
market that wins	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
approach of building	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
building a quick-and-dirty	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
system that works	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
clear what parts	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
system are easier	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
big complicated learning	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
complicated learning system	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
big complicated pipeline	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
working on right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
nt the right	0.0	0.0	0.0	0.0	0.0000000000	False
easily have spent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
spent three months	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
works was inputting	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
out what parts	0.00170529866832	0.0	0.0	0.0	0.0000000000	False
parts and find	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
parts to implement	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
make a difference	0.000534351225834	0.0	0.0	1.58496250072	0.0000000000	False
difference in performance	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
performance in fact	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
build a people	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
people recognition system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
converged a system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
system you re	0.0	0.0	0.0	0.0	0.0000000000	False
piece of advice	0.00170529866832	0.0	0.0	1.58496250072	0.0000000000	False
build a working	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
design a system	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
plot your data	0.00341059733663	0.0	4.99854386604	6.33985000288	0.0000000000	False
data you re	0.0	0.0	0.0	0.0	0.0000000000	False
numbers are negative	0.0	0.0	0.0	1.58496250072	0.0000000000	False
out be implementing	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implementing these big	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
complicated learning algorithms	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
plotting the data	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
sounds so simple	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
advice that lots	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
algorithms all right	0.0	0.0	0.0	0.0	0.0000000000	False
complicated than logistic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
simple and figure	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
focus your efforts	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
add another hack	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
hack to fix	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
machine learning research	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
follow this specifically	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
two more slides	0.0	0.0	0.0	3.16992500144	0.0000000000	False
optimization of code	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
optimize one component	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
big complicated machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
complicated machine learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sort of cartoon	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
written by christos	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
progress of research	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
build a mail	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
mail delivery robot	0.00426324667079	0.0	9.99817983254	7.92481250361	0.0000000000	False
drawn a circle	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
free up people	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
robot to wander	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
wander around indoor	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
robot to manipulate	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
objects and pickup	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
components in order	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
arrows to denote	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
avoidance is needed	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
build your mail	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
obstacle for avoidance	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
avoid the obstacles	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
vision to detect	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
detect the objects	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
morning or noontime	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
noontime or evening	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
color of things	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
things to change	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
object detection system	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
represented by three-dimensional	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
out and study	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
study differential geometry	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
build a sound	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
similarity learning algorithms	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
understand the fundamental	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
study the complexity	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
complexity of non-riemannian	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
eventually you re	0.0	0.0	0.0	0.0	0.0000000000	False
re proving convergence	0.0	0.0	0.0	0.0	0.0000000000	False
proving convergence bounds	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
bounds for sampled	0.00255794800248	0.0	5.99890789953	0.0	0.0000000000	False
sampled of non-monotonic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
nt real color	0.0	0.0	0.0	0.0	0.0000000000	False
real color variance	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
barely helped object	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
helped object recognition	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
circles can represent	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
represent a person	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
written on differential	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
guy once told	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
friend of mine	0.00138700055999	0.0	0.0	1.58496250072	0.0000000000	False
working on color	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
working on convergence	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
sampled non-monotonic logic	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
light of day	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
criticizing the role	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
role of theory	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
dramatically advanced data	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
advanced data machine	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
data machine learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
theory of np-hardness	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
highly theoretical things	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
re only hoping	0.0	0.0	0.0	1.58496250072	0.0000000000	False
tend to work	0.000693500279996	0.0	0.0	1.58496250072	0.0000000000	False
tend to trust	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
choose to work	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
work on theory	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
nt necessarily trust	0.0	0.0	0.0	0.0	0.0000000000	False
summarize one lesson	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
diagnostics for learning	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implementing learning algorithms	0.00170529866832	0.0	0.0	3.16992500144	0.0000000000	False
algorithms and making	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
implementing those tests	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
talked about error	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
risks of premature	0.000852649334158	0.0	0.0	1.58496250072	0.0000000000	False
good morning	0.000201389376076	0.0	0.0	0.0	0.0000000000	False
learning theory	0.00096623334805	1.0	1.99890789953	2.0	0.0000000000	False
bayesian statistics	0.00113686577888	1.0	0.0	0.0	0.0000000000	True
online learning	0.00284216444719	1.0	6.99817983254	4.0	0.0000000000	True
applying machine	0.000462333519998	0.0	0.0	1.0	0.0000000000	False
machine learning	0.00838780337473	0.0	17.9887149618	30.0	0.3236205828	False
learning algorithms	0.00996774331801	0.0	33.9770658901	62.0	0.3965195774	False
last week	0.0	0.0	0.0	0.0	0.0000000000	False
previous lecture	0.00100053912446	0.0	2.99854386604	3.0	0.0000000000	False
lecture talking	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
model selection	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
feature selection	0.00200134683762	0.0	6.99817983254	4.0	0.0000000000	False
cross-validation right	0.0	0.0	0.0	0.0	0.0000000000	False
selection algorithms	0.000800538735049	0.0	0.0	1.0	0.0000000000	False
reduce overfitting	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
overfitting right	0.0	0.0	5.99854386604	3.0	0.0000000000	False
algorithms choose	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
prevent overfitting	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
linear regression	0.00108229720964	0.0	5.99854386604	3.0	0.0000000000	False
regression model	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
first model	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
maximum likelihood	0.00324689162893	1.0	13.9956315981	11.0	0.3940704138	False
likelihood right	0.0	0.0	0.0	0.0	0.0000000000	False
parameters theta	0.00294169998083	0.0	6.99745176556	6.0	0.2782727896	False
common frequencies	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
frequencies procedure	0.00113686577888	1.0	0.0	1.0	0.0000000000	False
philosophical view	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
true parameter	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
govern housing	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
housing prices	0.000644155565367	0.0	0.0	1.0	0.0000000000	False
unknown value	0.0	0.0	0.0	0.0	0.0000000000	False
random variable	0.000696317536829	0.0	2.99890789953	2.0	0.0000000000	False
variable right	0.0	0.0	0.0	0.0	0.0000000000	False
true value	0.0	0.0	0.0	1.0	0.0000000000	False
frequency school	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
bayesian school	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
school students	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
gaussian distribution	0.000294169998083	0.0	0.0	1.0	0.0000000000	False
curvalence matrix	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
tau squared	0.00227373155776	0.0	6.99854386604	2.0	0.0000000000	False
training set	0.0042291768976	0.0	19.9923552967	20.0	0.2697674419	False
theta represents	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
bayesian procedure	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
posterior probability	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
posterior distribution	0.00277400111999	0.0	5.99781579905	5.0	0.0000000000	False
expected value	0.0	0.0	0.0	1.0	0.0000000000	False
bayesian formulation	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
writing semicolon	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
semicolon theta	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
treating theta	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
one-dimensional vector	0.000462333519998	0.0	0.0	1.0	0.0000000000	False
one-dimensional parameter	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
parameter vector	0.000800538735049	0.0	0.0	1.0	0.0000000000	False
compute integrals	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
high dimensional	0.00120080810257	0.0	1.99890789953	2.0	0.0000000000	False
dimensional spaces	0.00128831113073	0.0	2.99854386604	2.0	0.0000000000	False
closed form	0.000356234150556	0.0	0.0	1.0	0.0000000000	False
bayesian logistic	0.0113686577888	0.0	28.9927193302	17.0	0.2018093250	False
logistic regression	0.00975525646349	0.0	35.9858026938	37.0	0.3567662566	False
full posterior	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
right-hand side	0.000924667039995	0.0	0.0	2.0	0.0000000000	False
map estimate	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
posteriori estimate	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
probable value	0.0	0.0	0.0	0.0	0.0000000000	False
ont max	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
max chi	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
usual hypothesis	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
map value	0.0	0.0	0.0	0.0	0.0000000000	False
standard maximum	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
likelihood estimation	0.000882509994249	0.0	3.99890789953	2.0	0.0000000000	False
likelihood value	0.0	0.0	0.0	0.0	0.0000000000	False
prior right	0.0	0.0	0.0	1.0	0.0000000000	False
prior distribution	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
set theta	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
eliminating feature	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
parameter values	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
data points	0.00128831113073	0.0	3.99854386604	3.0	0.0000000000	False
fourth-order polynomial	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
high polynomial	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
small dataset	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
large oscillations	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
bayesian regularization	0.00170529866832	0.0	5.99890789953	1.0	0.0000000000	True
higher-order polynomial	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
smoother fit	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
decrease tau	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
large number	0.000164474932969	0.0	0.0	0.0	0.0000000000	False
last piece	0.0	0.0	0.0	0.0	0.0000000000	False
problem set	0.000750404343345	0.0	3.99890789953	3.0	0.0000000000	False
post online	0.000644155565367	0.0	0.0	1.0	0.0000000000	False
regression turns	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
prior term	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
authorization objective	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
optimizing turns	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
extra term	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
parameters small	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
check questions	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
smoothing behavior	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
mass close	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
gaussian prior	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
smoothing effects	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
right cool	0.0	0.0	0.0	1.0	0.0000000000	False
text classification	0.00120080810257	0.0	5.99890789953	2.0	0.0000000000	False
spam classifier	0.000400269367524	0.0	0.0	1.0	0.0000000000	False
training examples	0.00215978413242	0.0	6.99563159811	11.0	0.3211517165	False
effective text	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
classification algorithm	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
regularization alex	0.0	0.0	0.0	0.0	0.0000000000	False
lambda equals	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
minutes talking	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
good place	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
bit disjointed	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
batch learning	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
test set	0.00454746311551	0.0	5.99708773207	7.0	0.3308883456	False
learning setting	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
make predictions	0.00178117075278	0.0	7.99817983254	4.0	0.2914572864	False
problem sees	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
classification problem	0.000294169998083	0.0	0.0	1.0	0.0000000000	False
guess right	0.0	0.0	0.0	0.0	0.0000000000	False
true label	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
guess randomly	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
educated guess	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
learning proceeds	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
model settings	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
users coming	0.000568432889439	0.0	0.0	2.0	0.0000000000	False
first user	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
user likes	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
total online	0.00170529866832	0.0	3.99890789953	0.0	0.0000000000	False
online error	0.00170529866832	0.0	3.99890789953	1.0	0.0000000000	False
total number	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
simple thing	0.000400269367524	0.0	0.0	1.0	0.0000000000	False
stochastic gradient	0.00170529866832	0.0	2.99890789953	2.0	0.0000000000	False
gradient descent	0.00320610735501	0.0	10.9967236986	8.0	0.3493975904	False
perceptron algorithms	0.00184933407999	0.0	3.99854386604	3.0	0.0000000000	False
standard perceptron	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
perceptron learning	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
learning rule	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
learning theorysection	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
amazing results	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
main lecture	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
infinite dimensional	0.00147084999042	0.0	4.99817983254	4.0	0.2845927380	False
dimensional feature	0.000644155565367	0.0	0.0	1.0	0.0000000000	False
feature vectors	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
simple vector	0.00113686577888	0.0	0.0	0.0	0.0000000000	False
vector machines	0.00135287151205	0.0	6.99817983254	4.0	0.0000000000	False
infinite feature	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
dimensional vectors	0.000322077782683	0.0	1.99890789953	2.0	0.0000000000	False
kernel representations	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
negative examples	0.00117667999233	0.0	3.99854386604	2.0	0.0000000000	False
finite number	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
entire lecture	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
lecture notes	0.000541148604821	0.0	0.0	1.0	0.0000000000	False
optional reading	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
prove things	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
theory results	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
feature spaces	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
perceptron bound	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
simplest instance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
notes online	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
re interested	0.0	0.0	1.99890789953	3.0	0.0000000000	False
theoretical results	0.000400269367524	0.0	0.0	1.0	0.0000000000	False
algorithms based	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
last thing	0.0	0.0	0.0	2.0	0.0000000000	False
powerpoint slides	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
lecture sort	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
good understanding	0.000462333519998	0.0	0.0	1.0	0.0000000000	False
powerful tools	0.000400269367524	0.0	0.0	1.0	0.0000000000	False
learning right	0.0	0.0	0.0	0.0	0.0000000000	False
learning tool	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
amazing job	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
difficult material	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
good machine	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
learning people	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
good advice	0.000462333519998	0.0	0.0	1.0	0.0000000000	False
learning system	0.00511589600495	0.0	8.9959956316	10.0	0.5225225225	False
great advice	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
make machine	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
algorithm work	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
working system	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
key areas	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
error analyses	0.00397903022607	1.0	11.9959956316	10.0	0.5178571429	False
ablative analysis	0.00284216444719	0.0	3.99817983254	4.0	0.0000000000	True
machine-learning problem	0.000322077782683	0.0	0.0	1.0	0.0000000000	False
premature optimization	0.00341059733663	0.0	4.99781579905	5.0	0.0000000000	False
writing software	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
writing piece	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
optimize heavily	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
run faster	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
undergraduate programming	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
programming classes	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
warn people	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
similar thing	0.000356234150556	0.0	0.0	1.0	0.0000000000	False
machine-learning systems	0.00113686577888	0.0	0.0	0.0	0.0000000000	False
statistical optimization	0.00170529866832	0.0	3.99890789953	0.0	0.0000000000	True
optimize part	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
important piece	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
first talk	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
debugging learning	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
anti-spam system	0.00227373155776	0.0	3.99854386604	1.0	0.0000000000	False
small set	0.000712468301113	0.0	0.0	1.0	0.0000000000	False
implement gradient	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
percent test	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
test error	0.00511589600495	0.0	7.99672369858	8.0	0.5272727273	False
unacceptably high	0.00227373155776	0.0	5.99854386604	3.0	0.0000000000	False
additional lambda	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
lambda squared	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
squared term	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
minus lambda	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
lambda theta	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
theta square	0.000924667039995	0.0	0.0	1.0	0.0000000000	False
regression algorithm	0.00120080810257	0.0	1.99890789953	2.0	0.0000000000	False
high error	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
training data	0.00189402011687	0.0	5.99745176556	6.0	0.3654365437	False
smaller set	0.000924667039995	0.0	0.0	0.0	0.0000000000	False
email headers	0.00170529866832	0.0	3.99890789953	2.0	0.0000000000	False
finding spam	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
spam emails	0.000800538735049	0.0	0.0	1.0	0.0000000000	False
running gradient	0.00120080810257	0.0	3.99890789953	1.0	0.0000000000	False
bit longer	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
descent longer	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
method converges	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
right thing	0.0	0.0	0.0	2.0	0.0000000000	False
picking ways	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
fixing problems	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
algorithm randomly	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
motivating story	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
regression test	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
high bias	0.00480323241029	0.0	11.9956315981	11.0	0.3096085409	False
forget forget	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
tables suppose	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
high variance	0.00600404051286	0.0	17.9941754641	15.0	0.3308883456	False
make sense	0.000144035411674	0.0	0.0	2.0	0.0000000000	False
features classified	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
simple diagnostic	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
variance problems	0.00341059733663	0.0	5.99781579905	1.0	0.4321907601	False
training error	0.00520350177782	0.0	11.9952675646	12.0	0.1777323800	False
tenth order	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
order polynomial	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
data set	0.000431956826484	0.0	0.0	1.0	0.0000000000	False
linear function	0.000270574302411	0.0	0.0	0.0	0.0000000000	False
typical learning	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
learning curve	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
horizontal axis	0.000294169998083	0.0	0.0	1.0	0.0000000000	False
set size	0.00240161620515	0.0	9.99781579905	3.0	0.2914572864	False
vertical axis	0.000322077782683	0.0	0.0	1.0	0.0000000000	False
set error	0.00170529866832	0.0	3.99890789953	2.0	0.0000000000	False
green curve	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
red horizontal	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
horizontal line	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
desired performance	0.00170529866832	0.0	1.99890789953	2.0	0.0000000000	False
error right	0.0	0.0	0.0	0.0	0.0000000000	False
set perfectly	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
perfectly right	0.0	0.0	0.0	0.0	0.0000000000	False
smart training	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
versus test	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
large gap	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
out test	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
error grows	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
desired level	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
performance right	0.0	0.0	0.0	1.0	0.0000000000	False
error sort	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
blue line	0.000322077782683	0.0	0.0	1.0	0.0000000000	False
bias problem	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
first fix	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
larger set	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
adding email	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
email features	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
re hypothesis	0.0	0.0	0.0	1.0	0.0000000000	False
people working	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
learning problems	0.00208895261049	0.0	5.99635966509	9.0	0.4113475177	False
examples helps	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
nt work	0.0	0.0	0.0	0.0	0.0000000000	False
spend lots	0.00170529866832	0.0	1.99890789953	3.0	0.0000000000	False
effort collecting	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
first place	0.000294169998083	0.0	0.0	2.0	0.0000000000	False
months collecting	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
silicon valley	0.00184933407999	0.0	5.99854386604	3.0	0.2914572864	False
people spending	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
months working	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
fruitless effort	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
bias versus	0.000924667039995	0.0	0.0	1.0	0.0000000000	False
versus variance	0.00113686577888	0.0	0.0	0.0	0.0000000000	False
common diagnostic	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
machine-learning algorithm	0.00138700055999	0.0	2.99890789953	2.0	0.0000000000	False
difference training	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
common question	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
common issues	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
applying learning	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
percent error	0.00227373155776	0.0	3.99854386604	3.0	0.3411764706	False
spam mail	0.00138700055999	0.0	6.99817983254	4.0	0.0000000000	False
error non-spam	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
non-spam mail	0.000924667039995	0.0	0.0	1.0	0.0000000000	False
mail right	0.0	0.0	0.0	0.0	0.0000000000	False
good email	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
linear kernel	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
acceptable performance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
computational efficiency	0.000462333519998	0.0	0.0	1.0	0.0000000000	False
retrain overnight	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
algorithm converging	0.00170529866832	0.0	6.99854386604	3.0	0.0000000000	False
run iterations	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
optimization objective	0.00560377114534	0.0	26.9945394976	14.0	0.3213296399	True
flattened out	0.00138700055999	0.0	3.99890789953	2.0	0.0000000000	False
ten times	0.000712468301113	0.0	3.99890789953	1.0	0.0000000000	False
right function	0.0	0.0	0.0	0.0	0.0000000000	False
weighted accuracy	0.00568432889439	0.0	19.9963596651	9.0	0.2600896861	True
accuracy function	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
weights times	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
predictions correct	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
likelihood thing	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
penalty thing	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
right optimization	0.0	0.0	0.0	0.0	0.0000000000	False
optimization function	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
support vector	0.000811722907232	0.0	5.99890789953	2.0	0.0000000000	False
machine optimization	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
optimization algorithm	0.00369866815998	0.0	15.9970877321	7.0	0.5178571429	False
svm outperforms	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
theta subscript	0.00200134683762	0.0	3.99817983254	4.0	0.3684879288	False
subscript svm	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
parameters learned	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
subscript blr	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
accuracy criteria	0.00113686577888	0.0	0.0	0.0	0.0000000000	False
machine outperforms	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
support-vector-machine parameters	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
wrong objective	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
objective function	0.00096623334805	0.0	3.99890789953	2.0	0.0000000000	False
equality hold	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
equations copied	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
theta svm	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
theta blr	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
theta output	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
nt converged	0.0	0.0	0.0	0.0	0.0000000000	False
higher value	0.0	0.0	0.0	0.0	0.0000000000	False
optimization problem	0.000294169998083	0.0	0.0	1.0	0.0000000000	False
accuracy measure	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
accuracy objective	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
wrong optimization	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
good objective	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
made sense	0.0	0.0	0.0	0.0	0.0000000000	False
method fixes	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
lambda times	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
times norm	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
data squared	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
common pattern	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
crazy optimization	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
flying helicopters	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
reinforcement learning	0.00508566871997	1.0	8.9959956316	10.0	0.2504907735	False
autonomous helicopters	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
first step	0.000215978413242	0.0	0.0	1.0	0.0000000000	False
joystick simulator	0.0	0.0	0.0	1.0	0.0000000000	False
cost function	0.00554800223997	0.0	12.9952675646	12.0	0.1989026063	False
squared error	0.00323633463998	0.0	6.99745176556	6.0	0.3452380952	False
reinforcement-learning algorithm	0.00341059733663	0.0	5.99781579905	5.0	0.4321907601	False
denoting theta	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
controller parameters	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
worse performance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
human pilot	0.00284216444719	0.0	5.99781579905	6.0	0.2914572864	False
natural things	0.000462333519998	0.0	0.0	1.0	0.0000000000	False
aerodynamic effects	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
turbulence affects	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
square area	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
controller output	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
things hold	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
hold true	0.000541148604821	0.0	0.0	1.0	0.0000000000	False
true suppose	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
guess suppose	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
helicopter simulator	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
accurate model	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
correct autonomous	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
autonomous flight	0.000924667039995	0.0	0.0	1.0	0.0000000000	False
things held	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
real helicopter	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
helicopter right	0.0	0.0	0.0	0.0	0.0000000000	False
learning control	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
simulation right	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm flies	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
simulator predicts	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
real life	0.000712468301113	0.0	0.0	2.0	0.0000000000	False
out efforts	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
efforts improving	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
write theta	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
subscript human	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
human control	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
control policy	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
means squared	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
good human	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
pilot attains	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
worse value	0.0	0.0	0.0	0.0	0.0000000000	False
lower value	0.0	0.0	0.0	0.0	0.0000000000	False
larger value	0.0	0.0	0.0	1.0	0.0000000000	False
theta excuse	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
helicopter position	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
human flies	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
job minimizing	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
good autonomous	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
modeling helicopter	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
helicopter aerodynamics	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
active area	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
entire phd	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
phd theses	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
phd thesis	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
wrong problem	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
specific learning	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
good idea	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
run diagnostics	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
application problem	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
high-paying job	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
significant economic	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
economic interest	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
specific important	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
important machine	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
learning application	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
valuable things	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
intuitive understanding	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
problem sort	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
important problem	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
personal intuitive	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
valley companies	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
terrible idea	0.000924667039995	0.0	0.0	2.0	0.0000000000	False
outsource agency	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
writing research	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
research papers	0.00138700055999	0.0	3.99890789953	2.0	0.0000000000	False
convey insight	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
research claims	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
specific component	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
error analysis	0.00227373155776	0.0	5.99854386604	3.0	0.0000000000	True
learning practice	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
call error	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
simulator building	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
accurate simulator	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
specific examples	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
actual machine	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
recognize people	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
camera image	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
long pipeline	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
first thing	0.000153914260769	0.0	0.0	1.0	0.0000000000	False
face detection	0.00284216444719	0.0	7.99817983254	4.0	0.0000000000	False
detection algorithm	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
detect people	0.0	0.0	0.0	1.0	0.0000000000	False
faces right	0.0	0.0	0.0	1.0	0.0000000000	False
soft match	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
match regression	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
long complicated	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
complicated pipeline	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
pipeline combining	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
learning components	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
typical error	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
analysis procedure	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
bottom left	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
left bottom	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
correct background	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
background removal	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
background versus	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
versus foreground	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
ground-truth data	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
accuracy increases	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
detection output	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
ground-truth label	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
nose segmentation	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
segmentation algorithm	0.0	0.0	0.0	0.0	0.0000000000	False
correct output	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
output label	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
percent accuracy	0.00284216444719	0.0	5.99817983254	4.0	0.0000000000	False
final performance	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
performance jumped	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
accuracy right	0.0	0.0	0.0	0.0	0.0000000000	False
accuracy improved	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
background subtraction	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
larger potential	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
right piece	0.0	0.0	0.0	0.0	0.0000000000	False
diagnostic tells	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
current performance	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
perfect performance	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
bad performance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
good anti-spam	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
anti-spam classifier	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
adding lots	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
clever features	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
algorithm right	0.0	0.0	0.0	1.0	0.0000000000	False
added features	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
spam correction	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
sender host	0.00227373155776	0.0	3.99854386604	1.0	0.2914572864	False
host features	0.00227373155776	0.0	3.99854386604	2.0	0.0000000000	False
header features	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
email text	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
text parser	0.00170529866832	0.0	2.99890789953	2.0	0.0000000000	False
parser features	0.00227373155776	0.0	3.99854386604	3.0	0.0000000000	False
javascript parser	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
embedded images	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
big difference	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
simple logistic	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
clever improvements	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
percent performance	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
adding components	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
remove components	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
spelling correction	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
performance drops	0.00170529866832	0.0	2.99890789953	3.0	0.0000000000	False
biggest drop	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
drop occurred	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
credible case	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
biggest difference	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
good candidate	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
remove things	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
similar result	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
natural ordering	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
add things	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
general advice	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
cartoon description	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
right features	0.0	0.0	0.0	1.0	0.0000000000	False
right data	0.0	0.0	0.0	0.0	0.0000000000	False
algorithmic structure	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
scalable algorithms	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
elegant learning	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
basic research	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
run error	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
application working	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
first product	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
deployed quickly	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
identifying people	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
big complicated	0.00227373155776	0.0	5.99854386604	3.0	0.4113475177	False
complicated learning	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
right component	0.0	0.0	0.0	1.0	0.0000000000	False
ultimately matter	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
hard parts	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
people recognition	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
recognition system	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
initial system	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
first system	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
concrete piece	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
working application	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
data sounds	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
bad advice	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
learning research	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
specifically shoot	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
complicated machine	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
paper written	0.000924667039995	0.0	0.0	1.0	0.0000000000	False
christos papadimitriou	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
developmental progress	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
mail delivery	0.00284216444719	0.0	9.99817983254	3.0	0.2318145484	False
delivery robot	0.00284216444719	0.0	9.99817983254	0.0	0.0000000000	False
deliver mail	0.00113686577888	0.0	0.0	2.0	0.0000000000	False
indoor environments	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
manipulate objects	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
pickup envelopes	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
obstacle avoidance	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
detect objects	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
computer vision	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
object detection	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
detection system	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
specific colors	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
object right	0.0	0.0	0.0	1.0	0.0000000000	False
rgb values	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
three-dimensional vectors	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
visual appearance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
lighting change	0.000568432889439	0.0	0.0	2.0	0.0000000000	False
differential geometry	0.00170529866832	0.0	5.99890789953	2.0	0.0000000000	False
sound theory	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
similarity learning	0.00170529866832	0.0	5.99890789953	2.0	0.0000000000	False
fundamental aspects	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
non-riemannian geometries	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
proving convergence	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
convergence bounds	0.00170529866832	0.0	5.99890789953	2.0	0.0000000000	False
non-monotonic logic	0.00170529866832	0.0	5.99890789953	2.0	0.0000000000	False
nt real	0.0	0.0	0.0	0.0	0.0000000000	False
real color	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
color variance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
helped object	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
object recognition	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
research community	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
real chance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
mine told	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
color invariance	0.00113686577888	0.0	0.0	1.0	0.0000000000	False
problem.and pretty	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
powerful theories	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
huge impact	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
advanced data	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
data machine	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
huge application	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
computer science	0.000250134781115	0.0	0.0	1.0	0.0000000000	False
theoretical things	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
high impact	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
peripheral relevance	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
personal choice	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
direct link	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
spent coming	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
great diagnostics	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
writing diagnostics	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
implementing learning	0.00113686577888	0.0	0.0	0.0	0.0000000000	False
making progress	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
implementing tests	0.000568432889439	0.0	0.0	1.0	0.0000000000	False
ablative analyses	0.000568432889439	0.0	5.99781579905	3.0	0.0000000000	False
good	0.000257906609336	0.0	0.0	0.0	0.4854751354	False
morning	0.000201389376076	0.0	0.0	0.0	0.0000000000	False
back	0.000246584274511	0.0	0.0	0.0	0.3940704138	False
today	0.000109489086999	0.0	0.0	0.0	0.2563131313	False
wrap	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
discussion	0.000104578798871	0.0	0.0	0.0	0.0000000000	False
learning	0.00513217745981	0.0	0.0	0.0	0.3282134196	False
theory	0.000986849597816	0.0	0.0	0.0	0.3383020091	False
sort	0.000941507266007	0.0	0.0	0.0	0.4287634409	False
start	0.0	0.0	0.0	0.0	0.3805774278	False
talking	0.000137790841932	0.0	0.0	0.0	0.2980652963	False
bayesian	0.0058039058291	0.0	0.0	0.0	0.2468085106	False
statistics	0.000875471733903	0.0	0.0	0.0	0.4321907601	False
regularization	0.000750404343345	1.0	0.0	0.0	0.0000000000	True
digression	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
online	0.00148815866326	0.0	0.0	0.0	0.3805774278	False
lecture	0.000318025014589	0.0	0.0	0.0	0.3383020091	False
pieces	0.00057174003981	0.0	0.0	0.0	0.2755939525	False
applying	0.000313736396613	0.0	0.0	0.0	0.3981693364	False
machine	0.00199701021967	0.0	0.0	0.0	0.3402044579	False
algorithms	0.00248637434903	1.0	0.0	0.0	0.3944852941	False
problems	0.000275581683865	0.0	0.0	0.0	0.3062302006	False
project	0.000175818568689	0.0	0.0	0.0	0.0000000000	False
work	0.000788047972972	0.0	0.0	0.0	0.3042441583	False
graduate	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
class	0.000192581031683	0.0	0.0	0.0	0.4618885097	False
remember	0.000238518760941	0.0	0.0	0.0	0.4618885097	False
last	0.0	0.0	0.0	0.0	0.5225225225	False
week	0.000246712399454	0.0	0.0	0.0	0.0000000000	False
bias	0.00257662226147	0.0	0.0	0.0	0.3302961276	False
variance	0.00294169998083	0.0	0.0	0.0	0.3446785521	False
guess	0.00129631870506	0.0	0.0	0.0	0.2563131313	False
previous	0.000159855809238	0.0	0.0	0.0	0.3211517165	False
spent	0.000735424995208	0.0	0.0	0.0	0.5132743363	False
model	0.000606400467154	0.0	0.0	0.0	0.4618885097	False
selection	0.000564211885925	0.0	0.0	0.0	0.0000000000	False
feature	0.00228696015924	0.0	0.0	0.0	0.3126684636	False
cross-validation	0.000568432889439	1.0	0.0	0.0	0.0000000000	False
right	0.0	0.0	0.0	0.0	0.5462603878	False
methods	0.000333515023222	0.0	0.0	0.0	0.4618885097	False
ways	0.000132510422745	0.0	0.0	0.0	0.4245973646	False
simply	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
eliminate	0.000541148604821	0.0	0.0	0.0	0.0000000000	False
number	1.32288602581e-05	0.0	0.0	0.0	0.4618885097	False
reduce	0.000230871391153	0.0	0.0	0.0	0.0000000000	False
parameters	0.00158736709769	0.0	0.0	0.0	0.3074204947	False
fit	0.00169263565778	0.0	0.0	0.0	0.2880514169	False
overfitting	0.00220148152138	0.0	0.0	0.0	0.0000000000	False
choose	0.000870491634217	0.0	0.0	0.0	0.3934871099	False
subset	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
prevent	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
lets	3.19711618475e-05	0.0	0.0	0.0	0.2987321712	False
idea	0.000189680211162	0.0	0.0	0.0	0.4734693878	False
illustrate	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
linear	0.000353191376491	0.0	0.0	0.0	0.4484536082	False
regression	0.00475152509132	0.0	0.0	0.0	0.3727506427	False
first	0.0	0.0	0.0	0.0	0.4669887279	False
maximum	0.000714213784705	0.0	0.0	0.0	0.3325981473	False
likelihood	0.00150080868669	0.0	0.0	0.0	0.3940704138	False
meant	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
theta	0.0087471257363	0.0	0.0	0.0	0.1815336463	False
maximized	0.00122245908617	0.0	0.0	0.0	0.2636363636	False
probability	0.000439546421722	0.0	0.0	0.0	0.4396159677	False
data	0.000727528341914	0.0	0.0	0.0	0.3196926674	False
observe	9.40353143209e-05	0.0	0.0	0.0	0.0000000000	False
give	2.45678833365e-05	0.0	0.0	0.0	0.2981554279	False
procedure	0.000504025904674	0.0	0.0	0.0	0.3211517165	False
common	0.000606400467154	0.0	0.0	0.0	0.3981693364	False
frequencies	0.000800538735049	0.0	0.0	0.0	0.0000000000	False
school	0.00050026956223	0.0	0.0	0.0	0.2914572864	False
philosophical	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
view	6.30032380842e-05	0.0	0.0	0.0	0.0000000000	False
writing	0.000205863163069	0.0	0.0	0.0	0.3332206827	False
envisioned	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
true	0.000302890703711	0.0	0.0	0.0	0.4080402010	False
out	0.0	0.0	0.0	0.0	0.4390464354	False
generated	2.32621787779e-05	0.0	0.0	0.0	0.0000000000	False
govern	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
housing	0.000696317536829	0.0	0.0	0.0	0.2914572864	False
prices	0.00050026956223	0.0	0.0	0.0	0.0000000000	False
function	0.000372531769041	1.0	0.0	0.0	0.2833037300	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
value	0.000189306689819	0.0	0.0	0.0	0.2698639943	False
estimating	0.00104447630524	0.0	0.0	0.0	0.3901345291	False
unknown	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
formulated	0.000348158768415	0.0	0.0	0.0	0.0000000000	False
random	0.000288070823347	0.0	0.0	0.0	0.3411764706	False
variable	0.000122956888801	0.0	0.0	0.0	0.0000000000	False
alternative	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
put	4.84383913102e-05	0.0	0.0	0.0	0.4113475177	False
prior	0.00220148152138	0.0	0.0	0.0	0.2917505030	False
students	0.00023546091766	0.0	0.0	0.0	0.0000000000	False
represent	0.000244017197366	0.0	0.0	0.0	0.3452380952	False
uncertainty	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
prior.so	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
gaussian	0.000676435756027	0.0	0.0	0.0	0.5225225225	False
distribution	0.000846528434228	0.0	0.0	0.0	0.3096085409	False
curvalence	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
matrix	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
tau	0.00198951511304	0.0	0.0	0.0	0.3096085409	False
squared	0.000762320053079	0.0	0.0	0.0	0.3164078892	False
denote	0.000336889148419	0.0	0.0	0.0	0.5225225225	False
training	0.00460529812314	0.0	0.0	0.0	0.1428822805	False
set	0.000279146145334	0.0	0.0	0.0	0.2769818529	False
beliefs	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
absence	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
calculate	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
posterior	0.00220148152138	0.0	0.0	0.0	0.2216560510	False
board	8.22374664847e-05	0.0	0.0	0.0	0.0000000000	False
bayes	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
rule	0.000315016190421	0.0	0.0	0.0	0.0000000000	False
proportional	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
call	1.51186974379e-05	0.0	0.0	0.0	0.3934871099	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
make	9.95156080622e-05	0.0	0.0	0.0	0.2815533981	False
prediction	0.00149445783385	0.0	0.0	0.0	0.3446519525	False
input	0.000174297998118	0.0	0.0	0.0	0.4321907601	False
size	0.000265029365747	0.0	0.0	0.0	0.3211517165	False
previously	0.000202133489051	0.0	0.0	0.0	0.0000000000	False
integral	0.000882509994249	0.0	0.0	0.0	0.2364130435	False
times	0.0	0.0	0.0	0.0	0.3918918919	False
expected	0.000384785651922	0.0	0.0	0.0	0.3684879288	False
respect	6.30032380842e-05	0.0	0.0	0.0	0.0000000000	False
notice	0.000470176571604	0.0	0.0	0.0	0.5178571429	False
formula	0.000302084064114	0.0	0.0	0.0	0.0000000000	False
property	6.97191992473e-05	0.0	0.0	0.0	0.0000000000	False
conditioned	5.49395219004e-05	0.0	0.0	0.0	0.0000000000	False
longer	0.000302084064114	0.0	0.0	0.0	0.0000000000	False
semicolon	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
treating	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
abstract	8.22374664847e-05	0.0	0.0	0.0	0.0000000000	False
turns	0.000689054198275	0.0	0.0	0.0	0.3497217069	False
check	0.000221214545682	0.0	0.0	0.0	0.5178571429	False
questions	9.42790332712e-05	0.0	0.0	0.0	0.4065420561	False
concrete	0.000302084064114	0.0	0.0	0.0	0.0000000000	False
steps	8.3064635404e-05	0.0	0.0	0.0	0.4321907601	False
computation	9.95355336355e-05	0.0	0.0	0.0	0.3098290598	False
difficult	0.000411187332423	0.0	0.0	0.0	0.4321907601	False
one-dimensional	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
vector	0.000904612131332	0.0	0.0	0.0	0.3981693364	False
numerically	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
high	0.00185815512938	0.0	0.0	0.0	0.1540731995	False
dimensional	0.000846317828888	0.0	0.0	0.0	0.2295789852	False
spaces	0.000204928148001	0.0	0.0	0.0	0.0000000000	False
hard	0.000986849597816	0.0	0.0	0.0	0.3677233429	False
exceptions	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
closed	0.000189680211162	0.0	0.0	0.0	0.2612612613	False
form	1.21095978276e-05	0.0	0.0	0.0	0.0000000000	False
logistic	0.00421157905822	0.0	0.0	0.0	0.2712555462	False
commonly	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
full	0.000134755659368	0.0	0.0	0.0	0.0000000000	False
chi	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
quantity	0.000269511318735	0.0	0.0	0.0	0.2914572864	False
right-hand	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
side	6.97191992473e-05	0.0	0.0	0.0	0.0000000000	False
map	0.000126006476168	0.0	0.0	0.0	0.0000000000	False
posteriori	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
ont	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
max	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
usual	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
hypothesis	0.000328949865939	0.0	0.0	0.0	0.0000000000	False
place	0.000113584013892	0.0	0.0	0.0	0.5178571429	False
difference	2.67926637091e-05	0.0	0.0	0.0	0.4496124031	False
standard	0.000102410780496	0.0	0.0	0.0	0.0000000000	False
intuition	0.000328949865939	0.0	0.0	0.0	0.4113475177	False
covariance	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
mass	0.000483116674025	0.0	0.0	0.0	0.0000000000	False
centered	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
point	1.32288602581e-05	0.0	0.0	0.0	0.4321907601	False
consideration	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
source	0.000215978413242	0.0	0.0	0.0	0.0000000000	False
equal	0.000185514591843	0.0	0.0	0.0	0.4080402010	False
drives	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
analogous	0.000107989206621	0.0	0.0	0.0	0.0000000000	False
reminiscent	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
pictures	6.97191992473e-05	0.0	0.0	0.0	0.0000000000	False
fourth-order	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
polynomial	0.000541148604821	0.0	0.0	0.0	0.4113475177	False
bumps	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
mind	0.00011773045883	0.0	0.0	0.0	0.0000000000	False
small	4.84383913102e-05	0.0	0.0	0.0	0.0000000000	False
dataset	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
large	0.000159012507294	0.0	0.0	0.0	0.4321907601	False
oscillations	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
contrast	0.000351637137377	0.0	0.0	0.0	0.5178571429	False
higher-order	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
smoother	0.0014210822236	0.0	0.0	0.0	0.2318145484	False
decrease	0.000464211691219	0.0	0.0	0.0	0.0000000000	False
closer	0.00023210584561	0.0	0.0	0.0	0.0000000000	False
practice	0.000164818565701	0.0	0.0	0.0	0.0000000000	False
word	0.000116751127056	0.0	0.0	0.0	0.0000000000	False
smaller	0.00019058001327	0.0	0.0	0.0	0.4113475177	False
curves	0.00175094346781	0.0	0.0	0.0	0.3536585366	False
tend	0.000879092843443	0.0	0.0	0.0	0.4489164087	False
toss	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
play	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
post	0.000175818568689	0.0	0.0	0.0	0.0000000000	False
minimize	0.000875911785889	0.0	0.0	0.0	0.3036649215	False
add	0.000163942518401	0.0	0.0	0.0	0.4113475177	False
term	3.98142134542e-05	0.0	0.0	0.0	0.0000000000	False
authorization	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
objective	0.00148495631719	0.0	0.0	0.0	0.3178540525	False
end	7.85658610593e-05	0.0	0.0	0.0	0.3981693364	False
optimizing	0.00441965977308	0.0	0.0	0.0	0.1814768461	False
extra	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
penalizes	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
similar	0.000159012507294	0.0	0.0	0.0	0.3452380952	False
effect	0.000307232341488	0.0	0.0	0.0	0.4113475177	False
kind	7.85658610593e-06	0.0	0.0	0.0	0.0000000000	False
strengthening	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
keeping	0.000116052922805	0.0	0.0	0.0	0.4618885097	False
sense	4.98387812424e-05	0.0	0.0	0.0	0.0000000000	False
bit	6.64517083232e-05	0.0	0.0	0.0	0.4113475177	False
smoothing	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
behavior	9.40353143209e-05	0.0	0.0	0.0	0.0000000000	False
depends	3.32258541616e-05	0.0	0.0	0.0	0.0000000000	False
convention	7.69571303844e-05	0.0	0.0	0.0	0.0000000000	False
laplace	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
cool	0.000351637137377	0.0	0.0	0.0	0.0000000000	False
text	0.000755924446347	0.0	0.0	0.0	0.4080402010	False
classification	0.000402778752152	0.0	0.0	0.0	0.0000000000	False
30,000	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
50,000	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
prone	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
imagine	0.000134755659368	0.0	0.0	0.0	0.0000000000	False
build	0.00151207771402	0.0	0.0	0.0	0.4133016627	False
spam	0.0017650199885	0.0	0.0	0.0	0.3378640777	False
classifier	0.000376141257283	0.0	0.0	0.0	0.0000000000	False
examples	0.000832949435205	0.0	0.0	0.0	0.3155902531	False
alex	0.0	0.0	0.0	0.0	0.0000000000	False
pick	0.000336889148419	0.0	0.0	0.0	0.2845927380	False
lambda	0.00178117075278	0.0	0.0	0.0	0.3383020091	False
relation	0.000102410780496	0.0	0.0	0.0	0.0000000000	False
spend	0.00139803693024	0.0	0.0	0.0	0.4144598571	False
minutes	0.000216053117511	0.0	0.0	0.0	0.0000000000	False
designing	0.000384576653303	0.0	0.0	0.0	0.4484536082	False
syllabus	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
find	8.64224471652e-05	0.0	0.0	0.0	0.3243518048	False
disjointed	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
rest	0.000202133489051	0.0	0.0	0.0	0.0000000000	False
batch	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
run	0.000431936104101	0.0	0.0	0.0	0.4308571429	False
test	0.00158438952841	0.0	0.0	0.0	0.3383897316	False
process	4.27957848185e-05	0.0	0.0	0.0	0.0000000000	False
sees	0.000322077782683	0.0	0.0	0.0	0.4058713091	False
label	0.000647935239726	0.0	0.0	0.0	0.3096085409	False
hat	0.000735424995208	0.0	0.0	0.0	0.2845927380	False
made	0.000286899407201	0.0	0.0	0.0	0.4618885097	False
reveal	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
odds	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
percent	0.00280771937215	0.0	0.0	0.0	0.2430652564	False
randomly	0.000215978413242	0.0	0.0	0.0	0.0000000000	False
show	8.3064635404e-05	0.0	0.0	0.0	0.4321907601	False
two	0.0	0.0	0.0	0.0	0.3951903808	False
slightly	9.59134855426e-05	0.0	0.0	0.0	0.0000000000	False
educated	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
proceeds	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
lot	0.000344527099138	0.0	0.0	0.0	0.4702702703	False
website	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
users	0.000216053117511	0.0	0.0	0.0	0.0000000000	False
coming	0.000109879043801	0.0	0.0	0.0	0.4166951762	False
likes	0.000200134683762	0.0	0.0	0.0	0.3671992765	False
dislikes	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
care	0.000340752041675	0.0	0.0	0.0	0.4368200837	False
total	0.000176971636545	0.0	0.0	0.0	0.2914572864	False
error	0.00563890253013	0.0	0.0	0.0	0.2799055344	False
sum	0.000109879043801	0.0	0.0	0.0	0.0000000000	False
sequence	8.84858182726e-05	0.0	0.0	0.0	0.0000000000	False
indicator	4.76450033175e-05	0.0	0.0	0.0	0.0000000000	False
mistakes	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
finish	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
thing	0.0	0.0	0.0	0.0	0.4072007201	False
asked	0.000246712399454	0.0	0.0	0.0	0.4734693878	False
simple	0.000114625159705	0.0	0.0	0.0	0.5272727273	False
leading	0.000215978413242	0.0	0.0	0.0	0.0000000000	False
stochastic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
gradient	0.00121758436085	0.0	0.0	0.0	0.3383020091	False
descent	0.00144935002207	0.0	0.0	0.0	0.3493975904	False
adapted	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
nicely	5.49395219004e-05	0.0	0.0	0.0	0.0000000000	False
perceptron	0.00161816731999	0.0	0.0	0.0	0.3023082651	False
initial	8.19712592004e-05	0.0	0.0	0.0	0.0000000000	False
update	7.20177058369e-05	0.0	0.0	0.0	0.0000000000	False
reel	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
essentially	1.66129270808e-05	0.0	0.0	0.0	0.0000000000	False
one-step	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
reason	0.000119537228319	0.0	0.0	0.0	0.5225225225	False
theorysection	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
prove	0.00075603885701	0.0	0.0	0.0	0.2504907735	False
fairly	0.000139438398495	0.0	0.0	0.0	0.4113475177	False
amazing	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
results	0.000204928148001	0.0	0.0	0.0	0.0000000000	False
main	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
infinite	0.000493424798908	0.0	0.0	0.0	0.2364130435	False
kernel	0.000270574302411	0.0	0.0	0.0	0.0000000000	False
representations	5.88652294151e-05	0.0	0.0	0.0	0.0000000000	False
extremely	6.30032380842e-05	0.0	0.0	0.0	0.0000000000	False
long	0.000384576653303	0.0	0.0	0.0	0.4080402010	False
positive	0.000212016676392	0.0	0.0	0.0	0.2318145484	False
negative	0.000269511318735	0.0	0.0	0.0	0.2027972028	False
separated	0.00019058001327	0.0	0.0	0.0	0.2027972028	False
margin	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
converge	0.00216459441929	0.0	0.0	0.0	0.4119318182	False
perfectly	0.000625336952788	0.0	0.0	0.0	0.0000000000	False
finite	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
digital	8.22374664847e-05	0.0	0.0	0.0	0.0000000000	False
boundary	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
proof	0.000263727853033	0.0	0.0	0.0	0.0000000000	False
entire	4.27957848185e-05	0.0	0.0	0.0	0.4321907601	False
written	0.000151445351856	0.0	0.0	0.0	0.4113475177	False
notes	7.57226759278e-05	0.0	0.0	0.0	0.0000000000	False
purposes	4.42429091363e-05	0.0	0.0	0.0	0.0000000000	False
optional	0.000215978413242	0.0	0.0	0.0	0.0000000000	False
reading	6.97191992473e-05	0.0	0.0	0.0	0.0000000000	False
midterm	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
specifically	0.000149785246865	0.0	0.0	0.0	0.5272727273	False
thought	0.000263727853033	0.0	0.0	0.0	0.0000000000	False
curious	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
svms	0.00254283435999	0.0	0.0	0.0	0.3243518048	False
bounded	0.000527455706066	0.0	0.0	0.0	0.3096085409	False
dimension	0.000464211691219	0.0	0.0	0.0	0.0000000000	False
simplest	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
instance	5.30041690981e-05	0.0	0.0	0.0	0.0000000000	False
half	0.000274697609502	0.0	0.0	0.0	0.4113475177	False
hour	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
understand	0.00013934974709	0.0	0.0	0.0	0.3705159705	False
interested	0.000139438398495	0.0	0.0	0.0	0.0000000000	False
page	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
theoretical	0.000588339996166	0.0	0.0	0.0	0.2914572864	False
based	0.000132728727409	0.0	0.0	0.0	0.0000000000	False
move	5.30041690981e-05	0.0	0.0	0.0	0.0000000000	False
majority	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
switch	0.000164474932969	0.0	0.0	0.0	0.0000000000	False
powerpoint	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
slides	0.000384576653303	0.0	0.0	0.0	0.5178571429	False
advice	0.00220148152138	1.0	0.0	0.0	0.2365415987	False
powerful	0.000132728727409	0.0	0.0	0.0	0.0000000000	False
tools	0.000282105942963	0.0	0.0	0.0	0.0000000000	False
humankind	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
people	0.000819712592004	0.0	0.0	0.0	0.4496124031	False
person	0.00180922426266	0.0	0.0	0.0	0.3117162307	False
job	0.000541148604821	0.0	0.0	0.0	0.5178571429	False
amazingly	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
convey	0.000270574302411	0.0	0.0	0.0	0.0000000000	False
caveats	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
mathematical	0.000175818568689	0.0	0.0	0.0	0.0000000000	False
hardest	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
conceptually	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
material	9.40353143209e-05	0.0	0.0	0.0	0.0000000000	False
easy	0.000202133489051	0.0	0.0	0.0	0.0000000000	False
debatable	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
agree	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
focusing	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
stuff	9.40353143209e-05	0.0	0.0	0.0	0.0000000000	False
company	0.000704862816267	0.0	0.0	0.0	0.2914572864	False
deliver	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
product	0.000202133489051	0.0	0.0	0.0	0.0000000000	False
system	0.00203276231031	0.0	0.0	0.0	0.3414174712	False
great	0.000113584013892	0.0	0.0	0.0	0.0000000000	False
goal	0.000971902859589	0.0	0.0	0.0	0.3981693364	False
invent	0.00120080810257	0.0	0.0	0.0	0.4484536082	False
deploy	0.00115583379999	0.0	0.0	0.0	0.4321907601	False
key	4.42429091363e-05	0.0	0.0	0.0	0.0000000000	False
areas	0.000189009714253	0.0	0.0	0.0	0.0000000000	False
diagnostics	0.00809083659996	0.0	0.0	0.0	0.4566929134	False
debugging	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
briefly	6.73778296838e-05	0.0	0.0	0.0	0.0000000000	False
analyses	0.00254283435999	0.0	0.0	0.0	0.4484536082	False
ablative	0.00170529866832	0.0	0.0	0.0	0.4321907601	False
analysis	0.000606400467154	0.0	0.0	0.0	0.3684879288	False
machine-learning	0.000882509994249	0.0	0.0	0.0	0.5272727273	False
theme	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
heard	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
premature	0.00255794800248	0.0	0.0	0.0	0.1956155143	False
software	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
over-designs	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
code	0.000333515023222	0.0	0.0	0.0	0.2577777778	False
subroutine	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
heavily	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
assembly	0.000270574302411	0.0	0.0	0.0	0.0000000000	False
guilty	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
faster	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
implement	0.000665670073225	0.0	0.0	0.0	0.3940704138	False
tune	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
quickly	0.000442429091363	0.0	0.0	0.0	0.0000000000	False
bottleneck	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
undergraduate	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
programming	3.78613379639e-05	0.0	0.0	0.0	0.0000000000	False
warn	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
part	2.67926637091e-05	0.0	0.0	0.0	0.1622053536	False
important	0.000159855809238	0.0	0.0	0.0	0.3211517165	False
motivating	0.000175818568689	0.0	0.0	0.0	0.0000000000	False
anti-spam	0.0014210822236	0.0	0.0	0.0	0.5225225225	False
chosen	0.000164474932969	0.0	0.0	0.0	0.0000000000	False
unacceptably	0.000924667039995	0.0	0.0	0.0	0.4113475177	False
additional	4.76450033175e-05	0.0	0.0	0.0	0.0000000000	False
minus	3.19711618475e-05	0.0	0.0	0.0	0.0000000000	False
improve	0.00162474091927	0.0	0.0	0.0	0.3446519525	False
sit	0.000216053117511	0.0	0.0	0.0	0.0000000000	False
wrong	0.001000442695	0.0	0.0	0.0	0.4837812790	False
algorithm.well	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
suspect	0.00128831113073	0.0	0.0	0.0	0.3493975904	False
email	0.000846317828888	0.0	0.0	0.0	0.3383020091	False
headers	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
figure	0.00110661199921	0.0	0.0	0.0	0.4308571429	False
hurt	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
hearing	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
newton	0.0	0.0	0.0	0.0	0.0000000000	False
listed	9.52900066349e-05	0.0	0.0	0.0	0.0000000000	False
endless	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
hundreds	6.73778296838e-05	0.0	0.0	0.0	0.0000000000	False
surely	0.000284216444719	0.0	0.0	0.0	0.4113475177	False
eventually	0.000126006476168	0.0	0.0	0.0	0.0000000000	False
time-consuming	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
matter	0.000102410780496	0.0	0.0	0.0	0.0000000000	False
luck	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
fixing	0.00161706791241	0.0	0.0	0.0	0.2279952145	False
deeply	0.00100067341881	0.0	0.0	0.0	0.0000000000	False
save	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
industry	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
research	0.00107989206621	0.0	0.0	0.0	0.3981693364	False
change	0.000189680211162	0.0	0.0	0.0	0.3658023826	False
story	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
suppose	0.000149516343727	0.0	0.0	0.0	0.2940845070	False
excuse	0.000376141257283	0.0	0.0	0.0	0.5178571429	False
wrote	7.20177058369e-05	0.0	0.0	0.0	0.0000000000	False
firstly	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
forget	0.000215978413242	0.0	0.0	0.0	0.0000000000	False
tables	0.000351637137377	0.0	0.0	0.0	0.0000000000	False
reversed	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
cartoon	0.000947010058437	0.0	0.0	0.0	0.3452380952	False
lower	0.000216053117511	0.0	0.0	0.0	0.0000000000	False
tenth	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
order	4.07088128613e-05	0.0	0.0	0.0	0.2782727896	False
quadratic	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
typical	0.000109879043801	0.0	0.0	0.0	0.0000000000	False
horizontal	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
axis	0.000215978413242	0.0	0.0	0.0	0.0000000000	False
plotting	0.00112842377185	0.0	0.0	0.0	0.1726190476	False
vertical	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
increase	0.000294326147076	0.0	0.0	0.0	0.3411764706	False
suggests	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
extrapolate	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
green	0.000201389376076	0.0	0.0	0.0	0.0000000000	False
red	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
line	8.75633452922e-05	0.0	0.0	0.0	0.0000000000	False
desired	0.00050026956223	0.0	0.0	0.0	0.2914572864	False
performance	0.000627472793226	0.0	0.0	0.0	0.3658023826	False
reach	7.20177058369e-05	0.0	0.0	0.0	0.0000000000	False
grow	0.000263727853033	0.0	0.0	0.0	0.0000000000	False
larger	0.000227168027783	0.0	0.0	0.0	0.4484536082	False
harder	0.000644155565367	0.0	0.0	0.0	0.3411764706	False
smart	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
10,000	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
versus	0.000464211691219	0.0	0.0	0.0	0.4113475177	False
gap	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
case	0.0	0.0	0.0	0.0	0.3654365437	False
flattened	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
sign	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
necessarily	0.000144035411674	0.0	0.0	0.0	0.0000000000	False
hold	0.00023546091766	0.0	0.0	0.0	0.5178571429	False
fact	7.16407248156e-05	0.0	0.0	0.0	0.0000000000	False
level	0.000132728727409	0.0	0.0	0.0	0.0000000000	False
worse	0.00108229720964	0.0	0.0	0.0	0.4080402010	False
blue	0.000164474932969	0.0	0.0	0.0	0.0000000000	False
stay	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
ambiguous	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
adding	0.000315016190421	0.0	0.0	0.0	0.4321907601	False
solutions	0.000176595688245	0.0	0.0	0.0	0.0000000000	False
helps	0.000376141257283	0.0	0.0	0.0	0.3101604278	False
money	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
effort	0.000644155565367	0.0	0.0	0.0	0.0000000000	False
collecting	0.000202133489051	0.0	0.0	0.0	0.0000000000	False
help.but	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
months	0.00140385968607	0.0	0.0	0.0	0.1548042705	False
realizing	8.22374664847e-05	0.0	0.0	0.0	0.0000000000	False
possibly	0.000144035411674	0.0	0.0	0.0	0.3452380952	False
silicon	0.000800538735049	0.0	0.0	0.0	0.2914572864	False
valley	0.000924667039995	0.0	0.0	0.0	0.2914572864	False
told	0.000625336952788	0.0	0.0	0.0	0.2845927380	False
ago	0.000215978413242	0.0	0.0	0.0	0.0000000000	False
easily	0.000288070823347	0.0	0.0	0.0	0.5178571429	False
surprisingly	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
depressing	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
joke	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
fruitless	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
bottom	0.000411187332423	0.0	0.0	0.0	0.4321907601	False
ingenuity	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
construct	0.000126006476168	0.0	0.0	0.0	0.0000000000	False
contrived	0.00113686577888	0.0	0.0	0.0	0.0000000000	False
issues	0.000109879043801	0.0	0.0	0.0	0.0000000000	False
mail	0.0017650199885	0.0	0.0	0.0	0.2365415987	False
non-spam	0.000800538735049	0.0	0.0	0.0	0.4113475177	False
rejecting	0.000483116674025	0.0	0.0	0.0	0.0000000000	False
friends	0.000811722907232	0.0	0.0	0.0	0.4321907601	False
acceptable	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
sake	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
customers	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
efficiency	5.88652294151e-05	0.0	0.0	0.0	0.0000000000	False
retrain	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
overnight	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
day	0.000164818565701	0.0	0.0	0.0	0.0000000000	False
iterations	0.000328949865939	0.0	0.0	0.0	0.0000000000	False
absentiles	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
ten	7.57226759278e-05	0.0	0.0	0.0	0.0000000000	False
slowly	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
weighted	0.0019324666961	0.0	0.0	0.0	0.2329317269	False
accuracy	0.00508566871997	0.0	0.0	0.0	0.2880514169	False
higher	0.000153914260769	0.0	0.0	0.0	0.0000000000	False
correct	0.000333515023222	0.0	0.0	0.0	0.4484536082	False
two-nom	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
penalty	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
wondering	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
support	0.000432106235021	0.0	0.0	0.0	0.3096085409	False
chose	0.000107989206621	0.0	0.0	0.0	0.0000000000	False
reiterate	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
outperforms	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
subscript	0.000580264614024	0.0	0.0	0.0	0.3684879288	False
blr	0.0014210822236	0.0	0.0	0.0	0.0000000000	False
criteria	0.000270574302411	0.0	0.0	0.0	0.0000000000	False
support-vector-machine	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
bigger-than	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
less-than	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
explain	0.000376141257283	0.0	0.0	0.0	0.3411764706	False
bigger	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
equations	6.73778296838e-05	0.0	0.0	0.0	0.0000000000	False
copied	9.40353143209e-05	0.0	0.0	0.0	0.0000000000	False
greater	0.000102410780496	0.0	0.0	0.0	0.0000000000	False
definition	3.19711618475e-05	0.0	0.0	0.0	0.0000000000	False
means	2.0788208977e-05	0.0	0.0	0.0	0.2888597641	False
output	0.000238225016587	0.0	0.0	0.0	0.5178571429	False
fails	0.000270574302411	0.0	0.0	0.0	0.0000000000	False
returned	6.73778296838e-05	0.0	0.0	0.0	0.0000000000	False
out-maximizing	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
tells	0.000549395219004	0.0	0.0	0.0	0.4697116942	False
correctly	0.000405861453616	0.0	0.0	0.0	0.0000000000	False
attains	0.00115583379999	0.0	0.0	0.0	0.2318145484	False
measure	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
correspond	0.000216053117511	0.0	0.0	0.0	0.5178571429	False
raise	6.30032380842e-05	0.0	0.0	0.0	0.0000000000	False
hand	2.91877817641e-05	0.0	0.0	0.0	0.0000000000	False
norm	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
pattern	0.000107989206621	0.0	0.0	0.0	0.0000000000	False
conjugate	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
crazy	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
hmm	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
flying	0.00300202025643	0.0	0.0	0.0	0.1920105937	False
helicopters	0.00480323241029	0.0	0.0	0.0	0.3164078892	False
complex	0.000134755659368	0.0	0.0	0.0	0.0000000000	False
draws	9.52900066349e-05	0.0	0.0	0.0	0.0000000000	False
reinforcement	0.00254283435999	0.0	0.0	0.0	0.2504907735	False
complicated	0.000529787064736	0.0	0.0	0.0	0.3493975904	False
redo	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
exact	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
autonomous	0.000483116674025	0.0	0.0	0.0	0.0000000000	False
controller	0.000741156126521	0.0	0.0	0.0	0.2482876712	False
simulator	0.00374045858084	0.0	0.0	0.0	0.3302961276	False
screenshot	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
joystick	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
cost	0.00122245908617	0.0	0.0	0.0	0.1828765462	False
reinforcement-learning	0.00170529866832	0.0	0.0	0.0	0.3901345291	False
human	0.00172782730594	0.0	0.0	0.0	0.1114313160	False
pilot	0.00115583379999	0.0	0.0	0.0	0.2914572864	False
natural	0.000132728727409	0.0	0.0	0.0	0.0000000000	False
chopped	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
accurate	0.000812370459634	0.0	0.0	0.0	0.0000000000	False
capture	0.000175818568689	0.0	0.0	0.0	0.0000000000	False
aerodynamic	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
airflow	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
turbulence	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
affects	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
modify	6.73778296838e-05	0.0	0.0	0.0	0.0000000000	False
cutting	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
subtle	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
wanted	6.73778296838e-05	0.0	0.0	0.0	0.4125177809	False
experiment	0.000107989206621	0.0	0.0	0.0	0.0000000000	False
poorly	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
contrary	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
assume	8.75633452922e-05	0.0	0.0	0.0	0.0000000000	False
crash	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
flight	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
held	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
real	0.000191826971085	0.0	0.0	0.0	0.3211517165	False
assumptions	0.000201389376076	0.0	0.0	0.0	0.0000000000	False
life	0.00023210584561	0.0	0.0	0.0	0.0000000000	False
policy	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
managing	0.000107989206621	0.0	0.0	0.0	0.0000000000	False
finally	8.84858182726e-05	0.0	0.0	0.0	0.0000000000	False
typo	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
years	0.00023546091766	0.0	0.0	0.0	0.0000000000	False
active	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
phd	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
theses	0.000231166759999	0.0	0.0	0.0	0.4205669084	False
thesis	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
happening	1.89680211162e-05	0.0	0.0	0.0	0.4113475177	False
described	0.0	0.0	0.0	0.0	0.0000000000	False
couple	8.22374664847e-05	0.0	0.0	0.0	0.0000000000	False
application	0.00049219739353	0.0	0.0	0.0	0.4080402010	False
stanford	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
high-paying	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
significant	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
economic	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
valuable	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
world	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
solving	6.30032380842e-05	0.0	0.0	0.0	0.0000000000	False
outsource	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
hire	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
firm	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
york	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
businessman	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
terrible	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
expertise	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
agency	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
maintain	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
knowledge	0.00023210584561	0.0	0.0	0.0	0.0000000000	False
papers	0.000676435756027	0.0	0.0	0.0	0.5178571429	False
insight	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
justify	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
claims	0.000441254997125	0.0	0.0	0.0	0.0000000000	False
built	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
flies,or	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
component	0.00183581651256	0.0	0.0	0.0	0.4469472436	False
justification	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
problem,and	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
flown	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
combine	0.000102410780496	0.0	0.0	0.0	0.0000000000	False
pipeline	0.000644155565367	0.0	0.0	0.0	0.0000000000	False
dissimilar	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
actual	5.49395219004e-05	0.0	0.0	0.0	0.3866666667	False
recognize	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
images	0.000431956826484	0.0	0.0	0.0	0.0000000000	False
camera	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
preprocess	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
remove	0.00122245908617	0.0	0.0	0.0	0.2040294212	False
background	0.00102959499329	0.0	0.0	0.0	0.3901345291	False
face	0.00061536499041	0.0	0.0	0.0	0.3096085409	False
detection	0.00135287151205	0.0	0.0	0.0	0.2974358974	False
identity	0.000175818568689	0.0	0.0	0.0	0.0000000000	False
segment	0.000323967619863	0.0	0.0	0.0	0.0000000000	False
eyes	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
nose	0.0014210822236	0.0	0.0	0.0	0.2845927380	False
mouth	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
found	5.88652294151e-05	0.0	0.0	0.0	0.0000000000	False
feed	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
soft	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
match	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
attributed	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
repeatedly	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
plug	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
ground-truth	0.00198951511304	0.0	0.0	0.0	0.2782727896	False
left	2.39074456637e-05	0.0	0.0	0.0	0.0000000000	False
foreground	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
color	0.000740137198362	0.0	0.0	0.0	0.2600896861	False
boost	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
jumped	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
waste	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
subtraction	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
potential	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
gains	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
critical	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
worth	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
type	0.000122956888801	0.0	0.0	0.0	0.0000000000	False
opposite	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
current	0.000164474932969	0.0	0.0	0.0	0.0000000000	False
perfect	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
baselines	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
bad	0.000144035411674	0.0	0.0	0.0	0.0000000000	False
clever	0.000356234150556	0.0	0.0	0.0	0.0000000000	False
sender	0.00113686577888	0.0	0.0	0.0	0.2914572864	False
host	0.000800538735049	0.0	0.0	0.0	0.2914572864	False
parser	0.00113686577888	0.0	0.0	0.0	0.3411764706	False
javascript	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
embedded	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
preview	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
contribute	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
big	0.000221214545682	0.0	0.0	0.0	0.4321907601	False
document	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
accounts	8.22374664847e-05	0.0	0.0	0.0	0.0000000000	False
rates	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
spelling	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
drops	0.000539946033105	0.0	0.0	0.0	0.0000000000	False
biggest	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
occurred	7.20177058369e-05	0.0	0.0	0.0	0.0000000000	False
credible	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
rid	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
speed	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
candidate	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
guarantees	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
shuffle	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
address	7.69571303844e-05	0.0	0.0	0.0	0.0000000000	False
answer	3.19711618475e-05	0.0	0.0	0.0	0.0000000000	False
constants	5.1205390248e-05	0.0	0.0	0.0	0.0000000000	False
feel	0.00023210584561	0.0	0.0	0.0	0.0000000000	False
free	0.00023210584561	0.0	0.0	0.0	0.0000000000	False
description	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
broad	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
structure	3.48595996237e-05	0.0	0.0	0.0	0.0000000000	False
hope	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
benefit	0.000400269367524	0.0	0.0	0.0	0.0000000000	False
approach	0.000625336952788	0.0	0.0	0.0	0.2914572864	False
nicer	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
scalable	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
elegant	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
basic	7.85658610593e-06	0.0	0.0	0.0	0.0000000000	False
slowing	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
thinking	0.000188070628642	0.0	0.0	0.0	0.4597289696	False
build-and-fix	0.000284216444719	1.0	0.0	0.0	0.0000000000	False
quick	7.69571303844e-05	0.0	0.0	0.0	0.0000000000	False
dirty	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
wins	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
market	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
quick-and-dirty	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
hack	0.00113686577888	0.0	0.0	0.0	0.2914572864	False
clear	3.78613379639e-05	0.0	0.0	0.0	0.0000000000	False
easier	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
identifying	7.69571303844e-05	0.0	0.0	0.0	0.0000000000	False
obvious	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
outset	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
knowing	0.000116052922805	0.0	0.0	0.0	0.5630258143	False
ultimately	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
recognition	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
prototyped	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
gee	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
surprising	0.000125067390558	0.0	0.0	0.0	0.0000000000	False
sounds	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
lying	6.30032380842e-05	0.0	0.0	0.0	0.0000000000	False
focus	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
pays	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
follow	4.09856296002e-05	0.0	0.0	0.0	0.0000000000	False
shoot	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
late	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
highly	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
influenced	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
christos	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
papadimitriou	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
progress	0.000405861453616	0.0	0.0	0.0	0.0000000000	False
developmental	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
delivery	0.0014210822236	0.0	0.0	0.0	0.2318145484	False
robot	0.00142493660223	0.0	0.0	0.0	0.2027972028	False
drawn	7.69571303844e-05	0.0	0.0	0.0	0.0000000000	False
circle	0.000188070628642	0.0	0.0	0.0	0.0000000000	False
wander	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
indoor	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
environments	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
manipulate	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
pickup	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
envelopes	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
arrows	9.40353143209e-05	0.0	0.0	0.0	0.0000000000	False
obstacle	0.000693500279996	0.0	0.0	0.0	0.0000000000	False
avoidance	0.000302084064114	0.0	0.0	0.0	0.0000000000	False
needed	0.000125067390558	0.0	0.0	0.0	0.2102973169	False
navigate	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
vision	0.000147084999042	0.0	0.0	0.0	0.0000000000	False
lighting	0.000580264614024	0.0	0.0	0.0	0.3211517165	False
noontime	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
evening	0.000161038891342	0.0	0.0	0.0	0.4430555556	False
invariant	0.000534351225834	0.0	0.0	0.0	0.0000000000	False
rgb	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
three-dimensional	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
visual	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
appearance	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
properly	0.000161038891342	0.0	0.0	0.0	0.0000000000	False
study	0.000134755659368	0.0	0.0	0.0	0.0000000000	False
differential	0.000600404051286	0.0	0.0	0.0	0.0000000000	False
geometry	0.000644155565367	0.0	0.0	0.0	0.0000000000	False
manifolds	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
develop	7.20177058369e-05	0.0	0.0	0.0	0.0000000000	False
fundamental	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
aspects	8.22374664847e-05	0.0	0.0	0.0	0.0000000000	False
non-riemannian	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
sampled	0.000323967619863	0.0	0.0	0.0	0.0000000000	False
non-monotonic	0.000852649334158	0.0	0.0	0.0	0.0000000000	False
logic	0.000230871391153	0.0	0.0	0.0	0.0000000000	False
reality	0.000294169998083	0.0	0.0	0.0	0.0000000000	False
chances	0.000250134781115	0.0	0.0	0.0	0.0000000000	False
link	0.000328949865939	0.0	0.0	0.0	0.2845927380	False
barely	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
community	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
head	0.000116052922805	0.0	0.0	0.0	0.0000000000	False
guy	6.73778296838e-05	0.0	0.0	0.0	0.0000000000	False
mine	0.000270574302411	0.0	0.0	0.0	0.0000000000	False
problem.and	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
pretty	8.79092843443e-05	0.0	0.0	0.0	0.0000000000	False
role	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
huge	0.000175818568689	0.0	0.0	0.0	0.0000000000	False
impact	0.000322077782683	0.0	0.0	0.0	0.0000000000	False
dramatically	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
advanced	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
np-hardness	0.000568432889439	0.0	0.0	0.0	0.0000000000	False
science	0.000107989206621	0.0	0.0	0.0	0.0000000000	False
peripheral	0.000200134683762	0.0	0.0	0.0	0.0000000000	False
relevance	0.000135287151205	0.0	0.0	0.0	0.0000000000	False
choice	4.76450033175e-05	0.0	0.0	0.0	0.0000000000	False
trust	0.000462333519998	0.0	0.0	0.0	0.0000000000	False
direct	7.69571303844e-05	0.0	0.0	0.0	0.0000000000	False
summarize	0.000100694688038	0.0	0.0	0.0	0.0000000000	False
lesson	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
uncommon	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
tempting	0.000284216444719	0.0	0.0	0.0	0.0000000000	False
lastly	0.000107989206621	0.0	0.0	0.0	0.0000000000	False
risks	0.000178117075278	0.0	0.0	0.0	0.0000000000	False
ran	0.000231166759999	0.0	0.0	0.0	0.0000000000	False
quick announcement of sorts	0.0	0.0	0.0	2.0	0.0000000000	False
years ago that stanford	0.0	0.0	0.0	2.0	0.0000000000	False
ago that stanford submitted	0.0	0.0	0.0	2.0	0.0000000000	False
stanford submitted an entry	0.0	0.0	0.0	2.0	0.0000000000	False
entry to the darpa	0.0	0.0	0.0	2.0	0.0000000000	False
darpa grand challenge phase	0.0	0.0	0.0	2.0	0.0000000000	False
thrun has a team	0.0	0.0	0.0	2.0	0.0000000000	False
racing another autonomous car	0.0	0.0	0.0	2.0	0.0000000000	False
tools and ai machines	0.0	0.0	0.0	2.0	0.0000000000	False
ll try to drive	0.0	0.0	0.0	2.0	0.0000000000	False
drive itself in midst	0.0	0.0	0.0	2.0	0.0000000000	False
carry out the sort	0.0	0.0	0.0	2.0	0.0000000000	False
re free this weekend	0.0	0.0	0.0	2.0	0.0000000000	False
weekend if you re	0.0	0.0	0.0	0.0	0.0000000000	False
re free on saturday	0.0	0.0	0.0	2.0	0.0000000000	False
watch tv or search	0.0	0.0	0.0	2.0	0.0000000000	False
search online for urban	0.0	0.0	0.0	2.0	0.0000000000	False
online for urban challenge	0.0	0.0	0.0	2.0	0.0000000000	False
fun thing to watch	0.0	0.0	0.0	2.0	0.0000000000	False
cool demo or instance	0.0	0.0	0.0	2.0	0.0000000000	False
died a few seconds	0.0	0.0	0.0	2.0	0.0000000000	False
seconds before class started	0.0	0.0	0.0	2.0	0.0000000000	False
show you the things	0.0	0.0	0.0	2.0	0.0000000000	False
morning and welcome back	0.0	0.0	0.0	2.0	0.0000000000	False
today is actually begin	0.0	0.0	0.0	2.0	0.0000000000	False
begin a new chapter	0.0	0.0	0.0	2.0	0.0000000000	False
briefly talk about clustering	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm with a mixture	0.0	0.0	0.0	2.0	0.0000000000	False
describe something called jensen	0.0	0.0	0.0	4.0	0.0000000000	False
derive a general form	0.0	0.0	0.0	2.0	0.0000000000	False
place and different unsupervised	0.0	0.0	0.0	2.0	0.0000000000	False
machine or any application	0.0	0.0	0.0	2.0	0.0000000000	False
application so the cartoons	0.0	0.0	0.0	2.0	0.0000000000	False
draw for supervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
positive and negative crosses	0.0	0.0	0.0	2.0	0.0000000000	False
call it the supervised	0.0	0.0	0.0	2.0	0.0000000000	False
learning because you re	0.0	0.0	0.0	0.0	0.0000000000	False
re sort of told	0.0	0.0	0.0	2.0	0.0000000000	False
told what the right	0.0	0.0	0.0	2.0	0.0000000000	False
supervision in unsupervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
study a different problem	0.0	0.0	0.0	2.0	0.0000000000	False
re given a data	0.0	0.0	0.0	2.0	0.0000000000	False
set with no labels	0.0	0.0	0.0	2.0	0.0000000000	False
labels and no indication	0.0	0.0	0.0	2.0	0.0000000000	False
job of the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to discover structure	0.0	0.0	0.0	2.0	0.0000000000	False
structure in the data	0.0	0.0	0.0	2.0	0.0000000000	False
weeks we ll talk	0.0	0.0	0.0	0.0	0.0000000000	False
talk about a variety	0.0	0.0	0.0	2.0	0.0000000000	False
variety of unsupervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
first unsupervised learning algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ll be an algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
automatically breaks the data	0.0	0.0	0.0	2.0	0.0000000000	False
breaks the data set	0.0	0.0	0.0	2.0	0.0000000000	False
set into different smaller	0.0	0.0	0.0	2.0	0.0000000000	False
applications just to rattle	0.0	0.0	0.0	2.0	0.0000000000	False
better-known ones i guess	0.0	0.0	0.0	2.0	0.0000000000	False
guess in biology application	0.0	0.0	0.0	2.0	0.0000000000	False
application you often cross	0.0	0.0	0.0	2.0	0.0000000000	False
cross the different things	0.0	0.0	0.0	2.0	0.0000000000	False
genes and they cluster	0.0	0.0	0.0	2.0	0.0000000000	False
cluster the different genes	0.0	0.0	0.0	2.0	0.0000000000	False
genes together in order	0.0	0.0	0.0	2.0	0.0000000000	False
examine them and understand	0.0	0.0	0.0	2.0	0.0000000000	False
understand the biological function	0.0	0.0	0.0	2.0	0.0000000000	False
common application of clustering	0.0	0.0	0.0	2.0	0.0000000000	False
clustering is market research	0.0	0.0	0.0	2.0	0.0000000000	False
market research so imagine	0.0	0.0	0.0	2.0	0.0000000000	False
common practice to apply	0.0	0.0	0.0	2.0	0.0000000000	False
practice to apply clustering	0.0	0.0	0.0	2.0	0.0000000000	False
clustering algorithms to break	0.0	0.0	0.0	2.0	0.0000000000	False
customers into different market	0.0	0.0	0.0	2.0	0.0000000000	False
products towards different market	0.0	0.0	0.0	2.0	0.0000000000	False
market segments and target	0.0	0.0	0.0	2.0	0.0000000000	False
target your sales pitches	0.0	0.0	0.0	2.0	0.0000000000	False
specifically to different market	0.0	0.0	0.0	2.0	0.0000000000	False
ll do later today	0.0	0.0	0.0	2.0	0.0000000000	False
clustering algorithm to everyday	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm to everyday group	0.0	0.0	0.0	2.0	0.0000000000	False
everyday group related news	0.0	0.0	0.0	2.0	0.0000000000	False
group related news articles	0.0	0.0	0.0	2.0	0.0000000000	False
articles together to display	0.0	0.0	0.0	2.0	0.0000000000	False
thousand news articles today	0.0	0.0	0.0	2.0	0.0000000000	False
top story of today	0.0	0.0	0.0	2.0	0.0000000000	False
websites on different story	0.0	0.0	0.0	2.0	0.0000000000	False
story of the day	0.0	0.0	0.0	2.0	0.0000000000	False
talks about image segmentation	0.0	0.0	0.0	2.0	0.0000000000	False
group together different subsets	0.0	0.0	0.0	2.0	0.0000000000	False
subsets of the picture	0.0	0.0	0.0	2.0	0.0000000000	False
picture into coherent pieces	0.0	0.0	0.0	2.0	0.0000000000	False
coherent pieces of pixels	0.0	0.0	0.0	2.0	0.0000000000	False
understand what s contained	0.0	0.0	0.0	0.0	0.0000000000	False
contained in the picture	0.0	0.0	0.0	2.0	0.0000000000	False
clustering the next idea	0.0	0.0	0.0	2.0	0.0000000000	False
automatically group the data	0.0	0.0	0.0	2.0	0.0000000000	False
group the data sets	0.0	0.0	0.0	2.0	0.0000000000	False
data sets into coherent	0.0	0.0	0.0	2.0	0.0000000000	False
sets into coherent clusters	0.0	0.0	0.0	2.0	0.0000000000	False
waiting for the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
nt i just start	0.0	0.0	0.0	0.0	0.0000000000	False
out the specific clustering	0.0	0.0	0.0	2.0	0.0000000000	False
show you the animation	0.0	0.0	0.0	4.0	0.0000000000	False
clustering algorithm for finding	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for finding clustering	0.0	0.0	0.0	2.0	0.0000000000	False
input to the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
set which i write	0.0	0.0	0.0	2.0	0.0000000000	False
talking about unsupervised learning	0.0	0.0	0.0	2.0	0.0000000000	False
sense when i show	0.0	0.0	0.0	2.0	0.0000000000	False
animation on my laptop	0.0	0.0	0.0	2.0	0.0000000000	False
re of training data	0.0	0.0	0.0	2.0	0.0000000000	False
steps so the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroid j is closest	0.0	0.0	0.0	2.0	0.0000000000	False
step is called assigning	0.0	0.0	0.0	2.0	0.0000000000	False
point xi to cluster	0.0	0.0	0.0	2.0	0.0000000000	False
picking the cluster centroid	0.0	0.0	0.0	2.0	0.0000000000	False
step is you update	0.0	0.0	0.0	2.0	0.0000000000	False
update the cluster centroids	0.0	0.0	3.99789621318	6.0	0.0000000000	False
bring down the display	0.0	0.0	0.0	2.0	0.0000000000	False
display for the laptop	0.0	0.0	0.0	2.0	0.0000000000	False
k-means algorithm and hope	0.0	0.0	0.0	2.0	0.0000000000	False
michael jordan in berkley	0.0	0.0	0.0	2.0	0.0000000000	False
berkley so these points	0.0	0.0	0.0	2.0	0.0000000000	False
green are my data	0.0	0.0	0.0	2.0	0.0000000000	False
randomly initialize a pair	0.0	0.0	0.0	2.0	0.0000000000	False
pair of cluster centroids	0.0	0.0	0.0	2.0	0.0000000000	False
blue crosses to note	0.0	0.0	0.0	2.0	0.0000000000	False
clusters in this data	0.0	0.0	0.0	2.0	0.0000000000	False
data sets of k-means	0.0	0.0	0.0	2.0	0.0000000000	False
sets of k-means algorithms	0.0	0.0	0.0	2.0	0.0000000000	False
k-means algorithms as follow	0.0	0.0	0.0	2.0	0.0000000000	False
points in my data	0.0	0.0	0.0	2.0	0.0000000000	False
denote that by painting	0.0	0.0	0.0	2.0	0.0000000000	False
blue or red depending	0.0	0.0	0.0	2.0	0.0000000000	False
cross points are painted	0.0	0.0	0.0	2.0	0.0000000000	False
points that i ve	0.0	0.0	0.0	0.0	0.0000000000	False
red dots and compute	0.0	0.0	0.0	2.0	0.0000000000	False
move the cluster centroids	0.0	0.0	0.0	2.0	0.0000000000	False
repeat the same process	0.0	0.0	0.0	2.0	0.0000000000	False
assign all the points	0.0	0.0	0.0	2.0	0.0000000000	False
cross to the color	0.0	0.0	0.0	2.0	0.0000000000	False
blue and similarly red	0.0	0.0	0.0	2.0	0.0000000000	False
points to the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
blue points and compute	0.0	0.0	0.0	2.0	0.0000000000	False
red points and update	0.0	0.0	0.0	2.0	0.0000000000	False
running these two sets	0.0	0.0	0.0	2.0	0.0000000000	False
two sets of k-means	0.0	0.0	0.0	2.0	0.0000000000	False
centroids and the assignment	0.0	0.0	0.0	2.0	0.0000000000	False
assignment of the points	0.0	0.0	0.0	2.0	0.0000000000	False
closest to the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroids will actually remain	0.0	0.0	0.0	2.0	0.0000000000	False
make sure you understand	0.0	0.0	0.0	2.0	0.0000000000	False
understand how the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
maps onto the animation	0.0	0.0	0.0	2.0	0.0000000000	False
two steps this step	0.0	0.0	0.0	2.0	0.0000000000	False
shifting the cluster centroid	0.0	0.0	0.0	2.0	0.0000000000	False
assigned to that cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroid okay okay questions	0.0	0.0	0.0	2.0	0.0000000000	False
converge ? the answer	0.0	0.0	0.0	2.0	0.0000000000	False
define the distortion function	0.0	0.0	0.0	4.0	0.0000000000	False
squared you can define	0.0	0.0	0.0	2.0	0.0000000000	False
function of the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroids and square distances	0.0	0.0	0.0	2.0	0.0000000000	False
points and the cluster	0.0	0.0	0.0	2.0	0.0000000000	False
centroids that they re	0.0	0.0	0.0	0.0	0.0000000000	False
sense as an authorization	0.0	0.0	0.0	2.0	0.0000000000	False
sense is the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
ll repeatedly with respect	0.0	0.0	0.0	2.0	0.0000000000	False
prove is that k-means	0.0	0.0	0.0	2.0	0.0000000000	False
k-means the two steps	0.0	0.0	0.0	2.0	0.0000000000	False
two steps of k-means	0.0	0.0	0.0	2.0	0.0000000000	False
respect a new alternately	0.0	0.0	0.0	2.0	0.0000000000	False
converge in the sense	0.0	0.0	0.0	2.0	0.0000000000	False
clustering s they give	0.0	0.0	0.0	0.0	0.0000000000	False
give the same value	0.0	0.0	0.0	2.0	0.0000000000	False
k-means may actually switch	0.0	0.0	0.0	2.0	0.0000000000	False
value for this objective	0.0	0.0	0.0	2.0	0.0000000000	False
ll just never happen	0.0	0.0	0.0	2.0	0.0000000000	False
randomly pick a number	0.0	0.0	0.0	2.0	0.0000000000	False
work best the number	0.0	0.0	0.0	2.0	0.0000000000	False
clusters in this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
hard to choose automatically	0.0	0.0	0.0	2.0	0.0000000000	False
automatic ways of choosing	0.0	0.0	0.0	2.0	0.0000000000	False
pick of the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of clusters randomly	0.0	0.0	0.0	2.0	0.0000000000	False
randomly and the reason	0.0	0.0	0.0	2.0	0.0000000000	False
problems the true number	0.0	0.0	0.0	2.0	0.0000000000	False
true number of clusters	0.0	0.0	0.0	2.0	0.0000000000	False
actual number of clusters	0.0	0.0	0.0	2.0	0.0000000000	False
right so yes k-means	0.0	0.0	0.0	2.0	0.0000000000	False
function and so k-means	0.0	0.0	0.0	2.0	0.0000000000	False
function is not guaranteed	0.0	0.0	0.0	2.0	0.0000000000	False
initializations and then run	0.0	0.0	0.0	2.0	0.0000000000	False
run clustering a bunch	0.0	0.0	0.0	2.0	0.0000000000	False
value for the distortion	0.0	0.0	0.0	2.0	0.0000000000	False
centroid has no points	0.0	0.0	0.0	2.0	0.0000000000	False
vast majority of applications	0.0	0.0	0.0	2.0	0.0000000000	False
ve seen for k-means	0.0	0.0	0.0	2.0	0.0000000000	False
norm and one norm	0.0	0.0	0.0	2.0	0.0000000000	False
variations on this algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
describe is actually talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about density estimation	0.0	0.0	0.0	2.0	0.0000000000	False
estimation as another k-means	0.0	0.0	0.0	2.0	0.0000000000	False
building off an assembly	0.0	0.0	0.0	2.0	0.0000000000	False
work for an aircraft	0.0	0.0	0.0	2.0	0.0000000000	False
re building aircraft engines	0.0	0.0	0.0	2.0	0.0000000000	False
engines off the assembly	0.0	0.0	0.0	2.0	0.0000000000	False
test these aircraft engines	0.0	0.0	0.0	2.0	0.0000000000	False
aircraft engines and measure	0.0	0.0	0.0	2.0	0.0000000000	False
measure various different properties	0.0	0.0	0.0	2.0	0.0000000000	False
heat and vibrations right	0.0	0.0	0.0	2.0	0.0000000000	False
vibrations right in reality	0.0	0.0	0.0	2.0	0.0000000000	False
amount of heat produced	0.0	0.0	0.0	4.0	0.0000000000	False
heat produced and vibrations	0.0	0.0	0.0	2.0	0.0000000000	False
produced and vibrations produced	0.0	0.0	0.0	2.0	0.0000000000	False
produced and the amount	0.0	0.0	0.0	2.0	0.0000000000	False
rolls off the assembly	0.0	0.0	0.0	4.0	0.0000000000	False
measure the same heat	0.0	0.0	0.0	2.0	0.0000000000	False
heat and vibration properties	0.0	0.0	0.0	2.0	0.0000000000	False
flaw in this aircraft	0.0	0.0	0.0	2.0	0.0000000000	False
typical distribution of features	0.0	0.0	0.0	2.0	0.0000000000	False
raise a red flag	0.0	0.0	0.0	2.0	0.0000000000	False
fly with the engine	0.0	0.0	0.0	2.0	0.0000000000	False
engine so this problem	0.0	0.0	0.0	2.0	0.0000000000	False
problem i just described	0.0	0.0	0.0	2.0	0.0000000000	False
described is an instance	0.0	0.0	0.0	2.0	0.0000000000	False
typical data you re	0.0	0.0	0.0	0.0	0.0000000000	False
unusual transactions to start	0.0	0.0	0.0	2.0	0.0000000000	False
stolen my credit card	0.0	0.0	0.0	2.0	0.0000000000	False
talk about specific algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
specific algorithm for density	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm for density estimation	0.0	0.0	0.0	2.0	0.0000000000	False
works with data sets	0.0	0.0	0.0	2.0	0.0000000000	False
standard text book distributions	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian or a explanation	0.0	0.0	0.0	2.0	0.0000000000	False
model to estimate densities	0.0	0.0	0.0	2.0	0.0000000000	False
imagine maybe a data	0.0	0.0	0.0	2.0	0.0000000000	False
axis and these dots	0.0	0.0	0.0	2.0	0.0000000000	False
dots represent the positions	0.0	0.0	0.0	2.0	0.0000000000	False
positions of the data	0.0	0.0	0.0	2.0	0.0000000000	False
coming from a density	0.0	0.0	0.0	2.0	0.0000000000	False
clear that the picture	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian s that generated	0.0	0.0	0.0	0.0	0.0000000000	False
generated this data set	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian to my crosses	0.0	0.0	0.0	2.0	0.0000000000	False
nt actually have access	0.0	0.0	0.0	0.0	0.0000000000	False
access to these labels	0.0	0.0	0.0	2.0	0.0000000000	False
idea in this model	0.0	0.0	0.0	2.0	0.0000000000	False
re gon na imagine	0.0	0.0	0.0	2.0	0.0000000000	False
distributed multinomial with parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameter are the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
distribution and the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution of xi conditioned	0.0	0.0	0.0	2.0	0.0000000000	False
equations that i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian discriminant analysis algorithm	0.0	0.0	0.0	2.0	0.0000000000	True
analysis with these latent	0.0	0.0	0.0	2.0	0.0000000000	False
explicit if we knew	0.0	0.0	0.0	2.0	0.0000000000	False
suppose for the sake	0.0	0.0	0.0	2.0	0.0000000000	False
estimation you can write	0.0	0.0	0.0	2.0	0.0000000000	False
write down the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
write down the law	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood and do maximum	0.0	0.0	0.0	2.0	0.0000000000	False
estimate all the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of your model	0.0	0.0	0.0	4.0	0.0000000000	False
model does this make	0.0	0.0	0.0	2.0	0.0000000000	False
make sense ? raise	0.0	0.0	0.0	2.0	0.0000000000	False
hand if this makes	0.0	0.0	2.99789621318	6.0	0.0000000000	False
nt raise your hands	0.0	0.0	0.0	0.0	0.0000000000	False
basically any other questions	0.0	0.0	0.0	2.0	0.0000000000	False
playing a similar role	0.0	0.0	0.0	2.0	0.0000000000	False
role to the cross	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian s discriminant analysis	0.0	0.0	0.0	0.0	0.0000000000	False
maximum likeliness estimation parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters but in reality	0.0	0.0	0.0	2.0	0.0000000000	False
guess what the values	0.0	0.0	0.0	2.0	0.0000000000	False
guess at the values	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the rest	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the model	0.0	0.0	0.0	4.0	0.0000000000	False
estimate for the parameters	0.0	0.0	5.99719495091	8.0	0.4233576642	False
parameters for the rest	0.0	0.0	0.0	2.0	0.0000000000	False
likeliness estimation to set	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of the model	0.0	0.0	0.0	2.0	0.0000000000	False
model so the algorithm	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm and it proceeds	0.0	0.0	0.0	2.0	0.0000000000	False
proceeds as follows repeat	0.0	0.0	0.0	2.0	0.0000000000	False
re going to guess	0.0	0.0	0.0	2.0	0.0000000000	False
values of the unknown	0.0	0.0	0.0	2.0	0.0000000000	False
rest of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters in my model	0.0	0.0	0.0	2.0	0.0000000000	False
sum from o equals	0.0	0.0	0.0	4.0	0.0000000000	False
essentially the same thing	0.0	0.0	0.0	2.0	0.0000000000	False
gaussian and the numerator	0.0	0.0	0.0	2.0	0.0000000000	False
numerator and the sum	0.0	0.0	0.0	2.0	0.0000000000	False
terms of the denominator	0.0	0.0	0.0	2.0	0.0000000000	False
estimates of the parameters	0.0	0.0	0.0	4.0	0.0000000000	False
lay down the formulas	0.0	0.0	0.0	2.0	0.0000000000	False
remember was the probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability that we computed	0.0	0.0	0.0	2.0	0.0000000000	False
nt want to call	0.0	0.0	0.0	0.0	0.0000000000	False
commonly use different covariant	0.0	0.0	0.0	2.0	0.0000000000	False
sort of by convention	0.0	0.0	0.0	2.0	0.0000000000	False
sigma i just wrote	0.0	0.0	0.0	2.0	0.0000000000	False
wrote down a lot	0.0	0.0	0.0	2.0	0.0000000000	False
values for the zis	0.0	0.0	0.0	2.0	0.0000000000	False
give you labeled data	0.0	0.0	0.0	2.0	0.0000000000	False
values of the zis	0.0	0.0	0.0	4.0	0.0000000000	False
giving you a data	0.0	0.0	0.0	2.0	0.0000000000	False
set that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
discriminant analysis we figured	0.0	0.0	0.0	2.0	0.0000000000	False
figured out the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
out the maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
estimation and the maximum	0.0	0.0	0.0	2.0	0.0000000000	False
probability that zi equals	0.0	0.0	0.0	4.0	0.0000000000	False
estimate that as sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum of i equals	0.0	0.0	0.0	2.0	0.0000000000	False
equals j and divide	0.0	0.0	0.0	2.0	0.0000000000	False
knew the cross labels	0.0	0.0	0.0	2.0	0.0000000000	False
estimate for the chance	0.0	0.0	0.0	2.0	0.0000000000	False
chance that the labels	0.0	0.0	0.0	2.0	0.0000000000	False
examples your maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
likeliness estimate for probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability of getting examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples in your training	0.0	0.0	0.0	2.0	0.0000000000	False
draw the same data	0.0	0.0	0.0	2.0	0.0000000000	False
cross label is unknown	0.0	0.0	0.0	2.0	0.0000000000	False
guess for the values	0.0	0.0	0.0	2.0	0.0000000000	False
step we computed wij	0.0	0.0	0.0	2.0	0.0000000000	False
guess for the probability	0.0	0.0	0.0	4.0	0.0000000000	False
probability that the point	0.0	0.0	0.0	2.0	0.0000000000	False
probability that this point	0.0	0.0	0.0	4.0	0.0000000000	False
point was a cross	0.0	0.0	0.0	2.0	0.0000000000	False
sum from i equals	0.0	0.0	0.0	2.0	0.0000000000	False
formula for the estimate	0.0	0.0	0.0	2.0	0.0000000000	False
back to the formula	0.0	0.0	0.0	2.0	0.0000000000	False
convey an intuitive sense	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm s make sense	0.0	0.0	0.0	0.0	0.0000000000	False
sense can you raise	0.0	0.0	0.0	2.0	0.0000000000	False
sense now ? cool	0.0	0.0	0.0	2.0	0.0000000000	False
present a broader view	0.0	0.0	0.0	2.0	0.0000000000	False
hour i have today	0.0	0.0	0.0	2.0	0.0000000000	False
describe a general description	0.0	0.0	0.0	2.0	0.0000000000	False
pre-cursor to actually deriving	0.0	0.0	0.0	2.0	0.0000000000	False
jensen s and equality	0.0	0.0	0.0	0.0	0.0000000000	False
function so a function	0.0	0.0	0.0	2.0	0.0000000000	False
function is a convex	0.0	0.0	0.0	2.0	0.0000000000	False
ve written f prime	0.0	0.0	0.0	2.0	0.0000000000	False
written f prime prime	0.0	0.0	0.0	2.0	0.0000000000	False
differentiatable to be convex	0.0	0.0	0.0	2.0	0.0000000000	False
prime should be creating	0.0	0.0	0.0	2.0	0.0000000000	False
applied to the expectation	0.0	0.0	0.0	2.0	0.0000000000	False
equal of 2d expectation	0.0	0.0	0.0	2.0	0.0000000000	False
remember i often drop	0.0	0.0	0.0	2.0	0.0000000000	False
drop the square back	0.0	0.0	0.0	2.0	0.0000000000	False
drop the square brackets	0.0	0.0	0.0	2.0	0.0000000000	False
picture that would explain	0.0	0.0	0.0	2.0	0.0000000000	False
equality is by drawing	0.0	0.0	0.0	2.0	0.0000000000	False
drawing the following picture	0.0	0.0	0.0	2.0	0.0000000000	False
ll illustrate this inequality	0.0	0.0	0.0	2.0	0.0000000000	False
vertical axis we re	0.0	0.0	0.0	0.0	0.0000000000	False
value in the middle	0.0	0.0	0.0	2.0	0.0000000000	False
prime of x makes	0.0	0.0	0.0	2.0	0.0000000000	False
makes than z row	0.0	0.0	0.0	2.0	0.0000000000	False
convex then the inequality	0.0	0.0	0.0	2.0	0.0000000000	False
inequality holds an equality	0.0	0.0	0.0	2.0	0.0000000000	False
variable x always takes	0.0	0.0	0.0	2.0	0.0000000000	False
value okay any questions	0.0	0.0	0.0	2.0	0.0000000000	False
definition for strictly convex	0.0	0.0	0.0	2.0	0.0000000000	False
part of this function	0.0	0.0	0.0	2.0	0.0000000000	False
strictly convexed just means	0.0	0.0	0.0	2.0	0.0000000000	False
nt have a convex	0.0	0.0	0.0	0.0	0.0000000000	False
nt any straight line	0.0	0.0	0.0	0.0	0.0000000000	False
goal is to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters of model right	0.0	0.0	0.0	2.0	0.0000000000	False
goal is to find	0.0	0.0	0.0	2.0	0.0000000000	False
find the maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
data where the likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
defined as something equals	0.0	0.0	0.0	2.0	0.0000000000	False
values of zi parameterized	0.0	0.0	0.0	2.0	0.0000000000	False
performing this maximum likeliness	0.0	0.0	0.0	2.0	0.0000000000	False
maximum likeliness estimation problem	0.0	0.0	0.0	2.0	0.0000000000	False
complicated by the fact	0.0	0.0	0.0	2.0	0.0000000000	False
zis in our model	0.0	0.0	0.0	2.0	0.0000000000	False
model that are unobserved	0.0	0.0	0.0	2.0	0.0000000000	False
axis in this cartoon	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon is the axis	0.0	0.0	0.0	2.0	0.0000000000	False
re trying to maximize	0.0	0.0	0.0	2.0	0.0000000000	False
construct a lower bound	0.0	0.0	5.99719495091	8.0	0.2974358974	False
bound for this law	0.0	0.0	0.0	2.0	0.0000000000	False
law of likelihood function	0.0	0.0	0.0	4.0	0.0000000000	False
bound will be tight	0.0	0.0	0.0	2.0	0.0000000000	False
equality after current guessing	0.0	0.0	0.0	2.0	0.0000000000	False
current guessing the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
parameters and they maximize	0.0	0.0	0.0	2.0	0.0000000000	False
maximize this lower boundary	0.0	0.0	0.0	2.0	0.0000000000	False
lower boundary with respect	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm look at theta	0.0	0.0	0.0	2.0	0.0000000000	False
construct a new lower	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound of theta	0.0	0.0	0.0	2.0	0.0000000000	False
converge to local optimum	0.0	0.0	0.0	2.0	0.0000000000	False
local optimum on theta	0.0	0.0	0.0	2.0	0.0000000000	False
optimum on theta function	0.0	0.0	0.0	2.0	0.0000000000	False
respect to theta sum	0.0	0.0	0.0	2.0	0.0000000000	False
sum over all values	0.0	0.0	0.0	2.0	0.0000000000	False
construct the probability distribution	0.0	0.0	0.0	2.0	0.0000000000	False
ll later go describe	0.0	0.0	0.0	2.0	0.0000000000	False
describe the specific choice	0.0	0.0	0.0	2.0	0.0000000000	False
choice of this distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution over the random	0.0	0.0	0.0	2.0	0.0000000000	False
function so that tells	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the expected	0.0	0.0	0.0	4.0	0.0000000000	False
expected value of log	0.0	0.0	0.0	2.0	0.0000000000	False
function form of jensen	0.0	0.0	0.0	2.0	0.0000000000	False
equality and so continuing	0.0	0.0	0.0	2.0	0.0000000000	False
summary of a log	0.0	0.0	0.0	2.0	0.0000000000	False
log and an expectation	0.0	0.0	0.0	2.0	0.0000000000	False
value of the log	0.0	0.0	0.0	2.0	0.0000000000	False
lastly just to expand	0.0	0.0	0.0	2.0	0.0000000000	False
expand out this formula	0.0	0.0	0.0	2.0	0.0000000000	False
distribution let s denote	0.0	0.0	0.0	0.0	0.0000000000	False
probability of that value	0.0	0.0	0.0	2.0	0.0000000000	False
value of z times	0.0	0.0	0.0	2.0	0.0000000000	False
right that s sort	0.0	0.0	0.0	0.0	0.0000000000	False
sort of the definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of a random	0.0	0.0	0.0	2.0	0.0000000000	False
step to this step	0.0	0.0	0.0	2.0	0.0000000000	False
ve been using distribution	0.0	0.0	0.0	2.0	0.0000000000	False
distribution qi to denote	0.0	0.0	0.0	2.0	0.0000000000	False
expected value with respect	0.0	0.0	0.0	2.0	0.0000000000	False
respect to a random	0.0	0.0	0.0	2.0	0.0000000000	False
random variable z joined	0.0	0.0	0.0	2.0	0.0000000000	False
joined from the distribution	0.0	0.0	0.0	2.0	0.0000000000	False
general when you re	0.0	0.0	0.0	0.0	0.0000000000	False
re doing maximum likelihood	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of the data	0.0	0.0	0.0	2.0	0.0000000000	False
previously we said probability	0.0	0.0	0.0	2.0	0.0000000000	False
probability of the data	0.0	0.0	0.0	4.0	0.0000000000	False
bound on the law	0.0	0.0	0.0	4.0	0.0000000000	False
theta are the parameters	0.0	0.0	0.0	2.0	0.0000000000	False
function of your parameters	0.0	0.0	0.0	2.0	0.0000000000	False
likelihood of your parameters	0.0	0.0	0.0	2.0	0.0000000000	False
theta is lower bounded	0.0	0.0	0.0	2.0	0.0000000000	False
bounded by this thing	0.0	0.0	0.0	2.0	0.0000000000	False
cartoon of repeatedly constructing	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound and optimizing	0.0	0.0	0.0	2.0	0.0000000000	False
optimizing the lower bound	0.0	0.0	0.0	4.0	0.0000000000	False
bound for the law	0.0	0.0	0.0	2.0	0.0000000000	False
current value for theta	0.0	0.0	0.0	4.0	0.0000000000	False
theta so just refrain	0.0	0.0	0.0	2.0	0.0000000000	False
construct some lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
bound to be tight	0.0	0.0	0.0	2.0	0.0000000000	False
equal to the law	0.0	0.0	0.0	2.0	0.0000000000	False
optimize my lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
nt think i ve	0.0	0.0	0.0	0.0	0.0000000000	False
bound is a concave	0.0	0.0	0.0	2.0	0.0000000000	False
concave function of theta	0.0	0.0	0.0	4.0	0.0000000000	False
equality if the random	0.0	0.0	0.0	2.0	0.0000000000	False
inside is a constant	0.0	0.0	0.0	2.0	0.0000000000	False
right if you re	0.0	0.0	0.0	0.0	0.0000000000	False
re taking an expectation	0.0	0.0	0.0	2.0	0.0000000000	False
respect to constant valued	0.0	0.0	0.0	2.0	0.0000000000	False
theta and just normalize	0.0	0.0	0.0	2.0	0.0000000000	False
skipping here to show	0.0	0.0	0.0	2.0	0.0000000000	False
ll just be convinced	0.0	0.0	0.0	2.0	0.0000000000	False
convinced it s true	0.0	0.0	0.0	0.0	0.0000000000	False
steps that i skipped	0.0	0.0	0.0	2.0	0.0000000000	False
out in the lecture	0.0	0.0	0.0	2.0	0.0000000000	False
definition of conditional probability	0.0	0.0	0.0	2.0	0.0000000000	False
algorithm has two steps	0.0	0.0	0.0	2.0	0.0000000000	False
formula we just worked	0.0	0.0	0.0	2.0	0.0000000000	False
created a lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
current value of theta	0.0	0.0	0.0	4.0	0.0000000000	False
optimize that lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound with respect	0.0	0.0	0.0	4.0	0.0000000000	False
respect to our parameters	0.0	0.0	0.0	2.0	0.0000000000	False
step that i wrote	0.0	0.0	0.0	2.0	0.0000000000	False
constructs this lower bound	0.0	0.0	0.0	2.0	0.0000000000	False
lower bound and makes	0.0	0.0	0.0	2.0	0.0000000000	False
data okay so lots	0.0	0.0	0.0	2.0	0.0000000000	False
lecture let s check	0.0	0.0	0.0	0.0	0.0000000000	False
questions before we close	0.0	0.0	0.0	2.0	0.0000000000	False
close no okay cool	0.0	0.0	0.0	2.0	0.0000000000	False
wrap up for today	0.0	0.0	0.0	2.0	0.0000000000	False
announcement of sorts	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
ago that stanford	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
submitted an entry	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
darpa grand challenge	0.00264177103744	0.0	0.0	1.58496250072	0.0000000000	False
competition to build	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
build a car	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
car to drive	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
grand challenge phase	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
stanford the team	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
colleagues sebastian thrun	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
ll be racing	0.0	0.0	0.0	1.58496250072	0.0000000000	False
racing another autonomous	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
car that incorporates	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
incorporates many tools	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
midst of traffic	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
traffic and avoid	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
avoid other cars	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
cars and carry	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
out the sort	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
sort of mission	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
free this weekend	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
free on saturday	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
online for urban	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
thing to watch	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
demo or instance	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
machines in action	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
seconds before class	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
start to talk	0.00071463434039	0.0	0.0	1.58496250072	0.0000000000	False
talk about clustering	0.0	0.0	0.0	0.0	0.0000000000	False
mixture of model	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
model to describe	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
jensen and equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
derive a general	0.00132088551872	0.0	0.0	0.0	0.0000000000	False
expectation maximization algorithm	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	True
algorithm we sort	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
draw for supervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
positive and negative	0.00071463434039	0.0	0.0	0.0	0.0000000000	False
sort of told	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
right cross label	0.0	0.0	0.0	1.58496250072	0.0000000000	False
supervision in unsupervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
problem you re	0.0	0.0	0.0	0.0	0.0000000000	False
comprises a set	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
set of points	0.00252132848065	0.0	4.99789621318	4.75488750216	0.0000000000	False
points you re	0.0	0.0	0.0	0.0	0.0000000000	False
algorithm to discover	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
couple of weeks	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
variety of unsupervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
unsupervised learning algorithms	0.00264177103744	0.0	0.0	1.58496250072	0.0000000000	False
types of structure	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
two different crosses	0.0	0.0	0.0	1.58496250072	0.0000000000	False
first unsupervised learning	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
breaks the data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
variety of applications	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guess in biology	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
order to examine	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
understand the biological	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
application of clustering	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
clustering is market	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
research so imagine	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
practice to apply	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
apply clustering algorithms	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
algorithms to break	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
break your database	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
database of customers	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
target your products	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
segments and target	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
target your sales	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm to everyday	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
everyday group related	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
group related news	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
related news articles	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
thousand news articles	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
news articles today	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
story of today	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
solid actually talks	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
talks about image	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
picture and group	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
picture into coherent	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
pieces of pixels	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
group the data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
sets into coherent	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
start to write	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
out the specific	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
specific clustering algorithm	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
k-means clustering algorithm	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
algorithm for finding	0.00114356841605	0.0	0.0	0.0	0.0000000000	False
inset the input	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
unlabeled data set	0.00487203332366	0.0	1.99789621318	4.75488750216	0.0000000000	False
re now talking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
talking about unsupervised	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
make a bit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
bit more sense	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
laptop to initialize	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
initialize a set	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
re of training	0.0	0.0	0.0	0.0	0.0000000000	False
repeat until convergence	0.0022871368321	0.0	0.0	3.16992500144	0.0000000000	False
assigning your point	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
point and picking	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
picking the cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
update the cluster	0.00487203332366	0.0	3.99789621318	0.0	0.0000000000	False
laptop ? excuse	0.0	0.0	0.0	1.58496250072	0.0000000000	False
algorithm and hope	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
hope the animation	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
animation will make	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
make more sense	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
jordan in berkley	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
points in green	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
initialize a pair	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
pair of cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
crosses to note	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
note the positions	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
positions of new1	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
new1 and new2	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
sets of k-means	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
algorithms as follow	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
two cluster centroids	0.0	0.0	0.0	1.58496250072	0.0000000000	False
dots either blue	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
blue or red	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
closer cluster centroid	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
blue cross points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
points are painted	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
step is updating	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ve painted blue	0.0	0.0	0.0	1.58496250072	0.0000000000	False
blue and compute	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
compute the average	0.00649604443155	0.0	3.99719495091	6.33985000288	0.2056737589	False
dots and compute	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
move the cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
points and assign	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
assignments of points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll again compute	0.0	0.0	0.0	1.58496250072	0.0000000000	False
points and compute	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
points and update	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm i wrote	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
steps this step	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
assigning the points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
shifting the cluster	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
k-means is guaranteed	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guaranteed to converge	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
define the distortion	0.0	0.0	0.0	0.0	0.0000000000	False
centroids and square	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
nt really prove	0.0	0.0	0.0	0.0	0.0000000000	False
show that k-means	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
repeatedly with respect	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
steps of k-means	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimizing this function	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
function with respect	0.00114356841605	0.0	0.0	1.58496250072	0.0000000000	False
extremely unlikely case	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
objective function k-means	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
converge another question	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
choose the number	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
number of clusters	0.0113680777552	0.0	7.99438990182	11.094737505	0.2423398329	False
people apply k-means	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
pick a number	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
clusters and pick	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
hard to choose	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
ways of choosing	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
problems the true	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
clusters is sort	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
sort of ambiguous	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
data point points	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
k-means is susceptible	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
susceptible to local	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
multiple random initializations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
clustering a bunch	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
bunch of times	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
times and pick	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
pick the solution	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
solution that ended	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
majority of applications	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
applications i ve	0.0	0.0	0.0	0.0	0.0000000000	False
longer to describe	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
closely related problem	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
talk about density	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
guys that worked	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
aircraft engine building	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
re building aircraft	0.0	0.0	0.0	0.0	0.0000000000	False
building aircraft engines	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
aircraft engines roll	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
test these aircraft	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
engines and measure	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
write these properties	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
properties as heat	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
heat and vibrations	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
right in reality	0.0	0.0	0.0	0.0	0.0000000000	False
measure different vibrations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll just write	0.0	0.0	0.0	1.58496250072	0.0000000000	False
write the amount	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
amount of heat	0.00324802221578	0.0	0.0	0.0	0.0000000000	False
produced and vibrations	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
estimate the density	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
amount of vibrations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
undergo further inspections	0.0	0.0	0.0	1.58496250072	0.0000000000	False
distribution of features	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
build a model	0.0022871368321	0.0	0.0	3.16992500144	0.0000000000	False
raise a red	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
anomaly aircraft engine	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
data you re	0.0	0.0	0.0	0.0	0.0000000000	False
transactions to start	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
stolen my credit	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
talk about specific	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm for density	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
works with data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
nt really fall	0.0	0.0	0.0	0.0	0.0000000000	False
standard text book	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
text book distributions	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
model to estimate	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
describe the algorithm	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
algorithm a bit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
represent the positions	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
two gaussian distributions	0.0	0.0	0.0	1.58496250072	0.0000000000	False
mixture of gaussian	0.0	0.0	3.99649368864	7.92481250361	0.4233576642	False
gaussian s model	0.0	0.0	0.0	0.0	0.0000000000	False
two separate gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
generated this data	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
put a gaussian	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
algorithm to fit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
fit this mixture	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
latent random variable	0.00649604443155	0.0	2.99719495091	6.33985000288	0.0000000000	False
synonymous with hidden	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
hidden or unobserved	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
chamber of probability	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
multinomial with parameters	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
gaussian discriminant analysis	0.00571784208025	0.0	5.99649368864	6.33985000288	0.2974358974	True
discriminant analysis algorithm	0.00132088551872	0.0	0.0	0.0	0.0000000000	False
guess supervised learning	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ve now replaced	0.0	0.0	0.0	1.58496250072	0.0000000000	False
unobserved random variables	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
make the link	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
sake of argument	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
likelihood the parameters	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
knew the value	0.00324802221578	0.0	3.99789621318	4.75488750216	0.0000000000	False
law of likelihood	0.0145297407059	0.0	12.992286115	14.2646625065	0.3251783894	True
sense ? raise	0.0	0.0	0.0	0.0	0.0000000000	False
raise your hand	0.00230147544123	0.0	3.99719495091	6.33985000288	0.0000000000	False
makes sense cool	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
playing a similar	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
labels in gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian s discriminant	0.0	0.0	0.0	0.0	0.0000000000	False
maximum likeliness estimation	0.014616099971	0.0	6.99368863955	12.6797000058	0.2556317336	True
likeliness estimation parameters	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
specific bootstrap procedure	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guessed to fit	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
fit the parameters	0.00114356841605	0.0	0.0	1.58496250072	0.0000000000	False
ll actually iterate	0.0	0.0	0.0	1.58496250072	0.0000000000	False
estimation to set	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
set even parameters	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
guess the values	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
compute the probability	0.00487203332366	0.0	3.99789621318	4.75488750216	0.0000000000	False
probability that point	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
sort of concrete	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
step is sort	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
gaussian density right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
divided by sum	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
update your estimates	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll just lay	0.0	0.0	0.0	1.58496250072	0.0000000000	False
maximum likelihood estimation	0.00168088565377	0.0	0.0	3.16992500144	0.0000000000	False
formulas on top	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
computed that point	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
call it cluster	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
covariant matrix sigma	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
lot of equations	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
give you labeled	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
labeled data sets	0.00162401110789	0.0	2.99719495091	6.33985000288	0.0000000000	False
analysis we figured	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
out the maximum	0.00132088551872	0.0	0.0	0.0	0.0000000000	False
parameters of gda	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
parameters for gda	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
indicator zi equals	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
re deriving gda	0.0	0.0	0.0	1.58496250072	0.0000000000	False
knew the cross	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
versus the negative	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
fraction of examples	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
examples your maximum	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
estimate for probability	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
examples from cross	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
estimation for gaussian	0.0	0.0	0.0	1.58496250072	0.0000000000	False
set of dots	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
observe the xis	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
zis are unknown	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
label is unknown	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm we re	0.0	0.0	0.0	0.0	0.0000000000	False
step we computed	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
current best guess	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
formula of estimating	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
sum of wij	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
wij so wij	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
wij is right	0.0	0.0	0.0	1.58496250072	0.0000000000	False
right the probability	0.0	0.0	0.0	1.58496250072	0.0000000000	False
point i belongs	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
belongs to gaussian	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
gaussian or belongs	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
belongs to cross	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
replaces the wijs	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
convey an intuitive	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
algorithm s make	0.0	0.0	0.0	0.0	0.0000000000	False
present a broader	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
specially to make	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
remaining half hour	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
describe a general	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
written f prime	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
drop the square	0.00324802221578	0.0	0.0	1.58496250072	0.0000000000	False
ll often drop	0.0	0.0	0.0	1.58496250072	0.0000000000	False
draw a picture	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
remember the sign	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
probability of one-half	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
illustrate this inequality	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
axis we re	0.0	0.0	0.0	0.0	0.0000000000	False
holds an equality	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
constant with probability	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
strictly convex function	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
inequality to hold	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
hold its equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
convexed just means	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
straight line portion	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
nt any straight	0.0	0.0	0.0	0.0	0.0000000000	False
problem was face	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
maximize the law	0.00264177103744	0.0	0.0	3.16992500144	0.0000000000	False
parameters of model	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
find the maximum	0.000920175286124	0.0	0.0	0.0	0.0000000000	False
likelihood is defined	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
data as usual	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
parameterized by data	0.00487203332366	0.0	5.99789621318	4.75488750216	0.0000000000	False
taking our model	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
performing this maximum	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
likeliness estimation problem	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
likelihood of theta	0.00396265655617	0.0	2.99789621318	4.75488750216	0.0000000000	False
maximizing our derivatives	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
initializes some value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
value of theta	0.0	0.0	3.99789621318	1.58496250072	0.0000000000	False
algorithm will end	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
construct a lower	0.00649604443155	0.0	5.99719495091	0.0	0.2974358974	False
tight of equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
equality after current	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
guessing the parameters	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
maximize this lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
boundary with respect	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
respect to theta	0.0022871368321	0.0	0.0	1.58496250072	0.0000000000	False
bound of theta	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
converge to local	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimum on theta	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
cartoon that displays	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
make that formal	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
maximize with respect	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
multiply and divide	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
construct the probability	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
describe the specific	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
value of log	0.0	0.0	0.0	0.0	0.0000000000	False
concave function form	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
form of jensen	0.0	0.0	0.0	0.0	0.0000000000	False
out this formula	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
equal to sum	0.00114356841605	0.0	0.0	1.58496250072	0.0000000000	False
denote the distribution	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
value with respect	0.0	0.0	0.0	0.0	0.0000000000	False
variable z joined	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
re doing maximum	0.0	0.0	0.0	0.0	0.0000000000	False
choose the parameters	0.000920175286124	0.0	0.0	1.58496250072	0.0000000000	False
parameters that maximizes	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
maximizes the probability	0.00132088551872	0.0	0.0	1.58496250072	0.0000000000	False
likelihood of parameters	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
wanted to maximize	0.00162401110789	0.0	0.0	3.16992500144	0.0000000000	False
ve know constructed	0.0	0.0	0.0	1.58496250072	0.0000000000	False
likelihood of data	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
function of theta	0.00305327978867	0.0	6.99719495091	3.16992500144	0.0000000000	False
ve just shown	0.0	0.0	0.0	1.58496250072	0.0000000000	False
theta is lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
thing okay remember	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
remember that cartoon	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
bound and optimizing	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimizing the lower	0.00324802221578	0.0	0.0	0.0	0.0000000000	False
likelihood for theta	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
hold with equality	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
value for theta	0.0	0.0	0.0	0.0	0.0000000000	False
construct some lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimize my lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
true objective function	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
function is concave	0.0	0.0	0.0	1.58496250072	0.0000000000	False
models we work	0.00324802221578	0.0	0.0	3.16992500144	0.0000000000	False
law of bound	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
right in general	0.0	0.0	0.0	1.58496250072	0.0000000000	False
choose a value	0.0	0.0	0.0	1.58496250072	0.0000000000	False
back to jensen	0.0	0.0	0.0	1.58496250072	0.0000000000	False
random variable inside	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
taking an expectation	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
expectation with respect	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
respect to constant	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
constant valued variables	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
zis must sum	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
parameterized by theta	0.0022871368321	0.0	0.0	3.16992500144	0.0000000000	False
normalize the sum	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
definition of conditional	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
summarize the algorithm	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
choose the distributions	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
step we ve	0.0	0.0	0.0	0.0	0.0000000000	False
ve now created	0.0	0.0	0.0	1.58496250072	0.0000000000	False
created a lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
optimize that lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
bound with respect	0.00324802221578	0.0	0.0	0.0	0.0000000000	False
ll probably show	0.0	0.0	0.0	1.58496250072	0.0000000000	False
gaussian s algorithm	0.0	0.0	0.0	0.0	0.0000000000	False
constructs this lower	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
bound and makes	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
respect to data	0.00162401110789	0.0	0.0	1.58496250072	0.0000000000	False
ll continue talking	0.0	0.0	0.0	1.58496250072	0.0000000000	False
good morning	0.000767158480412	0.0	0.0	2.0	0.0000000000	False
quick announcement	0.000560295217923	0.0	0.0	0.0	0.0000000000	False
stanford submitted	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
darpa grand	0.00176118069163	0.0	0.0	1.0	0.0000000000	False
grand challenge	0.00176118069163	0.0	0.0	1.0	0.0000000000	False
challenge phase	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
sebastian thrun	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
autonomous car	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
search online	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
urban challenge	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
fun thing	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
cool demo	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
laptop died	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
class started	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
special case	0.0025767666438	0.0	1.99649368864	5.0	0.4233576642	False
expectation maximization	0.00216534814385	0.0	0.0	1.0	0.0000000000	False
general form	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
maximization algorithm	0.00216534814385	0.0	0.0	0.0	0.0000000000	False
unsupervised machine	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
data set	0.00987279515133	0.0	15.9831697055	23.0	0.3454339195	False
negative crosses	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
supervised learning	0.00203551985911	0.0	6.9950911641	6.0	0.0000000000	False
re sort	0.0	0.0	0.0	0.0	0.0000000000	False
right cross	0.0	0.0	0.0	0.0	0.0000000000	False
cross label	0.0086613925754	0.0	3.99438990182	7.0	0.5576923077	False
unsupervised learning	0.00352236138326	1.0	4.99719495091	3.0	0.0000000000	True
right answers	0.0	0.0	0.0	2.0	0.0000000000	False
discover structure	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
learning algorithms	0.000716422983625	0.0	0.0	1.0	0.0000000000	False
data lives	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
clustering algorithm	0.00528354207489	0.0	8.99579242637	5.0	0.2917505030	True
smaller clusters	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
biology application	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
biological function	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
common application	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
market research	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
customer database	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
customers behave	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
common practice	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
apply clustering	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
market segments	0.00264177103744	0.0	2.99789621318	2.0	0.0000000000	False
sales pitches	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
everyday group	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
group related	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
related news	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
news articles	0.00324802221578	0.0	5.99789621318	2.0	0.0000000000	False
thousand news	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
articles today	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
top story	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
image segmentation	0.00108267407193	1.0	0.0	0.0	0.0000000000	False
coherent pieces	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
automatically group	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
coherent clusters	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
specific clustering	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
k-means clustering	0.00216534814385	0.0	0.0	1.0	0.0000000000	False
finding clustering	0.0	0.0	0.0	0.0	0.0000000000	False
unlabeled data	0.00324802221578	0.0	1.99789621318	0.0	0.0000000000	False
k-means algorithm	0.00324802221578	0.0	5.99789621318	2.0	0.0000000000	True
cluster centroids	0.0216534814385	0.0	21.9859747546	19.0	0.2145877378	False
training data	0.000515353328761	0.0	0.0	0.0	0.0000000000	False
inch chopped	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
michael jordan	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
data points	0.0036807011445	0.0	2.99579242637	5.0	0.4489164087	False
blue crosses	0.00324802221578	0.0	5.99789621318	2.0	0.0000000000	False
green dots	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
closer cluster	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
cross points	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
blue dots	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
red dots	0.00216534814385	0.0	0.0	1.0	0.0000000000	False
respective locations	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
color blue	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
similarly red	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
blue points	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
red points	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
points closest	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
closest centroid	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
points assigned	0.00176118069163	0.0	0.0	2.0	0.0000000000	False
algorithm converge	0.0	0.0	0.0	1.0	0.0000000000	False
distortion function	0.00324802221578	0.0	3.99789621318	1.0	0.0000000000	False
cluster assignments	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
square distances	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
authorization algorithm	0.000880590345815	0.0	0.0	1.0	0.0000000000	False
multiple clustering	0.0	0.0	0.0	1.0	0.0000000000	False
objective function	0.0012269003815	0.0	0.0	1.0	0.0000000000	False
function k-means	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
vast majority	0.00152475788807	0.0	0.0	1.0	0.0000000000	False
choose automatically	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
automatic ways	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
clusters randomly	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
clustering problems	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
true number	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
actual number	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
point points	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
convex function	0.00440295172907	0.0	6.99579242637	5.0	0.4233576642	True
non-convex function	0.000880590345815	0.0	0.0	1.0	0.0000000000	False
local optimal	0.000762378944034	0.0	0.0	2.0	0.0000000000	False
multiple random	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
random initializations	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
lowest value	0.0	0.0	0.0	1.0	0.0000000000	False
infinity norm	0.0	0.0	0.0	2.0	0.0000000000	False
related problem	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
density estimation	0.00216534814385	1.0	0.0	1.0	0.0000000000	False
aircraft engine	0.0086613925754	0.0	15.9943899018	7.0	0.2116788321	False
engine building	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
aircraft company	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
building aircraft	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
assembly line	0.00324802221578	0.0	5.99789621318	3.0	0.0000000000	False
engines roll	0.00216534814385	0.0	0.0	0.0	0.0000000000	False
vibrations right	0.0	0.0	0.0	0.0	0.0000000000	False
heat produced	0.00216534814385	0.0	0.0	1.0	0.0000000000	False
vibrations produced	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
joint distribution	0.00339253309852	0.0	5.99649368864	5.0	0.4233576642	False
vibration properties	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
undetected flaw	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
typical distribution	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
red flag	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
anomaly aircraft	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
anomaly detection	0.00324802221578	1.0	5.99789621318	3.0	0.0000000000	False
training set	0.000767158480412	0.0	0.0	2.0	0.0000000000	False
typical data	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
low probability	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
security applications	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
unusual transactions	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
credit card	0.00152475788807	0.0	0.0	1.0	0.0000000000	False
specific algorithm	0.000762378944034	1.0	0.0	0.0	0.0000000000	False
standard text	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
text book	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
book distributions	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
estimate densities	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
unusual shapes	0.0	0.0	0.0	1.0	0.0000000000	False
horizontal access	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
dots represent	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
gaussian distributions	0.00112059043585	0.0	0.0	1.0	0.0000000000	False
specific model	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
separate gaussian	0.0	0.0	0.0	0.0	0.0000000000	False
latent random	0.0043306962877	0.0	2.99719495091	0.0	0.4233576642	False
multinomial distribution	0.000880590345815	0.0	0.0	1.0	0.0000000000	False
covariant sigler	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
gaussian discriminant	0.00381189472017	0.0	5.99649368864	2.0	0.3302961276	False
discriminant analysis	0.00991092627244	0.0	16.9908835905	12.0	0.3198529412	False
analysis algorithm	0.000762378944034	0.0	0.0	0.0	0.0000000000	False
random variables	0.00530500579371	0.0	6.99158485273	11.0	0.4434250765	False
unobserved random	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
maximum likeliness	0.0108267407193	0.0	9.99158485273	10.0	0.2593917710	False
make sense	0.00109735666993	0.0	5.99579242637	6.0	0.0000000000	False
sense cool	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
similar role	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
likeliness estimation	0.00974406664733	0.0	6.99368863955	7.0	0.2556317336	False
estimation parameters	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
specific bootstrap	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
bootstrap procedure	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
unknown zis	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
set wij	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
gaussian number	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
gaussian density	0.000678506619704	0.0	0.0	0.0	0.0000000000	False
density right	0.0	0.0	0.0	0.0	0.0000000000	False
similar terms	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
denominator excuse	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
maximization step	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
maximum likelihood	0.00103070665752	0.0	0.0	1.0	0.0000000000	False
likelihood estimation	0.00112059043585	0.0	0.0	0.0	0.0000000000	False
slight difference	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
covariant matrix	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
matrix sigma	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
labeled data	0.00108267407193	0.0	2.99719495091	2.0	0.0000000000	False
equals sum	0.000880590345815	0.0	0.0	1.0	0.0000000000	False
deriving gda	0.00216534814385	0.0	0.0	0.0	0.0000000000	False
positive versus	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
computed wij	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
current hypothesis	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
cross versus	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
indicator functions	0.000560295217923	0.0	0.0	1.0	0.0000000000	False
intuitive sense	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
broader view	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
general description	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
general view	0.00176118069163	0.0	0.0	2.0	0.0000000000	False
prime prime	0.00216534814385	0.0	0.0	1.0	0.0000000000	False
square back	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
square brackets	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
worth probability	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
probability one-half	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
expected value	0.0	0.0	15.9915848527	11.0	0.2447257384	False
horizontal axis	0.00112059043585	0.0	0.0	2.0	0.0000000000	False
vertical axis	0.000613450190749	0.0	0.0	1.0	0.0000000000	False
percent chance	0.00216534814385	0.0	0.0	2.0	0.0000000000	False
double prime	0.00203551985911	0.0	5.99789621318	3.0	0.0000000000	False
strictly convex	0.00757871850348	0.0	13.9950911641	6.0	0.2917505030	False
inequality holds	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
straight line	0.00142926868078	0.0	5.99789621318	2.0	0.0000000000	False
line portion	0.00216534814385	0.0	0.0	0.0	0.0000000000	False
general version	0.000880590345815	0.0	0.0	1.0	0.0000000000	False
model right	0.0	0.0	0.0	0.0	0.0000000000	False
parameters data	0.000678506619704	0.0	0.0	1.0	0.0000000000	False
estimation problem	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
lower bound	0.0129604420486	0.0	30.9873772791	17.0	0.2286036036	False
likelihood function	0.00176118069163	0.0	0.0	0.0	0.0000000000	False
current guessing	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
lower boundary	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
local optimum	0.000678506619704	0.0	0.0	0.0	0.0000000000	False
theta function	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
theta sum	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
probability distribution	0.00154605998628	0.0	2.99789621318	2.0	0.0000000000	False
specific choice	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
log function	0.00108267407193	0.0	0.0	2.0	0.0000000000	False
concave function	0.00541337035963	0.0	7.99649368864	4.0	0.3302961276	True
function form	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
previous expression	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
right right	0.0	0.0	0.0	1.0	0.0000000000	False
data comprises	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
parameters theta	0.00168088565377	0.0	5.99789621318	3.0	0.0000000000	False
last piece	0.0	0.0	0.0	1.0	0.0000000000	False
current value	0.0	0.0	7.99719495091	2.0	0.3901345291	False
previous cartoon	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
true objective	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
great question	0.000880590345815	0.0	0.0	1.0	0.0000000000	False
re right	0.0	0.0	0.0	1.0	0.0000000000	False
variable inside	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
constant right	0.0	0.0	0.0	1.0	0.0000000000	False
valued variables	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
right thing	0.0	0.0	0.0	1.0	0.0000000000	False
actual steps	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
lecture notes	0.000515353328761	0.0	0.0	1.0	0.0000000000	False
conditional probability	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
worked out	0.000383579240206	0.0	0.0	1.0	0.0000000000	False
general template	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
step responded	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
step constructs	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
step optimizes	0.00108267407193	0.0	0.0	1.0	0.0000000000	False
good	5.45806245155e-05	0.0	0.0	0.0	0.0000000000	False
morning	0.000383579240206	0.0	0.0	0.0	0.0000000000	False
quick	0.000146577531429	0.0	0.0	0.0	0.0000000000	False
announcement	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
sorts	0.000529825540649	0.0	0.0	0.0	0.4133016627	False
two	0.0	0.0	0.0	0.0	0.3394402036	False
years	0.00011211852588	0.0	0.0	0.0	0.0000000000	False
ago	0.000411366464639	0.0	0.0	0.0	0.0000000000	False
stanford	0.000613450190749	0.0	0.0	0.0	0.0000000000	False
submitted	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
entry	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
darpa	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
grand	0.000613450190749	0.0	0.0	0.0	0.0000000000	False
challenge	0.00101775992956	0.0	0.0	0.0	0.0000000000	False
competition	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
build	0.000600000225079	0.0	0.0	0.0	0.3805774278	False
car	0.00135701323941	0.0	0.0	0.0	0.0000000000	False
drive	0.000476422893593	0.0	0.0	0.0	0.0000000000	False
desert	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
weekend	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
phase	0.000339253309852	0.0	0.0	0.0	0.0000000000	False
team	0.000476422893593	0.0	0.0	0.0	0.0000000000	False
colleagues	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
sebastian	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
thrun	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
ll	0.0	0.0	0.0	0.0	0.0000000000	False
racing	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
autonomous	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
incorporates	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
tools	0.000179105745906	0.0	0.0	0.0	0.0000000000	False
machines	0.000292587301304	0.0	0.0	0.0	0.0000000000	False
midst	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
traffic	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
avoid	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
carry	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
out	0.0	0.0	0.0	0.0	0.5209580838	False
mission	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
re	0.0	0.0	0.0	0.0	0.0000000000	False
free	0.000442083816142	0.0	0.0	0.0	0.0000000000	False
saturday	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
watch	0.000515353328761	0.0	0.0	0.0	0.0000000000	False
search	0.000128332175313	0.0	0.0	0.0	0.0000000000	False
online	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
urban	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
fun	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
thing	0.0	0.0	0.0	0.0	0.4685816876	False
cool	0.00066975085087	0.0	0.0	0.0	0.0000000000	False
demo	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
instance	0.000100955171055	0.0	0.0	0.0	0.0000000000	False
action	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
laptop	0.00103070665752	0.0	0.0	0.0	0.5370370370	False
died	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
seconds	0.000381189472017	0.0	0.0	0.0	0.5576923077	False
class	4.07558108191e-05	0.0	0.0	0.0	0.0000000000	False
started	0.0	0.0	0.0	0.0	0.5370370370	False
show	0.000284778505414	0.0	0.0	0.0	0.3570451436	False
blackboard	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
back	0.000325149486172	0.0	0.0	0.0	0.5065502183	False
today	0.000151665455683	0.0	0.0	0.0	0.4891566265	False
begin	7.80638828508e-05	0.0	0.0	0.0	0.0000000000	False
chapter	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
talk	8.019163649e-05	0.0	0.0	0.0	0.3766233766	False
briefly	0.000128332175313	0.0	0.0	0.0	0.0000000000	False
clustering	0.0153362547687	0.0	0.0	0.0	0.1481525484	False
algorithm	0.00200356940843	0.0	0.0	0.0	0.3609209708	False
special	0.000672711155281	0.0	0.0	0.0	0.3302961276	False
case	0.0	0.0	0.0	0.0	0.4291754757	False
expectation	0.00263839556572	0.0	0.0	0.0	0.2296227294	False
maximization	0.00197016320497	0.0	0.0	0.0	0.3878157504	False
mixture	0.00203551985911	1.0	0.0	0.0	0.4489164087	False
model	0.00320830438283	0.0	0.0	0.0	0.4688221709	False
describe	0.00102665740251	0.0	0.0	0.0	0.4434250765	False
jensen	0.000541337035963	1.0	0.0	0.0	0.4065420561	False
equality	0.00196862583557	0.0	0.0	0.0	0.3373213692	False
derive	0.00115498957782	0.0	0.0	0.0	0.4702702703	False
general	9.96899654229e-05	0.0	0.0	0.0	0.3822975518	False
form	4.61294475845e-05	0.0	0.0	0.0	0.0000000000	False
place	7.21131547866e-05	0.0	0.0	0.0	0.0000000000	False
unsupervised	0.00220147586454	0.0	0.0	0.0	0.3302961276	False
application	0.000576905238293	0.0	0.0	0.0	0.3805774278	False
cartoons	0.00154605998628	0.0	0.0	0.0	0.5471698113	False
draw	0.00036299102819	0.0	0.0	0.0	0.4233576642	False
supervised	0.00169626654926	0.0	0.0	0.0	0.2974358974	False
learning	0.000589875357934	0.0	0.0	0.0	0.3302961276	False
data	0.00199703473014	0.0	0.0	0.0	0.4269299820	False
set	0.000398759861692	0.0	0.0	0.0	0.3536585366	False
right	0.0	0.0	0.0	0.0	0.4308571429	False
positive	0.00020191034211	0.0	0.0	0.0	0.5370370370	False
negative	0.000384996525939	0.0	0.0	0.0	0.0000000000	False
crosses	0.00282330785689	0.0	0.0	0.0	0.3241085684	False
call	7.19901241702e-06	0.0	0.0	0.0	0.4549019608	False
told	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
label	0.00267388202015	0.0	0.0	0.0	0.3766233766	False
training	0.0006265392053	0.0	0.0	0.0	0.5370370370	False
study	0.000128332175313	0.0	0.0	0.0	0.0000000000	False
problem	6.56113389463e-05	0.0	0.0	0.0	0.5686274510	False
comprises	0.000442083816142	0.0	0.0	0.0	0.0000000000	False
points	0.000140380742132	0.0	0.0	0.0	0.2086330935	False
indication	0.00036299102819	0.0	0.0	0.0	0.5370370370	False
answers	0.000243577376501	0.0	0.0	0.0	0.4233576642	False
job	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
discover	0.000613450190749	0.0	0.0	0.0	0.0000000000	False
structure	0.000199187548987	0.0	0.0	0.0	0.0000000000	False
lecture	0.00020191034211	0.0	0.0	0.0	0.0000000000	False
couple	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
weeks	0.00031326960265	0.0	0.0	0.0	0.0000000000	False
variety	0.000560295217923	0.0	0.0	0.0	0.0000000000	False
types	7.80638828508e-05	0.0	0.0	0.0	0.0000000000	False
ve	0.0	0.0	0.0	0.0	0.0000000000	False
drawn	0.000146577531429	0.0	0.0	0.0	0.0000000000	False
lives	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
first	0.0	0.0	0.0	0.0	0.0000000000	False
automatically	0.000716422983625	0.0	0.0	0.0	0.0000000000	False
breaks	0.000560295217923	0.0	0.0	0.0	0.0000000000	False
smaller	9.07477570475e-05	0.0	0.0	0.0	0.0000000000	False
rattle	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
better-known	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
guess	0.00192037417238	0.0	0.0	0.0	0.3593898951	False
biology	0.000560295217923	0.0	0.0	0.0	0.0000000000	False
genes	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
order	1.10766628248e-05	0.0	0.0	0.0	0.0000000000	False
examine	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
understand	5.68745458811e-05	0.0	0.0	0.0	0.0000000000	False
function	0.00106432217805	0.0	0.0	0.0	0.3221137664	False
common	0.000384996525939	0.0	0.0	0.0	0.0000000000	False
market	0.00135701323941	0.0	0.0	0.0	0.2056737589	False
research	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
imagine	0.000513328701253	0.0	0.0	0.0	0.4233576642	False
customer	0.000773029993141	0.0	0.0	0.0	0.0000000000	False
database	0.000515353328761	0.0	0.0	0.0	0.0000000000	False
behave	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
practice	0.000104641369264	0.0	0.0	0.0	0.0000000000	False
apply	0.000199187548987	0.0	0.0	0.0	0.0000000000	False
segments	0.000822732929277	0.0	0.0	0.0	0.0000000000	False
target	0.000762378944034	0.0	0.0	0.0	0.0000000000	False
products	0.000128332175313	0.0	0.0	0.0	0.0000000000	False
sales	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
pitches	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
specifically	0.000326046486553	0.0	0.0	0.0	0.5686274510	False
nt	0.0	0.0	0.0	0.0	0.0000000000	False
website	0.000663125724213	0.0	0.0	0.0	0.0000000000	False
use.google.com	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
everyday	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
group	0.000575368860309	0.0	0.0	0.0	0.0000000000	False
related	0.000195058200869	0.0	0.0	0.0	0.0000000000	False
news	0.00132088551872	0.0	0.0	0.0	0.0000000000	False
articles	0.00114356841605	0.0	0.0	0.0	0.0000000000	False
display	0.000575368860309	0.0	0.0	0.0	0.0000000000	False
thousand	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
top	0.000144226309573	0.0	0.0	0.0	0.0000000000	False
story	0.000613450190749	0.0	0.0	0.0	0.0000000000	False
day	0.000104641369264	0.0	0.0	0.0	0.0000000000	False
solid	0.000339253309852	0.0	0.0	0.0	0.0000000000	False
image	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
picture	0.000464770947636	0.0	0.0	0.0	0.4489164087	False
subsets	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
coherent	0.000880590345815	0.0	0.0	0.0	0.0000000000	False
pieces	0.000181495514095	0.0	0.0	0.0	0.0000000000	False
pixels	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
contained	0.000221041908071	0.0	0.0	0.0	0.0000000000	False
idea	0.000108383162057	0.0	0.0	0.0	0.0000000000	False
waiting	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
write	0.000230647237923	0.0	0.0	0.0	0.4865771812	False
animation	0.00135701323941	0.0	0.0	0.0	0.4233576642	False
k-means	0.0113680777552	0.0	0.0	0.0	0.3267064281	False
finding	2.99283247989e-05	0.0	0.0	0.0	0.0000000000	False
inset	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
input	6.63958496622e-05	0.0	0.0	0.0	0.0000000000	False
unlabeled	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
lot	0.000151432756582	0.0	0.0	0.0	0.0000000000	False
make	0.000116642380349	0.0	0.0	0.0	0.3922452660	False
bit	9.49261684714e-05	0.0	0.0	0.0	0.0000000000	False
sense	0.000411346730043	0.0	0.0	0.0	0.3878157504	False
initialize	0.000312255531403	0.0	0.0	0.0	0.4233576642	False
centroids	0.0113680777552	0.0	0.0	0.0	0.1967435550	False
randomly	0.00123409939392	0.0	0.0	0.0	0.3805774278	False
muse	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
vectors	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
repeat	0.00033635557764	0.0	0.0	0.0	0.0000000000	False
convergence	0.00206141331504	0.0	0.0	0.0	0.4891566265	False
steps	0.000822693460085	0.0	0.0	0.0	0.3146139119	False
centers	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
closest	0.0012269003815	0.0	0.0	0.0	0.3493975904	False
assigning	0.00123330378468	1.0	0.0	0.0	0.2465986395	False
picking	0.000641660876566	0.0	0.0	0.0	0.3805774278	False
update	0.000548678334965	0.0	0.0	0.0	0.4233576642	False
median	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
bring	0.000358211491812	0.0	0.0	0.0	0.0000000000	False
excuse	0.000537317237719	0.0	0.0	0.0	0.0000000000	False
hope	0.000179105745906	0.0	0.0	0.0	0.0000000000	False
inch	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
chopped	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
basically	2.99283247989e-05	0.0	0.0	0.0	0.0000000000	False
michael	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
jordan	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
berkley	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
green	0.000383579240206	0.0	0.0	0.0	0.0000000000	False
pair	0.000167437712718	0.0	0.0	0.0	0.0000000000	False
blue	0.00140971321192	0.0	0.0	0.0	0.1263922518	False
note	0.000144226309573	0.0	0.0	0.0	0.0000000000	False
new1	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
new2	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
follow	7.80638828508e-05	0.0	0.0	0.0	0.4489164087	False
repeatedly	0.000952845787186	0.0	0.0	0.0	0.4233576642	False
associate	0.000137169583741	0.0	0.0	0.0	0.0000000000	False
dots	0.000960187086188	0.0	0.0	0.0	0.2365415987	False
closer	0.000884167632285	0.0	0.0	0.0	0.2056737589	False
visually	0.000339253309852	0.0	0.0	0.0	0.0000000000	False
denote	0.000384996525939	0.0	0.0	0.0	0.0000000000	False
painting	0.00114356841605	0.0	0.0	0.0	0.0000000000	False
red	0.00132625144843	0.0	0.0	0.0	0.2365415987	False
depending	3.16420561571e-05	0.0	0.0	0.0	0.0000000000	False
compute	0.000208540001564	0.0	0.0	0.0	0.2907930720	False
average	0.0015472933565	0.0	0.0	0.0	0.2040201005	False
move	5.04775855274e-05	0.0	0.0	0.0	0.0000000000	False
respective	0.00120000045016	0.0	0.0	0.0	0.4243902439	False
locations	0.000120000045016	0.0	0.0	0.0	0.0000000000	False
process	4.07558108191e-05	0.0	0.0	0.0	0.0000000000	False
color	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
similarly	9.1071336747e-05	0.0	0.0	0.0	0.0000000000	False
finally	8.42679082763e-05	0.0	0.0	0.0	0.0000000000	False
running	6.32841123142e-05	0.0	0.0	0.0	0.0000000000	False
remain	0.00031326960265	0.0	0.0	0.0	0.0000000000	False
wrote	0.000685847918706	0.0	0.0	0.0	0.5272727273	False
maps	0.000120000045016	0.0	0.0	0.0	0.0000000000	False
question	0.000119713299195	0.0	0.0	0.0	0.4702702703	False
shifting	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
guaranteed	0.00071463434039	0.0	0.0	0.0	0.0000000000	False
define	3.61277206858e-05	0.0	0.0	0.0	0.0000000000	False
distortion	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
squared	0.00036299102819	0.0	0.0	0.0	0.0000000000	False
distances	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
prove	0.000240000090032	0.0	0.0	0.0	0.0000000000	False
remembers	0.000302865513164	0.0	0.0	0.0	0.3302961276	False
authorization	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
optimizing	0.00107463447544	0.0	0.0	0.0	0.5471698113	False
alternately	0.000167437712718	0.0	0.0	0.0	0.0000000000	False
decreasing	0.000221041908071	0.0	0.0	0.0	0.0000000000	False
monotonically	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
variation	0.000411366464639	0.0	0.0	0.0	0.0000000000	False
eventually	0.000120000045016	0.0	0.0	0.0	0.0000000000	False
stop	0.000120000045016	0.0	0.0	0.0	0.0000000000	False
give	1.4398024834e-05	0.0	0.0	0.0	0.3493975904	False
value	0.00115381047659	0.0	0.0	0.0	0.2920216886	False
switch	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
extremely	0.000240000090032	0.0	0.0	0.0	0.0000000000	False
multiple	0.000256664350626	0.0	0.0	0.0	0.0000000000	False
objective	0.000195058200869	0.0	0.0	0.0	0.0000000000	False
happen	3.61277206858e-05	0.0	0.0	0.0	0.0000000000	False
choose	0.000585174602607	0.0	0.0	0.0	0.4702702703	False
number	3.23955558766e-05	0.0	0.0	0.0	0.2184100418	False
turns	0.000252387927637	0.0	0.0	0.0	0.3805774278	False
vast	0.000613450190749	0.0	0.0	0.0	0.0000000000	False
majority	0.000383579240206	0.0	0.0	0.0	0.0000000000	False
people	7.80638828508e-05	0.0	0.0	0.0	0.0000000000	False
work	0.000191032185804	0.0	0.0	0.0	0.4291754757	False
parameters	0.00234069841043	0.0	0.0	0.0	0.2966390648	False
hard	0.00031326960265	0.0	0.0	0.0	0.0000000000	False
ways	5.04775855274e-05	0.0	0.0	0.0	0.5547826087	False
reason	4.55356683735e-05	0.0	0.0	0.0	0.0000000000	False
true	0.00043267892872	0.0	0.0	0.0	0.0000000000	False
ambiguous	0.000476422893593	0.0	0.0	0.0	0.0000000000	False
four	0.0	0.0	0.0	0.0	0.0000000000	False
actual	0.000209282738528	0.0	0.0	0.0	0.5093484419	False
susceptible	0.00108267407193	0.0	0.0	0.0	0.0000000000	False
convex	0.00287354480492	0.0	0.0	0.0	0.2400300978	False
non-convex	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
local	0.00031326960265	0.0	0.0	0.0	0.0000000000	False
random	0.00178320458864	0.0	0.0	0.0	0.4040728832	False
bunch	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.4489164087	False
solution	0.00011211852588	0.0	0.0	0.0	0.0000000000	False
ended	4.48924871983e-05	0.0	0.0	0.0	0.0000000000	False
lowest	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
eliminate	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
reinitialize	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
norm	0.00154605998628	0.0	0.0	0.0	0.1715976331	False
infinity	0.0	0.0	0.0	0.0	0.0000000000	False
personally	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
commonly	0.000560295217923	0.0	0.0	0.0	0.0000000000	False
longer	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
closely	7.22554413716e-05	0.0	0.0	0.0	0.0000000000	False
wanted	0.000256664350626	0.0	0.0	0.0	0.3759259259	False
density	0.00271402647882	0.0	0.0	0.0	0.3446519525	False
estimation	0.00530500579371	0.0	0.0	0.0	0.2493551161	False
guys	0.000128332175313	0.0	0.0	0.0	0.0000000000	False
aircraft	0.00343070524815	0.0	0.0	0.0	0.1906501096	False
engine	0.00185114909087	0.0	0.0	0.0	0.2116788321	False
assembly	0.00103070665752	0.0	0.0	0.0	0.0000000000	False
company	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
line	0.000333557629617	0.0	0.0	0.0	0.3198529412	False
roll	0.000762378944034	0.0	0.0	0.0	0.0000000000	False
test	0.000137169583741	0.0	0.0	0.0	0.0000000000	False
measure	0.000537317237719	0.0	0.0	0.0	0.0000000000	False
properties	0.000199187548987	0.0	0.0	0.0	0.0000000000	False
heat	0.0012269003815	0.0	0.0	0.0	0.2974358974	False
vibrations	0.00270668517981	0.0	0.0	0.0	0.0000000000	False
reality	0.000560295217923	0.0	0.0	0.0	0.0000000000	False
frequencies	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
amount	0.000313924107792	0.0	0.0	0.0	0.0000000000	False
produced	0.000469904403975	0.0	0.0	0.0	0.0000000000	False
joint	0.0012883833219	0.0	0.0	0.0	0.4489164087	False
distribution	0.00337128322286	0.0	0.0	0.0	0.3086834734	False
detect	0.00103070665752	0.0	0.0	0.0	0.2974358974	False
undetected	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
flaw	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
undergo	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
inspections	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
typical	0.000313924107792	0.0	0.0	0.0	0.0000000000	False
features	9.07477570475e-05	0.0	0.0	0.0	0.0000000000	False
small	2.30647237923e-05	0.0	0.0	0.0	0.0000000000	False
raise	0.000600000225079	0.0	0.0	0.0	0.4489164087	False
flag	0.000762378944034	0.0	0.0	0.0	0.0000000000	False
anomaly	0.00270668517981	0.0	0.0	0.0	0.2917505030	False
subject	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
fly	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
low	0.000167437712718	0.0	0.0	0.0	0.0000000000	False
probability	0.00452081824338	0.0	0.0	0.0	0.2900935786	False
security	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
unusual	0.000762378944034	0.0	0.0	0.0	0.0000000000	False
transactions	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
credit	0.000762378944034	0.0	0.0	0.0	0.0000000000	False
card	0.000613450190749	0.0	0.0	0.0	0.0000000000	False
sign	0.000358211491812	0.0	0.0	0.0	0.0000000000	False
stolen	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
fall	0.000146577531429	0.0	0.0	0.0	0.0000000000	False
standard	9.75291004345e-05	0.0	0.0	0.0	0.0000000000	False
text	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
book	0.00011211852588	0.0	0.0	0.0	0.0000000000	False
gaussian	0.00412282663009	0.0	0.0	0.0	0.1790705232	False
explanation	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
shapes	0.0	0.0	0.0	0.0	0.0000000000	False
dimensional	0.000179105745906	0.0	0.0	0.0	0.0000000000	False
horizontal	0.00071463434039	0.0	0.0	0.0	0.0000000000	False
access	0.000334875425435	0.0	0.0	0.0	0.0000000000	False
axis	0.00123409939392	0.0	0.0	0.0	0.4233576642	False
represent	6.63958496622e-05	0.0	0.0	0.0	0.0000000000	False
coming	0.000104641369264	0.0	0.0	0.0	0.4489164087	False
sum	0.00188354464675	0.0	0.0	0.0	0.3843888071	False
clear	7.21131547866e-05	0.0	0.0	0.0	0.0000000000	False
visioning	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
separate	9.07477570475e-05	0.0	0.0	0.0	0.0000000000	False
knew	0.00214707566762	0.0	0.0	0.0	0.3822975518	False
put	4.61294475845e-05	0.0	0.0	0.0	0.0000000000	False
fit	0.000358211491812	0.0	0.0	0.0	0.0000000000	False
latent	0.00220147586454	0.0	0.0	0.0	0.3302961276	False
variable	0.00101483047706	0.0	0.0	0.0	0.4434250765	False
synonymous	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
hidden	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
unobserved	0.00162401110789	0.0	0.0	0.0	0.0000000000	False
chamber	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
multinomial	0.000762378944034	0.0	0.0	0.0	0.0000000000	False
conditioned	0.000209282738528	0.0	0.0	0.0	0.0000000000	False
covariant	0.000920175286124	0.0	0.0	0.0	0.0000000000	False
sigler	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
familiar	0.000120000045016	0.0	0.0	0.0	0.0000000000	False
written	0.00021633946436	0.0	0.0	0.0	0.0000000000	False
pretty	0.000334875425435	0.0	0.0	0.0	0.0000000000	False
equations	0.000256664350626	0.0	0.0	0.0	0.0000000000	False
discriminant	0.00441029302808	0.0	0.0	0.0	0.3236051502	False
analysis	0.00166831827907	0.0	0.0	0.0	0.3198529412	False
differences	1.45802975436e-05	0.0	0.0	0.0	0.2219387755	False
replaced	0.000411508751224	0.0	0.0	0.0	0.0000000000	False
link	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
explicit	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
suppose	9.49261684714e-05	0.0	0.0	0.0	0.0000000000	False
sake	0.000339253309852	0.0	0.0	0.0	0.0000000000	False
argument	0.000221041908071	0.0	0.0	0.0	0.0000000000	False
likelihood	0.00404959459554	0.0	0.0	0.0	0.3267064281	False
formula	0.00230147544123	0.0	0.0	0.0	0.3240223464	False
law	0.00336177130754	0.0	0.0	0.0	0.3074204947	False
maximum	0.00125569643117	0.0	0.0	0.0	0.2924369748	False
likeliness	0.00541337035963	0.0	0.0	0.0	0.2593917710	False
hand	0.000222371753078	0.0	0.0	0.0	0.0000000000	False
playing	0.000179105745906	0.0	0.0	0.0	0.0000000000	False
similar	0.000151432756582	0.0	0.0	0.0	0.0000000000	False
role	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
bootstrap	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
procedure	0.000120000045016	0.0	0.0	0.0	0.0000000000	False
rest	0.000384996525939	0.0	0.0	0.0	0.0000000000	False
iterate	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
proceeds	0.000339253309852	0.0	0.0	0.0	0.0000000000	False
unknown	0.00101775992956	0.0	0.0	0.0	0.0000000000	False
zis	0.00308206621035	0.0	0.0	0.0	0.2948438635	False
wij	0.00324802221578	0.0	0.0	0.0	0.4233576642	False
concrete	0.000383579240206	0.0	0.0	0.0	0.0000000000	False
means	1.79975310425e-05	0.0	0.0	0.0	0.3081463991	False
completely	2.72903122577e-05	0.0	0.0	0.0	0.0000000000	False
rate	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
divided	0.000292587301304	0.0	0.0	0.0	0.0000000000	False
essentially	3.16420561571e-05	0.0	0.0	0.0	0.0000000000	False
numerator	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
terms	1.89581819604e-05	0.0	0.0	0.0	0.0000000000	False
denominator	0.00101775992956	0.0	0.0	0.0	0.0000000000	False
lay	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
compare	0.000146577531429	0.0	0.0	0.0	0.0000000000	False
slight	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
convention	0.000146577531429	0.0	0.0	0.0	0.0000000000	False
matrix	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
sigma	0.000339253309852	0.0	0.0	0.0	0.0000000000	False
explain	0.000358211491812	0.0	0.0	0.0	0.0000000000	False
recall	0.000128332175313	0.0	0.0	0.0	0.0000000000	False
figured	7.80638828508e-05	0.0	0.0	0.0	0.0000000000	False
gda	0.00216534814385	0.0	0.0	0.0	0.0000000000	False
chance	0.00071463434039	0.0	0.0	0.0	0.0000000000	False
versus	0.000442083816142	0.0	0.0	0.0	0.0000000000	False
fraction	0.000358211491812	0.0	0.0	0.0	0.0000000000	False
examples	0.00021633946436	0.0	0.0	0.0	0.3804238143	False
observe	0.000537317237719	0.0	0.0	0.0	0.0000000000	False
xis	0.000541337035963	0.0	0.0	0.0	0.4259012016	False
current	0.00109644360927	0.0	0.0	0.0	0.4065420561	False
hypothesis	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
belongs	0.000383579240206	0.0	0.0	0.0	0.0000000000	False
convey	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
intuitive	0.000156634801325	0.0	0.0	0.0	0.0000000000	False
present	0.000209282738528	0.0	0.0	0.0	0.0000000000	False
broader	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
view	0.000360000135047	0.0	0.0	0.0	0.0000000000	False
half	0.000209282738528	0.0	0.0	0.0	0.0000000000	False
hour	0.000221041908071	0.0	0.0	0.0	0.0000000000	False
description	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
devised	0.000381189472017	0.0	0.0	0.0	0.0000000000	False
pre-cursor	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
prime	0.00166748012758	0.0	0.0	0.0	0.3822975518	False
differentiatable	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
creating	0.000195058200869	0.0	0.0	0.0	0.0000000000	False
drop	0.000411366464639	0.0	0.0	0.0	0.0000000000	False
brackets	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
friends	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
great	0.000144226309573	0.0	0.0	0.0	0.0000000000	False
one-half	0.000476422893593	0.0	0.0	0.0	0.0000000000	False
worth	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
illustrate	0.000179105745906	0.0	0.0	0.0	0.0000000000	False
inequality	0.00169626654926	0.0	0.0	0.0	0.4489164087	False
middle	0.000411366464639	0.0	0.0	0.0	0.0000000000	False
read	6.63958496622e-05	0.0	0.0	0.0	0.0000000000	False
contrast	0.000167437712718	0.0	0.0	0.0	0.0000000000	False
vertical	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
percent	0.000411366464639	0.0	0.0	0.0	0.0000000000	False
greater	0.000487645502173	0.0	0.0	0.0	0.4489164087	False
double	0.000384996525939	0.0	0.0	0.0	0.0000000000	False
row	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
strictly	0.00252132848065	0.0	0.0	0.0	0.1520093186	False
holds	0.00033635557764	0.0	0.0	0.0	0.0000000000	False
words	0.000111185876539	0.0	0.0	0.0	0.0000000000	False
constant	0.000292587301304	0.0	0.0	0.0	0.0000000000	False
takes	0.000108383162057	0.0	0.0	0.0	0.5863141524	False
strict	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
hear	0.000167437712718	0.0	0.0	0.0	0.0000000000	False
definition	0.000365366064752	0.0	0.0	0.0	0.0000000000	False
part	7.29014877182e-06	0.0	0.0	0.0	0.0000000000	False
straight	0.00033635557764	0.0	0.0	0.0	0.0000000000	False
portion	0.00071463434039	0.0	0.0	0.0	0.0000000000	False
formal	0.000274339167482	0.0	0.0	0.0	0.0000000000	False
speaking	0.000383579240206	0.0	0.0	0.0	0.0000000000	False
informally	9.07477570475e-05	0.0	0.0	0.0	0.0000000000	False
version	0.000137169583741	0.0	0.0	0.0	0.0000000000	False
face	0.000167437712718	0.0	0.0	0.0	0.0000000000	False
goal	0.000411366464639	0.0	0.0	0.0	0.0000000000	False
usual	0.000191789620103	0.0	0.0	0.0	0.4489164087	False
parameterized	0.00140073804481	0.0	0.0	0.0	0.3805774278	False
marginalizing	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
performing	6.63958496622e-05	0.0	0.0	0.0	0.0000000000	False
complicated	0.00011211852588	0.0	0.0	0.0	0.0000000000	False
fact	2.72903122577e-05	0.0	0.0	0.0	0.0000000000	False
math	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
mind	0.00011211852588	0.0	0.0	0.0	0.0000000000	False
theta	0.00555344727262	0.0	0.0	0.0	0.2003948667	False
construct	0.00108000040514	0.0	0.0	0.0	0.3446519525	False
lower	0.00246905250734	0.0	0.0	0.0	0.2020905923	False
bound	0.00301387882892	0.0	0.0	0.0	0.2135493373	False
tight	0.0012269003815	0.0	0.0	0.0	0.0000000000	False
boundary	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
jump	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
optimum	0.000339253309852	0.0	0.0	0.0	0.0000000000	False
multiply	0.000179105745906	0.0	0.0	0.0	0.0000000000	False
choice	0.000181495514095	0.0	0.0	0.0	0.0000000000	False
frowns	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
log	0.000560592629401	0.0	0.0	0.0	0.2917505030	False
concave	0.00220147586454	0.0	0.0	0.0	0.3302961276	False
tells	0.000104641369264	0.0	0.0	0.0	0.0000000000	False
continuing	0.000100955171055	0.0	0.0	0.0	0.0000000000	False
previous	0.000121788688251	0.0	0.0	0.0	0.0000000000	False
expression	0.000137169583741	0.0	0.0	0.0	0.0000000000	False
summary	0.000440295172907	0.0	0.0	0.0	0.0000000000	False
lastly	0.000205683232319	0.0	0.0	0.0	0.0000000000	False
expand	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
joined	0.000280147608962	0.0	0.0	0.0	0.0000000000	False
previously	0.000128332175313	0.0	0.0	0.0	0.0000000000	False
reserve	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
manipulations	0.00025767666438	0.0	0.0	0.0	0.0000000000	False
shown	0.000156127765702	0.0	0.0	0.0	0.0000000000	False
last	0.0	0.0	0.0	0.0	0.0000000000	False
refrain	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
inside	9.75291004345e-05	0.0	0.0	0.0	0.0000000000	False
normalize	8.42679082763e-05	0.0	0.0	0.0	0.0000000000	False
skipping	0.000515353328761	0.0	0.0	0.0	0.0000000000	False
convinced	0.000306725095375	0.0	0.0	0.0	0.0000000000	False
summarize	0.000191789620103	0.0	0.0	0.0	0.0000000000	False
template	0.000541337035963	0.0	0.0	0.0	0.0000000000	False
responded	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
check	8.42679082763e-05	0.0	0.0	0.0	0.0000000000	False
wrap	0.000238211446797	0.0	0.0	0.0	0.0000000000	False
today we shall discuss	0.0	0.0	0.0	2.0	0.0000000000	False
discuss what embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
covering in forty lectures	0.0	0.0	0.0	2.0	0.0000000000	False
lectures we shall cover	0.0	0.0	0.0	2.0	0.0000000000	False
processors a bus structures	0.0	0.0	0.0	2.0	0.0000000000	False
bus structures interfacing issues	0.0	0.0	0.0	2.0	0.0000000000	False
optimization of the program	0.0	0.0	0.0	2.0	0.0000000000	False
real time os issues	0.0	0.0	0.0	2.0	0.0000000000	False
aspects of network embedded	0.0	0.0	0.0	2.0	0.0000000000	False
start with the definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition of an embedded	0.0	0.0	0.0	2.0	0.0000000000	False
system micro any device	0.0	0.0	0.0	2.0	0.0000000000	False
computer it has hardware	0.0	0.0	0.0	2.0	0.0000000000	False
system and its expected	0.0	0.0	0.0	2.0	0.0000000000	False
function without human intervention	0.0	0.0	0.0	2.0	0.0000000000	False
intervention an embedded system	0.0	0.0	0.0	2.0	0.0000000000	False
expect to respond monitor	0.0	0.0	0.0	2.0	0.0000000000	False
external environment using sensors	0.0	0.0	0.0	2.0	0.0000000000	False
talking about is embedding	0.0	0.0	0.0	2.0	0.0000000000	False
embedding a computer embedding	0.0	0.0	0.0	2.0	0.0000000000	False
computer embedding a computer	0.0	0.0	0.0	2.0	0.0000000000	False
computer into an applies	0.0	0.0	0.0	2.0	0.0000000000	False
applies and that computer	0.0	0.0	0.0	2.0	0.0000000000	False
computer is not expected	0.0	0.0	0.0	2.0	0.0000000000	False
embedded into an plants	0.0	0.0	0.0	2.0	0.0000000000	False
interfaces and the model	0.0	0.0	0.0	2.0	0.0000000000	False
examples are personal digital	0.0	0.0	0.0	2.0	0.0000000000	False
personal digital assistance printers	0.0	0.0	0.0	2.0	0.0000000000	False
family are with automobiles	0.0	0.0	0.0	2.0	0.0000000000	False
automobiles in fact automobiles	0.0	0.0	0.0	2.0	0.0000000000	False
embedded networks computing system	0.0	0.0	0.0	2.0	0.0000000000	False
networks computing system television	0.0	0.0	0.0	2.0	0.0000000000	False
system television in television	0.0	0.0	0.0	2.0	0.0000000000	False
television from various purposes	0.0	0.0	0.0	2.0	0.0000000000	False
managing these microcontrollers designing	0.0	0.0	0.0	2.0	0.0000000000	False
microcontrollers designing there hardware	0.0	0.0	0.0	2.0	0.0000000000	False
designing there hardware designing	0.0	0.0	0.0	2.0	0.0000000000	False
hardware designing the software	0.0	0.0	0.0	2.0	0.0000000000	False
managing this a planes	0.0	0.0	0.0	2.0	0.0000000000	False
challenge than the adopt	0.0	0.0	0.0	2.0	0.0000000000	False
designing a general purpose	0.0	0.0	0.0	2.0	0.0000000000	False
purpose computer so lets	0.0	0.0	0.0	2.0	0.0000000000	False
surveillance system in fact	0.0	0.0	0.0	2.0	0.0000000000	False
system in fact surveillance	0.0	0.0	0.0	2.0	0.0000000000	False
fact surveillance system oblate	0.0	0.0	0.0	2.0	0.0000000000	False
reasons so your video	0.0	0.0	0.0	2.0	0.0000000000	False
part of embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
palm that is appeared	0.0	0.0	0.0	2.0	0.0000000000	False
cases the different types	0.0	0.0	0.0	2.0	0.0000000000	False
thirty two bit microcontroller	0.0	0.0	2.99793530626	6.0	0.0000000000	False
planes example front panel	0.0	0.0	0.0	2.0	0.0000000000	False
front panel of microwave	0.0	0.0	0.0	2.0	0.0000000000	False
panel of microwave oven	0.0	0.0	0.0	2.0	0.0000000000	False
examples because the functionality	0.0	0.0	0.0	2.0	0.0000000000	False
functionality that it handles	0.0	0.0	0.0	2.0	0.0000000000	False
fact that the camera	0.0	0.0	0.0	2.0	0.0000000000	False
thirty two bit processor	0.0	0.0	0.0	2.0	0.0000000000	False
processor because it handles	0.0	0.0	0.0	2.0	0.0000000000	False
similarly in an analog	0.0	0.0	0.0	2.0	0.0000000000	False
handles primarily the problem	0.0	0.0	0.0	2.0	0.0000000000	False
tuning and channel selection	0.0	0.0	0.0	2.0	0.0000000000	False
digital tv decompression disk	0.0	0.0	0.0	2.0	0.0000000000	False
box your microcontroller handles	0.0	0.0	0.0	2.0	0.0000000000	False
microcontroller handles a number	0.0	0.0	0.0	2.0	0.0000000000	False
number of complex functions	0.0	0.0	0.0	2.0	0.0000000000	False
microprocessors of four bit	0.0	0.0	0.0	2.0	0.0000000000	False
bit microcontroller can check	0.0	0.0	0.0	2.0	0.0000000000	False
tension of the seat	0.0	0.0	0.0	2.0	0.0000000000	False
belt microcontrollers can run	0.0	0.0	0.0	2.0	0.0000000000	False
run the display services	0.0	0.0	0.0	2.0	0.0000000000	False
services on the dashboard	0.0	0.0	0.0	2.0	0.0000000000	False
sees the engine controlling	0.0	0.0	0.0	2.0	0.0000000000	False
microcontroller that is sixteen	0.0	0.0	0.0	2.0	0.0000000000	False
two bit microcontroller lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets look an architecture	0.0	0.0	0.0	2.0	0.0000000000	False
system of breaking system	0.0	0.0	0.0	2.0	0.0000000000	False
aspect of an automobile	0.0	0.0	0.0	2.0	0.0000000000	False
break which are control	0.0	0.0	0.0	2.0	0.0000000000	False
control by hydraulic pump	0.0	0.0	0.0	2.0	0.0000000000	False
pump and your embedded	0.0	0.0	0.0	2.0	0.0000000000	False
system is this automated	0.0	0.0	0.0	2.0	0.0000000000	False
breaking system which receives	0.0	0.0	0.0	2.0	0.0000000000	False
system which receives input	0.0	0.0	0.0	2.0	0.0000000000	False
input from the sensors	0.0	0.0	0.0	2.0	0.0000000000	False
sensors and then depending	0.0	0.0	0.0	2.0	0.0000000000	False
depending on the software	0.0	0.0	0.0	2.0	0.0000000000	False
software that is running	0.0	0.0	0.0	2.0	0.0000000000	False
running in the automated	0.0	0.0	0.0	2.0	0.0000000000	False
automated breaking system actuate	0.0	0.0	0.0	2.0	0.0000000000	False
actuate the hydraulic pump	0.0	0.0	0.0	2.0	0.0000000000	False
hydraulic pump to control	0.0	0.0	0.0	2.0	0.0000000000	False
control system begin implemented	0.0	0.0	0.0	2.0	0.0000000000	False
microcontrollers in an automobile	0.0	0.0	0.0	2.0	0.0000000000	False
characteristics of embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems first thing	0.0	0.0	0.0	2.0	0.0000000000	False
sophisticated functionality the degree	0.0	0.0	0.0	2.0	0.0000000000	False
vary from a plans	0.0	0.0	0.0	2.0	0.0000000000	False
plans this satisfy real	0.0	0.0	0.0	2.0	0.0000000000	False
satisfy real time operation	0.0	0.0	0.0	2.0	0.0000000000	False
operation we shall comeback	0.0	0.0	0.0	2.0	0.0000000000	False
comeback to this point	0.0	0.0	0.0	2.0	0.0000000000	False
cases low manufacturing cost	0.0	0.0	0.0	2.0	0.0000000000	False
manufacturing cost but cost	0.0	0.0	0.0	2.0	0.0000000000	False
request further closer examination	0.0	0.0	0.0	2.0	0.0000000000	False
examination in many cases	0.0	0.0	0.0	2.0	0.0000000000	False
cases this a plans	0.0	0.0	0.0	2.0	0.0000000000	False
plans to uses application	0.0	0.0	0.0	2.0	0.0000000000	False
processors which we find	0.0	0.0	0.0	2.0	0.0000000000	False
work with restricted memory	0.0	0.0	0.0	2.0	0.0000000000	False
val mounter devices powered	0.0	0.0	0.0	2.0	0.0000000000	False
powered from direct power	0.0	0.0	0.0	2.0	0.0000000000	False
power supply then power	0.0	0.0	0.0	2.0	0.0000000000	False
supply then power consumption	0.0	0.0	0.0	2.0	0.0000000000	False
heat management heat dissipation	0.0	0.0	0.0	2.0	0.0000000000	False
management heat dissipation design	0.0	0.0	0.0	2.0	0.0000000000	False
design for this devices	0.0	0.0	0.0	2.0	0.0000000000	False
devices which can add	0.0	0.0	0.0	2.0	0.0000000000	False
cost of the embedded	0.0	0.0	0.0	2.0	0.0000000000	False
embedded system so lets	0.0	0.0	0.0	2.0	0.0000000000	False
issue of manufacturing cost	0.0	0.0	0.0	2.0	0.0000000000	False
two aspects first aspect	0.0	0.0	0.0	2.0	0.0000000000	False
call non recurring engineering	0.0	0.0	0.0	2.0	0.0000000000	False
non recurring engineering cost	0.0	0.0	0.0	2.0	0.0000000000	False
cost into that system	0.0	0.0	0.0	2.0	0.0000000000	False
system the other aspect	0.0	0.0	0.0	2.0	0.0000000000	False
aspect of the cost	0.0	0.0	0.0	2.0	0.0000000000	False
targeting um mass market	0.0	0.0	0.0	2.0	0.0000000000	False
optimize is a production	0.0	0.0	0.0	2.0	0.0000000000	False
set for high production	0.0	0.0	0.0	2.0	0.0000000000	False
designing um an automated	0.0	0.0	0.0	2.0	0.0000000000	False
system for an aircraft	0.0	0.0	0.0	2.0	0.0000000000	False
aircraft i can invest	0.0	0.0	0.0	2.0	0.0000000000	False
money for its development	0.0	0.0	0.0	2.0	0.0000000000	False
designing as cell phone	0.0	0.0	0.0	2.0	0.0000000000	False
phone or low cost	0.0	0.0	0.0	2.0	0.0000000000	False
low cost cell phone	0.0	0.0	0.0	2.0	0.0000000000	False
cost cell phone aiming	0.0	0.0	0.0	2.0	0.0000000000	False
phone aiming to serve	0.0	0.0	0.0	2.0	0.0000000000	False
serve a mass market	0.0	0.0	0.0	2.0	0.0000000000	False
market so the based	0.0	0.0	0.0	2.0	0.0000000000	False
depend on the number	0.0	0.0	0.0	2.0	0.0000000000	False
back to this issue	0.0	0.0	0.0	2.0	0.0000000000	False
operation that will started	0.0	0.0	0.0	2.0	0.0000000000	False
operation the basic definition	0.0	0.0	0.0	2.0	0.0000000000	False
definition is then operations	0.0	0.0	0.0	2.0	0.0000000000	False
operations must be completed	0.0	0.0	0.0	4.0	0.0000000000	False
hard real time headlines	0.0	0.0	0.0	2.0	0.0000000000	False
soft real time headlines	0.0	0.0	0.0	2.0	0.0000000000	False
occluding also we classify	0.0	0.0	0.0	2.0	0.0000000000	False
classify real time systems	0.0	0.0	0.0	2.0	0.0000000000	False
hard real time systems	0.0	0.0	0.0	2.0	0.0000000000	False
control if i miss	0.0	0.0	0.0	2.0	0.0000000000	False
soft real time systems	0.0	0.0	0.0	2.0	0.0000000000	False
video on a laptop	0.0	0.0	0.0	2.0	0.0000000000	False
distance you viewing experience	0.0	0.0	0.0	2.0	0.0000000000	False
viewing experience many systems	0.0	0.0	0.0	2.0	0.0000000000	False
means this embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems are receiving	0.0	0.0	0.0	2.0	0.0000000000	False
systems are receiving inputs	0.0	0.0	0.0	2.0	0.0000000000	False
worlds and these inputs	0.0	0.0	0.0	2.0	0.0000000000	False
handle this different rate	0.0	0.0	0.0	2.0	0.0000000000	False
requirements in many cases	0.0	0.0	0.0	2.0	0.0000000000	False
fault tolerance and reliability	0.0	0.0	0.0	4.0	0.0000000000	False
reliability further the systems	0.0	0.0	0.0	2.0	0.0000000000	False
safe systems um avoid	0.0	0.0	0.0	2.0	0.0000000000	False
physical or economic damage	0.0	0.0	0.0	2.0	0.0000000000	False
economic damage to person	0.0	0.0	0.0	2.0	0.0000000000	False
systems then the design	0.0	0.0	0.0	2.0	0.0000000000	False
programmability of this systems	0.0	0.0	0.0	2.0	0.0000000000	False
lifetime of the system	0.0	0.0	0.0	2.0	0.0000000000	False
system that means nonce	0.0	0.0	0.0	2.0	0.0000000000	False
nonce programmed this systems	0.0	0.0	0.0	2.0	0.0000000000	False
expected to be programmed	0.0	0.0	0.0	2.0	0.0000000000	False
design for specific task	0.0	0.0	0.0	2.0	0.0000000000	False
basically what we call	0.0	0.0	0.0	2.0	0.0000000000	False
important you can realize	0.0	0.0	0.0	2.0	0.0000000000	False
finally deliver the goals	0.0	0.0	0.0	2.0	0.0000000000	False
vending machine which users	0.0	0.0	0.0	2.0	0.0000000000	False
users eight bit motorola	0.0	0.0	0.0	2.0	0.0000000000	False
two thousand four introduction	0.0	0.0	0.0	2.0	0.0000000000	False
thousand four introduction product	0.0	0.0	0.0	2.0	0.0000000000	False
web enabled cashless vending	0.0	0.0	0.0	2.0	0.0000000000	False
enabled cashless vending machine	0.0	0.0	0.0	2.0	0.0000000000	False
simple task of delivering	0.0	0.0	0.0	2.0	0.0000000000	False
response to the cash	0.0	0.0	0.0	2.0	0.0000000000	False
change into an web	0.0	0.0	0.0	2.0	0.0000000000	False
web enabling the stock	0.0	0.0	0.0	2.0	0.0000000000	False
stock can be monitor	0.0	0.0	0.0	2.0	0.0000000000	False
remotely the whole cash	0.0	0.0	0.0	2.0	0.0000000000	False
credit cards or smart	0.0	0.0	0.0	2.0	0.0000000000	False
cards or smart cards	0.0	0.0	0.0	2.0	0.0000000000	False
monitored from a remote	0.0	0.0	0.0	2.0	0.0000000000	False
location this has happen	0.0	0.0	0.0	2.0	0.0000000000	False
brought in sophisticated processors	0.0	0.0	0.0	2.0	0.0000000000	False
sophisticated processors sophisticated functionalities	0.0	0.0	0.0	2.0	0.0000000000	False
robot and it users	0.0	0.0	0.0	2.0	0.0000000000	False
users an eight bit	0.0	0.0	0.0	2.0	0.0000000000	False
intel microprocessor in fact	0.0	0.0	0.0	2.0	0.0000000000	False
gps receiver global positioning	0.0	0.0	0.0	2.0	0.0000000000	False
receiver global positioning system	0.0	0.0	0.0	2.0	0.0000000000	False
system which actually enables	0.0	0.0	0.0	2.0	0.0000000000	False
enables any any transport	0.0	0.0	0.0	2.0	0.0000000000	False
transport vehicle to deprovement	0.0	0.0	0.0	2.0	0.0000000000	False
systems which provides automated	0.0	0.0	0.0	2.0	0.0000000000	False
navigational tool this gps	0.0	0.0	0.0	2.0	0.0000000000	False
tool this gps receivers	0.0	0.0	0.0	2.0	0.0000000000	False
component is the communication	0.0	0.0	0.0	2.0	0.0000000000	False
output regarding its positions	0.0	0.0	0.0	2.0	0.0000000000	False
mp3 player various versions	0.0	0.0	0.0	2.0	0.0000000000	False
versions of mp3 players	0.0	0.0	0.0	2.0	0.0000000000	False
compress form of audio	0.0	0.0	0.0	2.0	0.0000000000	False
decompress audio to play	0.0	0.0	0.0	2.0	0.0000000000	False
apprentic sophisticated computational task	0.0	0.0	0.0	2.0	0.0000000000	False
find that the microprocessor	0.0	0.0	0.0	2.0	0.0000000000	False
thirty two bit risk	0.0	0.0	0.0	2.0	0.0000000000	False
two bit risk microprocessor	0.0	0.0	0.0	2.0	0.0000000000	False
player the same issue	0.0	0.0	0.0	2.0	0.0000000000	False
dvd has got pdo	0.0	0.0	0.0	2.0	0.0000000000	False
rate at a video	0.0	0.0	0.0	2.0	0.0000000000	False
video rate video rate	0.0	0.0	0.0	2.0	0.0000000000	False
rate video rate means	0.0	0.0	0.0	2.0	0.0000000000	False
rate means what twenty	0.0	0.0	0.0	2.0	0.0000000000	False
effectively of about forty	0.0	0.0	0.0	2.0	0.0000000000	False
forty milliseconds to decompress	0.0	0.0	0.0	2.0	0.0000000000	False
decompress of video file	0.0	0.0	0.0	2.0	0.0000000000	False
case aprentic sophisticated microprocessor	0.0	0.0	0.0	2.0	0.0000000000	False
sophisticated microprocessor to work	0.0	0.0	0.0	2.0	0.0000000000	False
thirty two bit risc	0.0	0.0	0.0	2.0	0.0000000000	False
two bit risc microprocessor	0.0	0.0	0.0	2.0	0.0000000000	False
sony aibo robotic dog	0.0	0.0	0.0	4.0	0.0000000000	False
popular pet in japan	0.0	0.0	0.0	2.0	0.0000000000	False
japan and it users	0.0	0.0	0.0	2.0	0.0000000000	False
microprocessor or a microcontroller	0.0	0.0	0.0	4.0	0.0000000000	False
reduces sixty four bit	0.0	0.0	0.0	2.0	0.0000000000	False
sixty four bit neat	0.0	0.0	0.0	4.0	0.0000000000	False
four bit neat processor	0.0	0.0	0.0	4.0	0.0000000000	False
processor it uses sixty	0.0	0.0	0.0	2.0	0.0000000000	False
number of complex tasks	0.0	0.0	0.0	2.0	0.0000000000	False
familiar with this robo	0.0	0.0	0.0	2.0	0.0000000000	False
football between different robotics	0.0	0.0	0.0	2.0	0.0000000000	False
robotics teams in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact this sony aibo	0.0	0.0	0.0	2.0	0.0000000000	False
algorithms into to detect	0.0	0.0	0.0	2.0	0.0000000000	False
balls towards a goal	0.0	0.0	0.0	2.0	0.0000000000	False
functionalities have been built	0.0	0.0	0.0	2.0	0.0000000000	False
request pretty sophisticated processors	0.0	0.0	0.0	2.0	0.0000000000	False
sophisticated processors to handle	0.0	0.0	0.0	2.0	0.0000000000	False
sixty four bit mips	0.0	0.0	0.0	2.0	0.0000000000	False
four bit mips risc	0.0	0.0	0.0	2.0	0.0000000000	False
risc so now lets	0.0	0.0	0.0	2.0	0.0000000000	False
types of a embedded	0.0	0.0	0.0	2.0	0.0000000000	False
examples now lets classify	0.0	0.0	0.0	2.0	0.0000000000	False
lets classify the examples	0.0	0.0	0.0	2.0	0.0000000000	False
examples into different types	0.0	0.0	0.0	2.0	0.0000000000	False
similar to general computing	0.0	0.0	5.99793530626	6.0	0.0000000000	False
general computing like pda	0.0	0.0	0.0	2.0	0.0000000000	False
computing like pda video	0.0	0.0	0.0	2.0	0.0000000000	False
pda video games set	0.0	0.0	0.0	2.0	0.0000000000	False
games set of boxes	0.0	0.0	0.0	2.0	0.0000000000	False
boxes automatic teller machines	0.0	0.0	0.0	2.0	0.0000000000	False
maturity of the task	0.0	0.0	0.0	2.0	0.0000000000	False
form of the task	0.0	0.0	0.0	2.0	0.0000000000	False
thing is the video	0.0	0.0	0.0	2.0	0.0000000000	False
games okay you provide	0.0	0.0	0.0	2.0	0.0000000000	False
user provides a input	0.0	0.0	0.0	2.0	0.0000000000	False
input and it expect	0.0	0.0	0.0	2.0	0.0000000000	False
change the external world	0.0	0.0	0.0	2.0	0.0000000000	False
world so these devices	0.0	0.0	0.0	2.0	0.0000000000	False
general purpose computing machines	0.0	0.0	0.0	2.0	0.0000000000	False
computing machines they respond	0.0	0.0	0.0	2.0	0.0000000000	False
respond to users input	0.0	0.0	0.0	2.0	0.0000000000	False
side i got control	0.0	0.0	0.0	2.0	0.0000000000	False
system whose basic job	0.0	0.0	0.0	2.0	0.0000000000	False
actuating the feedback control	0.0	0.0	0.0	2.0	0.0000000000	False
actions i mean examples	0.0	0.0	0.0	2.0	0.0000000000	False
vehicles engine foal injection	0.0	0.0	0.0	2.0	0.0000000000	False
injection to be control	0.0	0.0	0.0	2.0	0.0000000000	False
control flight control nuclear	0.0	0.0	0.0	2.0	0.0000000000	False
flight control nuclear reactors	0.0	0.0	0.0	2.0	0.0000000000	False
examples of embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems which belongs	0.0	0.0	0.0	2.0	0.0000000000	False
belongs to the category	0.0	0.0	0.0	2.0	0.0000000000	False
category of control systems	0.0	0.0	0.0	2.0	0.0000000000	False
job or basic focus	0.0	0.0	0.0	2.0	0.0000000000	False
focus is signal processing	0.0	0.0	0.0	2.0	0.0000000000	False
signal processing your mp3	0.0	0.0	0.0	2.0	0.0000000000	False
processing your mp3 players	0.0	0.0	0.0	2.0	0.0000000000	False
mp3 players your dvd	0.0	0.0	0.0	2.0	0.0000000000	False
players your dvd players	0.0	0.0	0.0	2.0	0.0000000000	False
dvd players radar control	0.0	0.0	0.0	2.0	0.0000000000	False
players radar control system	0.0	0.0	0.0	2.0	0.0000000000	False
system the basic job	0.0	0.0	0.0	2.0	0.0000000000	False
cising of the deter	0.0	0.0	0.0	2.0	0.0000000000	False
deter similarly a sonar	0.0	0.0	0.0	2.0	0.0000000000	False
similarly a sonar system	0.0	0.0	0.0	2.0	0.0000000000	False
processing systems and communication	0.0	0.0	0.0	2.0	0.0000000000	False
networking is another category	0.0	0.0	0.0	2.0	0.0000000000	False
web enable vending machine	0.0	0.0	0.0	2.0	0.0000000000	False
kind of an internet	0.0	0.0	0.0	2.0	0.0000000000	False
embedded system is expected	0.0	0.0	0.0	4.0	0.0000000000	False
actuation sensing an actuation	0.0	0.0	0.0	2.0	0.0000000000	False
task it must realize	0.0	0.0	0.0	2.0	0.0000000000	False
control second important issue	0.0	0.0	0.0	2.0	0.0000000000	False
sequencing logic this sequencing	0.0	0.0	0.0	2.0	0.0000000000	False
logic this sequencing logic	0.0	0.0	0.0	2.0	0.0000000000	False
logic is obviously task	0.0	0.0	0.0	2.0	0.0000000000	False
general purpose sequencing logic	0.0	0.0	0.0	2.0	0.0000000000	False
task specific sequencing logic	0.0	0.0	0.0	2.0	0.0000000000	False
specific sequencing logic implemented	0.0	0.0	0.0	2.0	0.0000000000	False
interfacing and embedded system	0.0	0.0	0.0	2.0	0.0000000000	False
system with external sense	0.0	0.0	0.0	2.0	0.0000000000	False
sense to be input	0.0	0.0	0.0	2.0	0.0000000000	False
processing ability to deal	0.0	0.0	0.0	2.0	0.0000000000	False
specific interfacing because application	0.0	0.0	0.0	2.0	0.0000000000	False
senses and what kind	0.0	0.0	0.0	2.0	0.0000000000	False
actuated to be interconnected	0.0	0.0	0.0	2.0	0.0000000000	False
interface this interfacing implies	0.0	0.0	0.0	2.0	0.0000000000	False
interfacing implies both hardware	0.0	0.0	0.0	2.0	0.0000000000	False
software next thing fault	0.0	0.0	0.0	2.0	0.0000000000	False
occurs the basic issue	0.0	0.0	0.0	2.0	0.0000000000	False
issue or basic design	0.0	0.0	0.0	2.0	0.0000000000	False
design philosophy for fault	0.0	0.0	0.0	2.0	0.0000000000	False
philosophy for fault response	0.0	0.0	0.0	2.0	0.0000000000	False
call graceful depredation cattest	0.0	0.0	0.0	2.0	0.0000000000	False
graceful depredation cattest traffic	0.0	0.0	0.0	2.0	0.0000000000	False
depredation cattest traffic failure	0.0	0.0	0.0	2.0	0.0000000000	False
failure should not happening	0.0	0.0	0.0	2.0	0.0000000000	False
system should tell users	0.0	0.0	0.0	2.0	0.0000000000	False
graceful it would decreed	0.0	0.0	0.0	2.0	0.0000000000	False
message to the user	0.0	0.0	0.0	2.0	0.0000000000	False
user saying that battery	0.0	0.0	0.0	2.0	0.0000000000	False
suddenly stop its activity	0.0	0.0	0.0	2.0	0.0000000000	False
sun so graceful degradation	0.0	0.0	0.0	2.0	0.0000000000	False
architecture of the embedded	0.0	0.0	0.0	2.0	0.0000000000	False
examples so now lets	0.0	0.0	0.0	2.0	0.0000000000	False
things which are involved	0.0	0.0	0.0	2.0	0.0000000000	False
expanded the basic block	0.0	0.0	0.0	4.0	0.0000000000	False
basic block have expanded	0.0	0.0	0.0	2.0	0.0000000000	False
block and have added	0.0	0.0	0.0	2.0	0.0000000000	False
earlier i adjust shown	0.0	0.0	0.0	2.0	0.0000000000	False
adjust shown the cpu	0.0	0.0	0.0	2.0	0.0000000000	False
showing obvious the memory	0.0	0.0	0.0	2.0	0.0000000000	False
analog to digital converters	0.0	0.0	0.0	2.0	0.0000000000	False
digital to analog converters	0.0	0.0	0.0	2.0	0.0000000000	False
converters this ad conversion	0.0	0.0	0.0	2.0	0.0000000000	False
interface to the sensor	0.0	0.0	0.0	2.0	0.0000000000	False
block actually provides interface	0.0	0.0	0.0	2.0	0.0000000000	False
interface to the actuators	0.0	0.0	0.0	2.0	0.0000000000	False
actuators because an embedded	0.0	0.0	0.0	2.0	0.0000000000	False
system which is situated	0.0	0.0	0.0	2.0	0.0000000000	False
situated in a environment	0.0	0.0	0.0	2.0	0.0000000000	False
expected to receive sensor	0.0	0.0	0.0	2.0	0.0000000000	False
sensor inputs and actuate	0.0	0.0	0.0	2.0	0.0000000000	False
change the external environment	0.0	0.0	0.0	2.0	0.0000000000	False
essential and integral component	0.0	0.0	0.0	2.0	0.0000000000	False
integral component in majority	0.0	0.0	0.0	2.0	0.0000000000	False
majority of your embedded	0.0	0.0	0.0	2.0	0.0000000000	False
systems here are shown	0.0	0.0	0.0	2.0	0.0000000000	False
fpga or acid block	0.0	0.0	0.0	2.0	0.0000000000	False
execute my software satisfying	0.0	0.0	0.0	2.0	0.0000000000	False
satisfying real time circumstance	0.0	0.0	0.0	2.0	0.0000000000	False
circumstance under those circumstance	0.0	0.0	0.0	2.0	0.0000000000	False
interface with my cpu	0.0	0.0	0.0	2.0	0.0000000000	False
implemented on an fpga	0.0	0.0	0.0	2.0	0.0000000000	False
alumeter cpu now lets	0.0	0.0	0.0	2.0	0.0000000000	False
lets look an order	0.0	0.0	0.0	2.0	0.0000000000	False
implement with the cpu	0.0	0.0	0.0	2.0	0.0000000000	False
cpu the human interface	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems any control	0.0	0.0	0.0	2.0	0.0000000000	False
systems any control functions	0.0	0.0	0.0	2.0	0.0000000000	False
functions to be altered	0.0	0.0	0.0	2.0	0.0000000000	False
interface so this interface	0.0	0.0	0.0	2.0	0.0000000000	False
find in many cases	0.0	0.0	0.0	2.0	0.0000000000	False
simple um simple led	0.0	0.0	0.0	2.0	0.0000000000	False
based informative um color	0.0	0.0	0.0	2.0	0.0000000000	False
informative um color color	0.0	0.0	0.0	2.0	0.0000000000	False
user can be informed	0.0	0.0	0.0	2.0	0.0000000000	False
informed what is happening	0.0	0.0	0.0	2.0	0.0000000000	False
tools why diagnostic tools	0.0	0.0	0.0	2.0	0.0000000000	False
ability is a failure	0.0	0.0	0.0	2.0	0.0000000000	False
occurs how to trace	0.0	0.0	0.0	2.0	0.0000000000	False
diagnostic tools to interface	0.0	0.0	0.0	2.0	0.0000000000	False
working second important thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing why diagnostic tools	0.0	0.0	0.0	2.0	0.0000000000	False
starting up or system	0.0	0.0	0.0	2.0	0.0000000000	False
parts are not functioning	0.0	0.0	0.0	2.0	0.0000000000	False
properly what can happen	0.0	0.0	0.0	2.0	0.0000000000	False
damage to the users	0.0	0.0	0.0	2.0	0.0000000000	False
users because of malfunctioning	0.0	0.0	0.0	2.0	0.0000000000	False
malfunctioning of some hardware	0.0	0.0	0.0	2.0	0.0000000000	False
check at regular basics	0.0	0.0	0.0	2.0	0.0000000000	False
regular basics so diagnostics	0.0	0.0	0.0	2.0	0.0000000000	False
basics so diagnostics tools	0.0	0.0	0.0	2.0	0.0000000000	False
design the cooling circuit	0.0	0.0	0.0	2.0	0.0000000000	False
aspect of it design	0.0	0.0	0.0	2.0	0.0000000000	False
important obviously the casing	0.0	0.0	0.0	2.0	0.0000000000	False
casing the whole system	0.0	0.0	0.0	2.0	0.0000000000	False
system should properly packaged	0.0	0.0	0.0	2.0	0.0000000000	False
exceptive to be pleased	0.0	0.0	0.0	2.0	0.0000000000	False
pleased so this packaging	0.0	0.0	0.0	2.0	0.0000000000	False
good well design system	0.0	0.0	0.0	2.0	0.0000000000	False
design system can fail	0.0	0.0	0.0	2.0	0.0000000000	False
bad packaging the system	0.0	0.0	0.0	2.0	0.0000000000	False
moister okay the moister	0.0	0.0	0.0	2.0	0.0000000000	False
effective electronics then heat	0.0	0.0	0.0	2.0	0.0000000000	False
heat can effective electronics	0.0	0.0	0.0	2.0	0.0000000000	False
aspect of the design	0.0	0.0	0.0	2.0	0.0000000000	False
design becomes extrument point	0.0	0.0	0.0	2.0	0.0000000000	False
discuss those mechanical aspects	0.0	0.0	0.0	2.0	0.0000000000	False
aspects of an embedded	0.0	0.0	0.0	2.0	0.0000000000	False
concuss about the fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact that these aspects	0.0	0.0	0.0	2.0	0.0000000000	False
important for any kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind an appliances design	0.0	0.0	0.0	2.0	0.0000000000	False
appliances design and implementation	0.0	0.0	0.0	2.0	0.0000000000	False
implement an embedded system	0.0	0.0	0.0	4.0	0.0000000000	False
discuss obviously the processing	0.0	0.0	0.0	2.0	0.0000000000	False
processing elements the processing	0.0	0.0	0.0	2.0	0.0000000000	False
elements the processing elements	0.0	0.0	0.0	2.0	0.0000000000	False
peripheral devices because input	0.0	0.0	0.0	2.0	0.0000000000	False
input an output devices	0.0	0.0	0.0	2.0	0.0000000000	False
component in this context	0.0	0.0	0.0	2.0	0.0000000000	False
interface sensors and actuators	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of interfacing protocols	0.0	0.0	0.0	2.0	0.0000000000	False
protocols which can vary	0.0	0.0	0.0	2.0	0.0000000000	False
vary from one sensors	0.0	0.0	0.0	2.0	0.0000000000	False
sensors to another sensors	0.0	0.0	0.0	2.0	0.0000000000	False
aspects of an hardware	0.0	0.0	0.0	2.0	0.0000000000	False
hardware of an embedded	0.0	0.0	0.0	2.0	0.0000000000	False
aspects of the hardware	0.0	0.0	0.0	2.0	0.0000000000	False
computing the only issue	0.0	0.0	0.0	2.0	0.0000000000	False
important is these aspects	0.0	0.0	0.0	2.0	0.0000000000	False
purpose computer we tend	0.0	0.0	0.0	2.0	0.0000000000	False
talk about standard input	0.0	0.0	0.0	4.0	0.0000000000	False
standard input output devices	0.0	1.0	0.0	4.0	0.0000000000	False
devices although that set	0.0	0.0	0.0	2.0	0.0000000000	False
set is getting expanded	0.0	0.0	0.0	2.0	0.0000000000	False
expanded day by day	0.0	0.0	0.0	2.0	0.0000000000	False
day but we tend	0.0	0.0	0.0	2.0	0.0000000000	False
set of input output	0.0	0.0	0.0	2.0	0.0000000000	False
sensors and its sensor	0.0	0.0	0.0	2.0	0.0000000000	False
processors which are targeted	0.0	0.0	0.0	2.0	0.0000000000	False
targeted for embedded applications	0.0	0.0	0.0	2.0	0.0000000000	False
mechanisms in many cases	0.0	0.0	0.0	2.0	0.0000000000	False
cases even simpler mechanisms	0.0	0.0	0.0	2.0	0.0000000000	False
complex mechanism to interface	0.0	0.0	0.0	2.0	0.0000000000	False
interface with external devices	0.0	0.0	0.0	2.0	0.0000000000	False
talked about system software	0.0	0.0	0.0	4.0	0.0000000000	False
system software and application	0.0	0.0	0.0	2.0	0.0000000000	False
software and application software	0.0	0.0	0.0	2.0	0.0000000000	False
software what s system	0.0	0.0	0.0	2.0	0.0000000000	False
software typically we talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about assemblers compilers	0.0	0.0	0.0	2.0	0.0000000000	False
compilers that is language	0.0	0.0	0.0	2.0	0.0000000000	False
translators i have clause	0.0	0.0	0.0	2.0	0.0000000000	False
clause of system software	0.0	0.0	0.0	4.0	0.0000000000	False
software the other clause	0.0	0.0	0.0	2.0	0.0000000000	False
system software or operating	0.0	0.0	0.0	2.0	0.0000000000	False
software or operating systems	0.0	0.0	0.0	2.0	0.0000000000	False
operating systems now majority	0.0	0.0	0.0	2.0	0.0000000000	False
majority of the cases	0.0	0.0	0.0	2.0	0.0000000000	False
systems will have specialized	0.0	0.0	0.0	2.0	0.0000000000	False
general purpose operating system	0.0	0.0	0.0	2.0	0.0000000000	False
system like your window	0.0	0.0	0.0	2.0	0.0000000000	False
window units order variance	0.0	0.0	0.0	2.0	0.0000000000	False
caricaturists of the embedded	0.0	0.0	0.0	2.0	0.0000000000	False
encounter in general purpose	0.0	0.0	0.0	2.0	0.0000000000	False
general purpose computing system	0.0	0.0	0.0	2.0	0.0000000000	False
satisfy the general purpose	0.0	0.0	0.0	2.0	0.0000000000	False
purpose need the requirements	0.0	0.0	0.0	2.0	0.0000000000	False
requirements of a programming	0.0	0.0	0.0	2.0	0.0000000000	False
case this embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems are dedicated	0.0	0.0	0.0	2.0	0.0000000000	False
tuned for that kind	0.0	0.0	0.0	2.0	0.0000000000	False
kind of a requirement	0.0	0.0	0.0	2.0	0.0000000000	False
real time scheduling features	0.0	0.0	0.0	2.0	0.0000000000	False
require real tome scheduling	0.0	0.0	0.0	2.0	0.0000000000	False
computer you also compilers	0.0	0.0	0.0	2.0	0.0000000000	False
compile your high level	0.0	0.0	0.0	2.0	0.0000000000	False
high level language code	0.0	0.0	0.0	2.0	0.0000000000	False
code to the target	0.0	0.0	0.0	2.0	0.0000000000	False
code to be executed	0.0	0.0	0.0	2.0	0.0000000000	False
executed on that system	0.0	0.0	0.0	2.0	0.0000000000	False
incase of an embedded	0.0	0.0	0.0	4.0	0.0000000000	False
systems you will find	0.0	0.0	0.0	2.0	0.0000000000	False
find what we call	0.0	0.0	0.0	2.0	0.0000000000	False
cross assemblers and cross	0.0	0.0	0.0	2.0	0.0000000000	False
assemblers and cross compilers	0.0	0.0	0.0	2.0	0.0000000000	False
compilers and various kinds	0.0	0.0	0.0	2.0	0.0000000000	False
kinds of other development	0.0	0.0	0.0	2.0	0.0000000000	False
high level language program	0.0	0.0	0.0	2.0	0.0000000000	False
software would take place	0.0	0.0	0.0	2.0	0.0000000000	False
software will be loaded	0.0	0.0	0.0	2.0	0.0000000000	False
loaded onto the target	0.0	0.0	0.0	2.0	0.0000000000	False
cross compilers and cross	0.0	0.0	3.99793530626	6.0	0.0000000000	False
compilers and cross assemblers	0.0	0.0	3.99793530626	6.0	0.0000000000	False
write a c program	0.0	0.0	0.0	2.0	0.0000000000	False
compile your c program	0.0	0.0	0.0	2.0	0.0000000000	False
generate it will generate	0.0	0.0	0.0	2.0	0.0000000000	False
code for big microcontroller	0.0	0.0	0.0	2.0	0.0000000000	False
microcontroller and that code	0.0	0.0	0.0	2.0	0.0000000000	False
executed on that target	0.0	0.0	0.0	2.0	0.0000000000	False
compilers for a family	0.0	0.0	0.0	2.0	0.0000000000	False
variance of this processor	0.0	0.0	0.0	2.0	0.0000000000	False
processor because this processor	0.0	0.0	0.0	2.0	0.0000000000	False
differences in the number	0.0	0.0	0.0	2.0	0.0000000000	False
number of registers etcetera	0.0	0.0	0.0	2.0	0.0000000000	False
part of system software	0.0	0.0	0.0	2.0	0.0000000000	False
software which a call	0.0	0.0	0.0	2.0	0.0000000000	False
emulators what are emulators	0.0	0.0	0.0	2.0	0.0000000000	False
instructions to the emulators	0.0	0.0	0.0	2.0	0.0000000000	False
emulators this instruction set	0.0	0.0	0.0	2.0	0.0000000000	False
set emulators actually emulates	0.0	0.0	0.0	2.0	0.0000000000	False
processors on another target	0.0	0.0	0.0	2.0	0.0000000000	False
emulates the um behavior	0.0	0.0	0.0	2.0	0.0000000000	False
behavior of the target	0.0	0.0	0.0	2.0	0.0000000000	False
simple implement the instruction	0.0	0.0	0.0	2.0	0.0000000000	False
implement the instruction set	0.0	0.0	0.0	2.0	0.0000000000	False
set of the target	0.0	0.0	0.0	2.0	0.0000000000	False
processor in many cases	0.0	0.0	0.0	2.0	0.0000000000	False
analysis of your code	0.0	0.0	0.0	2.0	0.0000000000	False
code on a host	0.0	0.0	0.0	2.0	0.0000000000	False
tools system software tools	0.0	0.0	0.0	2.0	0.0000000000	False
typically targeted for embedded	0.0	0.0	0.0	2.0	0.0000000000	False
targeted for embedded system	0.0	0.0	0.0	4.0	0.0000000000	False
communication of the tool	0.0	0.0	0.0	2.0	0.0000000000	False
simple software to execute	0.0	0.0	0.0	2.0	0.0000000000	False
connected to the target	0.0	0.0	0.0	2.0	0.0000000000	False
board through a hardware	0.0	0.0	0.0	2.0	0.0000000000	False
hardware connector that code	0.0	0.0	0.0	2.0	0.0000000000	False
developed on the target	0.0	0.0	0.0	2.0	0.0000000000	False
board can be loaded	0.0	0.0	0.0	2.0	0.0000000000	False
loaded via the connector	0.0	0.0	0.0	2.0	0.0000000000	False
happen you can monitor	0.0	0.0	0.0	2.0	0.0000000000	False
execution of the code	0.0	0.0	0.0	2.0	0.0000000000	False
tools so to summarize	0.0	0.0	0.0	2.0	0.0000000000	False
software we are talking	0.0	0.0	0.0	2.0	0.0000000000	False
talking about what compilers	0.0	0.0	0.0	2.0	0.0000000000	False
compilers in particular cross	0.0	0.0	0.0	2.0	0.0000000000	False
assemblers when you talk	0.0	0.0	0.0	2.0	0.0000000000	False
simulators and we talk	0.0	0.0	0.0	2.0	0.0000000000	False
talk about debugging tools	0.0	0.0	0.0	2.0	0.0000000000	False
tools so this system	0.0	0.0	0.0	2.0	0.0000000000	False
expect for general purpose	0.0	0.0	0.0	2.0	0.0000000000	False
systems which are targeted	0.0	0.0	0.0	2.0	0.0000000000	False
targeted for dedicated appliances	0.0	0.0	0.0	2.0	0.0000000000	False
appliances and many times	0.0	0.0	0.0	2.0	0.0000000000	False
times they do support	0.0	0.0	0.0	2.0	0.0000000000	False
support real time scheduling	0.0	0.0	0.0	2.0	0.0000000000	False
real time scheduling capabilities	0.0	0.0	0.0	2.0	0.0000000000	False
capabilities the next thing	0.0	0.0	0.0	2.0	0.0000000000	False
thing is application software	0.0	0.0	0.0	2.0	0.0000000000	False
application software obviously software	0.0	0.0	0.0	2.0	0.0000000000	False
support the same system	0.0	0.0	0.0	2.0	0.0000000000	False
operating system weak works	0.0	0.0	0.0	2.0	0.0000000000	False
system weak works running	0.0	0.0	0.0	2.0	0.0000000000	False
running on your laser	0.0	0.0	0.0	2.0	0.0000000000	False
plants but application software	0.0	0.0	0.0	2.0	0.0000000000	False
software in the laser	0.0	0.0	0.0	2.0	0.0000000000	False
laser printer is targeted	0.0	0.0	0.0	2.0	0.0000000000	False
multiple just a appliances	0.0	0.0	0.0	2.0	0.0000000000	False
appliances but your application	0.0	0.0	0.0	2.0	0.0000000000	False
application software would things	0.0	0.0	0.0	2.0	0.0000000000	False
things which the functionality	0.0	0.0	0.0	2.0	0.0000000000	False
functionality of this appliances	0.0	0.0	0.0	2.0	0.0000000000	False
history of hardware evolution	0.0	0.0	0.0	2.0	0.0000000000	False
status to the status	0.0	0.0	0.0	2.0	0.0000000000	False
status of embedded system	0.0	0.0	0.0	2.0	0.0000000000	False
purpose microprocessor and microcontroller	0.0	0.0	0.0	2.0	0.0000000000	False
microcontroller and in fact	0.0	0.0	0.0	2.0	0.0000000000	False
higher degree of integration	0.0	0.0	0.0	4.0	0.0000000000	False
peripherals have got integrated	0.0	0.0	0.0	2.0	0.0000000000	False
integrated into the chip	0.0	0.0	0.0	2.0	0.0000000000	False
general purpose microprocessor microcontroller	0.0	0.0	0.0	2.0	0.0000000000	False
system so unary cost	0.0	0.0	0.0	2.0	0.0000000000	False
unary cost towards development	0.0	0.0	0.0	2.0	0.0000000000	False
development of the processor	0.0	0.0	0.0	2.0	0.0000000000	False
processor is to minimized	0.0	0.0	0.0	2.0	0.0000000000	False
purpose processors and microcontrollers	0.0	0.0	0.0	2.0	0.0000000000	False
dsp that digital signal	0.0	0.0	0.0	2.0	0.0000000000	False
talking about digital signal	0.0	0.0	0.0	2.0	0.0000000000	False
processing i am talking	0.0	0.0	0.0	2.0	0.0000000000	False
variety of signal processor	0.0	0.0	0.0	2.0	0.0000000000	False
processor with different architecture	0.0	0.0	0.0	2.0	0.0000000000	False
architecture which are today	0.0	0.0	0.0	2.0	0.0000000000	False
microcontroller in many cases	0.0	0.0	0.0	2.0	0.0000000000	False
permit this additional unary	0.0	0.0	0.0	2.0	0.0000000000	False
unary cost the kind	0.0	0.0	0.0	2.0	0.0000000000	False
top i have put	0.0	0.0	0.0	2.0	0.0000000000	False
put system on chip	0.0	0.0	0.0	2.0	0.0000000000	False
system on chip soc	0.0	0.0	0.0	2.0	0.0000000000	False
chip soc and soc	0.0	0.0	0.0	2.0	0.0000000000	False
find in an soc	0.0	0.0	0.0	2.0	0.0000000000	False
processor code but multiple	0.0	0.0	0.0	2.0	0.0000000000	False
code but multiple processor	0.0	0.0	0.0	2.0	0.0000000000	False
multiple processor codes alu	0.0	0.0	0.0	2.0	0.0000000000	False
processor codes alu peripherals	0.0	0.0	0.0	2.0	0.0000000000	False
integrated why because today	0.0	0.0	0.0	2.0	0.0000000000	False
textes instrument omap processor	0.0	0.0	0.0	2.0	0.0000000000	False
sitting inside the chip	0.0	0.0	0.0	2.0	0.0000000000	False
find there are variety	0.0	0.0	0.0	2.0	0.0000000000	False
talking about the system	0.0	0.0	0.0	2.0	0.0000000000	False
processor and its peripherals	0.0	0.0	0.0	2.0	0.0000000000	False
large number of peripherals	0.0	0.0	0.0	2.0	0.0000000000	False
coprocessors and even multiple	0.0	0.0	0.0	2.0	0.0000000000	False
multiple processors being integrated	0.0	0.0	0.0	2.0	0.0000000000	False
single piece of silicon	0.0	0.0	0.0	2.0	0.0000000000	False
sophisticated functionality being implemented	0.0	0.0	0.0	2.0	0.0000000000	False
system as single silicon	0.0	0.0	0.0	2.0	0.0000000000	False
design in a power	0.0	0.0	0.0	2.0	0.0000000000	False
power of the man	0.0	0.0	0.0	2.0	0.0000000000	False
canjancem of power software	0.0	0.0	0.0	2.0	0.0000000000	False
characteristics of the application	0.0	0.0	0.0	2.0	0.0000000000	False
software and the operating	0.0	0.0	0.0	2.0	0.0000000000	False
operating systems that supports	0.0	0.0	0.0	2.0	0.0000000000	False
means in an execution	0.0	0.0	0.0	2.0	0.0000000000	False
correct logically correct means	0.0	0.0	0.0	2.0	0.0000000000	False
means you all understand	0.0	0.0	0.0	2.0	0.0000000000	False
thing is temporal correctness	0.0	0.0	0.0	2.0	0.0000000000	False
correctness in this case	0.0	0.0	0.0	2.0	0.0000000000	False
purpose computer we talk	0.0	0.0	0.0	2.0	0.0000000000	False
multiple users multiple processors	0.0	0.0	0.0	2.0	0.0000000000	False
users multiple processors running	0.0	0.0	0.0	2.0	0.0000000000	False
reliability and fault tolerance	0.0	0.0	0.0	2.0	0.0000000000	False
tolerance obviously critical issues	0.0	0.0	0.0	2.0	0.0000000000	False
effort to this fault	0.0	0.0	0.0	2.0	0.0000000000	False
software has to application	0.0	0.0	0.0	2.0	0.0000000000	False
specific and single purpose	0.0	0.0	0.0	2.0	0.0000000000	False
familiar with this definition	0.0	0.0	0.0	2.0	0.0000000000	False
review so by multitasking	0.0	0.0	0.0	2.0	0.0000000000	False
important for embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
systems need to deal	0.0	0.0	0.0	2.0	0.0000000000	False
deal with several inputs	0.0	0.0	0.0	2.0	0.0000000000	False
outputs and multiple events	0.0	0.0	0.0	2.0	0.0000000000	False
multiple events can occur	0.0	0.0	0.0	2.0	0.0000000000	False
system in many cases	0.0	0.0	0.0	2.0	0.0000000000	False
exceptive to be multitasking	0.0	0.0	0.0	2.0	0.0000000000	False
multitasking and separating task	0.0	0.0	0.0	2.0	0.0000000000	False
task can other issue	0.0	0.0	0.0	2.0	0.0000000000	False
issue is separating task	0.0	0.0	0.0	2.0	0.0000000000	False
task simplifies your programming	0.0	0.0	0.0	2.0	0.0000000000	False
simplifies your programming complexity	0.0	0.0	0.0	2.0	0.0000000000	False
kernel which would support	0.0	0.0	0.0	2.0	0.0000000000	False
switching of the processor	0.0	0.0	0.0	2.0	0.0000000000	False
processor between different tasks	0.0	0.0	0.0	2.0	0.0000000000	False
concurrency is basically appearance	0.0	0.0	0.0	2.0	0.0000000000	False
appearance of simultaneous execution	0.0	0.0	0.0	2.0	0.0000000000	False
simultaneous execution of multiple	0.0	0.0	0.0	2.0	0.0000000000	False
execution of multiple tasks	0.0	0.0	0.0	2.0	0.0000000000	False
multiple tasks so lets	0.0	0.0	0.0	2.0	0.0000000000	False
concurrency in temperature controller	0.0	0.0	0.0	2.0	0.0000000000	False
supposed to just control	0.0	0.0	0.0	2.0	0.0000000000	False
request to handle concurrency	0.0	0.0	0.0	2.0	0.0000000000	False
monitoring temperature and depending	0.0	0.0	0.0	2.0	0.0000000000	False
depending on the temperature	0.0	0.0	0.0	2.0	0.0000000000	False
day the different temperature	0.0	0.0	0.0	2.0	0.0000000000	False
modification in the setting	0.0	0.0	0.0	2.0	0.0000000000	False
setting from the keypad	0.0	0.0	0.0	2.0	0.0000000000	False
evens that can occur	0.0	0.0	0.0	2.0	0.0000000000	False
concurrent processors or task	0.0	0.0	0.0	2.0	0.0000000000	False
task and being handled	0.0	0.0	0.0	2.0	0.0000000000	False
embedded system also request	0.0	0.0	0.0	2.0	0.0000000000	False
system also request concurrency	0.0	0.0	0.0	2.0	0.0000000000	False
interact to the system	0.0	0.0	0.0	2.0	0.0000000000	False
system in a concurrent	0.0	0.0	0.0	2.0	0.0000000000	False
issue in this contest	0.0	0.0	0.0	2.0	0.0000000000	False
processors from multiple users	0.0	0.0	0.0	2.0	0.0000000000	False
multiple users being run	0.0	0.0	0.0	2.0	0.0000000000	False
designing an embedded system	0.0	0.0	0.0	2.0	0.0000000000	False
size of the cpu	0.0	0.0	0.0	2.0	0.0000000000	False
deadline on project deadlines	0.0	0.0	0.0	2.0	0.0000000000	False
project deadlines but deadlines	0.0	0.0	0.0	2.0	0.0000000000	False
deadlines to be met	0.0	0.0	0.0	2.0	0.0000000000	False
system okay faster hardware	0.0	0.0	0.0	2.0	0.0000000000	False
faster hardware or cleverer	0.0	0.0	0.0	2.0	0.0000000000	False
hardware or cleverer software	0.0	0.0	0.0	2.0	0.0000000000	False
software and in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact there maybe cases	0.0	0.0	0.0	2.0	0.0000000000	False
cases i might write	0.0	0.0	0.0	2.0	0.0000000000	False
write a clever software	0.0	0.0	0.0	2.0	0.0000000000	False
deadline on the cpu	0.0	0.0	0.0	2.0	0.0000000000	False
cpu as incase executed	0.0	0.0	0.0	2.0	0.0000000000	False
executed i might require	0.0	0.0	0.0	2.0	0.0000000000	False
require a first cpu	0.0	0.0	0.0	2.0	0.0000000000	False
cpu but first cpu	0.0	0.0	0.0	2.0	0.0000000000	False
design on an fpga	0.0	0.0	0.0	2.0	0.0000000000	False
fpga at dedicated function	0.0	0.0	0.0	2.0	0.0000000000	False
cpu but that function	0.0	0.0	0.0	2.0	0.0000000000	False
deadline using the software	0.0	0.0	0.0	2.0	0.0000000000	False
design at dedicated logic	0.0	0.0	0.0	2.0	0.0000000000	False
logic on an fpga	0.0	0.0	0.0	2.0	0.0000000000	False
turn of unnecessary logic	0.0	0.0	0.0	2.0	0.0000000000	False
unnecessary logic reduce memory	0.0	0.0	0.0	2.0	0.0000000000	False
logic reduce memory access	0.0	0.0	0.0	2.0	0.0000000000	False
reduce memory access reducing	0.0	0.0	0.0	2.0	0.0000000000	False
memory access reducing memory	0.0	0.0	0.0	2.0	0.0000000000	False
access reducing memory access	0.0	0.0	0.0	2.0	0.0000000000	False
access why each memory	0.0	0.0	0.0	2.0	0.0000000000	False
power when we discuss	0.0	0.0	0.0	2.0	0.0000000000	False
discuss is power management	0.0	0.0	0.0	2.0	0.0000000000	False
important point to deal	0.0	0.0	0.0	2.0	0.0000000000	False
objectives dependability affordability safety	0.0	0.0	0.0	2.0	0.0000000000	False
dependability affordability safety security	0.0	0.0	0.0	2.0	0.0000000000	False
affordability safety security scalability	0.0	0.0	0.0	2.0	0.0000000000	False
safety security scalability timeliness	0.0	0.0	0.0	2.0	0.0000000000	False
timeliness as an issue	0.0	0.0	0.0	2.0	0.0000000000	False
kind of fault tolerance	0.0	0.0	0.0	2.0	0.0000000000	False
tolerance and graceful degradation	0.0	0.0	0.0	2.0	0.0000000000	False
hum to the users	0.0	0.0	0.0	2.0	0.0000000000	False
users i am depending	0.0	0.0	0.0	2.0	0.0000000000	False
kind of a multi	0.0	0.0	0.0	2.0	0.0000000000	False
approach why one aspect	0.0	0.0	0.0	2.0	0.0000000000	False
aspect is electronic hardware	0.0	0.0	0.0	2.0	0.0000000000	False
hardware the other aspect	0.0	0.0	0.0	2.0	0.0000000000	False
aspect is mechanical hardware	0.0	0.0	0.0	2.0	0.0000000000	False
talked about the control	0.0	0.0	0.0	2.0	0.0000000000	False
important the other thing	0.0	0.0	0.0	2.0	0.0000000000	False
institutions the sociological aspect	0.0	0.0	0.0	2.0	0.0000000000	False
sociological aspect about accepting	0.0	0.0	0.0	2.0	0.0000000000	False
product you can make	0.0	0.0	0.0	2.0	0.0000000000	False
people may not accepting	0.0	0.0	0.0	2.0	0.0000000000	False
acceptable depending on norms	0.0	0.0	0.0	2.0	0.0000000000	False
norms of the society	0.0	0.0	0.0	2.0	0.0000000000	False
sociological perspective for introducing	0.0	0.0	0.0	2.0	0.0000000000	False
introducing an a plans	0.0	0.0	0.0	2.0	0.0000000000	False
cycle how the embedded	0.0	0.0	0.0	2.0	0.0000000000	False
embedded system gets developed	0.0	0.0	0.0	2.0	0.0000000000	False
design look into manufacturing	0.0	0.0	0.0	2.0	0.0000000000	False
system and then requirement	0.0	0.0	0.0	2.0	0.0000000000	False
means how to draw	0.0	0.0	0.0	2.0	0.0000000000	False
product because after introducing	0.0	0.0	0.0	2.0	0.0000000000	False
wont support the product	0.0	0.0	0.0	2.0	0.0000000000	False
consumer you are invested	0.0	0.0	0.0	2.0	0.0000000000	False
commitment to that product	0.0	0.0	0.0	2.0	0.0000000000	False
product so the retirement	0.0	0.0	0.0	2.0	0.0000000000	False
plan of the product	0.0	0.0	0.0	2.0	0.0000000000	False
important so the design	0.0	0.0	0.0	2.0	0.0000000000	False
design goal in terms	0.0	0.0	0.0	2.0	0.0000000000	False
performance the overall speed	0.0	0.0	0.0	2.0	0.0000000000	False
functionality and user interface	0.0	0.0	0.0	2.0	0.0000000000	False
user interface manufacturing cost	0.0	0.0	0.0	2.0	0.0000000000	False
interface manufacturing cost power	0.0	0.0	0.0	2.0	0.0000000000	False
manufacturing cost power consumption	0.0	0.0	0.0	2.0	0.0000000000	False
power consumption physical size	0.0	0.0	0.0	2.0	0.0000000000	False
give you the performance	0.0	0.0	0.0	2.0	0.0000000000	False
performance as a criteria	0.0	0.0	0.0	2.0	0.0000000000	False
satisfied otherwise your product	0.0	0.0	0.0	2.0	0.0000000000	False
acceptability in the market	0.0	0.0	0.0	2.0	0.0000000000	False
kbs nobody will buy	0.0	0.0	0.0	2.0	0.0000000000	False
output as a function	0.0	0.0	0.0	2.0	0.0000000000	False
non-functional requirements non-functional requirements	0.0	0.0	0.0	2.0	0.0000000000	False
size power consumption reliability	0.0	0.0	0.0	2.0	0.0000000000	False
power consumption reliability etcetera	0.0	0.0	0.0	2.0	0.0000000000	False
part of your design	0.0	0.0	0.0	2.0	0.0000000000	False
design goal and design	0.0	0.0	0.0	2.0	0.0000000000	False
goal and design objective	0.0	0.0	0.0	2.0	0.0000000000	False
non-functional requirement at times	0.0	0.0	0.0	2.0	0.0000000000	False
appliances are a embedded	0.0	0.0	0.0	2.0	0.0000000000	False
system so this design	0.0	0.0	0.0	2.0	0.0000000000	False
architecture that is design	0.0	0.0	0.0	2.0	0.0000000000	False
architecture is a block	0.0	0.0	0.0	2.0	0.0000000000	False
shown is basically testing	0.0	0.0	0.0	2.0	0.0000000000	False
testing face because testing	0.0	0.0	0.0	2.0	0.0000000000	False
rectify that um bug	0.0	0.0	0.0	2.0	0.0000000000	False
embedded system that flexibility	0.0	0.0	0.0	2.0	0.0000000000	False
product to the user	0.0	0.0	0.0	2.0	0.0000000000	False
connect to the internet	0.0	0.0	0.0	2.0	0.0000000000	False
patch so these systems	0.0	0.0	0.0	2.0	0.0000000000	False
tested and the bug	0.0	0.0	0.0	2.0	0.0000000000	False
software faults the design	0.0	0.0	0.0	2.0	0.0000000000	False
faults the design approaches	0.0	0.0	0.0	2.0	0.0000000000	False
top down or bottom	0.0	0.0	0.0	2.0	0.0000000000	False
abstract description and work	0.0	0.0	0.0	2.0	0.0000000000	False
detailed level the bottom	0.0	0.0	0.0	2.0	0.0000000000	False
terms of embedded system	0.0	0.0	0.0	2.0	0.0000000000	False
system design um strategies	0.0	0.0	0.0	2.0	0.0000000000	False
work from small component	0.0	0.0	0.0	2.0	0.0000000000	False
component to big system	0.0	0.0	0.0	2.0	0.0000000000	False
cases when some bodies	0.0	0.0	0.0	2.0	0.0000000000	False
bodies developing a product	0.0	0.0	0.0	2.0	0.0000000000	False
component from previous system	0.0	0.0	0.0	2.0	0.0000000000	False
system because its availability	0.0	0.0	0.0	2.0	0.0000000000	False
process and in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact any real design	0.0	0.0	0.0	2.0	0.0000000000	False
real design actually involves	0.0	0.0	0.0	2.0	0.0000000000	False
talking about software development	0.0	0.0	0.0	2.0	0.0000000000	False
talking about both hardware	0.0	0.0	0.0	2.0	0.0000000000	False
development and you realize	0.0	0.0	0.0	2.0	0.0000000000	False
hardware and software development	0.0	0.0	0.0	2.0	0.0000000000	False
embedded system go handing	0.0	0.0	0.0	2.0	0.0000000000	False
system go handing hand	0.0	0.0	0.0	2.0	0.0000000000	False
design a special purpose	0.0	0.0	0.0	2.0	0.0000000000	False
hardware and in fact	0.0	0.0	0.0	2.0	0.0000000000	False
hardware um who designing	0.0	0.0	0.0	2.0	0.0000000000	False
designing software hardware partitioning	0.0	0.0	0.0	2.0	0.0000000000	False
partitioning and those approaches	0.0	0.0	0.0	2.0	0.0000000000	False
approaches so the step	0.0	0.0	0.0	2.0	0.0000000000	False
talking about is stepwise	0.0	0.0	0.0	2.0	0.0000000000	False
refinement of both hardware	0.0	0.0	0.0	2.0	0.0000000000	False
sort of the software	0.0	0.0	0.0	2.0	0.0000000000	False
requirement of the system	0.0	0.0	0.0	2.0	0.0000000000	False
system as a hole	0.0	0.0	0.0	2.0	0.0000000000	False
abroad overview um introductory	0.0	0.0	0.0	2.0	0.0000000000	False
overview um introductory overview	0.0	0.0	0.0	2.0	0.0000000000	False
appliances which are embedded	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems in fact	0.0	0.0	0.0	2.0	0.0000000000	False
fact some body made	0.0	0.0	0.0	2.0	0.0000000000	False
body made this statement	0.0	0.0	0.0	2.0	0.0000000000	False
viewer microwave your cell	0.0	0.0	0.0	2.0	0.0000000000	False
microwave your cell phone	0.0	0.0	0.0	2.0	0.0000000000	False
cell phone a viewer	0.0	0.0	0.0	2.0	0.0000000000	False
embedded computers and embedded	0.0	0.0	0.0	2.0	0.0000000000	False
computers and embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
move how to design	0.0	0.0	0.0	2.0	0.0000000000	False
issue and therefore embedded	0.0	0.0	0.0	2.0	0.0000000000	False
system goes mainly design	0.0	0.0	0.0	2.0	0.0000000000	False
challenges design time deadlines	0.0	0.0	0.0	2.0	0.0000000000	False
realize that embedded systems	0.0	0.0	0.0	2.0	0.0000000000	False
form a general purpose	0.0	0.0	0.0	2.0	0.0000000000	False
methodology and the principles	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems are expected	0.0	0.0	0.0	2.0	0.0000000000	False
methodologies help us mange	0.0	0.0	0.0	2.0	0.0000000000	False
mange the design process	0.0	0.0	0.0	2.0	0.0000000000	False
questions if you don	0.0	0.0	0.0	2.0	0.0000000000	False
class we shall start	0.0	0.0	0.0	2.0	0.0000000000	False
discussion on embedded hardware	0.0	0.0	0.0	2.0	0.0000000000	False
embedded systems today	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
discuss what embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
covering in forty	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cover the processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors a bus	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bus structures interfacing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
structures interfacing issues	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
program also real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
occasion to examine	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examine different aspects	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
aspects of network	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
network embedded systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sets of books	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
books which action	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
action primarily follow	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded system micro	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
micro any device	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
device that includes	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
includes a computer	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
general purpose computer	0.0176830004486	0.0	11.9903647626	20.6045125094	0.4338498212	True
expected to function	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
function without human	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
intervention an embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system is expect	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
expect to expect	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expect to respond	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control external environment	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
environment using sensors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sensors and actuators	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
embedding a computer	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
simplest possible model	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded system lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examples are personal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
personal digital assistance	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital assistance printers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computers cell phone	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
automobiles in fact	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
number of microcontrollers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded networks computing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
networks computing system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computing system television	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
television in television	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
household appliances lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microcontrollers sitting inside	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
managing these microcontrollers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designing there hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designing the software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software for managing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing a general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computer so lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system in fact	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
fact surveillance system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
surveillance system oblate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
smart cards etcetera	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
part of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
types of microcontroller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
users are thirty	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
thirty two bit	0.00656109227832	0.0	3.99587061253	7.92481250361	0.3589743590	False
two bit microcontroller	0.0	0.0	3.99793530626	1.58496250072	0.0000000000	False
planes example front	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
panel of microwave	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
size much smaller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
camera in fact	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
two bit processor	0.0	0.0	0.0	0.0	0.0000000000	False
handles complex functions	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
primarily the problem	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
problem of tuning	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tuning and channel	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital tv decompression	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
decompression disk family	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
set of box	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
box your microcontroller	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
handles a number	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
number of complex	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
complex functions lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
automobile system today	0.0	0.0	0.0	1.58496250072	0.0000000000	False
four bit microcontroller	0.0	0.0	0.0	1.58496250072	0.0000000000	False
microcontroller can check	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
check the tension	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
seat belt microcontrollers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microcontrollers can run	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
run the display	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control the engine	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
engine and sees	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sees the engine	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sixteen or thirty	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
bit microcontroller lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system of breaking	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sensors this sensors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensors actually sensors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensors the speed	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control by hydraulic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
automated breaking system	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
system which receives	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
breaking system actuate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
actuate the hydraulic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
pump to control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control the break	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control system begin	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system begin implemented	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
characteristics of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems first thing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implement sophisticated functionality	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
functionality the degree	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
degree of sophistication	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sophistication can vary	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
plans by plans	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
plans this satisfy	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real time operation	0.00631535730306	0.0	9.99655884377	6.33985000288	0.2922755741	False
cases low manufacturing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
low manufacturing cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost but cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue which request	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
request further closer	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
application dependent processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
general purpose processors	0.00252614292122	0.0	0.0	3.16992500144	0.0000000000	False
find in computers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
work with restricted	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
battery operator devices	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
val mounter devices	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
mounter devices powered	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
powered from direct	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
direct power supply	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
supply then power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
heat management heat	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
management heat dissipation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
heat dissipation design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system so lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue of manufacturing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aspects first aspect	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
call non recurring	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
non recurring engineering	0.0	0.0	0.0	0.0	0.0000000000	False
recurring engineering cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost is production	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
production and marketing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
marketing each unit	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
targeting um mass	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
production marketing cost	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
invest into enary	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
set for high	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
high production cost	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
highly sophisticated recruitments	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing as cell	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
phone or low	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
low cost cell	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost cell phone	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cell phone aiming	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aiming to serve	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
serve a mass	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
based technology choice	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of units	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
units with plans	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
plans to produce	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
produce now lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
issue of real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
operation the basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
completed by deadlines	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deadline so real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
completed within headline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kinds of real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
real time headlines	0.00465878848625	0.0	5.99793530626	3.16992500144	0.0000000000	False
headlines hard real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
headlines and soft	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
headlines and occluding	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
real time systems	0.0108705064679	0.0	5.99518238128	9.50977500433	0.3835616438	True
miss a deadline	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
automatic reactor control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
times miss deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
playing a video	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
decode a frame	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
distance you viewing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
experience many systems	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
multi-rate that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
means this embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems are receiving	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
application dependent requirements	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
monitoring accritical person	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tolerance and reliability	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
systems um avoid	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
physical or economic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
damage to person	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system that means	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
means nonce programmed	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
programmed this systems	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems um expected	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expected to execute	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
programmed or design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design for specific	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
call dedicated systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deliver the goals	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
goals and accept	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
accept the cache	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
machine which users	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users eight bit	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bit motorola microcontroller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
thousand four introduction	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
four introduction product	0.0	0.0	0.0	0.0	0.0000000000	False
web enabled cashless	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
enabled cashless vending	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cashless vending machine	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
task of delivering	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
delivering a good	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
good in response	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
web enabled device	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
enabling the stock	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cards or smart	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
brought in sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sophisticated processors sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors sophisticated functionalities	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bit intel microprocessor	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microprocessor in fact	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
robot which move	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
move down mars	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
gps receiver global	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
receiver global positioning	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
global positioning system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
vehicle to deprovement	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deprovement its location	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
automated navigational tool	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tool this gps	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
two receive input	0.0	0.0	0.0	1.58496250072	0.0000000000	False
display because display	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
player various versions	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
versions of mp3	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
form of audio	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
audio to play	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computational task apprentic	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
task apprentic sophisticated	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
apprentic sophisticated computational	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sophisticated computational task	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
two bit risk	0.0	0.0	0.0	0.0	0.0000000000	False
bit risk microprocessor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue is applicable	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
decompression and decompression	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
decompression what rate	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
video rate video	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
rate video rate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
video rate means	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
means what twenty	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
twenty five hertz	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
milliseconds to decompress	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
decompress of video	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
case aprentic sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aprentic sophisticated microprocessor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
microprocessor to work	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
two bit risc	0.0	0.0	0.0	0.0	0.0000000000	False
bit risc microprocessor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sony aibo robotic	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
aibo robotic dog	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
pet in japan	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users just note	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sixty four bit	0.00465878848625	0.0	3.99793530626	3.16992500144	0.0000000000	False
four bit neat	0.0	0.0	0.0	0.0	0.0000000000	False
bit neat processor	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
handle and number	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
coordinate its emotions	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
emotions that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control the manipulator	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computational robo football	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
teams in fact	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fact this sony	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
detect the ball	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
request pretty sophisticated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
pretty sophisticated processors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors to handle	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
handle it tasks	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
four bit mips	0.0	0.0	0.0	0.0	0.0000000000	False
bit mips risc	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
variety of examples	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examples now lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
classify the examples	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
similar to general	0.00465878848625	0.0	5.99793530626	0.0	0.0000000000	False
computing like pda	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
pda video games	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
video games set	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
boxes automatic teller	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
automatic teller machines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computing the similar	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
pda the maturity	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computer similar thing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
provide the input	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
input the user	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expect some output	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
output they note	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
note really sensing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensing external environment	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
activating any actuator	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
influence or change	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
change the external	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
purpose computing machines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
machines they respond	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
respond to users	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system whose basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sensing and actuating	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
actuating the feedback	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control of real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system various real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
feedback control depending	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
examples of user	0.0	0.0	0.0	1.58496250072	0.0000000000	False
vehicles engine foal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
engine foal injection	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control flight control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
flight control nuclear	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
control nuclear reactors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
examples of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems which belongs	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
category of control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
job or basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
focus is signal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processing your mp3	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
players your dvd	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
dvd players radar	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
players radar control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
radar control system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system the basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
similarly a sonar	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
signal processing systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
systems and communication	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
communication and networking	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of internet	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
internet a planes	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
planes in fact	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
fact the web	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
web enable vending	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
enable vending machine	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kind of functions	0.00109351537972	0.0	0.0	1.58496250072	0.0000000000	False
expected to implement	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sensing an actuation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
realize some control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
realize a control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control second important	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logic this sequencing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose sequencing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
purpose sequencing logic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
task specific sequencing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
specific sequencing logic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sequencing logic implemented	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interfacing and embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system with external	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
signal processing ability	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
ability to deal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deal with sense	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sense your inputs	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inputs next thing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
thing is application	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
application specific interfacing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
interfacing because application	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kind of senses	0.00155292949542	0.0	0.0	3.16992500144	0.0000000000	False
kind of actuated	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
interface this interfacing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implies both hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software next thing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing fault response	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
occurs the basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue or basic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
basic design philosophy	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
philosophy for fault	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
call graceful depredation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
graceful depredation cattest	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
depredation cattest traffic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cattest traffic failure	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
happening the system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
users that things	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
things are failing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
failing and graceful	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
battery is low	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
low so user	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
stop its activity	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
sun so graceful	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implement so lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expanded the basic	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
block have expanded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
shown the cpu	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cpu the alum	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
alum its cpu	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
obvious the memory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
memory because memory	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software to control	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control the system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
analog to digital	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
converters and digital	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
digital to analog	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
environment is expected	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expected to receive	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
receive sensor inputs	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inputs and actuate	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
actuate the actuators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
actuators to change	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
essential and integral	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
component in majority	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
shown an fpga	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
fpga or acid	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cases my cpu	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
ability to execute	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
execute my software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software satisfying real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
real time circumstance	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fpga and acid	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
cpu now lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cpu the human	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kind of reading	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
systems any control	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
lcd display panel	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simple um simple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
simple led based	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
led based informative	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
informative um color	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
color color codes	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tools why diagnostic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems are expected	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
expected to work	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
trace that failure	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
out and thrown	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tools to interface	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interface and check	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
working second important	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing why diagnostic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tools are important	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system is starting	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system is working	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
check at regular	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
basics so diagnostics	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
diagnostics tools form	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dealt with power	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
powered to dissipation	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dissipation when cooling	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design the cooling	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
extra heat dissipations	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design becomes important	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
casing the casing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system is exceptive	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
good well design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system can fail	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
packaging the system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
electronics then heat	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
heat can effective	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design becomes extrument	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
discuss those mechanical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
embedded system design	0.00465878848625	0.0	2.99793530626	4.75488750216	0.0000000000	True
kind an appliances	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design and implementation	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
implement an embedded	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
elements the processing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
basically your microprocessors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microprocessors and microcontrollers	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
devices because input	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
input an output	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
kinds of interfacing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
computer we tend	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tend to talk	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
talk about standard	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
standard input output	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
input output devices	0.00378921438184	0.0	5.99793530626	1.58496250072	0.0000000000	True
day by day	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
set of input	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
devices a large	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kind of sensors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
targeted for embedded	0.00465878848625	0.0	1.99793530626	3.16992500144	0.0000000000	False
cases even simpler	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
mechanism to interface	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interface with external	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
devices and external	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
external io devices	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
talked about system	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
software and application	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
components one aspects	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
aspects of vsd	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
typically we talk	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
talk about assemblers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
clause of system	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
software or operating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems now majority	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cases embedded systems	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
specialized operating systems	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
general purpose operating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
purpose operating system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
window units order	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
units order variance	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
satisfy certain caricaturists	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
encounter in general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
purpose computing system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designed to satisfy	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
satisfy the general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
case this embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems are dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real time scheduling	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
cases we require	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
require real tome	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real tome scheduling	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
compilers your compilers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compilers which compile	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compile your high	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
high level language	0.00194642685162	0.0	0.0	1.58496250072	0.0000000000	False
level language code	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
target machine code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system but incase	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
call cross assemblers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
assemblers and cross	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
entire development process	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
level language program	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
compilers and cross	0.00465878848625	0.0	3.99793530626	0.0	0.0000000000	False
compiler would run	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compiler to compile	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
generate the code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
code for big	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
compiler is running	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
find this compilers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
compilers and assemblers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
family of processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
targeting one processor	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of registers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
part of system	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
emulators this instruction	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
instruction set emulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
emulators actually emulates	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
emulates your processors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simple bevorial emulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
implement the instruction	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
complete simulation environment	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tools system software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system software tools	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
embedded system development	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
tool that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software to execute	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
execute your code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
connector that code	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
talk about emulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
emulators and simulators	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
talk about debugging	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
system software set	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
expect for general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
targeted for dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software obviously software	0.0	0.0	0.0	0.0	0.0000000000	False
flavors different kinds	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kinds of flavors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
operating system weak	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system weak works	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
weak works running	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
plants but application	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
printer is targeted	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
targeted for printing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
supported on top	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
present in multiple	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software would things	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
history of hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
status of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose microprocessor	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
fact this arrow	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
arrow actually tells	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
faster clock rate	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
faster execution speed	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
degree of integration	0.00310585899083	0.0	0.0	0.0	0.0000000000	False
integration that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
devices and peripherals	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
purpose microprocessor microcontroller	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
develop a system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system so unary	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost towards development	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors and microcontrollers	0.00155292949542	0.0	1.99793530626	3.16992500144	0.0000000000	False
microcontrollers for implementing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
embedded system dsp	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dsp that digital	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital signal processor	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	True
talking about digital	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
digital signal processing	0.00155292949542	1.0	2.99793530626	4.75488750216	0.0000000000	False
variety of signal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose microcontroller	0.00465878848625	0.0	2.99793530626	4.75488750216	0.0000000000	True
application specific processor	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing a processor	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
suit you application	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
application is search	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
permit this additional	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
additional unary cost	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
cost the kind	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system on chip	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
soc and soc	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
single processor code	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
code but multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
multiple processor codes	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processor codes alu	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
codes alu peripherals	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
textes instrument omap	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
instrument omap processor	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
dsp sitting inside	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inside the chip	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
peripheral also integrated	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
variety of issues	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system it means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
number of peripherals	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
special purpose coprocessors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors being integrated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
piece of silicon	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
functionality being implemented	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system as single	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
associate a design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
canjancem of power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
systems that supports	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
supports that means	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
correct logically correct	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logically correct means	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing is temporal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
real time consideration	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
correct at wrong	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deal with inherent	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
inherent physical concurrency	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computer we talk	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
talk about concurrency	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multiple users multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users multiple processors	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
multiple processors running	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
world is concurrent	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
reliability and fault	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tolerance obviously critical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
specific and single	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
single purpose lets	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multitasking and concurrency	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multitasking is important	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
important for embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
inputs and outputs	0.00109351537972	0.0	0.0	1.58496250072	0.0000000000	False
outputs and multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
events can occur	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cases as exceptive	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multitasking and separating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
issue is separating	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
separating task simplifies	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simplifies your programming	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tasks and concurrency	0.00155292949542	0.0	0.0	3.16992500144	0.0000000000	False
appearance of simultaneous	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
execution of multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tasks so lets	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
concurrency in temperature	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
simple temperature controller	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
control the temperature	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
request to handle	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
temperature and depending	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
processors or task	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
handled in dependent	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
simple embedded system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system also request	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
external world interact	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
processors from multiple	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
users being run	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
general purpose system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
challenges in designing	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing an embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
size of memory	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
meet our deadlines	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deadline on project	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deadlines but deadlines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
system okay faster	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
hardware or cleverer	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
write a clever	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
meet my deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
cpu as incase	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
require a first	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fpga at dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
low cost cpu	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
meat the deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
software i design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design at dedicated	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fpga or make	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
acid and include	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
dealing with real	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
systems next issue	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
minimize power turn	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
turn of unnecessary	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
unnecessary logic reduce	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logic reduce memory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
reduce memory access	0.00310585899083	0.0	0.0	1.58496250072	0.0000000000	False
memory access reducing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
access reducing memory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption of power	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
discuss is power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
power management issue	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
point to deal	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
designing a system	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
objectives dependability affordability	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
dependability affordability safety	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
affordability safety security	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
safety security scalability	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
security scalability timeliness	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
discussed the timeliness	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
kind of fault	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
tolerance and graceful	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
safe and secure	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
depending on market	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
objectives in order	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
order to multi	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multi the objectives	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
objectives we require	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
require a kind	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
multi disciplinary approach	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
aspect is electronic	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aspect is mechanical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
thing is humans	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
humans on society	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
society or institutions	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
institutions the sociological	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
aspect about accepting	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
accepting a product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
make a product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
product but people	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
sociologically acceptable depending	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
depending on norms	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
perspective for introducing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
life cycle events	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system gets developed	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
logistics of maintaining	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
maintaining the system	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
draw the product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
introducing a product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
support the product	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
important design goal	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
goal in terms	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
terms of performance	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
speed and deadlines	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
deadlines then functionality	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
functionality and user	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
user interface manufacturing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
interface manufacturing cost	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
manufacturing cost power	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cost power consumption	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
power consumption physical	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption physical size	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption although related	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
product is non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non be acceptability	0.0	0.0	0.0	1.58496250072	0.0000000000	False
functional and non	0.0	0.0	0.0	1.58496250072	0.0000000000	False
non functional requirements	0.0	0.0	0.0	1.58496250072	0.0000000000	False
function of input	0.00126307146061	0.0	0.0	1.58496250072	0.0000000000	False
non-functional requirements non-functional	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
requirements non-functional requirements	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
size power consumption	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
power consumption reliability	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
consumption reliability etcetera	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
goal and design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
requirement at times	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
important for acceptance	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design development process	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
start with requirements	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design an architecture	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
block level architecture	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
component level design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
basically testing face	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
face because testing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
find a bug	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
download a patch	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
system that flexibility	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
giving that product	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
user and user	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
user is expect	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
internet and download	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
download the patch	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
bug for hardware	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
faults the design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
top down design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design you start	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
description and work	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
level the bottom	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bottom up design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
common in terms	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
terms of embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design um strategies	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
strategies you work	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
work from small	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
component to big	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
developing a product	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
component from previous	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
bottom up process	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
fact any real	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design actually involves	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
step wise requirement	0.00310585899083	0.0	0.0	3.16992500144	0.0000000000	False
talking about software	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
hardware and software	0.00109351537972	0.0	0.0	0.0	0.0000000000	False
system go handing	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
meet at deadline	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design a special	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
special purpose hardware	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
designing software hardware	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
software hardware partitioning	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
show for covered	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
overview um introductory	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
fact some body	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
made this statement	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
statement that today	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microcontrollers and microprocessors	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microprocessors at home	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
home then computers	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
microwave your cell	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
phone a viewer	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
microcontroller setting inside	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
computers and embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design challenges design	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
design time deadlines	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
deadlines and power	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
realize that embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
form a general	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
characteristics of components	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
mange the design	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
design process perfect	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
end this lecture	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
start our discussion	0.00155292949542	0.0	0.0	1.58496250072	0.0000000000	False
discussion on embedded	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
embedded systems	0.0488387631437	0.0	25.9600825877	57.0	0.6086956522	True
systems today	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
broad outline	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
forty lectures	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bus structures	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
interfacing issues	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
software optimization	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
network embedded	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
lets start	0.000729010253146	0.0	0.0	1.0	0.0000000000	False
system micro	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
general purpose	0.0210511910102	0.0	15.9827942189	23.0	0.4038461538	False
purpose computer	0.0117886669657	0.0	11.9903647626	12.0	0.4338498212	False
larger system	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
human intervention	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
respond monitor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
external environment	0.00414114532111	0.0	1.99724707502	3.0	0.5384615385	False
computer embedding	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
external world	0.00414114532111	0.0	2.99724707502	3.0	0.5384615385	False
analog interfaces	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
system lets	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
examples examples	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
personal digital	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
digital assistance	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
assistance printers	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
computers cell	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cell phone	0.00621171798166	0.0	6.99587061253	5.0	0.3814713896	False
fact automobiles	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
embedded networks	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
networks computing	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
computing system	0.00107154312655	0.0	0.0	1.0	0.0000000000	False
system television	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
purposes microcontrollers	0.00414114532111	0.0	2.99724707502	1.0	0.5384615385	False
household appliances	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
appliances lets	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
digital camera	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
microcontrollers sitting	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
sitting inside	0.00252614292122	0.0	1.99793530626	2.0	0.0000000000	False
microcontrollers designing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
hardware designing	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
channels challenge	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
adopt designing	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
surveillance system	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
fact surveillance	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
system oblate	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
tremendous important	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
security reasons	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
video cameras	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
biometric systems	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
smart cards	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
cards etcetera	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
pdi users	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
bit microcontroller	0.00414114532111	0.0	4.99724707502	3.0	0.2058823529	True
front panel	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
microwave oven	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
words size	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
bit processor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
complex functions	0.00414114532111	0.0	2.99724707502	3.0	0.2978723404	False
simpler microcontroller	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
microcontroller handles	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
channel selection	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
decompression disk	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
disk family	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
functions lets	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
automobile system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sophisticated automobile	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
hundred microprocessors	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
seat belt	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
belt microcontrollers	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
display services	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
engine controlling	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
powerful microcontroller	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
microcontroller lets	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
breaking system	0.00310585899083	0.0	5.99793530626	2.0	0.0000000000	False
hydraulic pump	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
receives input	0.00310585899083	0.0	3.99793530626	2.0	0.0000000000	False
system actuate	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
control system	0.00517643165139	0.0	7.99655884377	4.0	0.2368866328	True
system begin	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
begin implemented	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
implement sophisticated	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sophisticated functionality	0.00310585899083	0.0	1.99793530626	2.0	0.0000000000	False
satisfy real	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
low manufacturing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
manufacturing cost	0.00310585899083	0.0	3.99793530626	2.0	0.0000000000	False
closer examination	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
application dependent	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
dependent processors	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
purpose processors	0.00168409528082	0.0	0.0	1.0	0.0000000000	False
restricted memory	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
important consideration	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
battery operator	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
operator devices	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
val mounter	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
mounter devices	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
devices powered	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
direct power	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
power supply	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
power consumption	0.00336819056163	0.0	2.99724707502	3.0	0.2978723404	False
important issues	0.00291604101259	0.0	1.99724707502	3.0	0.5384615385	False
heat management	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
management heat	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
heat dissipation	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
dissipation design	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
call non	0.0	0.0	0.0	0.0	0.0000000000	False
non recurring	0.0	0.0	0.0	0.0	0.0000000000	False
recurring engineering	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
engineering cost	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
development cost	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
mass market	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
production marketing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
marketing cost	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
specialize application	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
combines set	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
high production	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
production cost	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
automated system	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
invest money	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
sophisticated recruitments	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
low cost	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
cost cell	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
phone aiming	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
based technology	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
technology choice	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
basic definition	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
soft real	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
hard real	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
automatic reactor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
reactor control	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
times miss	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
miss deadline	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
viewing experience	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
rate inputs	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
multi-rate systems	0.00103528633028	0.0	0.0	1.0	0.0000000000	True
dependent requirements	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
aircraft system	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
fault tolerance	0.00517643165139	0.0	3.99655884377	4.0	0.3814713896	True
medical equipments	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
accritical person	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
safe systems	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
economic damage	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
dedicated systems	0.00207057266055	1.0	0.0	1.0	0.0000000000	False
design consideration	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
regular basics	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
right lifetime	0.0	0.0	0.0	1.0	0.0000000000	False
means nonce	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
large duration	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
users intervention	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
specific task	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
vending machine	0.00724700431194	0.0	7.99518238128	6.0	0.1656804734	False
electronic part	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
mechanical part	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
critical important	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
bit motorola	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
motorola microcontroller	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
introduction product	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
web enabled	0.00414114532111	0.0	4.99724707502	3.0	0.2978723404	False
enabled cashless	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cashless vending	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simple task	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cash input	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
enabled device	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cash transactions	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
credit cards	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
remote location	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
sophisticated processors	0.00168409528082	0.0	0.0	1.0	0.0000000000	False
mars rover	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
mobile robot	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
bit intel	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
intel microprocessor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
global positioning	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
positioning system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
transport vehicle	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
automotive systems	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
navigational tool	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
gps receivers	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
common place	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
critical component	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
communication equipment	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
provide output	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
mp3 player	0.00310585899083	0.0	3.99793530626	2.0	0.0000000000	False
mp3 mp3	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
compress form	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
decompress audio	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
computational task	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
apprentic sophisticated	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sophisticated computational	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
bit risk	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
risk microprocessor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
dvd player	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
complex form	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
video rate	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
rate video	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
rate means	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
forty milliseconds	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
video file	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
aprentic sophisticated	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sophisticated microprocessor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bit risc	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
risc microprocessor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sony aibo	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
robotic dog	0.00168409528082	0.0	0.0	0.0	0.0000000000	False
popular pet	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
complex microprocessor	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
reduces sixty	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bit neat	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
neat processor	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
complex tasks	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
communication facility	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
robo cup	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
computational robo	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
robo football	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
robotics teams	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
aibo robotics	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
question algorithms	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
bit mips	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
mips risc	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
lets classify	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
general computing	0.00252614292122	0.0	5.99793530626	1.0	0.0000000000	False
pda video	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
video games	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
games set	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
automatic teller	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
teller machines	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
restricted form	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
similar thing	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
computing machines	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
users input	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
basic job	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
feedback control	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
control depending	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
external input	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
vehicles engine	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
foal injection	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
control flight	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
flight control	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
control nuclear	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
nuclear reactors	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
signal processing	0.00931757697249	0.0	13.9917412251	11.0	0.2563580875	True
core job	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
basic focus	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
players radar	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
radar control	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sonar system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
processing systems	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cellular phones	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
enable vending	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
internet appliance	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
actuation sensing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
basic task	0.00168409528082	0.0	0.0	2.0	0.0000000000	False
sequencing logic	0.00414114532111	0.0	7.99724707502	3.0	0.2058823529	True
task specific	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
purpose sequencing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
specific sequencing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
logic implemented	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
external sense	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
core activity	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
processing ability	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
specific interfacing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
interfacing implies	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
thing fault	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
fault response	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
fault occurs	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
basic issue	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
basic design	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
design philosophy	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
graceful depredation	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
depredation cattest	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cattest traffic	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
traffic failure	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
battery failure	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
graceful degradation	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
important function	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
complete architecture	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
simplest model	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
previous modal	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
basic block	0.00414114532111	0.0	2.99724707502	3.0	0.2058823529	False
showing analog	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
digital converters	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
analog converters	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
conversion blocks	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
receive sensor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sensor inputs	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
integral component	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
acid block	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
software satisfying	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
special hardware	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
alumeter cpu	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
order issues	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
human interface	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
control functions	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
human users	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
important component	0.00168409528082	0.0	0.0	2.0	0.0000000000	False
lcd display	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
display panel	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simple led	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
color color	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
color codes	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
happening inside	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
diagnostic tools	0.00517643165139	0.0	4.99655884377	4.0	0.2368866328	False
failure occurs	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
important thing	0.000845468352031	0.0	0.0	1.0	0.0000000000	False
continuous base	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
hardware components	0.000842047640408	0.0	0.0	1.0	0.0000000000	False
tools form	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
essential component	0.00168409528082	0.0	0.0	2.0	0.0000000000	False
auxiliary systems	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
cooling circuit	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
extra heat	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
mechanical aspect	0.00310585899083	0.0	2.99793530626	2.0	0.0000000000	False
packaging issue	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
design system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bad packaging	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
effective electronics	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
extrument point	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
system design	0.00218703075944	0.0	2.99793530626	1.0	0.0000000000	False
appliances design	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
processing elements	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
peripheral devices	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
output devices	0.00336819056163	0.0	6.99724707502	2.0	0.2058823529	False
interface sensors	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
interfacing protocols	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bus design	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
standard input	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
input output	0.00218703075944	0.0	5.99793530626	1.0	0.0000000000	False
expanded day	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
embedded applications	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
complex mechanisms	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
simpler mechanisms	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
external devices	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
system software	0.00926252404449	1.0	13.9924294563	10.0	0.1975625401	False
application software	0.00421023820204	0.0	4.99655884377	4.0	0.3309692671	True
assemblers compilers	0.00103528633028	1.0	0.0	0.0	0.0000000000	False
language translators	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
operating systems	0.00510307177202	0.0	7.99518238128	6.0	0.2666666667	False
cases embedded	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
purpose operating	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
window units	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
units order	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
order variance	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
specialized operating	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
important characteristics	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
scheduling features	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
real tome	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
tome scheduling	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
high level	0.000733580593201	0.0	0.0	1.0	0.0000000000	False
level language	0.00129761790108	0.0	0.0	1.0	0.0000000000	False
language code	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
target machine	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
machine code	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
call cross	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cross assemblers	0.00414114532111	1.0	5.99724707502	3.0	0.2978723404	True
cross compilers	0.00517643165139	0.0	7.99655884377	3.0	0.3309692671	True
development tools	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
entire development	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
development process	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
language program	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
target processor	0.00310585899083	0.0	1.99793530626	3.0	0.0000000000	False
target system	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
big microcontroller	0.00310585899083	0.0	5.99793530626	2.0	0.0000000000	False
windows environment	0.000842047640408	0.0	0.0	1.0	0.0000000000	False
target board	0.00724700431194	0.0	4.99518238128	7.0	0.3146067416	False
interesting features	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
targeting variance	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
similar architecture	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
registers etcetera	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
call emulators	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
instruction set	0.00145802050629	0.0	0.0	1.0	0.0000000000	False
set emulators	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simple bevorial	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bevorial emulators	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simple implement	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
complete simulation	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simulation environment	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
timing analysis	0.000842047640408	0.0	0.0	1.0	0.0000000000	False
host machine	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
tools system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
software tools	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
system development	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simple software	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
layer running	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
hardware connector	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
monitor execution	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
target code	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
debugging tools	0.00207057266055	1.0	0.0	1.0	0.0000000000	False
software set	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
dedicated appliances	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
scheduling capabilities	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
system weak	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
weak works	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
works running	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
laser printer	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
hardware evolution	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
lower tense	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
purpose microprocessor	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
faster clock	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
clock rate	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
faster execution	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
execution speed	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
higher degree	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
microprocessor microcontroller	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
unary cost	0.00310585899083	0.0	2.99793530626	2.0	0.0000000000	False
system dsp	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
digital signal	0.00310585899083	0.0	2.99793530626	2.0	0.0000000000	False
signal processor	0.00310585899083	0.0	2.99793530626	2.0	0.0000000000	False
application specific	0.00252614292122	0.0	2.99793530626	2.0	0.0000000000	False
specific processor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
additional unary	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
put system	0.00103528633028	0.0	1.99793530626	2.0	0.0000000000	False
chip soc	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
current frames	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
single processor	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
processor code	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
multiple processor	0.00336819056163	0.0	6.99724707502	3.0	0.4242424242	True
codes alu	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
alu peripherals	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
textes instrument	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
instrument omap	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
omap processor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
risk processor	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
dsp sitting	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
entire communication	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
large number	0.000299558053273	0.0	0.0	0.0	0.0000000000	False
special purpose	0.00168409528082	0.0	0.0	1.0	0.0000000000	False
purpose coprocessors	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
single piece	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
single silicon	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
smaller area	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
man faction	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
power software	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
typical characteristics	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
correct means	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
temporal correctness	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
inherent physical	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
physical concurrency	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
multiple users	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
users multiple	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
processors running	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
support concurrency	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
critical issues	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
single purpose	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
purpose lets	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
multiple events	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
separating task	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
task simplifies	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
programming complexity	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
multitasking system	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
basically appearance	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simultaneous execution	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
multiple tasks	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
temperature controller	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
simple temperature	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
handle concurrency	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
monitoring temperature	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
temperature setting	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
concurrent evens	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
concurrent processors	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
request concurrency	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
world interact	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
concurrent fashion	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
purpose system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
project deadlines	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
faster hardware	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cleverer software	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
incase executed	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
first cpu	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
extra cost	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
dedicated function	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cost cpu	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
dedicated logic	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
important point	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
minimize power	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
power turn	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
unnecessary logic	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
logic reduce	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
reduce memory	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
memory access	0.00310585899083	0.0	2.99793530626	2.0	0.0000000000	False
access reducing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
power management	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
management issue	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
global picture	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
multi objective	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
objectives dependability	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
dependability affordability	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
affordability safety	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
safety security	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
security scalability	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
scalability timeliness	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bordely hum	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
disciplinary approach	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
electronic hardware	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
mechanical hardware	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
control algorithm	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
sociological aspect	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
acceptable depending	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sociological perspective	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
life cycle	0.00310585899083	0.0	2.99793530626	2.0	0.0000000000	False
cycle events	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
requirement means	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
wont support	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
retirement plan	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
design objective	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
important design	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
design goal	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
user interface	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
interface manufacturing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cost power	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
physical size	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
ten kbs	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
functional requirements	0.00168409528082	0.0	0.0	1.0	0.0000000000	False
non-functional requirements	0.00310585899083	0.0	2.99793530626	2.0	0.0000000000	False
size power	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
consumption reliability	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
reliability etcetera	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
form part	0.000842047640408	0.0	0.0	1.0	0.0000000000	False
design development	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
block level	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
level architecture	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
component level	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
level design	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
system integration	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
testing face	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
computer save	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
software faults	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
design approaches	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
software design	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
abstract description	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
detailed level	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
small component	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
big system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
bodies developing	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
previous system	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
real design	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
step wise	0.00168409528082	0.0	0.0	0.0	0.0000000000	False
wise requirement	0.00207057266055	0.0	0.0	0.0	0.0000000000	False
software development	0.00414114532111	1.0	7.99724707502	3.0	0.2058823529	False
handing hand	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
separate things	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
pure software	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
purpose hardware	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
software hardware	0.00207057266055	0.0	0.0	1.0	0.0000000000	False
designing software	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
hardware partitioning	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
stepwise refinement	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
stepwise requirement	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
concluding remark	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
introductory overview	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
body made	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
washing machine	0.000842047640408	0.0	0.0	1.0	0.0000000000	False
viewer microwave	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
microcontroller setting	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
setting inside	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
embedded computers	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
design challenges	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
challenges design	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
precisely reason	0.00103528633028	0.0	0.0	1.0	0.0000000000	False
basic principles	0.000842047640408	0.0	0.0	1.0	0.0000000000	False
design methodology	0.00207057266055	0.0	0.0	2.0	0.0000000000	False
design process	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
process perfect	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
embedded hardware	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
embedded	0.0190644995857	0.0	0.0	0.0	0.4385820280	False
systems	0.0141086438297	0.0	0.0	0.0	0.3614643545	False
today	7.25135925554e-05	0.0	0.0	0.0	0.5384615385	False
discuss	0.000380938552007	0.0	0.0	0.0	0.4501607717	False
lets	0.000989893840521	0.0	0.0	0.0	0.4242424242	False
syllabus	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
follow	0.000223941275309	0.0	0.0	0.0	0.0000000000	False
broad	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
outline	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
covering	0.000480327310807	0.0	0.0	0.0	0.0000000000	False
forty	0.000492796743142	0.0	0.0	0.0	0.0000000000	False
lectures	9.65364473705e-05	0.0	0.0	0.0	0.0000000000	False
processors	0.0110297521592	0.0	0.0	0.0	0.2197599261	True
bus	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
structures	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
interfacing	0.00334357102775	0.0	0.0	0.0	0.2756224667	False
issues	0.00240147129016	0.0	0.0	0.0	0.5098970705	False
software	0.0073650187657	0.0	0.0	0.0	0.2228373702	False
optimization	0.000342532873409	0.0	0.0	0.0	0.0000000000	False
program	0.000689568221126	0.0	0.0	0.0	0.3286384977	False
real	0.00128103908773	0.0	0.0	0.0	0.2425196850	False
occasion	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
examine	0.000586599987251	0.0	0.0	0.0	0.0000000000	False
aspects	0.00239646442618	0.0	0.0	0.0	0.2814070352	False
network	0.000513799310113	0.0	0.0	0.0	0.0000000000	False
sets	0.000137694004839	0.0	0.0	0.0	0.4158415842	False
books	0.000321633574382	0.0	0.0	0.0	0.0000000000	False
market	0.00227083132689	0.0	0.0	0.0	0.2886597938	False
action	0.000803657344916	0.0	0.0	0.0	0.0000000000	False
primarily	0.000535771563277	0.0	0.0	0.0	0.0000000000	False
start	0.0	0.0	0.0	0.0	0.4501607717	False
definition	0.000174687148327	0.0	0.0	0.0	0.5490196078	False
micro	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
device	0.00338187340813	0.0	0.0	0.0	0.2814070352	False
includes	0.000200122607513	0.0	0.0	0.0	0.0000000000	False
computer	0.000580108740444	0.0	0.0	0.0	0.3223501389	False
general	0.000317755395782	0.0	0.0	0.0	0.4029776675	False
purpose	0.00233680759304	0.0	0.0	0.0	0.4242424242	False
hardware	0.00465007593617	0.0	0.0	0.0	0.3623529412	False
larger	6.89568221126e-05	0.0	0.0	0.0	0.0000000000	False
expected	0.0021024293259	0.0	0.0	0.0	0.3414634146	False
function	0.000574108436847	0.0	0.0	0.0	0.3507972665	False
human	0.000983403243456	0.0	0.0	0.0	0.3309692671	False
intervention	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
respond	0.00045557026067	0.0	0.0	0.0	0.0000000000	False
monitor	0.00160731468983	0.0	0.0	0.0	0.4719101124	False
control	0.00306787957432	0.0	0.0	0.0	0.2161160852	False
external	0.00437406151888	0.0	0.0	0.0	0.4158415842	False
environment	0.001724788601	0.0	0.0	0.0	0.4912280702	False
sensors	0.00505228584245	0.0	0.0	0.0	0.2937062937	False
actuators	0.00569407481652	0.0	0.0	0.0	0.3472378805	False
basically	0.000314802256666	0.0	0.0	0.0	0.3867403315	False
talking	0.000153363430812	0.0	0.0	0.0	0.3879093199	False
applies	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
plants	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
interact	0.000492796743142	0.0	0.0	0.0	0.0000000000	False
world	0.000960654621614	0.0	0.0	0.0	0.5600000000	False
analog	0.000983403243456	0.0	0.0	0.0	0.3814713896	False
model	0.000368145548919	0.0	0.0	0.0	0.0000000000	False
showing	0.000151285548674	0.0	0.0	0.0	0.3814713896	False
simplest	0.0003667902966	0.0	0.0	0.0	0.0000000000	False
examples	0.000758525043239	0.0	0.0	0.0	0.3973916379	False
personal	0.000449337079909	0.0	0.0	0.0	0.0000000000	False
digital	0.00149779026636	0.0	0.0	0.0	0.3517587940	False
assistance	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
printers	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cell	0.00175979996175	0.0	0.0	0.0	0.3814713896	False
phone	0.00227083132689	0.0	0.0	0.0	0.4077669903	False
family	0.000803657344916	0.0	0.0	0.0	0.0000000000	False
automobiles	0.00310585899083	0.0	0.0	0.0	0.3206106870	False
fact	0.0003392458945	0.0	0.0	0.0	0.5250000000	False
number	2.40937117553e-05	0.0	0.0	0.0	0.5714285714	False
microcontrollers	0.0160469381193	0.0	0.0	0.0	0.1747363891	True
television	0.000586599987251	0.0	0.0	0.0	0.0000000000	False
household	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
appliances	0.00336819056163	0.0	0.0	0.0	0.3835616438	False
physically	0.000856332183521	0.0	0.0	0.0	0.4501607717	False
appediate	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
camera	0.00175979996175	0.0	0.0	0.0	0.3206106870	False
sitting	0.000393497356202	0.0	0.0	0.0	0.0000000000	False
inside	0.000466301665027	0.0	0.0	0.0	0.4242424242	False
managing	0.000786722594765	0.0	0.0	0.0	0.4242424242	False
designing	0.00480294258032	0.0	0.0	0.0	0.3015497767	False
planes	0.000634101264023	0.0	0.0	0.0	0.0000000000	False
channels	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
challenge	0.000973213425809	0.0	0.0	0.0	0.0000000000	False
adopt	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
back	0.000207278642797	0.0	0.0	0.0	0.4719101124	False
surveillance	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
oblate	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
tremendous	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
important	0.00168864243383	0.0	0.0	0.0	0.4836212031	False
security	0.00145802050629	0.0	0.0	0.0	0.4242424242	False
reasons	8.70852202515e-05	0.0	0.0	0.0	0.0000000000	False
video	0.00169093670406	0.0	0.0	0.0	0.4057971014	False
biometric	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
smart	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
cards	0.000879899980877	0.0	0.0	0.0	0.0000000000	False
etcetera	0.00109351537972	0.0	0.0	0.0	0.0000000000	False
part	5.57685202951e-05	0.0	0.0	0.0	0.4516129032	False
palm	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
appeared	0.0003667902966	0.0	0.0	0.0	0.0000000000	False
cases	0.0	0.0	0.0	0.0	0.5098970705	False
types	0.000223941275309	0.0	0.0	0.0	0.0000000000	False
pdi	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
users	0.00275448149341	0.0	0.0	0.0	0.4338028169	False
thirty	0.0011003708898	0.0	0.0	0.0	0.3589743590	False
two	0.0	0.0	0.0	0.0	0.3888888889	False
bit	0.000363085316818	0.0	0.0	0.0	0.2270270270	False
front	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
panel	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
microwave	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
oven	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
typically	0.000500306518783	0.0	0.0	0.0	0.4501607717	False
words	0.000106319363404	0.0	0.0	0.0	0.0000000000	False
size	0.000344784110563	0.0	0.0	0.0	0.3814713896	False
smaller	0.000173551606732	0.0	0.0	0.0	0.0000000000	False
handles	0.0020173466313	0.0	0.0	0.0	0.2919431280	False
minutes	0.000131165785401	0.0	0.0	0.0	0.0000000000	False
complex	0.00147258219568	0.0	0.0	0.0	0.3442622951	False
similarly	8.70852202515e-05	0.0	0.0	0.0	0.0000000000	False
simpler	0.000342532873409	0.0	0.0	0.0	0.0000000000	False
problem	6.97106503689e-06	0.0	0.0	0.0	0.0000000000	False
tuning	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
selection	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
decompression	0.00258821582569	0.0	0.0	0.0	0.3309692671	False
disk	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
box	0.00045557026067	0.0	0.0	0.0	0.0000000000	False
sophisticated	0.00322629992988	0.0	0.0	0.0	0.4645550528	False
hundred	0.000122715182973	0.0	0.0	0.0	0.0000000000	False
microprocessors	0.0067293611468	0.0	0.0	0.0	0.3472378805	True
four	0.0	0.0	0.0	0.0	0.3309692671	False
check	0.000322318288695	0.0	0.0	0.0	0.4242424242	False
tension	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
seat	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
belt	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
run	0.000272313987614	0.0	0.0	0.0	0.4710280374	False
display	0.000733580593201	0.0	0.0	0.0	0.4242424242	False
services	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
dashboard	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
engine	0.000786722594765	0.0	0.0	0.0	0.4242424242	False
sees	0.000293299993626	0.0	0.0	0.0	0.5426356589	False
powerful	0.00128927315478	0.0	0.0	0.0	0.3127326880	False
sixteen	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
architecture	0.00241097203475	0.0	0.0	0.0	0.3320158103	False
breaking	0.00133942890819	0.0	0.0	0.0	0.2368866328	False
found	0.000107211191461	0.0	0.0	0.0	0.0000000000	False
speed	0.000683355391005	0.0	0.0	0.0	0.0000000000	False
hydraulic	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
pump	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
automated	0.00145802050629	0.0	0.0	0.0	0.4242424242	False
receives	0.00218703075944	0.0	0.0	0.0	0.3589743590	False
input	0.00126979517336	0.0	0.0	0.0	0.3465346535	False
depending	0.000393342426553	0.0	0.0	0.0	0.3252904379	False
begin	7.46470917698e-05	0.0	0.0	0.0	0.0000000000	False
implemented	0.00111912399607	0.0	0.0	0.0	0.4468085106	False
characteristics	0.00218703075944	0.0	0.0	0.0	0.3814713896	False
first	0.0	0.0	0.0	0.0	0.4719101124	False
thing	0.0	0.0	0.0	0.0	0.4338498212	False
degree	0.000480327310807	0.0	0.0	0.0	0.0000000000	False
vary	0.000393361297382	0.0	0.0	0.0	0.0000000000	False
plans	0.00194642685162	0.0	0.0	0.0	0.3589743590	False
satisfy	0.000748895133182	0.0	0.0	0.0	0.4501607717	False
operation	0.000724023355278	0.0	0.0	0.0	0.2501488982	False
true	0.000275827288451	0.0	0.0	0.0	0.3906976744	False
necessarily	0.000131165785401	0.0	0.0	0.0	0.0000000000	False
comeback	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
point	1.72097941109e-05	0.0	0.0	0.0	0.4501607717	False
slightly	5.82290494424e-05	0.0	0.0	0.0	0.0000000000	False
low	0.000640436414409	0.0	0.0	0.0	0.5384615385	False
manufacturing	0.00129761790108	0.0	0.0	0.0	0.5384615385	False
cost	0.00291152942397	0.0	0.0	0.0	0.2188505747	False
request	0.00168409528082	0.0	0.0	0.0	0.4242424242	False
closer	0.000211367088008	0.0	0.0	0.0	0.0000000000	False
application	0.00117226597591	0.0	0.0	0.0	0.4511848341	False
find	0.000143091934848	0.0	0.0	0.0	0.4895104895	False
work	0.000208766704308	0.0	0.0	0.0	0.4516129032	False
restricted	0.0003667902966	0.0	0.0	0.0	0.0000000000	False
memory	0.00137013149363	0.0	0.0	0.0	0.2886597938	False
consideration	0.000683355391005	0.0	0.0	0.0	0.0000000000	False
battery	0.00168409528082	0.0	0.0	0.0	0.3500000000	False
val	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
mounter	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
direct	0.00014016195506	0.0	0.0	0.0	0.0000000000	False
supply	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
consumption	0.00210511910102	0.0	0.0	0.0	0.3309692671	False
heat	0.0011731999745	0.0	0.0	0.0	0.3500000000	False
dissipation	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
add	7.46470917698e-05	0.0	0.0	0.0	0.0000000000	False
call	2.06517529331e-05	0.0	0.0	0.0	0.5600000000	False
non	0.0	0.0	0.0	0.0	0.0000000000	False
recurring	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
development	0.00222981835181	0.0	0.0	0.0	0.2669657880	False
production	0.00184072774459	0.0	0.0	0.0	0.2779616148	False
unit	0.000449337079909	0.0	0.0	0.0	0.0000000000	False
targeting	0.00801911278461	0.0	0.0	0.0	0.1520236920	False
mass	0.000586599987251	0.0	0.0	0.0	0.0000000000	False
specialize	0.000643267148763	0.0	0.0	0.0	0.4719101124	False
invest	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
enary	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
combines	9.32603330054e-05	0.0	0.0	0.0	0.0000000000	False
high	0.000260327410097	0.0	0.0	0.0	0.0000000000	False
aircraft	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
money	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
highly	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
recruitments	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
flexibility	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
aiming	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
serve	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
based	0.000241738716522	0.0	0.0	0.0	0.0000000000	False
technology	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
choice	8.67758033658e-05	0.0	0.0	0.0	0.0000000000	False
produce	0.000149779026636	0.0	0.0	0.0	0.0000000000	False
completed	0.000104383352154	0.0	0.0	0.0	0.4242424242	False
deadlines	0.00589433348286	0.0	0.0	0.0	0.2242760320	False
headline	0.00207057266055	0.0	0.0	0.0	0.2058823529	False
kinds	0.000228947095757	0.0	0.0	0.0	0.3916083916	False
hard	0.000299558053273	0.0	0.0	0.0	0.0000000000	False
soft	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
occluding	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
classify	0.000342532873409	0.0	0.0	0.0	0.0000000000	False
miss	0.000739195114712	0.0	0.0	0.0	0.0000000000	False
automatic	0.000342532873409	0.0	0.0	0.0	0.0000000000	False
reactor	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
catesed	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
hand	0.000159479045106	0.0	0.0	0.0	0.0000000000	False
times	0.0	0.0	0.0	0.0	0.2871794872	False
playing	0.000342532873409	0.0	0.0	0.0	0.0000000000	False
laptop	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
decode	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
frame	0.000492796743142	0.0	0.0	0.0	0.0000000000	False
distance	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
viewing	0.000114747743073	0.0	0.0	0.0	0.0000000000	False
experience	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
multi-rate	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
means	5.16293823328e-05	0.0	0.0	0.0	0.3746958637	False
rates	0.0011003708898	0.0	0.0	0.0	0.3206106870	False
requirements	0.00133328493202	0.0	0.0	0.0	0.3485477178	False
fault	0.00465878848625	0.0	0.0	0.0	0.3584637269	False
tolerance	0.00210511910102	0.0	0.0	0.0	0.3814713896	False
medical	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
equipments	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
accritical	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
reliability	0.00207057266055	0.0	0.0	0.0	0.4242424242	False
safe	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
avoid	0.0001833951483	0.0	0.0	0.0	0.0000000000	False
economic	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
damage	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
property	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
dedicated	0.00310585899083	0.0	0.0	0.0	0.4719101124	False
regular	0.00045557026067	0.0	0.0	0.0	0.0000000000	False
programmability	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
right	0.0	0.0	0.0	0.0	0.0000000000	False
lifetime	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
nonce	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
execute	0.0020173466313	0.0	0.0	0.0	0.4645550528	False
infinitely	0.000149779026636	0.0	0.0	0.0	0.0000000000	False
large	0.000144804671056	0.0	0.0	0.0	0.0000000000	False
duration	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
specific	0.000311775703618	0.0	0.0	0.0	0.3835616438	False
task	0.00508982985114	0.0	0.0	0.0	0.4212193191	False
vending	0.00362350215597	0.0	0.0	0.0	0.1656804734	False
machine	0.00121238432907	0.0	0.0	0.0	0.2359550562	False
electronic	0.000985593486283	0.0	0.0	0.0	0.4242424242	False
realize	0.000748895133182	0.0	0.0	0.0	0.4242424242	False
mechanical	0.00119823221309	0.0	0.0	0.0	0.3684210526	False
critical	0.00146649996813	0.0	0.0	0.0	0.4501607717	False
finally	8.05795721738e-05	0.0	0.0	0.0	0.0000000000	False
deliver	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
goals	0.000786722594765	0.0	0.0	0.0	0.4242424242	False
accept	0.00147839022942	0.0	0.0	0.0	0.3206106870	False
cache	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
motorola	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
thousand	0.000299558053273	0.0	0.0	0.0	0.0000000000	False
introduction	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
web	0.000911140521341	0.0	0.0	0.0	0.2978723404	False
enabled	0.00146649996813	0.0	0.0	0.0	0.3309692671	False
cashless	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
simple	0.000234862542346	0.0	0.0	0.0	0.3584637269	False
good	5.2191676077e-05	0.0	0.0	0.0	0.0000000000	False
response	0.000803657344916	0.0	0.0	0.0	0.0000000000	False
cash	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
change	0.000103639321399	0.0	0.0	0.0	0.0000000000	False
advantage	0.000393361297382	0.0	0.0	0.0	0.0000000000	False
stock	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
remotely	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
transactions	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
credit	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
location	0.000229495486147	0.0	0.0	0.0	0.0000000000	False
happen	0.000241825083263	0.0	0.0	0.0	0.5260960334	False
brought	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
nasa	0.0	0.0	0.0	0.0	0.0000000000	False
mars	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
rover	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
robot	0.00194642685162	0.0	0.0	0.0	0.3206106870	False
mobile	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
intel	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
variant	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
80c85	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
familiar	0.00034424322922	0.0	0.0	0.0	0.0000000000	False
move	9.65364473705e-05	0.0	0.0	0.0	0.0000000000	False
gps	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
global	0.000422734176016	0.0	0.0	0.0	0.0000000000	False
positioning	9.65364473705e-05	0.0	0.0	0.0	0.0000000000	False
transport	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
vehicle	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
deprovement	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
automotive	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
navigational	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
tool	0.00256899655056	0.0	0.0	0.0	0.2587800370	False
common	0.000368145548919	0.0	0.0	0.0	0.0000000000	False
place	0.000137913644225	0.0	0.0	0.0	0.0000000000	False
component	0.00275352908168	0.0	0.0	0.0	0.3614697120	False
communication	0.0011003708898	0.0	0.0	0.0	0.4719101124	False
satellite	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
provide	0.000245430365946	0.0	0.0	0.0	0.3835616438	False
output	0.000694206426926	0.0	0.0	0.0	0.3111111111	False
mp3	0.00258821582569	0.0	0.0	0.0	0.2368866328	False
player	0.00258821582569	0.0	0.0	0.0	0.2922755741	False
versions	0.000131165785401	0.0	0.0	0.0	0.0000000000	False
compress	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
form	0.000132331200347	0.0	0.0	0.0	0.4501607717	False
audio	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
apprentic	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
risk	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
dvd	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
pdo	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
twenty	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
hertz	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
effectively	0.000373041332022	0.0	0.0	0.0	0.4242424242	False
milliseconds	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
file	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
aprentic	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
risc	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
sony	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
aibo	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
dog	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
popular	0.000211367088008	0.0	0.0	0.0	0.0000000000	False
pet	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
japan	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
note	0.000137913644225	0.0	0.0	0.0	0.0000000000	False
reduces	0.000420485865181	0.0	0.0	0.0	0.0000000000	False
sixty	0.000590041946073	0.0	0.0	0.0	0.0000000000	False
neat	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
coordinate	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
emotions	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
manipulator	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
sensing	0.000211799768144	0.0	0.0	0.0	0.2666666667	False
facility	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
robo	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cup	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
football	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
teams	0.000227785130335	0.0	0.0	0.0	0.0000000000	False
extensible	0.000211367088008	0.0	0.0	0.0	0.0000000000	False
built	0.000342532873409	0.0	0.0	0.0	0.0000000000	False
question	4.29275804545e-05	0.0	0.0	0.0	0.0000000000	False
algorithms	8.70852202515e-05	0.0	0.0	0.0	0.0000000000	False
detect	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
ball	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
pretty	0.000160109103602	0.0	0.0	0.0	0.0000000000	False
mips	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
variety	0.000803657344916	0.0	0.0	0.0	0.0000000000	False
similar	0.000386145789482	0.0	0.0	0.0	0.3835616438	False
pda	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
games	0.000586599987251	0.0	0.0	0.0	0.0000000000	False
teller	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
maturity	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
activating	0.000683355391005	0.0	0.0	0.0	0.0000000000	False
influence	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
side	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
job	0.000739195114712	0.0	0.0	0.0	0.0000000000	False
feedback	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
foal	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
injection	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
flight	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
nuclear	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
belongs	0.0001833951483	0.0	0.0	0.0	0.0000000000	False
category	0.000535771563277	0.0	0.0	0.0	0.0000000000	False
signal	0.00351959992351	0.0	0.0	0.0	0.2110552764	False
processing	0.000584579444283	0.0	0.0	0.0	0.3255813953	False
core	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
focus	0.000535771563277	0.0	0.0	0.0	0.0000000000	False
radar	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
cising	0.0	0.0	0.0	0.0	0.0000000000	False
deter	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
sonar	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
cellular	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
internet	0.000973213425809	0.0	0.0	0.0	0.0000000000	False
sequencing	0.000322318288695	0.0	0.0	0.0	0.2058823529	False
logic	0.00112129564048	0.0	0.0	0.0	0.2692307692	False
ability	0.000985593486283	0.0	0.0	0.0	0.4242424242	False
deal	0.000960654621614	0.0	0.0	0.0	0.3814713896	False
interconnected	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
accludingly	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
implies	0.000131165785401	0.0	0.0	0.0	0.0000000000	False
occurs	0.000524663141603	0.0	0.0	0.0	0.5384615385	False
philosophy	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
graceful	0.00168409528082	0.0	0.0	0.0	0.4242424242	False
depredation	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
cattest	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
traffic	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
failure	0.00258821582569	0.0	0.0	0.0	0.3309692671	False
failing	0.000739195114712	0.0	0.0	0.0	0.0000000000	False
decreed	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
message	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
suddenly	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
stop	0.000114747743073	0.0	0.0	0.0	0.0000000000	False
sun	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
degradation	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
make	2.09131951107e-05	0.0	0.0	0.0	0.0000000000	False
understood	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
reviewed	0.000492796743142	0.0	0.0	0.0	0.0000000000	False
involved	0.000420485865181	0.0	0.0	0.0	0.0000000000	False
shown	0.000298588367079	0.0	0.0	0.0	0.4242424242	False
previous	0.000116458098885	0.0	0.0	0.0	0.0000000000	False
modal	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
expanded	0.000683355391005	0.0	0.0	0.0	0.0000000000	False
block	0.00182228104268	0.0	0.0	0.0	0.1830065359	False
added	0.000114747743073	0.0	0.0	0.0	0.0000000000	False
earlier	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
adjust	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
cpu	0.00389285370324	0.0	0.0	0.0	0.2270270270	False
alum	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
obvious	0.0003667902966	0.0	0.0	0.0	0.0000000000	False
converters	0.000422734176016	0.0	0.0	0.0	0.0000000000	False
conversion	0.000299558053273	0.0	0.0	0.0	0.0000000000	False
situated	0.000149779026636	0.0	0.0	0.0	0.0000000000	False
essential	9.07713292046e-05	0.0	0.0	0.0	0.0000000000	False
integral	0.00214308625311	0.0	0.0	0.0	0.2886597938	False
majority	0.0003667902966	0.0	0.0	0.0	0.0000000000	False
fpga	0.00207057266055	0.0	0.0	0.0	0.3500000000	True
acid	0.000973213425809	0.0	0.0	0.0	0.0000000000	True
circumstance	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
alumeter	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
order	3.17755395782e-05	0.0	0.0	0.0	0.0000000000	False
reading	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
obtain	0.000114747743073	0.0	0.0	0.0	0.0000000000	False
altered	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
lcd	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
led	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
informative	0.000173551606732	0.0	0.0	0.0	0.0000000000	False
color	0.000299558053273	0.0	0.0	0.0	0.0000000000	False
codes	0.00104130964039	0.0	0.0	0.0	0.2937062937	False
diagnostic	0.00210511910102	0.0	0.0	0.0	0.2368866328	False
forever	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
trace	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
repaired	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
simply	0.000480327310807	0.0	0.0	0.0	0.0000000000	False
out	0.0	0.0	0.0	0.0	0.0000000000	False
thrown	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
continuous	4.82682236852e-05	0.0	0.0	0.0	0.0000000000	False
properly	0.00146649996813	0.0	0.0	0.0	0.1717791411	False
malfunctioning	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
exceptive	0.000634101264023	0.0	0.0	0.0	0.0000000000	False
auxiliary	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
dealt	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
cooling	0.000320218207205	0.0	0.0	0.0	0.0000000000	False
circuit	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
extra	0.000422734176016	0.0	0.0	0.0	0.0000000000	False
packaged	0.00255153588601	0.0	0.0	0.0	0.1290322581	False
pleased	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
bad	0.000131165785401	0.0	0.0	0.0	0.0000000000	False
moister	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
extrument	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
concuss	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
presented	0.000200122607513	0.0	0.0	0.0	0.0000000000	False
elements	0.00014929418354	0.0	0.0	0.0	0.0000000000	False
peripheral	0.00218703075944	0.0	0.0	0.0	0.2641509434	False
context	0.0001833951483	0.0	0.0	0.0	0.0000000000	False
protocols	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
conceptually	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
tend	0.000320218207205	0.0	0.0	0.0	0.0000000000	False
standard	0.000186520666011	0.0	0.0	0.0	0.0000000000	False
day	0.00030018391127	0.0	0.0	0.0	0.0000000000	False
fill	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
vsd	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
assemblers	0.00147839022942	0.0	0.0	0.0	0.3589743590	False
compilers	0.00410013234603	0.0	0.0	0.0	0.1212704524	False
language	0.000449337079909	0.0	0.0	0.0	0.0000000000	False
translators	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
clause	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
window	0.00045557026067	0.0	0.0	0.0	0.0000000000	False
variance	0.000535771563277	0.0	0.0	0.0	0.0000000000	False
caricaturists	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
encounter	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
scheduling	0.00109351537972	0.0	0.0	0.0	0.0000000000	False
features	0.000173551606732	0.0	0.0	0.0	0.0000000000	False
tome	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
level	0.000402897860869	0.0	0.0	0.0	0.2922755741	False
incase	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
cross	0.00110443664676	0.0	0.0	0.0	0.1910538287	False
entire	7.79439259044e-05	0.0	0.0	0.0	0.0000000000	False
tested	0.000524663141603	0.0	0.0	0.0	0.2978723404	False
loaded	0.000803657344916	0.0	0.0	0.0	0.0000000000	False
big	0.000322318288695	0.0	0.0	0.0	0.2978723404	False
write	4.41104001157e-05	0.0	0.0	0.0	0.0000000000	False
board	0.00104845318645	0.0	0.0	0.0	0.3146067416	False
interesting	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
differences	6.97106503689e-06	0.0	0.0	0.0	0.4179104478	False
registers	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
care	0.000137913644225	0.0	0.0	0.0	0.0000000000	False
emulators	0.00414114532111	1.0	0.0	0.0	0.1435897436	False
instructions	0.000973213425809	0.0	0.0	0.0	0.0000000000	False
bevorial	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
behavior	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
simulation	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
analysis	0.000122715182973	0.0	0.0	0.0	0.0000000000	False
host	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
layer	0.000227785130335	0.0	0.0	0.0	0.0000000000	False
connected	0.000262331570801	0.0	0.0	0.0	0.0000000000	False
connector	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
debugging	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
summarize	0.0001833951483	0.0	0.0	0.0	0.0000000000	False
top	0.000344784110563	0.0	0.0	0.0	0.3814713896	False
support	0.00104932628321	0.0	0.0	0.0	0.3373493976	False
capabilities	0.000227785130335	0.0	0.0	0.0	0.0000000000	False
flavors	0.000586599987251	0.0	0.0	0.0	0.0000000000	False
weak	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
laser	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
printing	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
multiple	0.00110443664676	0.0	0.0	0.0	0.3092024540	False
history	0.000227785130335	0.0	0.0	0.0	0.0000000000	False
evolution	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
status	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
lower	0.000131165785401	0.0	0.0	0.0	0.0000000000	False
tense	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
arrow	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
tells	0.000100061303757	0.0	0.0	0.0	0.0000000000	False
faster	0.000803657344916	0.0	0.0	0.0	0.0000000000	False
clock	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
higher	0.00028032391012	0.0	0.0	0.0	0.0000000000	False
chip	0.00182252563287	0.0	0.0	0.0	0.2368866328	False
unary	0.00109351537972	0.0	0.0	0.0	0.0000000000	False
minimized	0.000245430365946	0.0	0.0	0.0	0.0000000000	False
dsp	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
universally	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
suit	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
search	0.000122715182973	0.0	0.0	0.0	0.0000000000	False
permit	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
additional	8.67758033658e-05	0.0	0.0	0.0	0.0000000000	False
list	0.000173551606732	0.0	0.0	0.0	0.0000000000	False
put	2.20552000578e-05	0.0	0.0	0.0	0.0000000000	False
soc	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
current	0.000149779026636	0.0	0.0	0.0	0.0000000000	False
single	0.000344784110563	0.0	0.0	0.0	0.2368866328	False
alu	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
textes	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
instrument	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
omap	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
arm	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
understand	3.62567962777e-05	0.0	0.0	0.0	0.0000000000	False
coprocessors	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
piece	8.67758033658e-05	0.0	0.0	0.0	0.0000000000	False
silicon	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
area	0.000114747743073	0.0	0.0	0.0	0.0000000000	False
associate	0.000131165785401	0.0	0.0	0.0	0.0000000000	False
man	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
faction	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
canjancem	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
temporally	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
correct	0.000433879016829	0.0	0.0	0.0	0.1717791411	False
wrong	0.00014016195506	0.0	0.0	0.0	0.0000000000	False
inherent	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
concurrency	0.00510307177202	0.0	0.0	0.0	0.1238938053	True
effort	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
multitasking	0.00207057266055	0.0	0.0	0.0	0.2058823529	True
events	0.00045557026067	0.0	0.0	0.0	0.0000000000	False
independently	0.000114747743073	0.0	0.0	0.0	0.0000000000	False
separating	0.000347103213463	0.0	0.0	0.0	0.4242424242	False
simplifies	0.000160109103602	0.0	0.0	0.0	0.0000000000	False
kernel	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
switching	0.000299558053273	0.0	0.0	0.0	0.0000000000	False
simultaneous	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
temperature	0.00218703075944	0.0	0.0	0.0	0.1473684211	False
famish	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
supposed	3.02571097349e-05	0.0	0.0	0.0	0.0000000000	False
modification	0.000211367088008	0.0	0.0	0.0	0.0000000000	False
keypad	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
evens	0.000293299993626	0.0	0.0	0.0	0.4710280374	False
fashion	0.000149779026636	0.0	0.0	0.0	0.0000000000	False
contest	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
meet	0.000739195114712	0.0	0.0	0.0	0.0000000000	False
project	0.000160109103602	0.0	0.0	0.0	0.0000000000	False
met	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
cleverer	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
compromise	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
meat	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
turn	4.82682236852e-05	0.0	0.0	0.0	0.0000000000	False
unnecessary	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
access	0.000480327310807	0.0	0.0	0.0	0.0000000000	False
picture	6.34897586678e-05	0.0	0.0	0.0	0.0000000000	False
hint	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
multi	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
objective	0.000559561998033	0.0	0.0	0.0	0.2427745665	False
affordability	0.000648808950539	0.0	0.0	0.0	0.0000000000	False
safety	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
scalability	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
timeliness	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
arbitrary	0.000160109103602	0.0	0.0	0.0	0.0000000000	False
bordely	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
hum	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
tat	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
disciplinary	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
approach	0.000683355391005	0.0	0.0	0.0	0.0000000000	False
absolutely	0.00028032391012	0.0	0.0	0.0	0.0000000000	False
society	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
institutions	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
sociological	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
people	7.46470917698e-05	0.0	0.0	0.0	0.0000000000	False
norms	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
perspective	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
introducing	0.000262331570801	0.0	0.0	0.0	0.0000000000	False
life	0.000634101264023	0.0	0.0	0.0	0.0000000000	False
cycle	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
deployment	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
logistics	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
maintaining	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
draw	8.67758033658e-05	0.0	0.0	0.0	0.0000000000	False
wont	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
consumer	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
commitment	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
retirement	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
terms	3.62567962777e-05	0.0	0.0	0.0	0.0000000000	False
performance	0.000126979517336	0.0	0.0	0.0	0.0000000000	False
give	6.88391764437e-06	0.0	0.0	0.0	0.0000000000	False
criteria	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
related	9.32603330054e-05	0.0	0.0	0.0	0.0000000000	False
ten	6.89568221126e-05	0.0	0.0	0.0	0.0000000000	False
kbs	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
buy	0.000211367088008	0.0	0.0	0.0	0.0000000000	False
non-functional	0.00155292949542	0.0	0.0	0.0	0.0000000000	False
ignore	0.000171266436704	0.0	0.0	0.0	0.0000000000	False
face	0.000160109103602	0.0	0.0	0.0	0.0000000000	False
bug	0.00126307146061	0.0	0.0	0.0	0.0000000000	False
download	0.000422734176016	0.0	0.0	0.0	0.0000000000	False
patch	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
rectify	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
save	0.000227785130335	0.0	0.0	0.0	0.0000000000	False
bottom	0.000449337079909	0.0	0.0	0.0	0.0000000000	False
abstract	0.000149779026636	0.0	0.0	0.0	0.0000000000	False
description	0.000246398371571	0.0	0.0	0.0	0.0000000000	False
detailed	5.31596817019e-05	0.0	0.0	0.0	0.0000000000	False
strategies	0.000227785130335	0.0	0.0	0.0	0.0000000000	False
small	2.20552000578e-05	0.0	0.0	0.0	0.0000000000	False
bodies	0.000586599987251	0.0	0.0	0.0	0.0000000000	False
availability	0.000364505126573	0.0	0.0	0.0	0.5384615385	False
step	6.05142194697e-05	0.0	0.0	0.0	0.0000000000	False
wise	0.000535771563277	0.0	0.0	0.0	0.0000000000	False
equally	4.82682236852e-05	0.0	0.0	0.0	0.0000000000	False
pure	0.000267885781639	0.0	0.0	0.0	0.0000000000	False
leads	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
partitioning	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
stepwise	0.00103528633028	0.0	0.0	0.0	0.0000000000	False
refinement	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
sort	3.89719629522e-05	0.0	0.0	0.0	0.0000000000	False
hole	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
concluding	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
remark	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
abroad	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
overview	0.000535771563277	0.0	0.0	0.0	0.0000000000	False
introductory	0.000364505126573	0.0	0.0	0.0	0.0000000000	False
made	7.46470917698e-05	0.0	0.0	0.0	0.0000000000	False
statement	0.000107211191461	0.0	0.0	0.0	0.0000000000	False
home	0.000196680648691	0.0	0.0	0.0	0.0000000000	False
washing	0.000421023820204	0.0	0.0	0.0	0.0000000000	False
viewer	0.000729010253146	0.0	0.0	0.0	0.0000000000	False
pds	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
precisely	0.00032440447527	0.0	0.0	0.0	0.0000000000	False
principles	0.000299558053273	0.0	0.0	0.0	0.0000000000	False
ways	4.82682236852e-05	0.0	0.0	0.0	0.5283018868	False
methodology	0.000842047640408	0.0	0.0	0.0	0.0000000000	False
mange	0.000517643165139	0.0	0.0	0.0	0.0000000000	False
perfect	0.000293299993626	0.0	0.0	0.0	0.0000000000	False
don	0.0	0.0	0.0	0.0	0.0000000000	False
end	1.43091934848e-05	0.0	0.0	0.0	0.0000000000	False
class	3.89719629522e-05	0.0	0.0	0.0	0.0000000000	False
