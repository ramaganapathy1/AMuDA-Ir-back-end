1 automatic keyphrase extraction and segmentation of video lectures arun balagopalan  lalitha lakshmi balasubramanian  vidhya balasubramanian  nithin chandrasekharan  aswin damodar department of computer science and engineering  amrita school of engineering amrita vishwa vidyapeetham  coimbatore  india arunbgg @ gmail.com  lalithalb @ am.amrita.edu  b_vidhya @ cb.amrita.edu  nithin.cs27 @ gmail.com  djs.aswin @ gmail.com abstract  keyphrases are essential meta-data that summarize the contents of an instructional video  in this paper  we present a domain independent  statistical approach for automatic keyphrase extraction from audio transcripts of video lectures  we identify new features in audio transcripts  that capture key patterns characterizing keyphrases in lecture videos  a system for keyphrase extraction is designed that uses a supervised machine learning algorithm  based on a naive-bayes classifier to extract relevant keyphrases  our extensive experimental studies show that our system extracts more relevant keywords than existing approaches  the paper also evaluates the performance of the proposed keyphrase extraction method for different categories of lectures  the extracted keyphrases are used further as features for automatic topic based segmentation of the video lectures  this process of automatic keyphrase extraction and segmentation results in a section-wise annotated video lecture which can be effectively viewed in a lecture browser  index terms  automatic keyphrase extraction  metadata extraction  lecture browser  segmentation  video lectures i i ntroduction universities around the world are increasingly using multimedia based instruction to augment classroom learning  several major universities have taken one step further  by making portions of their courses in digital form available to the public over the internet  video lectures in university channels  hosted on video sharing websites have become immensely popular  garnering millions of viewers  the proliferation of such content has led to increasing research into developing smart lecture browsers  that improve the overall learning experience of the student  to improve the lecture browser 's utility to students  video lectures are often accompanied by lecture notes  slides or syllabus books  a few advanced lecture browsers synchronize text  1  with lecture video and also allow search within the transcript  however  these systems are of little use if for instance  a student wants to quickly scan the contents of a particular lecture among a series of lectures  to facilitate such browsing  some form of lecture summary needs to be made available  a possible solution is to display lectures with section-wise annotations or titles provided by the instructor or students  2   while the benefits of such an approach are high  the process is tedious  and unviable given the large repositories  long durations  40-60 minutes on average  and sequential nature of such lectures  we note that user-invited tagging or annotation is highly prone to errors  due to variations in levels of academic sophistication and subject knowledge amongst users  again  the large size of e-learning repositories today makes this approach cumbersome  thus the major proportion of video lectures produced come untagged  providing very little skimming information to the viewer  in this paper  we introduce a system that can automatically generate and display section-wise annotations using lecture transcripts  existing systems for information retrieval and summarization from spoken documents rely on a variety of lexical  structural  prosodic and disfluency features  3  or dictionary-based semantic processing  4   however  the performance of such techniques when scaled to large corpora or their suitability to the domain of lectures have not been well studied  our approach uses a simpler keyphrase-based annotation technique  which functionally strikes a middle ground between detailed annotation and basic video tagging  keyphrases are commonly identified in technical documents such as journal articles and technical reports  to highlight key topics and concepts  similarly  when applied to lectures  keyphrases can give important summarizing information and can allow students to identify lectures that correspond to their learning requirements  to achieve this  we need an automatic keyphrase extractor and segmenter  automating the process of keyphrase extraction and segmentation in lecture transcripts presents several challenges  the lack of proper content structuring  imperfections in language usage  conversational nature and variations of style across domains are common features of lectures that hamper performance of information retrieval systems  in this paper we address these issues in the specific context of classroom lectures ordinarily seen in university video channels and webcasts  non-classroom discourse  technical talks  guest lectures  conference presentations etc   is not 2 considered  class room lectures range across varying levels of structuredness  and can span multiple domains  the longer duration of these lectures help provide more information for segmentation and keyphrase extraction  variations in the delivery styles  classroom interactions  etc also make it a much more interesting area to study  we show that a machine learning based approach  coupled with effective feature extraction specifically tailored for the lecture domain can address challenges in keyphrase extraction from lecture transcripts  the following are our specific contributions in this paper we make use of a corpus of lectures for training the classifier  to the best of our knowledge  such supervised techniques have not been applied to lecture transcripts  to address the challenges of mining from transcripts with limited structure  we propose a set of features based on commonly observed characteristics in lecture speech  to perform segmentation within the transcript  we deviate from traditional text segmentation methods and instead use the automatically extracted keyphrases as features for identifying topic cohesion  empirical evaluation of our techniques on a large corpus of lectures and comparing our techniques with existing keyphrase extraction and automatic segmentation solutions  we will discuss the existing work and contrast our methodology in the related work section  section 2   section 3 describes the architecture of our system  sections 4 and 5 explain the keyphrase extraction module in detail and show experimental results respectively  in section 6  we show how the extracted keyphrases can be used for topic segmentation of lectures  and then present corresponding experimental results by comparing with existing segmentation algorithms  ii  r elated w ork several methodologies have been proposed to extract keyphrases from structured documents like scientific articles  journals  etc  however very little work has been done to extract keyphrases from unstructured documents like audio transcripts  automatic keyphrase extraction from written documents has been a subject of extensive study and research for well over a decade  keyphrase extraction is often modeled as a classification problem that requires application of machine learning techniques  the popular kea system  5  uses supervised machine learning to build a domain-specific classifier model from a training corpus  the trained classifier  naive bayes  then extracts keyphrases in new documents ranked according to feature values  classic tf-idf and relative position of first occurrence of candidate phrases within the document are basic features employed by kea  the genex system developed by turney  6  uses a genetic algorithm operating with several features such as n-gram size and frequency measures  and gives comparable performance  hulth  7  suggested use of linguistic features such as noun phrases and part-of-speech information to improve keyphrase extraction  improvements to kea when a domain vocabulary is available has been studied by medelyan and witten  8   more recently  kim and kan  9  analyzed common linguistic patterns in keyphrases to develop regular expressions for candidate phrase extraction  the work also assesses performance of a large number of features in both supervised and unsupervised extraction algorithms  our keyphrase extraction system draws from kea  and incorporates improvements specific to lectures motivated by work in  7    8   besides machine learning  keyphrase extraction systems that rely on information retrieval  nlp and graph-based techniques have been proposed  suzuki et al   10   used an encyclopedia with 141 different domains and a large corpus of news articles to construct feature vectors for each domain  document sections were assigned keyphrases from the feature vector that was found most similar to that section  matsuo and ishizuka  11  showed how co-occurrence probability distributions of terms can be used to obtain keyphrases  the method does not use a large external corpus but still manages to give results comparable to algorithms that use tf-idf  the suitability of these approaches when applied to spoken audio documents such as lecture transcripts remains to be studied  keyphrase extraction from speech transcripts has not received much attention when compared to written documents  several lexical features pertaining to written documents are not effective in the context of unstructured speech transcripts  plas et al   12  explored usage of linguistic tools such as wordnet to extract keyphrases from transcripts in the multiparty meeting corpus  liu et al   13  also studied meeting transcripts  comparing keyphrase extraction performance of an unsupervised tf-idf based method and a graph based approach  applying techniques used with other spoken data to lectures is not possible  as almost all approaches are domain centric and exploit very specialized features  very limited work can be found on information retrieval from classroom lecture transcripts  haubold  14  studied index terms that appear in an asr generated lecture transcript  and presented several ways to visualize them  the work also explored techniques to match lectures to textbook chapters and to cluster lectures using index terms  the goal is to provide quick browsing in a series of lectures  rather than in a single lecture  it also assumes the availability of a high-level domain and sub-domain information  e.g  computer science  data structures   if such classifications are unavailable  finding out the text book for comparison will be difficult  for each domain and sub-domain category  at least one text book has to be maintained and there is a dependency on external sources of data  yamamoto et al   15  used the entire course textbook to build a lecture segmentation and information retrieval system  the system makes use of a vector space model constructed from the textbook sections and tries to match vectors obtained from transcripts with the textbook vectors  while presence of text book material is useful for keyphrase extraction  this is often not the case and therefore the approach can not be generalized to all classroom lectures  although segmentation of spoken documents is a relatively new area of research  several different approaches have already been applied  the tdt initiative  16   attempts to segment broadcast news streams using corpus based learning of features  halliday and hassan 's lexical cohesion theory  17  is the basis for almost all domain-independent techniques for 3 topically cohesive segments  a variant of hearst 's classic text tiling algorithm is used to perform segmentation in lecture transcripts  each segment in the lecture video contains the start boundary  terminating boundary and the associated keyphrases  this information is used to display the annotated and segmented video in the lecture browser  a detailed description of this subsystem is given in section vi  d interface figure 2 shows a screen shot of our lecture browser  the lecture browser uses the automatically generated metadata  and presents it in a simple user-friendly interface  the combination of segmentation and keyphrase annotation is a powerful summarization and skimming tool  salient features and functionalities of the browser are as follows  topically cohesive sections in the lecture annotated with corresponding keyphrases are shown alongside the video  this enables the student to easily judge how well a lecture corresponds to his/her learning requirements  the interface allows the student to quickly jump to any required section of the lecture  attention can be concentrated on relevant sections of the lecture  while other sections may be skimmed or skipped  the search feature allows users to find not just relevant lectures  but also relevant sections in the lecture  comparison of multiple lectures covering similar topics is also made possible  section-wise lecture transcript to video association is also available  users can view the transcript corresponding to the specific section of the video if required  guided by keyphrases  students can quickly correlate the video lecture with course textbook material  the browser also allows quick review for students wishing to revise  iv  k eyphrase e xtraction the goal of keyphrase extraction is to generate an optimal set of phrases appearing in the lecture  that best summarizes its content  generally  keyphrases are either terms spread throughout the lecture  theme phrases  or terms important to particular sections  topic phrases   the extraction algorithm needs to capture both classes of keyphrases to build a good lecture summary  keyphrase extraction from lecture transcripts pose several unique challenges  as noted earlier  the defining characteristic of lecture speech is its spontaneity  a majority of the sentences may be incomplete or grammatically incorrect  also  different speakers have their own unique styles of lecture delivery  for instance  instructors who use presentation slides usually follow a well planned sequence or scheme  and therefore such lectures tend to possess good topic structuring  lecture characteristics can vary significantly based on the subject domain  for example  extraction results for lectures in engineering management will usually be better than  say for a set of calculus lectures which carry very little keyphrase information due to increased board work and the usage of specialized language  lectures may not possess proper introductions or conclusions  and due to its conversational style often contain `` non-academic speech '' such as anecdotes  digressions and humor  figure 1 system architecture linear text segmentation  the theory states that topic coherence across text segments can be measured based on the extent of similarity in the vocabulary used in each segment  alternately  this means that large shifts in vocabulary usage indicates a topic boundary  researchers have used several techniques to select segments of text  making comparisons using varied lexical features  one of the earliest approaches  by hearst  18   used sliding windows of fixed length where text in adjacent windows were compared for topic cohesion  a vector space model with word stems as features was used to represent the windows  in our system we use a modified version of this algorithm  iii  s ystem a rchitecture previous sections introduced the problem of automatic keyphrase extraction and showed why existing work is insufficient for classroom lectures  to be able to automatically extract keyphrase and segment lectures  we have developed an annotation system which is described in this section  figure 1 shows the top level architecture of the system  the transcript generator  human or asr system  produces transcripts of lectures  the transcripts are stored in the digital repository and is assumed to be part of an existing support framework  the system consists of three major components as follows  a databases the output from the transcript generator i.e  the lecture transcripts are stored in the database along with the lecture videos  following keyphrase extraction and segmentation steps  the generated lecture metadata is saved as xml files in the database for use by the lecture browser  b keyphrase extraction the keyphrase extraction component uses the database of training lectures to first build a keyphrase classifier model  once trained  the classifier is run on untagged lectures for keyphrase extraction  the generated keyphrases are passed on to the segmentation component  c segmentation the segmentation system uses keyphrases as features to detect topic boundaries in a lecture in order to generate 4 figure 2 screenshot of the lecture browser more difficulties arise if the transcripts are obtained from an asr system  as extraction performance is directly influenced by the word error rate  wer   the impact of transcription errors can be reduced by using an external corpus of expected terms as shown in  14   currently this paper focuses on keyphrase extraction based on manually generated transcripts  and a study of the impact of asr errors will be part of future work  our system follows a supervised machine learning approach to keyphrase extraction  similar to kea  we define features which takes into account the characteristics of spoken lectures  which will be used by the machine learning system for classifying keyphrases  the details of the keyphrase extraction system is described in the following sections  a proposed features features in the context of machine learning algorithms  are parameters used to characterize and classify input data  our studies on keyphrase extraction from lecture transcripts show that features used for keyphrase extraction from written documents  are insufficient when applied to lecture transcripts  even with domain knowledge  due to the challenges discussed earlier  we therefore define a new set of features  dispersion  local-span and cuewords  for classroom lectures  in order to improve accuracy of keyphrase extraction  in addition  suitable features used with existing keyphrase extraction systems have been identified  both these set of features are described in detail in the following paragraphs  1  dispersion and local-span one of the important tasks of keyphrase extraction methods in classroom lectures is to identify both the topic keyphrases and subtopics which are specific to segments  the timeline spread of the keyphrase in the lecture is a key factor in determining both these types of keyphrases  this is illustrated in figure 3 the dispersion plot in figure 3a shows that keyphrases are more spread out than non keyphrases  shown in the second plot in figure 3 topic keyphrases have a more uniform spread  while segment specific keyphrases are more clustered in some regions  the non-keyphrase terms have no proper configuration or recognizable pattern in their dispersion plot  the terms are either too local  or form unorganized clusters  some exceptions do exist  but such terms maybe eliminated by tf-idf and the other features  to identify topic phrases we define a feature `` dispersion '' which is a measure of the spread of the keyphrase in the lecture  dispersion captures phrases that have both high spread across the lecture and have a high frequency of occurrence  such phrases generally capture the main topics of the lecture  dispersion is determined by calculating the intervals during which the phrase appears in the document  for a high dispersion the length of the interval is small and the number of intervals is large  let  h1  h2  ..hm  i where  i is the set of m intervals of term t each interval hi is calculated by finding the difference between adjacent occurrence of the phrase  ie  hi = pi+1  pi  where  p1  p2  ..pn  are the word positions of phraseterm in the lecture  if the terms occur very close to each other  ie occuring small range clusters  they are recognized as a single position  this step is done to reduce variance when the term occurs in such a cluster  dispersion is defined as the ratio of the number of intervals where the term occurs to the variance of the interval set i i.e  m var  i  where  hi  2 and = dispersion = var  i  = m k=1   m k=1  hi  m 5  a  figure 3   3.a  lexical dispersion plot for keyphrases in a lecture  b   3.b  lexical dispersion plot for non-keyphrases in a lecture 2  local-span phrases that are sub-topics  are often clustered in few specific segments of a lecture  for instance the word `` sorting '' will occur throughout the lecture which is on sorting techniques  however the subtopics like `` quicksort ''  or allied terms like `` divide and conquer '' usually occur in some parts of the lecture where that particular subtopic or method is being discussed  these phrase mostly have low dispersion values but are important to the lecture or to the segment of the lecture  we propose a feature called `` local-span '' to identify such locally clustered phrases  to calculate local-span  each lecture transcript is divided in to 'm ' overlapping segments  the word count for each segment is the number of times the term occurs in a time span of minutes  let cavg be the average occurrence of term 't ' across m segments i.e  cavg = n/m  let ci be the count of term 't ' in segment si  local-span   t  is therefore defined as follows   t  = max  m i=1  ci the frequency of candidate phrase as a part of other longer candidate phrases number of these longer candidate phrases the length of the candidate phrase  in number of words   using these parameters  c-value is calculated as shown below  c  v alue = log2 |len  a  |.f  a   if a is not nested  else c  v alue = log2 |len  a  |   f  a    p  1 bta f  b    ta   where a is the candidate string  len  a  is the length of candidate phrase  in number of words  f  a  is the frequency of occurrence of phrase 'a ' in the corpus ta is the set of extracted candidate terms that contain a  p  ta  is the number of these candidate terms the negative effect of higher order frequency term reduces the c-value of phrases that appear only as substring of higher order phrases  4  cuewords while frequency of occurrence of the term is a useful parameter to identify keyphrases  it can be observed in many video lectures that there are phrases that are spoken very rarely  though being highly relevant to the lecture  such phrases can not be easily detected using the previously defined features due to limited occurrence  however they are observed to follow cuewords like 'called as '  'defined as ' etc  based on the normalized frequency of occurrence of each such term  their relevance is computed  5  tf-idf tf-idf is a common measure used to determine the importance of a term to a document  tf-idf is the product of the term frequency of term t in a document d  and its inverse document frequency  20   tf  t  d  is the frequency of the term t in the lecture d idf  t  = log2 dfd  t   where df  t  is the document frequency i.e  the number of documents in the global domain corpus containing the term t  and d is total number of documents in the domain corpus   cavg   since dispersion and local-span capture essential properties of keyphrases  they can also be used to improve the video lecture search  lectures in which the search phrase has a better dispersion value are more likely to be relevant  as the phrase can be the topic of the lecture  similarly local-span can be used to output the relevant segments matching the search query  3  c-value c-value  19  by frantzi et al  is useful to identify nested collocations thereby improving the accuracy of keyphrase extraction  for e.g  in the phrase 'data mining '  the terns 'data ' and 'mining ' are meaningful  however 'data ' and 'mining ' can be considered as keyphrases for a lecture only if the lecture explains or defines each of them individually  c-value combines linguistic and statistical information to extract the keyphrase  emphasis being placed on the statistical part  this measure is built based on the following parameters  the total frequency of occurrence of the candidate phrase in the corpus 6 t f  idf for term t in document d is hence defined as tf  idf  t  d  = tf  t  d  idf  t  since idf  t  is high when the term t occurs in few documents  term can be assumed to be important to those documents  and is not a stop word  usually terms with high tfidf values occur many times in fewer documents  while terms that occur more frequenctly in most documents have lower tf-idf  thus  the higher the value of tf-idf  the more important the term is  and the higher the probability of the term being a keyphrase  the features we have defined captures most of the identifying properties of keyphrases in video lectures  b generating the feature table the next step in the pipeline is to compute the feature values for the candidate phrases in the lectures  a feature table is built  for use in the training and testing module of the keyphrase extraction system  before keyphrase extraction  the transcript needs to be preprocessed  after which feature extraction and discretization is performed on the preprocessed transcript  1  text preprocessing removing unnecessary information from the transcript is an essential step in processing noisy data and preventing wrongly identified keywords  basic text filtering steps include punctuation processing  stemming  ngram formation  and stopgram removal  as the size of the transcripts tends to be large  as an additional filtering step  we exclude all terms which appear once in the transcript  5   the first step is punctuation processing where punctuations that appear in manual or perfect transcripts are removed  hyphens are replaced by spaces  for better recognition of bigrams  dots are kept as such  as it helps in ngram formation  or removed if an abbreviation can be detected  close proximity dots   next stemming is peformed to reduce terms to root forms since it allows the classifier to treat similar words in different forms of speech as the same  e.g  compiling and compiler   the porter stemmer  20  has been found most suitable for our purposes  after stemming the next step is part-of-speech  pos  tagging which is required to filter the phrases during n-gram extraction based on its part of speech classification  then n-grams are extracted using a selected set of linguistic filters  based on the analysis done for 40 lectures  only phrases that satisfy these linguistic filters have high probability of being a keyphrase  2  feature extraction and discretization the feature values explained earlier are calculated for the given transcript  with the exception of idf  all other feature values can be calculated from the single transcript alone  the naive-bayes algorithm works best for feature ranges rather than feature values are given  it then assigns probabilities for each range  existing methods for data discretization include the entropy-mdl method  and divisions based on equal frequency or width  discretization using entropy-mdl method was found to provide best results and hence it is the chosen method in our system  determining discretization points is a step before training  after determining the discretization points of each feature  each term in the feature table is modified to represent the feature ranges  and the final feature table is generated  this is sent to a classifier to classify the terms as keyphrases or nonkeyphrases  c the learning algorithm we use a naive-bayes classifier for classifying keyphrases from other terms  the naive-bayes classifier is a probabilistic model that uses bayes ' theorem and assumes feature independence  naive bayes is a simple yet effective statistical machine learning tool  well suited for text classification purposes  20   as it assumes feature independence  simple multiplication of the probability distribution of each feature can be done  given the value of the class variable  p  c  p  fi |c  p  c |f1    fn  = z i=1 where c is the class variable  f1    fn are the n features  p  c |f1    fn  is the conditional distribution over c  and z is a scaling factor dependent on f1    fn d training a key component of the keyphrase extraction system is the training module in which the supervised machine learning algorithm  naive-bayes learner  is given sample transcripts with manual keyword information  the text transcript is first converted into feature vectors  which are given as input to the training module  the classifier then tries to create the most probable feature profile for keyphrases using feature statistics of manual keywords  a model is built that stores the training information  and used later for testing  a set of 25 lectures from different domains is fed into the trainer  and the probability information of each feature is stored  we limit the training to 25 lectures empirically  as improvements in the system performance were insignificant with further addition of lectures  we use different domains  to account for any feature probability variance in different domains  we also train the system with different kinds of lectures  introductory  descriptive or analytical   e testing of keyword extraction the testing module is used to identify and extract keywords from new  untrained lectures  each transcript is converted into a feature vector  and the feature vector is fed into the classifier  the algorithm then  uses the probabilistic information from the learned keyphrase profile  and computes the likelihood of the term being a keyword  the terms so identified are ranked by the highest probability  feature ranking is also used in cases of equal probabilities  we also include segment size as a feature ranking criteria  as terms uttered in the entire lecture are more probable keywords  but this criteria is only applied after segmentation is performed  v e valuation we have described the details of our keyphrase extraction system in the previous sections  we now evaluate the perforn 7 table i c omparison  p roposed s ystem v s kea v s c-value lecture name lecture lecture lecture lecture lecture lecture lecture lecture lecture lecture lecture lecture lecture lecture lecture lecture 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 proposed system precision recall f-score 0.778 0.500 0.609 0.867 0.52 0.65 0.556 0.417 0.476 0.667 0.462 0.545 0.778 0.500 0.609 0.750 0.545 0.632 0.750 0.800 0.774 0.500 0.667 0.571 0.571 0.615 0.593 0.455 0.714 0.556 0.800 0.400 0.533 0.714 0.625 0.667 0.667 0.500 0.571 0.438 0.636 0.519 0.50 0.63 0.56 0.500 0.417 0.454 kea recall 0.118 0.232 0.112 0.200 0.230 0.234 0.340 0.367 0.167 0.200 0.250 0.234 0.340 0.367 0.223 0.230 c-value recall 0.286 0.385 0.417 0.231 0.357 0.273 0.400 0.500 0.385 0.429 0.400 0.455 0.333 0.364 0.222 0.235 precision 0.400 0.433 0.322 0.143 0.340 0.480 0.456 0.432 0.400 0.143 0.340 0.484 0.443 0.432 0.320 0.330 f-score 0.182 0.302 0.166 0.167 0.274 0.315 0.390 0.397 0.236 0.167 0.288 0.315 0.385 0.397 0.263 0.271 precision 0.444 0.278 0.556 0.333 0.556 0.375 0.375 0.375 0.357 0.273 0.800 0.417 0.444 0.250 0.250 0.400 f-score 0.348 0.323 0.476 0.273 0.435 0.316 0.387 0.429 0.370 0.333 0.533 0.435 0.381 0.296 0.235 0.296 mance of our keyphrase extraction system by investigating the following aspects  improvement in keyphrase extraction over existing systems  impact of different features in automatic keyphrase extraction impact of the number of potential keyphrases on the accuracy performance across various classes of lectures covered as introductory  descriptive  illustrative and analytical  we do so inorder to identify the impact of the lecture style on the keyphrase extraction system  for evaluation of keyphrase extraction performance we use the traditional precision  recall and f-score metrics  given a brief description of the experimental setup the following paragraphs will describe and discuss about experiments and their results  1  comparison of our system with existing systems we first compared the performance of our keyphrase extraction system with existing systems like kea and a system that primarily used c-value as its feature  the different systems extracted keyphrases from a selected number of lectures and the extracted keyphrases evaluated for precision and recall  table i shows the results of this experiment  from the results  it was observed that the f-score of our system is 46 percent higher than kea and 33 percent better than the system using c-value  this is because  the fundamental features in both systems use frequency of occurrence of a phrase  5   however that is insufficient to capture many phrases in an unstructured domain like lectures where phrases can occur less frequently yet be highly relevant  integration of the features like cuewords  dispersion and local-span in our system ensures that even less frequent yet highly relevant phrases are also extracted  this firmly establishes the improved performance of our system  2  impact of different features in automatic keyphrase extraction the next set of experiments evaluate the effectiveness of our technique  we first evaluate the role  the different features play in keyphrase extraction  table ii shows keyphrases extracted and the impacting feature  in bold   it is observed that dispersion captures the major topics of the lecture  here the lecture is on 'binary trees ' and hence `binary tree ' has been extracted using dispersion  cuewords also help in identifying theme phrases  using localspan we can get the subtopics or aspects of the main topic  here for instance a part of the lecture discusses `` height of a experimental setup due to the requirement of large corpora of lecture transcripts for training and testing  we had to compile and build our datasets from various sources  our major source is a large corpus of around 300 manual transcripts of lectures in computer science  obtained with permission from nptel  21   these lectures are aimed at undergraduate students  and cover a wide range of subjects in computer science  most lectures are part of a semester-long series comprising 3040 lectures  the rest of the dataset is comprised of publicly available lectures for graduate and undergraduate students from university websites  2    22   that included manual lecture transcripts  these lectures primarily belong to the computer science domain and includes subjects like algorithms and data structures  computer graphics  machine learning etc  all lectures in the dataset are held in a classroom environment  the duration of a lecture is between 40 to 60 minutes on an average  with transcripts containing 8000 to 14000 words  for each lecture in the development set  a human annotator manually extracts keyphrases  which is taken to be the gold standard  5   we collected manual keyphrases for each of the lectures from 3 users  one of them being a domain expert  keyphrases identified by the domain expert is given higher priority  followed by phrases identified by atleast 2 users  the number of keyphrases extracted from a lecture varies between 10 to 25 it must noted that while the majority of literature in the field consider human picked keyphrases as the gold standard  5   there is no real consensus on managing variations arising from subjectivity of judges  we also categorize the lectures approximately based on the delivery style and content 8 table iii n umber of keyphrases per lecture v s f-s core range of keyphrase count < =9 > =10 and < =19 > =20 and < =30 average precision 0.713 0.507 0.422 average recall 0.475 0.559 0.607 average f-score 0.568 0.524 0.497 they tend to occur frequently  this apparently leads to higher dispersion and frequency of occurrence of illustrative phrases  in such scenarios  our system will capture such illustrative phrases as key phrases leading to lower precision  vi  automatic l ecture s egmentation a introduction to build a successful lecture browser  we need to improve the speed and ease with which a user can find what he is looking for  besides using keyphrases which enable summarization and search  the learning experience can be further improved by guiding user navigation towards relevant sections in the lecture  this functionality can be achieved by dividing the lecture into topically cohesive segments  segmentation of a lecture maybe performed using its video track  audio track or transcript  since ordinary lectures contain only weak cues in video and audio for topic shifts  segmentation in both these mediums is not very effective  therefore we use lecture transcripts  and the problem becomes purely one of text segmentation  segmentation in lecture transcripts is also a challenging problem  due to the smooth nature of topic transitions seen in lectures  topic boundaries tend to be fuzzy and difficult to detect  the issues with spontaneous speech and asr errors discussed for keyphrase extraction  also hold for segmentation  we use a variant of hearst 's classic text tiling algorithm  18  to perform segmentation in lecture transcripts  the motivations for our choice of text tiling over more recent  advanced algorithms are as follows  texttiling is simple  both conceptually and implementation wise  our studies showed that texttiling is well suited for the coarse nature of segmentation required by the user  details in the related work section   texttiling runs in linear time  compared to other algorithms  this reduced cost becomes important when the system is used on large-scale digital repositories  the original texttiling algorithm  18  computes lexical scores between text segments  using word stems  other than for stopwords  as features  instead we reformulate the algorithm to use automatically generated keyphrases for that lecture as features  we base our modification on the idea that changes in usage of keyphrases in a lecture strongly correlate with topic shifts  this technique is in many ways similar to how human beings approach the task of manual segmentation  for example  when volunteers were asked to view a lecture and later find topic segments in the transcript  it was observed that the majority relied on keyphrase occurrence patterns in the text  we show experimentally that keyphrases provide the algorithm with enough resolving power to achieve required accuracy levels for coarse segmentation  an added advantages of using only keyphrases for features  is that the algorithm runs even quicker with the reduced feature space  b the texttiling segmentation algorithm texttiling uses sliding windows to locate possible boundaries in text  a text window moves through the transcript at fixed intervals assumed to approximate a typical boundary  figure 4 evaluating the keyphrase extraction for different lecture categories a tree ''  and hence that is identified as a keyphrase  c-value and tf-idf features complement the other features by capturing the frequency of the keywords  the diverse roles played by the different features amounts to significant contribution in improving the performance of our system  3  impact of various factors on keyphrase extraction accuracy now we study the effect the following have on the accuracy of automatic keyphrase extraction from lecture videos 1  number of potential keyphrases in the lecture 2  lecture category table iii shows the precision  recall and f-score for different ranges of potential number of keywords in each lecture  it is interesting to note that precision is high when the number of keyphrases are lower  while recall is better when the number of keyphrases are higher  we believe this could be primarily due to the type of lecture  rather than actual number of keyphrases which is impacting the results thus  we see this more clearly in figure 4 where the average precision  recall and f-score for each category of lectures is presented  we see that the f-score is high for analytical and descriptive lectures when compared to other categories.this is because  a particular topic is described in more detail in analytical and descriptive lectures  and we observe that this is directly proportional to the dispersion of the keyphrase  however in an introductory lecture  the features such as dispersion  local-span  tf-idf and c-value yield lower scores  primarily since the lecturer does not dwell on a specific topic for much time  precision for illustrative lectures is less when compared to other categories of lectures  this is because  illustrative lectures normally use analogy of real world entities to explain the topic  which we term illustrative phrases  though illustrative phrases usually are not keyphrases for a lecture  9 table ii k eyphrases identified using each feature for a lecture on `` c omplete b inary t ree `` in data s tructures sub  domain manual keyphrase trees  ordered tree  binary tree  complete binary tree  abstract data type  adt for binary tree  unbounded branching  root node  degree of node  leaves of the tree  nodes of a tree  internal node  height of the tree  left sub tree  right sub tree  decision tree keyphrase from each feature cuewords  tree  internal node  ordered tree dispersion  binary tree  complete binary tree  root node  height of the tree localspan  height of the tree  left subtree  decision trees  tree on n node  root node cscore  binary tree  complete binary tree  number of leaves  internal node keyphrase result of the system internal node  tree  left sub tree  tree on n node  complete binary tree  number of leaves  ordered tree  root node  decision tree  height of the tree  binary tree baseline algorithms  a parameters and metrics parameters required for the segmentation algorithm are determined on an empirical basis  the window size is set to 500 words  which is approximately half the average segment size in a typical lecture containing 8000 words and 4-6 segments  the sliding interval is taken to be 50 words  roughly equal to 20 seconds of lecture speech  since the granularity of topics varies based on various factors such as domain  instructor 's style and lecture length  these parameter need to be varied appropriately according to the dataset chosen  as in keyphrase extraction manual segmentation done by humans is taken as the gold standard for evaluation  since metrics such as precision and recall are unsuited to the segmentation task  we use two recently proposed metrics  pk and w indowdif f  now widely used for such evaluations  18   pk estimates the probability that two words chosen from the transcript at random  are correctly identified  or not  as falling in the same segment by the algorithm  the window size parameter k is set to 250  which is half the average segment size  as suggested by beeferman  24  to give appropriate metric values for baseline systems  the windowdiff metric counts the number of boundaries in a sliding window and penalizes the algorithm if any variation is discovered with respect to the human segmented reference  the metric reduces problems associated with pk to do with overpenalizing near misses and false negatives  and susceptibility to variations in segment size  b experiments and results to evaluate the segmentation technique  we find the level of annotator agreement by having 2 annotators segment a small set of lectures  we gave the annotators a range of values for the number of segments  in order to ensure that both segment at similar levels of granularity  the results are tabulated in table iv  it is observed that our algorithm consistently performs much better than the existing methods  in addition  since we use only the extracted keyphrases for segmentation  this results in faster segmentation  however it is observed that the algorithm does not perform very well for introductory lectures due to the lack of specific topics in the lecture  viii  c onclusions in this paper  a lecture browser system that uses automatic keyphrase extraction and segmentation was presented  the paper has shown that a combination of automatic keyphrase extraction and segmentation enhances the functionality of figure 5 texttiling window similarity boundaries are calculated based on the measure of dissimilarity between adjacent windows  for each window w  any keyphrase t appearing in the lecture is given a window score calculated as fw  t  sw  t  = isf  t  where fw  t  is the frequency of t in w and isf  t  is the inverse segment frequency of t  which denotes the importance of t in w isf  t  is analogous to tf-idf and is calculated as log  n/n  t   where n denotes the total number of windows and n  t  stands for the number of windows containing keyphrase t a vector space model is constructed for each window whose members are scores calculated for keyphrases as described  cosine similarity scores are computed for each pair of adjacent windows with corresponding feature vectors vi and vadj  i  as ci  i+1 = vit vadj  i  |vi ||vadj  i  | when the cosine scores are plotted against the transcript timeline  graphs similar to figure 5 are obtained  as hearst explains  to obtain better scoring accuracy a moving average based smoothing needs to be done on the scores  the deepest valleys or dips are selected as probable boundaries  the actual number of boundaries is set based on the variation of scores from the mean score   n   vii  e valuation to evaluate our segmentation algorithm we use the same corpora as used for keyphrase extraction  our evaluation strategy parallels the approach in  23   we compare our results with the classic texttiling algorithm to show that keyphrases are indeed strong features for segmentation  we also compare our results with choi 's system and a few 10 table iv c omparing segmentation algorithms lecture name ml1 type reference our algorithm text tiling orig c99 choi* reference our algorithm text tiling orig c99 choi* reference our algorithm text tiling orig c99 choi* reference our algorithm text tiling orig c99 choi* reference our algorithm text tiling orig c99 choi* segments 1787 4919 1600 2800 3054 5492 601 3348 1327 3214 1600 2950 2651 5152 1213 2780 1020 3208 2050 3100 1627 1981 2458 3660 1016 3395 1000 2596 6098 2239 2387 1219 2491 1300 1242 1600 492 2198 lecture size 10463 9700 p 0.538461538 0.711538462 0.509090909 9087 0.314814815 0.574074074 0.345454545 8734 7450 6219 7562 7500 5748 6860 7000 6197 5632 9403 7649 8950 9088 0.290909091 0.725490196 0.375 8925 0.351851852 0.456140351 0.543859649 0.351851852 0.421052632 0.543859649 0.290909091 0.725490196 0.375 0.5172 0.456140351 0.672727273 0.5172 0.456140351 0.672727273 0.314814815 0.574074074 0.345454545 wd 0.538461538 0.711538462 0.509090909 ml2 6843 4150 8392 4791 6210 6500 6569 6718 4150 3397 4710 4631 4300 3398 3340 3400 1958 3450 8633 5650 5106 8299 9736 8050 8643 ml3 ml6 7876 6070 6400 4770 7727 5747 6100 4221 5100 5600 3340 4625 ml7 8582 8186 7974 a lecture browser system  our experimental evaluation of the keyphrase extraction algorithm shows that our technique performs better than existing techniques  we also evaluated the system for different categories of lectures and we believe that our technique can be enhanced to perform better for introductory and illustrative lectures  the evaluation of the segmentation technique  which uses keyphrases  also performs better than existing methods  we hope to add to this work by identifying features from modalities other than lecture transcripts to capture the content of the lecture  we also plan to use the proposed features to calculate the relevance of a term to a particular document  so as to improve search results  r eferences  1  j r glass  t j hazen  d s cyphers  k schutte  and a park  `` the mit spoken lecture processing project  '' in proceedings of hlt/emnlp on interactive demonstrations  pp  2829  2005   2  `` see stanford engineering everywhere  '' http  //see.stanford.edu/default.aspx   3  k zechner  `` automatic generation of concise summaries of spoken dialogues in unrestricted domains  '' in sigir '01  proceedings of the 24th annual international acm sigir conference on research and development in information retrieval  pp  199207  2001   4  i gurevych and m strube  `` semantic similarity applied to spoken dialogue summarization  '' in coling '04  2004   5  i h witten  g w paynter  e frank  c gutwin  and c g nevillmanning  `` kea  practical automatic keyphrase extraction  '' in dl '99  proceedings of the fourth acm conference on digital libraries  pp  254 255  1999   6  p d turney  `` learning algorithms for keyphrase extraction  '' information retrieval  pp  303336  2000   7  a hulth  `` improved automatic keyword extraction given more linguistic knowledge  '' in proceedings of the 2003 conference on empirical methods in natural language processing  pp  216223  2003   8  o medelyan and i h witten  `` thesaurus based automatic keyphrase indexing  '' in jcdl '06  proceedings of the 6th acm/ieee-cs joint conference on digital libraries  pp  296297  2006   9  s n kim and m.-y  kan  `` re-examining automatic keyphrase extraction approaches in scientific articles  '' in mwe '09  proceedings of the workshop on multiword expressions  pp  916  2009   10  f fukumoto and y sekiguchi  `` keyword extraction of radio news using term weighting with an encyclopedia and newspaper articles  '' in proceedings of the 21st annual international acm sigir conference on research and development in information retrieval  1998   11  y matsuo and m ishizuka  `` keyword extraction from a single document using word co-ocurrence statistical information  '' 2003   12  l van der plas  v pallotta  m rajman  and h ghorbel  `` automatic keyword extraction from spoken text  a comparison of two lexical resources  the edr and wordnet  '' arxiv computer science e-prints  2004   13  f liu  d pennell  f liu  and y liu  `` unsupervised approaches for automatic keyword extraction using meeting transcripts  '' in naacl '09  proceedings of human language technologies  pp  620628  2009   14  a haubold and j r kender  `` analysis and visualization of index words from audio transcripts of instructional videos  '' ieee international symposium on multimedia software engineering   pp  570573  2004   15  n yamamoto  j ogata  and y ariki  `` topic segmentation and retrieval system for lecture videos based on spontaneous speech recognition  '' in eurospeech-2003  pp  961964  2003   16  o perspective and c l wayne  `` topic detection tracking  tdt   '' in in proceedings darpa broadcast news transcription and understanding workshop  1998   17  m.a.k  halliday and r hasan  language  context and text  aspects of language in a social-semiotic perspective  deakin university press  1989   18  m a hearst  `` texttiling  segmenting text into multi-paragraph subtopic passages  '' computational linguistics  pp  3364  1997   19  k t frantzi and s ananiadou  `` extracting nested collocations  '' in coling  1996   20  p r christopher manning and h schutze  an introduction to information retrieval  cambridge university press  2009   21  `` nptel  national programme on technology enhanced education  '' http  //nptel.iitm.ac.in   22  `` mit ocw  mit opencourseware  '' http  //ocw.mit.edu   23  i malioutov and r barzilay  `` minimum cut model for spoken lecture segmentation  '' in acl-44  proceedings of the 21st international conference on computational linguistics  pp  2532  2006   24  d beeferman  a berger  and j lafferty  `` statistical models for text segmentation  '' in machine learning  pp  177210  1999  