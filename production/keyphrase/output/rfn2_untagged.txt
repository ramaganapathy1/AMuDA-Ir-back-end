efficient data interpretation and compression over rfid streams richard cocci  thanh tran  yanlei diao and prashant shenoy department of computer science  university of massachusetts amherst  rcocci  ttran  yanlei  shenoy  @ cs.umass.edu abstract despite its promise  rfid technology presents numerous challenges  including incomplete data  lack of location and containment information  and very high volumes  in this work  we present a novel data interpretation and compression substrate over rfid streams to address these challenges in enterprise supply-chain environments  our results show that our inference techniques provide good accuracy while retaining efficiency  and our compression algorithm yields significant reduction in data volume  i i ntroduction rfid is a promising electronic identification technology that enables a real-time information infrastructure to provide timely  high-value content to monitoring and tracking applications  however  rfid dataa triplet < tag id  reader id  timestamp > in its most basic formraises new challenges since it may be insufficient  incomplete  and voluminous  insufficient information  since rfid is inherently an identification technology designed to identify individual objects  a stream of rfid readings does not capture inter-object relationships such as co-location and containment  incomplete data  despite technological advances  rfid readings are inherently noisy with observed read rates below 100 % in actual deployments  missed readings result in a lack of information about an objects location  significantly impairing the tasks of determining both location and containment  high volume streams  perhaps the key distinguishing characteristic of rfid streams are their high data volumes which can easily overwhelm a data stream system  hence  it is imperative that data be filtered and compressed close to the hardware while preserving all useful information  in this paper  we present spire  a system that addresses the above challenges  spire departs from the prior work by building an interpretation and compression substrate over rfid data streams which employs three key techniques   1  a time-varying graph model that captures possible object locations and containment relationships with its stream-driven construction   2  a probabilistic algorithm that infers the mostlikely locations and containment relationships of objects  and  3  an output algorithm that transforms an input stream to a compressed  yet informative output stream  we have implemented our interpretation and compression substrate and have evaluated it using synthetic rfid streams emulating an enterprise supply-chain environment  our results show that our inference techniques provide good accuracy while retaining efficiency  and our compression algorithm yields significant reduction in data volume  ii  p roblem s tatement before defining the problem  we present the notion of the physical world  a physical world covers a geographical area event db complex event processor network output  compression interpretation & interpretation  probabilistic inference compression data capture  graph contruction per-tag cleaning rfid devices fig  1 architecture of spire  our substrate consists of  i  a data capture module for stream-driven construction of a time-varying graph model encoding possible object locations and containments ;  ii  an interpretation module to probabilistically infer the most likely location and containment for an object  and  iii  a compression module that outputs stream data in an compressed format with smoothing  comprising a set of objects o  a set of pre-defined  fixed locations l  and an ordered discrete time domain t  the set of locations can be either pre-defined logical areas such as aisle 1 in warehouse a  or  x  y  z  coordinates generated by a positioning system  at time instant t  the state of the world includes a set of location relationships  where each oi o is present at some lk l additionally  there exists containment relationships between objects oi  oj o at some lk l note that containment is dependent on the fact that both the container and contained object are present at the same location  the state of the world changes whenever an object enters the world  an object exits the world through a designated channel  or an existing object changes its location or containment relationship with other objects  the set of locations l also contains a special location called unknown  in particular  an object is in the unknown location if it is not present in any pre-defined location  e.g  in transit between two locations  or if it exited the physical world improperly  e.g  was stolen   rfid readers provide a means to observe the physical world  the readings produced at time t are collectively called an observation of the world  in this work  we focus on readers mounted at fixed locationsa common configuration in todays rfid deployments  for such fixed readers  a reading captures the location of the object  which is the same as the location of the reader   such readings  however  are inadequate for capturing the containment between objects  the data interpretation problem is to construct an approximate yet accurate estimate of the state of the world based on the observations thus far  for a given object  we provide probabilistic values representing its most likely location and container  recent research on rfid data cleaning  1   2  has employed temporal and spatial smoothing to alleviate missed time t=1 level 1  pallet locations 8 3 2 level 2  case level 3  item t=3 t=2 1 4 5 6 7 a  loading dock fig  2  9 3 6 7 b  belt 10 9 3 11 6 7 10 11 c  packaging area b  belt c  packaging area a sequence of observations in a warehouse  readings  but does not capture inter-object relationships or provide location estimates  note that in our definition  data interpretation over streams is only concerned about the present state of the physical world and not the past or the future  the data compression problem is to transform the input stream into an output stream with a reduced data volume but with no loss of information  such compression requires the knowledge of what data is redundant and thus can be safely discarded  in this work  we use interpretation to obtain such knowledge and generate an output stream that  i  augments the input stream with additional  likely information about objects  and  ii  has a significantly reduced volume of data  a warehouse scenario is depicted in figure 2  where rfid readers are installed above the loading dock  the conveyor belt  and the packaging area  at time t=1  the loading dock reader reports objects 1 to 6  denoted by the shaded nodes  these nodes are arranged according to the packaging levels that the reported tag ids indicate  3   object 7 is also present but was missed by the reader  denoted by an unshaded node  i.e  a missed reading  containment between objects  depicted by the dashed edges  is not reported by the readings and often uncertain  examples of ambiguous containment are the containment between items 4  5  6 and cases 2  3 at this time  at time t=2  case 3 is scanned individually on the belt  it is possible to confirm the containment between the case and its item  s  now if the domain knowledge of the deployment reveals such special readers that scan containers of a particular type one at a time  additionally  a new case 9 is read in the packaging area  at time t=3  item 6 is read at the belt again  it fell off its case at t=2 and stayed here   a new pallet 8 is assembled from cases 3 and 9 in the packaging area  item 10 remained with its case but was not read  creating the inaccurate appearance that the item is missing  iii  data c apture this section describes our data capture technique to construct a time-varying graph model from the raw stream  a time-varying colored graph model  our graph model g =  v  e  encodes the current view of the objects in the physical world  including their reported locations and  unreported  possible containment relationships  in addition  the model incorporates statistical history about co-occurrences between objects  example graphs for the observations in figure 2 are shown in figure 3 the node set v denotes all rfid-tagged objects in the physical world  since we are assuming a supply-chain environment  an object has a packaging level of an item  case or a pallet ; the packaging level is encoded in the rfid tag id  3   our graph is arranged into layers  with one layer for each packaging level  each node either has a color that denotes its location or is uncolored if its location is currently unknown  the node colors are updated for the stream of readings in each epoch using the color of the location where each tag is observed  if an object is not read by any reader in a particular epoch  its node becomes uncolored  however  uncolored nodes retain memory of their most recent color and the observation time denoted by  recent color  seen at   the directed edge set e encodes possible containment relationships between objects  a directed edge oi oj denotes that oi contains object oj  e.g  case i contains item j   we allow multiple outgoing and incoming edges to and from each node  indicating an object such as a case may contain multiple items  and conversely  an item may have multiple potential cases  our probabilistic inference will subsequently chose only one of these possibilities   we allow combinations of colored and uncolored nodes  with the exception that an edge can not connect two nodes of different colors ; that is  containment is prohibited for two objects resident in two different locations  to enable inference  the graph also encodes additional statistics  each edge maintains a bit-vector recent collocations to record recent positive and negative evidence for the collocation of the two objects  the bit is set every time the two nodes connected by the edge are assigned the same color  further  each node maintains past certain parent statistics to remember the last confirmed parent  either revealed by a special reader or through inference with high certainty  the time of confirmation  and the number of conflicting observations obtained thus far  among all incoming edges  only one can be a confirmed edge  denoted by the edges with double arrows in figure 3 we assume that time is divided into epochs and the graph is updated using stream data from each epoch  our construction algorithm takes the graph g from the previous epoch and a set of readings rk from each reader k  1 k k  in the current epoch  and produces a new graph g  an important feature of the algorithm is that it proceeds incrementally as readings arrive from each reader  and guarantees a consistent output g after seeing the readings from all readers in an epoch  this ensures that the algorithm works even when the various readers are coarsely synchronized in time  given rk of each reader  the graph update procedure entails four steps  step 1 update and color nodes  if a new object is observed for the first time  a new node is created in the graph  for each observed object  the corresponding node is colored with the color of the reader that observed it  the colors of unobserved objects are not updated but simplify fade at a certain rate  step 2 update edges  if two nodes in adjacent layers have the same color  an edge is added between them if one does not exist  this enumerates all possible containment relationships  e.g  a blue item can be contained in any of the blue cases that are present on a shelf   t=1 in figure 3 demonstrates edges being constructed for the arriving pallet  step 3 prune graph  an edge is removed from the graph if its vertices are assigned different colors  which may occur when two previously co-located objects are now reported in different locations  t=3 in figure 3 shows the edge v3 v6 being pruned due to conflicting node colors  alternatively  edges can be removed from an object when a single edge t=1 time level 1 level 2 t=2  a,1   a,1  2 level 3  a,1  3 5 4 6  a,1   a,1   a,1  a  loading dock locations fig  3 t=3 1  a,1  1  a,1  2  b  2  3 8  c,3  1  a,1   c,2  9  a,1  2  c,3  3  c,3  9 5 4 6 7 10 11 4 5 6 11 7 10  a,1   a,1   b,2   b,2   c,2   c,2   a,1   a,1   b,3   c,3   c,2   c,3  c  packaging area b  belt c  packaging area b  belt examples of the time-varying colored graph model  is confirmed as the objects container  special readers  such as a belt reader that read exactly one pallet at a time  allow for improvement in the accuracy of the graph model while simultaneously helping to prune unnecessary edges  step 4 update statistics  this step updates statistics of the edges that have at least one node colored in step 1 given an edge e  if the two linked nodes have the same color  recent collocations of e is updated by setting the most recent bit to true  furthermore  if the reader k is able to confirm the containment denoted by e  we update the past certain parent of the child node  if one of the linked nodes is uncolored  the most recent bit of recent collocations is set to false  in this case  we also check if e was set as the certain parent edge of the child node  and if so count the current observation as a conflicting observation of the confirmation  these statistics play a key role in containment inference  iv  data i nterpretation the graph constructed from the data capture step can result in uncolored nodes or nodes with multiple parent nodes  the data interpretation step attempts to estimate the most likely location of an unreported  uncolored  object and the most likely container  parent  of an  either reported or unreported  object using a probabilistic inference technique  edge inference  edge inference is applied to each incoming edge of a node v regardless of whether the node is colored or not  it assigns a probability pei to each edge ; the edge with the highest probability is then chosen as the most likely container of v past history is used to compute probability values  which includes  i  the recent history of co-locations  as represented by the bit-vector recent collocations and  ii  the last confirmation of an edge either by a special reader or as a result of inference with high certainty  as captured in the data structure past certain parent  the use of past history makes edge inference less sensitive to missed readings  edge inference at a node consists of two steps  the first step computes a weight wei for each incoming edge using the history of observed co-locations  the next step builds a probability distribution across all incoming edges  it computes a probability pei for each edge by balancing the relative weight on this edge against the edges last confirmed parent  node inference  node inference is applied to an uncolored node van object with an unknown locationand attempts to infer the most likely location of the object or confirm its absence from any known location  the key challenge in node inference arises from a three-way tradeoff among object dynamics  continuation of past state  and absence with no other knowledge  specifically  a given object can remain in its current location  move to a new observable location  or disappear from all observable locations  to account for these possibilities  node inference builds a probabilistic distribution over all possible colors of a node v  including  1  its most recent color   2  the colors of its neighboring nodes that can be propagated through the edges  and  3  a special color unknown  among all possible colors  the one with the highest probability represents the most likely estimate of this objects location  in t=3 in figure 3  v10 s location was inferred due to color inherited from its neighbors  v s tream o utput with c ompression the output module takes the results of inference  i.e  the most likely estimates of the location and container of each object  and transforms them into a compressed output event stream  the key idea behind compression is that only those readings that indicate a state change need to be included in the output stream  the state of an object is said to have changed if its location or its containment changes  in the absence of a state change  all readings merely confirm the current state of the physical world and can be safely discarded  our location compression works on the intuition that if an object is stationaryresident at the same location for a period of timeonly an initial event needs to be output to indicate its first arrival at this location and all subsequent readings in the same location can be safely discarded  separately  containment compression exploits stable containment  for both stationary and mobile objects  based on the intuition that for the extent of a containment relationship it is possible to infer all of the childs events through the parent  location and containment compression techniques have been previously proposed for rfid warehouses  4  but use expensive disk-based operations such as sorting and summarization  as opposed to our methods which are processed on the fly and modify the output stream  vi  s ummary of p erformance e valuation r esults overall  our results show that the our framework for inference is able to correctly infer both object location and containment with a higher than 90 % accuracy when the readers read rate is above 80 %  a level reached in many current rfid deployments  our compression techniques are also capable of reducing total data volume by more than 80 % when compared to the raw reader output  furthermore  our framework is capable of scaling to simulated workloads in excess of 100,000 objects while still maintaining processing throughput above stream speed  acknowledgments  the work has been supported in part by the national science foundation under the grant cns-052072  r eferences  1  m j franklin  s r jeffery  s krishnamurthy  f reiss  s rizvi  e w 0002  o cooper  a edakkunni  and w hong  design considerations for high fan-in systems  the hifi approach  in cidr  2005  pp  290304   2  s r jeffery  m n garofalakis  and m j franklin  adaptive cleaning for rfid data streams  in vldb  2006  pp  163174   3  epcglobal tag data standards version 1.3 http  //www.epcglobalinc.org/  mar 2006   4  h gonzalez  j han  x li  and d klabjan  warehousing and analyzing massive rfid data sets  in icde  2006  p 83  