common term::32.0
data set::31.0
common terms::30.0
document pair::20.0
document pairs::16.0
two document::15.0
topic term::15.0
ground truth::13.0
two documents::13.0
topic terms::12.0
data sets::12.0
d-span similarity::12.0
digital libraries::11.0
background terms::11.0
background term::11.0
relatedness model::10.0
high d-span similarity::9.50977500433
pair of documents::9.50977500433
hash tables::9.0
similarity measure::9.0
continuation relation::9.0
subtopic and background terms::8.0
relevance of a term::8.0
digital library::8.0
semantic relatedness::8.0
relationships between documents::7.92481250361
types of relatedness::7.92481250361
latent semantic analysis::7.92481250361
user rating::7.0
cosine similarity::7.0
knowledge base::7.0
semantic analysis::7.0
background topic::7.0
document relationships::7.0
high d-span::7.0
document relation::7.0
type of relatedness::6.33985000288
science and technology::6.33985000288
set of documents::6.33985000288
shown in table::6.33985000288
data point::6.0
average precision::6.0
query processing::6.0
semantic relation::6.0
information science::6.0
document relatedness::6.0
specific relation::6.0
higher c-value::6.0
similarity measures::6.0
information science and technology::6.0
subtopic term::6.0
syst table::6.0
elaboration measure::5.0
computer science::5.0
latent semantic::5.0
subtopic terms::5.0
information retrieval::5.0
statistical model::5.0
document similarity::5.0
occurrence pattern::5.0
prototype system::5.0
linked list::5.0
document pairs exhibiting::4.75488750216
knowing and understanding::4.75488750216
evaluation of continuation::4.75488750216
document similarity measure::4.75488750216
computing semantic relatedness::4.75488750216
similarity between documents::4.75488750216
types of document::4.75488750216
quantify the strength::4.75488750216
c-value and tf-idf::4.75488750216
measures to quantify::4.75488750216
segmentation of video::4.75488750216
defining and quantifying::4.75488750216
alue of common term::4.0
users of digital libraries::4.0
measures that are based::4.0
occurrence patterns::4.0
d-span score::4.0
average precision and recall::4.0
specific relationship::4.0
data points::4.0
term in the document::4.0
external knowledge::4.0
results obtained::4.0
term frequency::4.0
ground truth was generated::4.0
standard deviation::4.0
term i in document::4.0
related work::4.0
machine learning::4.0
lecture on `` hashing::4.0
direction for future work::4.0
relatedness type::4.0
semantic relatedness using wikipedia::4.0
types of document relatedness::4.0
terms with a higher::4.0
common terms or phrases::4.0
continuation elaboration application data::4.0
based approach::4.0
scientific literature::4.0
terms of low relevance::4.0
semantic similarity::4.0
relationships between two documents::4.0
linked lists::4.0
strength of these relationships::4.0
content of the document::4.0
term in a document::4.0
low or moderate d-span::4.0
scientific document::4.0
probabilistic latent semantic analysis::4.0
source document::4.0
rest of this section::4.0
specific relations::4.0
intro to machine learning::4.0
presence of common terms::4.0
evaluation of application::3.16992500144
term is characterized::3.16992500144
related by application::3.16992500144
probabilistic latent semantic::3.16992500144
play a role::3.16992500144
low or moderate::3.16992500144
elaboration application data::3.16992500144
teaching and learning::3.16992500144
transcripts in data::3.16992500144
relation is defined::3.16992500144
cdiff ; c-values::3.16992500144
truth was generated::3.16992500144
c-value as filter::3.16992500144
knowledge based approach::3.16992500144
terms with high::3.16992500144
proposed by mccormak::3.16992500144
explicit semantic analysis::3.16992500144
aspects of relatedness::3.16992500144
cosine similarity index::3.16992500144
aspects of learning::3.16992500144
aspects of teaching::3.16992500144
based on topic::3.16992500144
difference or similarity::3.16992500144
types of relationships::3.16992500144
shown in fig::3.16992500144
explicit user rating::3.16992500144
intro to machine::3.16992500144
d-span and c-value::3.16992500144
topic in document::3.16992500144
based on expert::3.16992500144
hashing and hash::3.16992500144
concept level relationships::3.16992500144
relationships between two::3.16992500144
terms of low::3.16992500144
segmentation of videos::3.16992500144
tf-idf and low::3.16992500144
frantzi and ananiadou::3.16992500144
topic being applied::3.16992500144
normalized relevance distance::3.16992500144
presence of common::3.16992500144
find more information::3.16992500144
order to provide::3.16992500144
serves to identify::3.16992500144
precision and recall::3.16992500144
background or subtopic::3.16992500144
tf-idf as filter::3.16992500144
gather user feedback::3.16992500144
effective in identifying::3.16992500144
evaluate the results::3.16992500144
continuation elaboration application::3.16992500144
large data sets::3.16992500144
indicating higher c-value::3.16992500144
evaluation of elaboration::3.16992500144
mccormak and yager::3.16992500144
external knowledge base::3.16992500144
identifying these relationships::3.16992500144
lecture transcripts::3.0
continuation elaboration::3.0
data structures::3.0
average recall::3.0
higher relevance::3.0
future work::3.0
user ratings::3.0
average rating::3.0
retrieval system::3.0
scientific documents::3.0
sample document::3.0
scientific publication::3.0
elaboration relation::3.0
large data::3.0
random set::3.0
semantic relationship::3.0
score pattern::3.0
related documents::3.0
tf-idf weighting::3.0
semantic relations::3.0
tf-idf weight::3.0
classroom lecture::3.0
statistical patterns::3.0
d-span values::3.0
computing semantic::3.0
elaboration application::3.0
continue a subtopic explained::2.0
similarity index is applied::2.0
literature proposed by mccormak::2.0
set3 continuation elaboration application::2.0
learning a concept-based document::2.0
digital library which typically::2.0
analyze the continuation relation::2.0
based on non-textual features::2.0
played by a term::2.0
definitions of these relationships::2.0
data point belonging table::2.0
balanced f-score and nmi::2.0
linking research articles related::2.0
systems must therefore provide::2.0
difference and the aggregate::2.0
briefly covered in document::2.0
relation by the measure::2.0
similarity and high minimum::2.0
tf-idf and high d-span::2.0
contextual relevance is brought::2.0
computational linguistics::2.0
direct measure of relevance::2.0
two documents have absolutely::2.0
statistical model for identifying::2.0
definition of the application::2.0
types elaboration and application::2.0
studied in the context::2.0
semantic relations in information::2.0
good indicator of continuation::2.0
statistical patterns within documents::2.0
involve presenting a diversified::2.0
automatic suggestions to enable::2.0
measure results in high::2.0
method is the explicit::2.0
measures that involve computing::2.0
common terms of low::2.0
programme on technology enhanced::2.0
definition of document relationships::2.0
concepts based on link::2.0
calculated between each pair::2.0
tower of hanoi applies::2.0
browsing experience remains focused::2.0
short snippets of text::2.0
identifying patterns between documents::2.0
relationships from the documents::2.0
stable metric for computing::2.0
large number of terms::2.0
c-value in the elaboration::2.0
probabilistic latent::2.0
aspects of the application::2.0
pair to be exhibiting::2.0
type between two documents::2.0
terms supervised learning functional::2.0
measures of the types::2.0
similar work or datasets::2.0
educational context::2.0
document pairs with feature::2.0
lecture on query processing::2.0
observed that studying patterns::2.0
document relationships and applying::2.0
measure uses a filter::2.0
pairwise relationship was determined::2.0
term distribution into account::2.0
queues have similar patterns::2.0
d-spans but high d-span::2.0
values for our approach::2.0
directions for future work::2.0
relative c-value::2.0
featuring topics::2.0
term a are represented::2.0
data set2 continuation elaboration::2.0
exhibiting these patterns play::2.0
terms increasing order linked::2.0
lie within the larger::2.0
define a relatedness model::2.0
clusters of the occurrence::2.0
quantifying application an application::2.0
knowledge of the topic::2.0
approach for identifying semantic::2.0
collaborative filtering involve user::2.0
dictionaries and hash tables::2.0
applied if this information::2.0
channelized series of document::2.0
brought out::2.0
learning process::2.0
list root node left::2.0
categories of learning objectives::2.0
digital libraries are fast::2.0
high dsim::2.0
led to relationships identified::2.0
theme of the document::2.0
done using statistical measures::2.0
respect to scientific literature::2.0
relatedness types are chosen::2.0
based on the equation::2.0
difference established in section::2.0
issues such as synonymy::2.0
journal of computer science::2.0
prone to false positives::2.0
study on their effectiveness::2.0
similarity measure and judged::2.0
automated guidance for users::2.0
precision ra with c-value::2.0
usage and other intrinsic::2.0
statistical approach for modeling::2.0
science education literature proposed::2.0
syst fig::2.0
identify the three relationships::2.0
featured in the media::2.0
alongside various other techniques::2.0
frequency and occurs infrequently::2.0
elaboration measure brings out::2.0
infer the above relationships::2.0
c-value of common terms::2.0
relationships in digital libraries::2.0
defined by the presence::2.0
ranks by our measure::2.0
document recommendation::2.0
strength of the relationships::2.0
research article::2.0
rating points::2.0
techniques in digital library::2.0
similarity for all terms::2.0
areas of information retrieval::2.0
d-span similarity of terms::2.0
increasing order linked list::2.0
filter based on c-value::2.0
data sets for judging::2.0
candidate keyphrases::2.0
serve more specific purposes::2.0
terms binary search machine::2.0
premise that the semantic::2.0
study in a focused::2.0
terms such as `circular::2.0
case where a topic::2.0
science+business media new york::2.0
pairs balanced f-score normalized::2.0
average ratings are presented::2.0
infer the underlying relationship::2.0
collaboration technologies and systems::2.0
results obtained when cosine::2.0
trees trees::2.0
document with the highest::2.0
c-value is defined based::2.0
lectures from data structures::2.0
tf-idf for measuring relevance::2.0
seelan1 narendranath vijayakumar1 vidhya::2.0
source document from dataset::2.0
data structures that form::2.0
machine learning context free::2.0
f-score values are shown::2.0
learner overcome these kinds::2.0
term has a high::2.0
considered as a measure::2.0
text document::2.0
relevance distancea stable metric::2.0
classes of common terms::2.0
similarity between two pieces::2.0
datasets and ground truth::2.0
identifying the application relation::2.0
identified features extensive experimentation::2.0
measure of the probability::2.0
elementary feature in information::2.0
similarity coefficients are examples::2.0
captures three important aspects::2.0
considerable similarity with respect::2.0
relatedness categories are continuation::2.0
biology and computer science::2.0
similarity for common terms::2.0
relatedness measure between documents::2.0
low cdiff::2.0
filtering involve user profiling::2.0
structures and machine learning::2.0
classified as exhibiting continuation::2.0
focusing on these specific::2.0
technology enhanced::2.0
terms with differing c-values::2.0
helping a learner browse::2.0
measures like cosine similarity::2.0
outlines the different aspects::2.0
topics or concepts featured::2.0
based on expert estimation::2.0
textual coherence with latent::2.0
learning needs of consumers::2.0
depend on the chosen::2.0
improved semantic similarity measure::2.0
similarity in both content::2.0
helping the learning process::2.0
architecture of proposed system::2.0
esa with the wikipedia::2.0
results show::2.0
efficient data clustering method::2.0
related by the content::2.0
concepts helping the learning::2.0
patterns of these terms::2.0
extensive analysis of sample::2.0
profiling in recommendation systems::2.0
certified by our experts::2.0
evaluation of clustering result::2.0
c-value of the elaborated::2.0
shows some sample documents::2.0
subject of the document::2.0
continuation have a high::2.0
items in a digital::2.0
terms and their context::2.0
machine learning syntax pointers::2.0
model can help design::2.0
pattern medium to high::2.0
development of recommendation systems::2.0
information retrieval digital libraries::2.0
sample sets had data::2.0
important concept in document::2.0
cdiff values::2.0
systems or standard data::2.0
learning or research requirements::2.0
retrieve the related documents::2.0
balanced f-score normalized mutual::2.0
similarity in the background::2.0
defined relatedness measures based::2.0
conceptual relationship between stacks::2.0
provide suggestions of related::2.0
terms related to background::2.0
section details the results::2.0
find any similar work::2.0
nxn document pairs balanced::2.0
helps the user find::2.0
patterns and some additional::2.0
knowledge derived from external::2.0
ground truth was determined::2.0
part of it applies::2.0
search trees for database::2.0
process was as described::2.0
syst as a start::2.0
cdiff ; c-values higher::2.0
identifying semantic::2.0
relation data set1 continuation::2.0
present in a document::2.0
nmi and f-score values::2.0
n-gram extraction and pos::2.0
search machine learning context::2.0
share similar background terms::2.0
spanning a wider range::2.0
quantifying continuation the `continuation::2.0
approaches like collaborative filtering::2.0
functional languages base address::2.0
examples of our results::2.0
model to find similarity::2.0
ananda seelan1 narendranath vijayakumar1::2.0
results of latent semantic::2.0
extract the different types::2.0
elaboration have been observed::2.0
concepts and their relationships::2.0
documents or text fragments::2.0
application if they satisfy::2.0
relationship between the documents::2.0
feedback by getting explicit::2.0
d-span similarity and tf-idf::2.0
natural progression of topics::2.0
ensure that the browsing::2.0
work focuses on relationships::2.0
set available and subjects::2.0
feedback from the prototype::2.0
metric for measuring relatedness::2.0
aspects of scientific learning::2.0
determine how to include::2.0
usage of topic terms::2.0
database applications and geographic::2.0
document an automated system::2.0
lsa uses a probabilistic::2.0
described in the current::2.0
user gets the liberty::2.0
likelihood of the document::2.0
evaluated for that data::2.0
aspects can be done::2.0
average nmi and f-score::2.0
sets by explicit user::2.0
causing the background terms::2.0
ratio of the length::2.0
based on the feature::2.0
techniques that involve hash::2.0
understanding of this concept::2.0
filter ra with tf-idf::2.0
based on their contribution::2.0
examples of elaboration document::2.0
documents in these sets::2.0
d-span similarity among common::2.0
set of data points::2.0
exhibited by the common::2.0
statistical term features two::2.0
characteristics and the style::2.0
data set for evaluation::2.0
potential results for sample::2.0
cubic spline interpolation hash::2.0
ranking of the results::2.0
respect to the usage::2.0
suggestions at each stage::2.0
semantic similarity or relatedness::2.0
measuring relatedness of scientificpapers::2.0
measures should be generic::2.0
syst we created data::2.0
query processing multilevel indexing::2.0
user in a digital::2.0
interfaces to data intensive::2.0
constitutes our relatedness model::2.0
case of our measure::2.0
segments of the document::2.0
birch clustering of nxn::2.0
applications for digital libraries::2.0
metric for computing semantic::2.0
represented several subject domains::2.0
higher c -v alue::2.0
features are the c-value::2.0
automatically identify::2.0
scientific and educational media::2.0
association for information science::2.0
estimation of bayesian probabilities::2.0
data set is broad::2.0
d-span scores::2.0
knowledge base and compute::2.0
query refinement in ontologybased::2.0
moderate d-span::2.0
guarantee a semantic relation::2.0
nxn document::2.0
flow of the content::2.0
filter re with tf-idf::2.0
relatedness between scientific documents::2.0
higher than the majority::2.0
determining if a document::2.0
greater extent::2.0
analyzing the data sets::2.0
ensured that all topics::2.0
computer science and engineering::2.0
proceedings of the fifteenth::2.0
terms to similar extents::2.0
paper is to meet::2.0
define the central theme::2.0
set1 continuation elaboration application::2.0
patterns that help quantify::2.0
continue the same topic::2.0
develop a statistical model::2.0
graph linking research articles::2.0
enable the user experience::2.0
understood the concept described::2.0
sources for gathering information::2.0
background knowledge::2.0
chosen from the data::2.0
phrase to each document::2.0
patterns mentioned in section::2.0
quantify the different kinds::2.0
statistic features to determine::2.0
terms of rating points::2.0
background topics or subtopics::2.0
consists of advanced scientific::2.0
truth was generated based::2.0
generated based on expert::2.0
usage of a document::2.0
users with the ground::2.0
relatedness in scientific document::2.0
d-span similarity and high::2.0
represents a starting point::2.0
role in the definition::2.0
background terms term topic::2.0
problem of quantifying semantic::2.0
elaboration application score pattern::2.0
prominent topics or concepts::2.0
scores for a term::2.0
prototype system the architecture::2.0
documents in which terms::2.0
term in the two::2.0
spread across a document::2.0
person doing a scientific::2.0
c-value difference::2.0
science our prototype system::2.0
model can be effective::2.0
generated the ground truth::2.0
considered in this paper::2.0
include semantic knowledge derived::2.0
points where aggregate dsim::2.0
wider range of domains::2.0
identifies a good continuing::2.0
transcripts of classroom lectures::2.0
similar subjects::2.0
documents from the repository::2.0
similarity in its d-spans::2.0
document in other domains::2.0
relationship between two documents::2.0
effective in generating graphs::2.0
characterized by high c-value::2.0
continuation in data set::2.0
means of a visualization::2.0
base address logical notation::2.0
term to a document::2.0
pairs are good candidates::2.0
series and parallel hash::2.0
sets had data points::2.0
estimated for a random::2.0
application of a document::2.0
experiment is a proof::2.0
gain the necessary background::2.0
similar patterns in subtopic::2.0
continuous flow of concepts::2.0
data set3 continuation elaboration::2.0
relation that can occur::2.0
extent of the information::2.0
terms with higher relevance::2.0
pairs with feature values::2.0
based on these relationships::2.0
detailed insight into linked::2.0
define the continuation measure::2.0
presented our experimental study::2.0
document ; similar d-span::2.0
type of relation data::2.0
digital libraries is provided::2.0
tables have similar patterns::2.0
fast becoming important sources::2.0
binary search::2.0
fall under this category::2.0
spread uniformly and widely::2.0
model that identifies types::2.0
low c-value and low::2.0
user interfaces to data::2.0
lead to discovering information::2.0
explicit semantic::2.0
common terms with similar::2.0
international journal on digital::2.0
automatically identify the dominating::2.0
importance of the common::2.0
results for sample documents::2.0
architecture of this system::2.0
database systems::2.0
classification should be improved::2.0
examples of statistical measures::2.0
information flow is continuous::2.0
distributional and wordnet-based approaches::2.0
consisting of data points::2.0
level relationships::2.0
publication ; presents method::2.0
concept and semantic relatedness::2.0
wikirelate ! computing semantic::2.0
elaboration relation is defined::2.0
-sp an = wordcount::2.0
measure is rather general::2.0
user rating as mentioned::2.0
data set1::2.0
sample sets::2.0
model the different types::2.0
measuring factor for terms::2.0
results of this measure::2.0
retrieval over such libraries::2.0
lead to the identification::2.0
product of term frequency::2.0
document relation scores defined::2.0
logic-based approach for query::2.0
show that our techniques::2.0
text without an external::2.0
association for computational linguistics::2.0
related work and guidance::2.0
background topic in document::2.0
value of re means::2.0
indicator of the continuation::2.0
results shown in tables::2.0
negative cdiff ; c-values::2.0
terms of varying relevance::2.0
terms indicates a stronger::2.0
unspecified number of clusters::2.0
based on these measures::2.0
based on the content::2.0
similarity metrics with content-based::2.0
properties of such terms::2.0
background terms increasing order::2.0
parallel hash tables queue::2.0
document pairs exhibiting elaboration::2.0
digital library recommendation engines::2.0
feature score::2.0
hold the particular relationship::2.0
related to `` segmentation::2.0
occurrences of the terms::2.0
relatedness and provide ranked::2.0
means that the high::2.0
collaborative filtering::2.0
d-span similarity for common::2.0
similarity measure for document::2.0
evaluation on their performance::2.0
elaborations of less prominent::2.0
theme but is generally::2.0
syst of modeling document::2.0
user experience these aspects::2.0
prototype system and analyze::2.0
model for identifying semantic::2.0
instance of the continuation::2.0
measure of the elaboration::2.0
determined using domain experts::2.0
international acm sigir conference::2.0
continuation we first evaluate::2.0
calculated between the expert::2.0
application have been commonly::2.0
document can be determined::2.0
methodology serves to identify::2.0
weighting rc without tf-idf::2.0
recognition of multi-word terms::2.0
proceedings of the sixth::2.0
measure of term usage::2.0
proceedings of the 28th::2.0
series of logical sequences::2.0
learning science education literature::2.0
stated that the fundamental::2.0
information access in digital::2.0
rely on external knowledge::2.0
c-value as a context::2.0
computing similarity between items::2.0
identification of the specific::2.0
means that the term::2.0
distribution or occurrence pattern::2.0
found in digital libraries::2.0
defining the continuation relationship::2.0
compare the obtained results::2.0
f-score normalized mutual information::2.0
proceedings of human language::2.0
libraries are often intended::2.0
terms in a document::2.0
document play a major::2.0
recommendation systems::2.0
common terms whereas documents::2.0
term in two documents::2.0
model is to provide::2.0
corpus as the knowledge::2.0
clustering of nxn document::2.0
describe measures to quantify::2.0
evaluating our relatedness model::2.0
semantic relationships::2.0
linked list root node::2.0
similarities between different segments::2.0
featured in the document::2.0
relatedness categories::2.0
documents that have related::2.0
application to word sense::2.0
background term is characterized::2.0
spread of common terms::2.0
lecture transcripts from mit-ocw::2.0
document pairs exhibiting application::2.0
precision re with c-value::2.0
common terms has lead::2.0
similarity and semantic relatedness::2.0
measures by extensive evaluation::2.0
judging these specific relations::2.0
involving hypertext are limited::2.0
term between the two::2.0
lectures and scientific publications::2.0
statistical measures::2.0
interesting directions for future::2.0
briefly mentions linked lists::2.0
makes it very relevant::2.0
number of common terms::2.0
indication that clustering based::2.0
lists from an implementation::2.0
picks up any case::2.0
featured more prominently i.e::2.0
concentrate on digital libraries::2.0
similar patterns for common::2.0
terms to be present::2.0
d-span of these terms::2.0
minimum of the tf-idf::2.0
specific relations between documents::2.0
approaches based on wikipedia::2.0
relationships without much domain::2.0
relevance of some terms::2.0
topic term in document::2.0
needed for large data::2.0
measure brings out results::2.0
term having high c-value::2.0
uncertainty in artificial intelligence::2.0
balanced f-score::2.0
similarity measures that involve::2.0
created data sets similar::2.0
opposite of the previously::2.0
relevant to the main::2.0
terms with high d-span::2.0
studying `` virtual memory::2.0
obtained using our data::2.0
documents such as lectures::2.0
characterized by moderate c-value::2.0
relationships identified between lectures::2.0
conclusion in this article::2.0
recall is quite similar::2.0
documents that are related::2.0
occurrence or term frequency::2.0
low relevance::2.0
helps a learner understand::2.0
generally a course handling::2.0
application is not explicit::2.0
degree of contextual relevance::2.0
scope of information access::2.0
patterns play a role::2.0
concept or a wikipedia::2.0
conference on computational linguistics-volume::2.0
precision of the results::2.0
exhibiting continuation have tended::2.0
rank suggestions of related::2.0
differences of those common::2.0
contribute to the relationship::2.0
terms must be greater::2.0
segmentation of video lectures::2.0
comprehensive approach that identifies::2.0
information through a series::2.0
show that both similarity::2.0
high dsim or low::2.0
continuation elaboration application average::2.0
shows the average precision::2.0
goal in this section::2.0
consideration the td-idf value::2.0
rating is done individually::2.0
syst for characterizing continuation::2.0
remaining dsim and cdiff::2.0
terms in the source::2.0
presence of the concept::2.0
documents from a learner::2.0
presenting a diversified chain::2.0
semantic relatedness using wikipedia-based::2.0
data points where aggregate::2.0
eliminating the densest bins::2.0
terms exhibiting these patterns::2.0
measure for document clustering::2.0
document formats and structures::2.0
identify the dominating relationship::2.0
terms is a good::2.0
approach for query refinement::2.0
domain characterized by similarity::2.0
distributed in a document::2.0
subject of its document::2.0
based on its length::2.0
term a is spread::2.0
recommendations based on collaborative::2.0
measure is further improved::2.0
result for an original::2.0
stacks and linked lists::2.0
terms like `` hashing::2.0
proceedings of the 16th::2.0
occurrence of the term::2.0
set of n documents::2.0
concept that is discussed::2.0
ensured that the data::2.0
modeling document relatedness presents::2.0
relationships in the organization::2.0
terms in these documents::2.0
generation for data sets::2.0
commonly used for address::2.0
patterns for common topic::2.0
higher in the elaboration::2.0
terms to the target::2.0
chain of concepts helping::2.0
discussed in a document::2.0
model that can automatically::2.0
involve computing semantic similarity::2.0
elaboration application average user::2.0
differs from similarity measures::2.0
rest of this article::2.0
lectures in the data::2.0
lsa and probabilistic lsa::2.0
relevance defines the continuation::2.0
hash tables have similar::2.0
play a major role::2.0
calls for a model::2.0
feature score patterns type::2.0
cosine similarity and jaccard::2.0
contextual to the core::2.0
interpolation hash tables elaboration::2.0
applications and geographic information::2.0
identifies types of document::2.0
define the three relationships::2.0
e-learning repositories and digital::2.0
weighted by a constant::2.0
purposes which involve presenting::2.0
measures defined in section::2.0
probability of a data::2.0
lecture transcripts from nptel::2.0
answer the following queries::2.0
common terms will make::2.0
goal of this relatedness::2.0
application data set3 continuation::2.0
comprehensive set of relations::2.0
doing a scientific literature::2.0
relationships using the identified::2.0
examine the d-span differences::2.0
similarity only in common::2.0
number of scientific publications::2.0
sets represented several subject::2.0
document data sets development::2.0
low in the data::2.0
weights as making relevance::2.0
recall for this dataset::2.0
rule for a random::2.0
effectiveness of our approach::2.0
set of larger terms::2.0
total number of document::2.0
literature may feature multiple::2.0
knowledge for some concept::2.0
moderate d-span for instance::2.0
users have a knowledge::2.0
relatedness model to identify::2.0
information systems::2.0
application data set2 continuation::2.0
d-span is a measure::2.0
lecture on `` greedy::2.0
answers to the type::2.0
empirically determined by analyzing::2.0
two approaches for identifying::2.0
limited to structured text::2.0
root node left child::2.0
averaged over the total::2.0
gather user::2.0
interpreting tf-idf term weights::2.0
scores using the measure::2.0
science research student conference::2.0
addressing the semantic aspects::2.0
publications in the areas::2.0
mentioned in the related::2.0
collaborative filtering for document::2.0
terms which are topic::2.0
means that the d-span::2.0
results against it gather::2.0
relationships from concept level::2.0
making it a background::2.0
contributions in this paper::2.0
types of terms influencing::2.0
typically is a heterogeneous::2.0
concept level::2.0
moderation of the nmi::2.0
process of a learner::2.0
relationship types between documents::2.0
browse through a set::2.0
organization of knowledge vol::2.0
applies especially to scientific::2.0
graduate level classroom lecture::2.0
independently for each category::2.0
terms that exhibit higher::2.0
infer their semantic relationship::2.0
high dsim negative cdiff::2.0
traversal cubic spline interpolation::2.0
elaboration application data set3::2.0
elaboration application data set2::2.0
types and a unique::2.0
concept-based document similarity measure::2.0
clustering result::2.0
provided through suggestions based::2.0
expanded with more features::2.0
potential documents that exhibit::2.0
search trees::2.0
symposium on applied computing::2.0
defining and quantifying application::2.0
generated by a group::2.0
dimensions in which documents::2.0
fifteenth conference on uncertainty::2.0
d-span as a measure::2.0
applies the main concept::2.0
determined by generating potential::2.0
keyphrase extraction::2.0
learner who is studying::2.0
c-values in the two::2.0
tf-idf as a direct::2.0
implicit feedback and semantic::2.0
document pairs are good::2.0
concepts to be featured::2.0
quantifying types of relatedness::2.0
terms is very high::2.0
queries of the user::2.0
features topics in computer::2.0
data set1 continuation elaboration::2.0
giving a detailed insight::2.0
widely in both lectures::2.0
subtopics like `` knapsack::2.0
tables queue scaled cont::2.0
approach taken to identifying::2.0
type helps the user::2.0
generating graphs of related::2.0
truth for the data::2.0
scaled for the sake::2.0
relevance of the common::2.0
continuation can be characterized::2.0
application measure::2.0
tf-idf is empirically determined::2.0
filter was determined arbitrarily::2.0
terms in the elaboration::2.0
value of the terms::2.0
wikipedia has its advatages::2.0
term features in order::2.0
model and the measures::2.0
document relatedness correspondingly answer::2.0
contribute to the continuation::2.0
build further relatedness types::2.0
concept or a subtopic::2.0
documents using such features::2.0
refinement in ontologybased information::2.0
trees intro to machine::2.0
helpful for a learner::2.0
precision and recall values::2.0
term does not define::2.0
suggestions of related work::2.0
term features two documents::2.0
order linked list root::2.0
majority of the data::2.0
document suggestions::2.0
concepts in the documents::2.0
lecture video::2.0
document d2 or part::2.0
factor with the c-value::2.0
part of larger n-grams::2.0
provide services to support::2.0
two documents demonstrate considerable::2.0
tree traversal cubic spline::2.0
lecture or an article::2.0
similar d-span::2.0
topic terms binary search::2.0
document tf-idf c-value d-span::2.0
relatedness before we define::2.0
present a comprehensive approach::2.0
value is an indication::2.0
insight into linked lists::2.0
absolutely nothing in common::2.0
characterized using the similarity::2.0
selected subset of test::2.0
mathematical definition of c-value::2.0
spread of the common::2.0
system modeled to provide::2.0
defining and quantifying elaboration::2.0
libraries with cultural items::2.0
based on collaborative citation::2.0
performance of the continuation::2.0
clustering result for nxn::2.0
feature scores for topic::2.0
dsim or cdiff values::2.0
syst uses the context::2.0
directly infer concept level::2.0
documents for a query::2.0
similarity or association relations::2.0
series of document suggestions::2.0
conceptual document similarity metrics::2.0
clustering of similar documents::2.0
suggestions to the user::2.0
term is very relevant::2.0
main topic::2.0
strength of such relationships::2.0
higher c-value of common::2.0
classify terms as topic::2.0
topic in `` query::2.0
base our continuation measure::2.0
analysis of sample document::2.0
factors that are important::2.0
introduce measures to quantify::2.0
elaborations from the dataset::2.0
out by the occurrence::2.0
start point for addressing::2.0
clustering based on topic::2.0
cosine index::2.0
lecture on `` dynamic::2.0
characterized by relatively low::2.0
exhibiting continuation::2.0
discussion on `` query::2.0
documents using cosine similarity::2.0
document pairs j intell::2.0
sort trees trees trees::2.0
aspects of common terms::2.0
database repository that consists::2.0
pearson coefficient and kld::2.0
scores for the candidate::2.0
repositories and digital libraries::2.0
kaufmann publishers inc hopfgartner::2.0
learning objectives::2.0
high tf-idf and high::2.0
captured by our continuation::2.0
characterization constitutes our relatedness::2.0
relatedness model that serves::2.0
based on extensive analysis::2.0
bring out the relevance::2.0
c-value or term frequency::2.0
relevant terms that contribute::2.0
described in this lecture::2.0
researchers have defined similarity::2.0
extensive experimentation and evaluation::2.0
identify them in technical::2.0
results of our evaluation::2.0
formally analyze the continuation::2.0
machine learning grammar quick::2.0
digital libraries statistical modeling::2.0
defines measures to quantify::2.0
relative c-value of terms::2.0
tf-idf means the term::2.0
information than a traditional::2.0
similarity among common terms::2.0
rating as mentioned earlier::2.0
studying patterns in d-span::2.0
typically use a graph::2.0
grammar quick sort subtopic::2.0
relatedness of scientificpapers based::2.0
required in a digital::2.0
characterizing the continuation relation::2.0
query about the main::2.0
background topics or common::2.0
reflect a single continuous::2.0
types serve more specific::2.0
common terms of varying::2.0
directions for information search::2.0
results for each document::2.0
relatedness based on distinct::2.0
exploring a new set::2.0
derived from external sources::2.0
hash tables queue scaled::2.0
relatedness category the set::2.0
implies that common terms::2.0
low d-spans but high::2.0
kinds of common terms::2.0
factor to be considered::2.0
computer graphics::2.0
relatedness is very low::2.0
part of longer candidate::2.0
require a knowledge base::2.0
acm transactions on information::2.0
sample document data sets::2.0
semantic similarity and semantic::2.0
scores for `` application::2.0
compute the relatedness measure::2.0
relatedness between each pair::2.0
pairs in video lecture::2.0
common terms with differing::2.0
helps counteract the effect::2.0
serves to identify interesting::2.0
information is not present::2.0
continuation scores for document::2.0
wordnet and bing similarities::2.0
document di the resulting::2.0
data structures and machine::2.0
proceedings of the 15th::2.0
concepts such as optimization::2.0
evaluated with the ground::2.0
measures for text document::2.0
28th annual acm symposium::2.0
data sets by explicit::2.0
hash tables elaboration score::2.0
semantic relatedness between documents::2.0
users was an expert::2.0
extended to include semantic::2.0
results against the ground::2.0
connections between different documents::2.0
subject of a discussion::2.0
texttiling for document similarity::2.0
results for `` application::2.0
risks like uncertain expertise::2.0
feature vectors representing tf-idf::2.0
access in digital libraries::2.0
type of an exploration::2.0
models in collaborative filtering::2.0
annual international acm sigir::2.0
evaluate the relatedness model::2.0
strictly require a knowledge::2.0
data set and category::2.0
feature high d-span similarity::2.0
subtopic terms supervised learning::2.0
made some exploratory visualizations::2.0
occurs between the content::2.0
information access::2.0
formally define these relations::2.0
sample documents::2.0
intent of users ground::2.0
node left child quick::2.0
types of semantic similarity::2.0
application from the results::2.0
interesting applications::2.0
relevance of terms exhibiting::2.0
create a ground truth::2.0
trust models in collaborative::2.0
documents demonstrate considerable similarity::2.0
progression from the content::2.0
explanation of a concept::2.0
topics such as database::2.0
document pairs balanced f-score::2.0
similar ? investigating item::2.0
terms that are relevant::2.0
truth generation for data::2.0
relevance and low d-spans::2.0
identification of interesting applications::2.0
manually created document graph::2.0
based on user rating::2.0
languages base address logical::2.0
types of relatedness characterized::2.0
characteristics of these relationships::2.0
domain knowledge is essential::2.0
transcripts from mit-ocw featuring::2.0
quantifying the application relationship::2.0
large number::2.0
semantic similarity between documents::2.0
degree of relatedness based::2.0
measure described in section::2.0
classifier to classify terms::2.0
semantic aspects of common::2.0
c-value for common terms::2.0
relationship helps the learner::2.0
topic in one document::2.0
documents was thus created::2.0
factor for terms present::2.0
term in each document::2.0
based on the data::2.0
score is a measure::2.0
review of information science::2.0
terms in a pair::2.0
video and audio lectures::2.0
learning needs of users::2.0
observed in the top-left::2.0
subset of test documents::2.0
term features to identify::2.0
computer science and technology::2.0
relation helps the user::2.0
definition of our intended::2.0
score for each pair::2.0
model proposed by mccormak::2.0
positive cdiff ; c-values::2.0
respect to the topic::2.0
observed in the bottom-left::2.0
scientificpapers based on non-textual::2.0
application relation::2.0
nptel that features topics::2.0
two pieces of text::2.0
related to information access::2.0
similarity in term frequencies::2.0
based on topic maps::2.0
specifically gathered a mix::2.0
difficult to create ground::2.0
relevant results::2.0
computer science research student::2.0
communications of the acm::2.0
subject of a discourse::2.0
patterns type of relatedness::2.0
cosine similarity or lsa::2.0
probability function for relevance::2.0
filtering for document recommendation::2.0
characterized by specific feature::2.0
strength of the elaboration::2.0
determine if a term::2.0
system returns a document::2.0
stage of the learning::2.0
quick sort trees trees::2.0
rule-based classifier to classify::2.0
built on the normalized::2.0
concordance with the intent::2.0
case with the background::2.0
recall that were observed::2.0
demonstrated that our measures::2.0
present in the applying::2.0
indicating a natural progression::2.0
dramatically improves the results::2.0
weight the d-span similarity::2.0
experiments over a large::2.0
pairs which had dsim::2.0
concept helps a learner::2.0
documents is the similarity::2.0
grammar quick::2.0
national programme on technology::2.0
hashing and hash functions::2.0
based on the results::2.0
based on link analysis::2.0
document pairs in video::2.0
diversified chain of concepts::2.0
information and learning material::2.0
make it the right::2.0
concept defined or mentioned::2.0
vijayakumar1 vidhya balasubramanian1 received::2.0
feature in query-document retrieval::2.0
means a greater likelihood::2.0
term weights as making::2.0
precision of the classification::2.0
development in information retrieval::2.0
relate to its core::2.0
model can be extended::2.0
contribution to the content::2.0
outlines the related work::2.0
address logical notation background::2.0
semantic relationships in digital::2.0
application is not considered::2.0
complexity or liked lists::2.0
application score pattern medium::2.0
types of semantic relatedness::2.0
potential document relatedness categories::2.0
expert opinion was sought::2.0
good candidates for continuation::2.0
observations to more formally::2.0
first identify different aspects::2.0
similarity relation between documents::2.0
digital libraries with cultural::2.0
c-value defined in frantzi::2.0
prototype system that identifies::2.0
probability that a data::2.0
focuses on the generic::2.0
analysis and its application::2.0
evaluation of continuation average::2.0
based on these features::2.0
sigir conference on research::2.0
systems and innovative visualizations::2.0
quantifying elaboration this relation::2.0
quick sort subtopic terms::2.0
takes into account common::2.0
important in the identification::2.0
measures to j intell::2.0
reasonable precision and recall::2.0
measure based on earth::2.0
continuation for a lecture::2.0
pairs in our visualizations::2.0
browse through a repository::2.0
likelihood that the score::2.0
evaluate the large data::2.0
relatedness has been widely::2.0
relatedness that would serve::2.0
d-span similarity of common::2.0
view a selected document::2.0
american society for information::2.0
relatedness model for identifying::2.0
train a rule-based classifier::2.0
suggested work is related::2.0
document as a product::2.0
users of a digital::2.0
content such as scholarly::2.0
evaluate by user ratings::2.0
describing extensive experimental results::2.0
libraries must also provide::2.0
relatedness in an educational::2.0
terms influencing this relationship::2.0
jeyavaishnavi muralikumar1 sri ananda::2.0
explained in the definition::2.0
relatedness measures::2.0
desirable in a digital::2.0
occurrence patterns of terms::2.0
free grammar quick sort::2.0
similarity and jaccard similarity::2.0
terms which are background::2.0
continued by the lecture::2.0
number of potential documents::2.0
defining and quantifying types::2.0
topic of the source::2.0
dsim is high document::2.0
libraries jeyavaishnavi muralikumar1 sri::2.0
sample documents that fall::2.0
similarity in occurrence pattern::2.0
tf-idf is an elementary::2.0
terms and the importance::2.0
graph such as wordnet::2.0
relatedness using different statistical::2.0
first evaluate the performance::2.0
approach does not strictly::2.0
deviation between the users::2.0
effective at identifying similar::2.0
application of implicit feedback::2.0
addressed have been proposed::2.0
techniques such as stop::2.0
journal of the american::2.0
major topic in document::2.0
notation background terms increasing::2.0
journal of the association::2.0
provide a starting point::2.0
transcripts in data set::2.0
cosine measure is fundamental::2.0
words between successive clusters::2.0
mind when we deal::2.0
relation between the documents::2.0
develop a prototype system::2.0
continuation score::2.0
minimum required d-span similarity::2.0
type of indirect application::2.0
choose the right dataset::2.0
weighting feature in query-document::2.0
user ratings for results::2.0
presents a more comprehensive::2.0
important sources for gathering::2.0
literature survey::2.0
similarity of more relevant::2.0
relations in information science::2.0
specific aspects of relatedness::2.0
semantic relatedness between scientific::2.0
keywords relatedness information retrieval::2.0
set and different types::2.0
tf-idf of common terms::2.0
first state the idea::2.0
points with low dsim::2.0
naive bayes and maximum::2.0
seeking information are met::2.0
child quick sort trees::2.0
terms will be greater::2.0
explicit user rating type::2.0
results for each category::2.0
set2 continuation elaboration application::2.0
bayes and maximum margin::2.0
c-value and low tf-idf::2.0
method for very large::2.0
based on a sample::2.0
based on expert judgement::2.0
visualizations and we observed::2.0
logical notation background terms::2.0
relatedness using wikipedia-based explicit::2.0
identifying patterns::2.0
relatedness types::2.0
model based on texttiling::2.0
effectiveness of the d-span::2.0
identifying similar::2.0
similarity in the subtopic::2.0
transcripts taken from nptel::2.0
binary search machine learning::2.0
documents in a digital::2.0
dsim and low cdiff::2.0
representations of the documents::2.0
documents and to quantify::2.0
feature a semantic relation::2.0
similarity of the documents::2.0
department of computer science::2.0
application is the presence::2.0
low dsim and low::2.0
document d2 is strongly::2.0
literature survey by browsing::2.0
definition of these relatedness::2.0
measurement of textual coherence::2.0
explorations in information visualization::2.0
based on this discussion::2.0
d-span for measuring occurrence::2.0
enable the learner overcome::2.0
specific feature score patterns::2.0
performance of this model::2.0
unbiased experts and compare::2.0
supervised learning functional languages::2.0
defines the continuation relation::2.0
current document::2.0
relying on external knowledge::2.0
important aspects of relatedness::2.0
concept in this lecture::2.0
references to `` hash::2.0
widely used to capture::2.0
interest-based approaches like collaborative::2.0
obtained when when cosine::2.0
learning and numerical methods::2.0
specifically we are interested::2.0
journal on digital libraries::2.0
shows some more examples::2.0
type of relatedness continuity::2.0
utility of the measure::2.0
taxonomy of science education::2.0
identify features that quantify::2.0
similarity relation::2.0
out better by c-value::2.0
alue in the destination::2.0
discussion of the topic::2.0
objectives of a person::2.0
services that can support::2.0
present in the current::2.0
processing multilevel indexing expressions::2.0
documents have t common::2.0
smaller sample sets out::2.0
scores defined in section::2.0
suggestions of related documents::2.0
aggregate dsim is high::2.0
works on a database::2.0
general trend of higher::2.0
relatedness characterized by specific::2.0
multi-level indexing computer graphics::2.0
opt for a graph-based::2.0
based on its context::2.0
approach for modeling inter-document::2.0
digital library of cultural::2.0
user profiling in recommendation::2.0
measured by the tf-idf::2.0
feedback and semantic user::2.0
c-value d-span rank documents::2.0
documents must feature high::2.0
low relevance and low::2.0
application score::2.0
d-span rank documents based::2.0
links have been widely::2.0
subtopic in a document::2.0
results are in concordance::2.0
simply estimated by applying::2.0
role in this relationship::2.0
case of a person::2.0
measures may be built::2.0
based on the naive::2.0
based on these scores::2.0
curves query processing document::2.0
calculated for the document::2.0
science education::2.0
term frequency and inverse-document::2.0
defined for identifying similarity::2.0
tf-idf vs d-span similarity::2.0
relatedness metric for wikipedia::2.0
based approaches::2.0
defining and quantifying continuation::2.0
cluster is the set::2.0
cultural heritage::2.0
rating for the lsa::2.0
narendranath vijayakumar1 vidhya balasubramanian1::2.0
destination document::2.0
society for information science::2.0
relationships in the educational::2.0
similarity in d-span values::2.0
quantifying the different types::2.0
demonstrating that the common::2.0
types of document relationships::2.0
relatedness measure::2.0
d-span of common terms::2.0
evaluation as that validates::2.0
article on `` segmentation::2.0
hashing and hash tables::2.0
document at regular intervals::2.0
learner motivates the presence::2.0
result for nxn document::2.0
gleaned from the measures::2.0
amrita school of engineering::2.0
metric for wikipedia concepts::2.0
importance of a term::2.0
keyphrase extraction and segmentation::2.0
results and the scores::2.0
tf-idf seem to bring::2.0
digital libraries jeyavaishnavi muralikumar1::2.0
term indicates how significant::2.0
term frequencies or tf-idfs::2.0
lecture transcripts in data::2.0
muralikumar1 sri ananda seelan1::2.0
sort subtopic terms supervised::2.0
point in c1 exhibits::2.0
document pairs were clustered::2.0
determined arbitrarily by making::2.0
provide such document suggestions::2.0
wikipedia-based explicit semantic analysis::2.0
occurrences of a term::2.0
defines three such types::2.0
documents in a data::2.0
evaluation based on user::2.0
types of context-based relatedness::2.0
prominently featured in document::2.0
adequately as to inform::2.0
domains are not comprehensively::2.0
number of technical documents::2.0
terms and their classes::2.0
topics in computer science::2.0
informative as to determining::2.0
tf-idf c-value d-span rank::2.0
context free grammar quick::2.0
measure and judged based::2.0
videos and associated transcripts::2.0
identify the inter-document relationships::2.0
usage of the data::2.0
linguistic and statistic features::2.0
lists may be background::2.0
large number of technical::2.0
justification for this choice::2.0
relatedness modeling our goal::2.0
concept is insufficiently described::2.0
indicative of any type::2.0
instance for data set1::2.0
dsim or low cdiff::2.0
learning grammar quick sort::2.0
identifying feature of application::2.0
find similarity between documents::2.0
examples of continuation document::2.0
topics or common subtopics::2.0
15th annual international acm::2.0
higher for the larger::2.0
extraction and pos tagging::2.0
identify similarity between short::2.0
based on distinct statistical::2.0
ideal subjects for applications::2.0
infer concept level relationships::2.0
feature in information retrieval::2.0
learning syntax pointers logical::2.0
capacitor dictionaries stack document::2.0
measure serves to identify::2.0
news recommendation using wordnet::2.0
provide this background knowledge::2.0
chose the following data::2.0
starting point for defining::2.0
based on the ratings::2.0
quantification of these aspects::2.0
provided by the users::2.0
providing a channelized series::2.0
transactions on information systems::2.0
result visualisation with xfind::2.0
extent and with equivalent::2.0
extent than the elaboration::2.0
covered multiple document formats::2.0
computing and cultural heritage::2.0
explained towards the end::2.0
value matrix was arbitrarily::2.0
define the elaboration measure::2.0
provide better document recommendations::2.0
represents the topic featured::2.0
nmi and the f-score::2.0
evaluation of elaboration average::2.0
obtained when cosine similarity::2.0
machine learning and numerical::2.0
annual review of information::2.0
categories of semantic relatedness::2.0
performance on varied data::2.0
development of conceptual document::2.0
application average::2.0
binary search trees intro::2.0
categorized under each relatedness::2.0
c-value over tf-idf dramatically::2.0
gathering information and learning::2.0
cdiff ; c-values lower::2.0
deal with the types::2.0
16th conference on computational::2.0
techniques for estimating similarity::2.0
performance of the measure::2.0
metrics with content-based recommender::2.0
application average user rating::2.0
values are min-max normalized::2.0
relationship between a pair::2.0
low tf-idf and low::2.0
truth generation::2.0
classroom lecture video transcripts::2.0
background or subtopic terms::2.0
trend of higher c-value::2.0
inverse of the elaboration::2.0
coherence with latent semantic::2.0
motivated by the identified::2.0
similarity measures for text::2.0
patterns for `` dictionaries::2.0
applications are interesting directions::2.0
learning context free grammar::2.0
min-max normalized and run::2.0
section is to model::2.0
prominent in the application::2.0
examples of application document::2.0
document of a selected::2.0
syntax pointers logical inference::2.0
dsim and cdiff values::2.0
continuity elaboration application score::2.0
datasets for our experiments::2.0
featuring topics in economics::2.0
understood that a term::2.0
evaluation of application average::2.0
vidhya balasubramanian b vidhya::2.0
patterns in term features::2.0
document is brought out::2.0
document graph::2.0
relevance is brought out::2.0
current document an automated::2.0
retrieval digital libraries statistical::2.0
estimate of the strength::2.0
uncertain expertise of contributors::2.0
ratings for the recommendation::2.0
discussed our inter-document relatedness::2.0
specific relationship maybe considered::2.0
distinct statistical patterns exhibited::2.0
considerable similarity::2.0
probabilistic model to find::2.0
analysis of an external::2.0
rating type of relation::2.0
personal and group-based trust::2.0
returns a document relatedness::2.0
high c-value::2.0
modeling inter-document semantic relationships::2.0
features to identify inter-document::2.0
lectures spanning a wider::2.0
set of documents tested::2.0
high document pairs exhibiting::2.0
based on these categories::2.0
measure quantifies the relevance::2.0
results in a reasonable::2.0
elaboration document::2.0
terms term topic terms::2.0
document have higher d-span::2.0
extracted after common pre-processing::2.0
terms to the document::2.0
medium to high dsim::2.0
expect that the concept::2.0
higher c-value for common::2.0
represented by the term::2.0
keyphrases from the documents::2.0
domain or sub domain::2.0
information sciences::2.0
characteristic relationship between two::2.0
similarity measures like cosine::2.0
information retrieval and defines::2.0
classroom lectures and scientific::2.0
easily estimate the likelihood::2.0
precision rc with tf-idf::2.0
level classroom lecture video::2.0
occurs infrequently as part::2.0
application of a concept::2.0
irrespective of the types::2.0
answers to the query::2.0
based on wikipedia hyperlinks::2.0
choose to create datasets::2.0
users ground truth generation::2.0
similarity in background terms::2.0
lsa account for issues::2.0
acm symposium on applied::2.0
identifying the characteristic relationship::2.0
moderate tf-idf and low::2.0
truth actually prefer applications::2.0
library of cultural heritage::2.0
number of document pairs::2.0
introduces the three relationships::2.0
factors beyond the scope::2.0
understanding about the concept::2.0
identifying and characterizing document::2.0
-sp an of common::2.0
graph shows recommended continuations::2.0
computer science our prototype::2.0
lecture on `` universal::2.0
semantic relationships between documents::2.0
candidate documents were chosen::2.0
heterogeneous collection of educational::2.0
teaching and learning science::2.0
relatedness information retrieval digital::2.0
classification and the clustering::2.0
model is to choose::2.0
term features::2.0
term topic terms binary::2.0
chosen subset of documents::2.0
two documents are related::2.0
relative c-value and d-span::2.0
statistical patterns that characterize::2.0
relatedness between them remains::2.0
usage in the document::2.0
relatedness model that captures::2.0
application of `` dictionaries::2.0
work represents a starting::2.0
context of term usage::2.0
spline interpolation hash tables::2.0
graph-based or knowledge-based approach::2.0
shows how its documents::2.0
dictionaries trees trees document::2.0
concept may be applied::2.0
knowledge base or hypertext::2.0
relevant to the subject::2.0
semantic relatedness over reference::2.0
based on earth mover::2.0
reference corpora::2.0
similarity of common terms::2.0
making a literature survey::2.0
scientific publication recommendations based::2.0
right document for giving::2.0
tf-idf weighting for comparison::2.0
implemented which can retrieve::2.0
zealand computer science research::2.0
scope of this paper::2.0
document pairs exhibiting continuation::2.0
results in high recall::2.0
weak between the two::2.0
document similarity measure based::2.0
sixth new zealand computer::2.0
serves as the basis::2.0
results between different document::2.0
terms that can play::2.0
decided by an expert::2.0
previously introduced elaboration measure::2.0
documents featuring similar subjects::2.0
structure of a document::2.0
tf-idf value::2.0
two methods to test::2.0
scores for document pairs::2.0
cdiff values are min-max::2.0
ontologybased information retrieval systems::2.0
specific purposes which involve::2.0
define document similarity measures::2.0
types in a large::2.0
matrix was arbitrarily lowered::2.0
scores have been decimal::2.0
defined as the ratio::2.0
identifying additional document relationships::2.0
terms with similar d-span::2.0
high frequency and occurs::2.0
content of a document::2.0
definition of these measures::2.0
elaboration this relation helps::2.0
defining types of document::2.0
start with two basic::2.0
patterns of the term::2.0
sets development of measures::2.0
documents were chosen independently::2.0
short these three types::2.0
ground truth creation process::2.0
recommendation systems and innovative::2.0
contents of the lectures::2.0
lower in the application::2.0
document pairs were classified::2.0
person making a literature::2.0
quick sort::2.0
highest c-value or term::2.0
retrieval system is implemented::2.0
graphs of related documents::2.0
rank of the singular::2.0
sample from each topic::2.0
samples as the evaluation::2.0
investigating item similarity types::2.0
logical sequences or paths::2.0
user gives a rating::2.0
language processing to find::2.0
tf-idf weighting cosine index::2.0
point for the definition::2.0
higher and wider occurrence::2.0
topics from the data::2.0
done individually and privately::2.0
reduced to a subtopic::2.0
document browser is included::2.0
concept in this document::2.0
mentioned in a document::2.0
users for each source::2.0
collection of educational content::2.0
choice of feature based::2.0
bayesian probabilities that types::2.0
evaluation of elaboration table::2.0
group of five users::2.0
evaluate the results obtained::2.0
lists in another document::2.0
deals with few techniques::2.0
title of document tf-idf::2.0
similarity between short snippets::2.0
frequency and inverse-document frequency::2.0
users rated for similarity::2.0
learning functional languages base::2.0
applying the bayes rule::2.0
term will be lower::2.0
describe clustering of similar::2.0
analyzes the statistical patterns::2.0
automatic recognition of multi-word::2.0
d-span is an important::2.0
trees for database systems::2.0
model that j intell::2.0
technique to automatically identify::2.0
document graph linking research::2.0
primary requirements for evaluating::2.0
sri ananda seelan1 narendranath::2.0
measure without the tf-idf::2.0
continuation measure::2.0
arrived at a consensus::2.0
primarily related to information::2.0
term to the subject::2.0
created document graph based::2.0
scope in both documents::2.0
collection of t common::2.0
pairs exhibiting::2.0
approach where user rating::2.0
examples of such terms::2.0
define on a logical::2.0
identification of additional patterns::2.0
naive bayes::2.0
mix of graduate level::2.0
calculate the average rating::2.0
identifying patterns in term::2.0
relatedness continuity elaboration application::2.0
ground truth actually prefer::2.0
choose from different material::2.0
low cdiff were eliminated::2.0
left child quick sort::2.0
run through an implementation::2.0
normalized relevance distancea stable::2.0
relatedness over reference corpora::2.0
order linked list::1.58496250072
guarantee a semantic::1.58496250072
application to word::1.58496250072
definition of document::1.58496250072
term in document::1.58496250072
spanning a wider::1.58496250072
filtering for document::1.58496250072
human language technologies::1.58496250072
association for computational::1.58496250072
machine learning grammar::1.58496250072
model to find::1.58496250072
search trees intro::1.58496250072
statistical term features::1.58496250072
giving a detailed::1.58496250072
taking into consideration::1.58496250072
two types serve::1.58496250072
topic is chosen::1.58496250072
series of logical::1.58496250072
identified features extensive::1.58496250072
turdakov and velikhov::1.58496250072
keywords relatedness information::1.58496250072
evaluation of clustering::1.58496250072
high document pairs::1.58496250072
tf-idf of common::1.58496250072
approaches like collaborative::1.58496250072
libraries with cultural::1.58496250072
semantic news recommendation::1.58496250072
affect the accuracy::1.58496250072
techniques identify connections::1.58496250072
evaluate the relatedness::1.58496250072
define a relatedness::1.58496250072
similarity of terms::1.58496250072
work is related::1.58496250072
clustering of documents::1.58496250072
linking research articles::1.58496250072
documents featuring similar::1.58496250072
development of measures::1.58496250072
15th annual international::1.58496250072
observed is shown::1.58496250072
features that quantify::1.58496250072
characterized by high::1.58496250072
examples are mentioned::1.58496250072
include semantic knowledge::1.58496250072
manually created document::1.58496250072
methods involving hypertext::1.58496250072
truth was determined::1.58496250072
structures and machine::1.58496250072
identifying the type::1.58496250072
characterizing the continuation::1.58496250072
require a knowledge::1.58496250072
services to support::1.58496250072
documents that reflect::1.58496250072
point for addressing::1.58496250072
calculate the average::1.58496250072
related to information::1.58496250072
directions for future::1.58496250072
filter was determined::1.58496250072
understanding of topics::1.58496250072
measures like cosine::1.58496250072
terms of behavior::1.58496250072
measure and judged::1.58496250072
resistors in series::1.58496250072
india j intell::1.58496250072
works like wan::1.58496250072
proceed to define::1.58496250072
extend our observations::1.58496250072
techniques that involve::1.58496250072
larger data sets::1.58496250072
hashing is mentioned::1.58496250072
pairs exhibiting continuation::1.58496250072
define these relations::1.58496250072
exhibit this relation::1.58496250072
document data sets::1.58496250072
relations beyond similarity::1.58496250072
method j intell::1.58496250072
patterns in subtopic::1.58496250072
research student conference::1.58496250072
applications and geographic::1.58496250072
relation scores defined::1.58496250072
characterize their strength::1.58496250072
piece of literature::1.58496250072
number of potential::1.58496250072
tended to end::1.58496250072
learning and numerical::1.58496250072
processing multilevel indexing::1.58496250072
reflect a single::1.58496250072
identify interesting applications::1.58496250072
effective at identifying::1.58496250072
mentions linked lists::1.58496250072
expect a document::1.58496250072
topics to follow::1.58496250072
term weighting feature::1.58496250072
rank documents based::1.58496250072
serves to provide::1.58496250072
models for identification::1.58496250072
helping the learning::1.58496250072
examples of application::1.58496250072
capacitor dictionaries stack::1.58496250072
structures that form::1.58496250072
document at regular::1.58496250072
balasubramanian b vidhya::1.58496250072
document pairs evaluated::1.58496250072
conceptual document similarity::1.58496250072
higher d -sp::1.58496250072
knowledge based approaches::1.58496250072
similarity with respect::1.58496250072
patterns in term::1.58496250072
give much importance::1.58496250072
averages are shown::1.58496250072
determine only similarity::1.58496250072
terms as part::1.58496250072
measure working irrespective::1.58496250072
rely on external::1.58496250072
traditional recommendation model::1.58496250072
topics or common::1.58496250072
model to identify::1.58496250072
improves the results::1.58496250072
lectures and documents::1.58496250072
implying an application::1.58496250072
document structures document::1.58496250072
relation provides answers::1.58496250072
linked list root::1.58496250072
general and picks::1.58496250072
understood the concept::1.58496250072
similar background terms::1.58496250072
types of context-based::1.58496250072
documents must serve::1.58496250072
represented by terms::1.58496250072
intrinsic term features::1.58496250072
matching other meta-data::1.58496250072
high tf-idf means::1.58496250072
resulting documents categorized::1.58496250072
average c-value difference::1.58496250072
number of scientific::1.58496250072
term can fall::1.58496250072
trees trees document::1.58496250072
evaluate by user::1.58496250072
means the term::1.58496250072
feature `` dispersion::1.58496250072
dictionaries trees trees::1.58496250072
improved semantic similarity::1.58496250072
details the results::1.58496250072
terms of rating::1.58496250072
two documents demonstrate::1.58496250072
problem of identifying::1.58496250072
development of recommendation::1.58496250072
d-span rank documents::1.58496250072
exploring and discovering::1.58496250072
collection of educational::1.58496250072
aspects are desirable::1.58496250072
lead to discovering::1.58496250072
elaboration this relation::1.58496250072
curves query processing::1.58496250072
identifies a good::1.58496250072
approach as evaluated::1.58496250072
proceedings of human::1.58496250072
syst for characterizing::1.58496250072
support the discussion::1.58496250072
document relatedness presents::1.58496250072
user rating type::1.58496250072
similarity in occurrence::1.58496250072
boost helps counteract::1.58496250072
term topic terms::1.58496250072
document is applied::1.58496250072
tf-idf weight means::1.58496250072
measuring occurrence patterns::1.58496250072
described in section::1.58496250072
similar to aletras::1.58496250072
review of information::1.58496250072
similarity and semantic::1.58496250072
analyzing the measure::1.58496250072
cdiff were eliminated::1.58496250072
compute the relatedness::1.58496250072
determined by generating::1.58496250072
user find answers::1.58496250072
hypertext for identifying::1.58496250072
terms term topic::1.58496250072
literature may feature::1.58496250072
data sets similar::1.58496250072
learning like `knowing::1.58496250072
serve such requirements::1.58496250072
systems or standard::1.58496250072
factor for terms::1.58496250072
quick sort trees::1.58496250072
documents is hard::1.58496250072
define the central::1.58496250072
rating as mentioned::1.58496250072
concentrate on digital::1.58496250072
data sets represented::1.58496250072
advanced scientific literature::1.58496250072
interfaces to data::1.58496250072
document tf-idf c-value::1.58496250072
context measuring factor::1.58496250072
muralikumar1 sri ananda::1.58496250072
video lecture transcripts::1.58496250072
relatedness of scientificpapers::1.58496250072
context of concepts::1.58496250072
tested the performance::1.58496250072
retrieval system shows::1.58496250072
development in information::1.58496250072
chain of concepts::1.58496250072
conference on uncertainty::1.58496250072
experimentation and results::1.58496250072
define document similarity::1.58496250072
introduction automated guidance::1.58496250072
definition of c-value::1.58496250072
provide detailed discussions::1.58496250072
providing more information::1.58496250072
style of discussion::1.58496250072
inter-document relatedness model::1.58496250072
semantic user profiles::1.58496250072
designed for scientific::1.58496250072
involve computing semantic::1.58496250072
out the relevance::1.58496250072
profiling in recommendation::1.58496250072
wikipedia-based explicit semantic::1.58496250072
mentioned in section::1.58496250072
role in defining::1.58496250072
relationships and describes::1.58496250072
applied is represented::1.58496250072
search result visualisation::1.58496250072
measure brings out::1.58496250072
explorations in information::1.58496250072
high minimum tf-idf::1.58496250072
document relatedness categories::1.58496250072
wan and peng::1.58496250072
user to view::1.58496250072
application data set3::1.58496250072
application data set2::1.58496250072
distinct statistical patterns::1.58496250072
spread of common::1.58496250072
jeyavaishnavi muralikumar1 sri::1.58496250072
takes into account::1.58496250072
matrix was arbitrarily::1.58496250072
features to determine::1.58496250072
multiple document formats::1.58496250072
aspects of common::1.58496250072
retrieval and defines::1.58496250072
systems and innovative::1.58496250072
approach for query::1.58496250072
browser is included::1.58496250072
described three categories::1.58496250072
wikipedia concepts based::1.58496250072
derived from external::1.58496250072
relationship that occurs::1.58496250072
experts and compare::1.58496250072
document similarity search::1.58496250072
languages base address::1.58496250072
insight into linked::1.58496250072
graph shows recommended::1.58496250072
content of documents::1.58496250072
feasible to analogize::1.58496250072
amrita vishwa vidyapeetham::1.58496250072
evaluating our relatedness::1.58496250072
relations in information::1.58496250072
frequency and inverse-document::1.58496250072
outlines the related::1.58496250072
top k results::1.58496250072
retrieval model based::1.58496250072
state the idea::1.58496250072
present appropriate suggestions::1.58496250072
queue scaled cont::1.58496250072
consisting of data::1.58496250072
c-value of common::1.58496250072
dsim or low::1.58496250072
number of documents::1.58496250072
publishers inc hopfgartner::1.58496250072
dsim and cdiff::1.58496250072
normalized and run::1.58496250072
relation are expected::1.58496250072
measurement of textual::1.58496250072
users after discussion::1.58496250072
account for relations::1.58496250072
symposium on applied::1.58496250072
refinement in ontologybased::1.58496250072
identify the inter-document::1.58496250072
categories of relatedness::1.58496250072
sample source document::1.58496250072
similarity or lsa::1.58496250072
application estimated probability::1.58496250072
words between successive::1.58496250072
replacing the c-value::1.58496250072
subtopic or background::1.58496250072
shows an illustration::1.58496250072
eliminating the densest::1.58496250072
publication recommendations based::1.58496250072
defined similarity measures::1.58496250072
measure for document::1.58496250072
measures more reliable::1.58496250072
trees trees trees::1.58496250072
similarity in background::1.58496250072
large digital library::1.58496250072
journal on computing::1.58496250072
involve hash tables::1.58496250072
points with low::1.58496250072
performance on varied::1.58496250072
mentioned in table::1.58496250072
probabilistic lsa account::1.58496250072
address logical notation::1.58496250072
shows recommended continuations::1.58496250072
definitions in section::1.58496250072
c-value difference established::1.58496250072
judging these specific::1.58496250072
28th annual acm::1.58496250072
continuation therefore differs::1.58496250072
relatedness through analysis::1.58496250072
sort subtopic terms::1.58496250072
contribute to detecting::1.58496250072
deal with factors::1.58496250072
tf-idf dramatically improves::1.58496250072
examine the d-span::1.58496250072
stacks and linked::1.58496250072
taking these factors::1.58496250072
relatedness over reference::1.58496250072
feature of application::1.58496250072
support automatic suggestions::1.58496250072
concept being applied::1.58496250072
tables have similar::1.58496250072
level classroom lecture::1.58496250072
system and analyze::1.58496250072
represented several subject::1.58496250072
results when c-value::1.58496250072
subtopics are featured::1.58496250072
consideration the td-idf::1.58496250072
providing a channelized::1.58496250072
presenting a diversified::1.58496250072
provide ranked suggestions::1.58496250072
categories of terms::1.58496250072
publication ; presents::1.58496250072
aspects or dimensions::1.58496250072
two basic premises::1.58496250072
sample feature scores::1.58496250072
application of implicit::1.58496250072
develop a prototype::1.58496250072
background terms increasing::1.58496250072
cubic spline interpolation::1.58496250072
measure of term::1.58496250072
needed for large::1.58496250072
similarity in d-span::1.58496250072
method that evolved::1.58496250072
counteract this effect::1.58496250072
transcripts or documents::1.58496250072
abstract e-learning repositories::1.58496250072
tf-idf and high::1.58496250072
coupling this factor::1.58496250072
measures are capable::1.58496250072
compare the results::1.58496250072
collaborative citation networks::1.58496250072
clustering of similar::1.58496250072
describes the approach::1.58496250072
kinds of relationships::1.58496250072
documents that characterize::1.58496250072
system is implemented::1.58496250072
concept-based document similarity::1.58496250072
terms that occur::1.58496250072
topics in economics::1.58496250072
pointers logical inference::1.58496250072
path can lead::1.58496250072
generation for data::1.58496250072
characterized by similarity::1.58496250072
degree of relatedness::1.58496250072
differs from similarity::1.58496250072
defined for identifying::1.58496250072
transcripts from mit-ocw::1.58496250072
difficulties is desirable::1.58496250072
relations is required::1.58496250072
potentially a keyword::1.58496250072
represents the extent::1.58496250072
set of larger::1.58496250072
repositories and digital::1.58496250072
relatedness correspondingly answer::1.58496250072
mix of graduate::1.58496250072
start with two::1.58496250072
based on earth::1.58496250072
found in digital::1.58496250072
c-value and d-span::1.58496250072
type application rank::1.58496250072
account for issues::1.58496250072
simple retrieval system::1.58496250072
definition of measures::1.58496250072
relatedness information retrieval::1.58496250072
capable of identifying::1.58496250072
nptel and mit-ocw::1.58496250072
evolved from lsa::1.58496250072
high d-span subtopic::1.58496250072
department of computer::1.58496250072
quantifying semantic similarity::1.58496250072
observe the utility::1.58496250072
users ground truth::1.58496250072
system is shown::1.58496250072
choose the right::1.58496250072
feature in query-document::1.58496250072
categories of semantic::1.58496250072
library of cultural::1.58496250072
generating potential results::1.58496250072
validate these measures::1.58496250072
set1 continuation elaboration::1.58496250072
part of longer::1.58496250072
relevance is brought::1.58496250072
gathered a mix::1.58496250072
trees for database::1.58496250072
document on stacks::1.58496250072
modeling inter-document semantic::1.58496250072
serves the learning::1.58496250072
common pre-processing techniques::1.58496250072
returns a document::1.58496250072
geographic information systems::1.58496250072
degree of contextual::1.58496250072
define the elaboration::1.58496250072
exhibiting these patterns::1.58496250072
chalmers and chitson::1.58496250072
technology enhanced education::1.58496250072
relatedness between documents::1.58496250072
scope of information::1.58496250072
elaboration is characterized::1.58496250072
modeling our goal::1.58496250072
learning grammar quick::1.58496250072
nature of connection::1.58496250072
experiments have demonstrated::1.58496250072
document graph based::1.58496250072
tables elaboration score::1.58496250072
identify and quantify::1.58496250072
indication that precision::1.58496250072
base or hypertext::1.58496250072
created document graph::1.58496250072
types of lectures::1.58496250072
analysis of sample::1.58496250072
documents using cosine::1.58496250072
information retrieval systems::1.58496250072
kld are effective::1.58496250072
repository of documents::1.58496250072
shown in section::1.58496250072
opinion was sought::1.58496250072
term having high::1.58496250072
scientific literature documents::1.58496250072
rated for similarity::1.58496250072
feature multiple topics::1.58496250072
infer these relationships::1.58496250072
meta-data like authors::1.58496250072
affect the ranking::1.58496250072
identify the nature::1.58496250072
means of reducing::1.58496250072
features to identify::1.58496250072
term is distributed::1.58496250072
defines the relevance::1.58496250072
technology enhanced learning::1.58496250072
rating is done::1.58496250072
account common terms::1.58496250072
point for defining::1.58496250072
lecture video transcripts::1.58496250072
term is potentially::1.58496250072
types between documents::1.58496250072
d-spans or c-values::1.58496250072
overburden the users::1.58496250072
average user rating::1.58496250072
cdiff is positive::1.58496250072
difference in d-span::1.58496250072
similarity is found::1.58496250072
indexing computer graphics::1.58496250072
results in high::1.58496250072
connection or relationship::1.58496250072
document clustering based::1.58496250072
based on link::1.58496250072
work on types::1.58496250072
relationships are modeled::1.58496250072
hash tables elaboration::1.58496250072
data intensive systems::1.58496250072
c-value we make::1.58496250072
vidhya balasubramanian1 received::1.58496250072
techniques effectively extract::1.58496250072
discussed in rafi::1.58496250072
strube and ponzetto::1.58496250072
intend to present::1.58496250072
determining the relationship::1.58496250072
approach this problem::1.58496250072
results is needed::1.58496250072
view a selected::1.58496250072
classroom lecture video::1.58496250072
concept and semantic::1.58496250072
information retrieval digital::1.58496250072
investigating item similarity::1.58496250072
unique statistical model::1.58496250072
related work relatedness::1.58496250072
level of similarity::1.58496250072
continuation of document::1.58496250072
sequences or paths::1.58496250072
purposes which involve::1.58496250072
pairs are good::1.58496250072
c-value as explained::1.58496250072
d-span and tf-idf::1.58496250072
led to relationships::1.58496250072
relationships from concept::1.58496250072
provide a starting::1.58496250072
computing and cultural::1.58496250072
terms will make::1.58496250072
dsim and low::1.58496250072
characterize different relationships::1.58496250072
similar ? investigating::1.58496250072
document is brought::1.58496250072
score pattern represented::1.58496250072
scientific literature survey::1.58496250072
types of terms::1.58496250072
provide this background::1.58496250072
defining different types::1.58496250072
cosine index method::1.58496250072
features two documents::1.58496250072
normalized relevance distancea::1.58496250072
cdiff values higher::1.58496250072
similar d-span values::1.58496250072
importance to dictionaries::1.58496250072
values are min-max::1.58496250072
support the learning::1.58496250072
presents method based::1.58496250072
generally a concept::1.58496250072
document d2 serves::1.58496250072
results of analyzing::1.58496250072
automatic keyphrase extraction::1.58496250072
user interest-based approaches::1.58496250072
characterizing document relationships::1.58496250072
measure in quantifying::1.58496250072
d-span is moderate::1.58496250072
notion in mind::1.58496250072
probabilities that types::1.58496250072
found in table::1.58496250072
document is chosen::1.58496250072
singular value matrix::1.58496250072
intent of users::1.58496250072
zarrinkalam and kahani::1.58496250072
eliminating the occurrences::1.58496250072
mit-ocw featuring topics::1.58496250072
fast becoming important::1.58496250072
aspects into account::1.58496250072
patterns of terms::1.58496250072
identify different aspects::1.58496250072
scientific publication recommendations::1.58496250072
conference on computational::1.58496250072
tf-idf to weight::1.58496250072
identification of interesting::1.58496250072
category of relatedness::1.58496250072
relevance and low::1.58496250072
risks like uncertain::1.58496250072
category the set::1.58496250072
elaboration application score::1.58496250072
indicating the effectiveness::1.58496250072
displays the results::1.58496250072
related by continuation::1.58496250072
value for terms::1.58496250072
c-value and low::1.58496250072
terms that contribute::1.58496250072
article is organized::1.58496250072
pairs balanced f-score::1.58496250072
syntax pointers logical::1.58496250072
multi-level indexing computer::1.58496250072
university of stellenbosch::1.58496250072
annual international acm::1.58496250072
transcripts in dataset::1.58496250072
nxn document pairs::1.58496250072
university of glasgow::1.58496250072
intended for learning::1.58496250072
types of content::1.58496250072
sake of readability::1.58496250072
graph linking research::1.58496250072
defines the continuation::1.58496250072
f-score normalized mutual::1.58496250072
bayes and maximum::1.58496250072
research and development::1.58496250072
extraction and segmentation::1.58496250072
case of academic::1.58496250072
problem of quantifying::1.58496250072
binary search machine::1.58496250072
focus on providing::1.58496250072
learning context free::1.58496250072
number of words::1.58496250072
documents are extracted::1.58496250072
defined in frantzi::1.58496250072
analogize a document::1.58496250072
frequency and occurs::1.58496250072
experimentation and evaluation::1.58496250072
main topic term::1.58496250072
model defines measures::1.58496250072
benefited when documents::1.58496250072
world wide web::1.58496250072
identifies such requirements::1.58496250072
interpolation hash tables::1.58496250072
recent corpus-based measure::1.58496250072
high distribution similarity::1.58496250072
similarity measure based::1.58496250072
address different aspects::1.58496250072
requirements without relying::1.58496250072
applications are interesting::1.58496250072
define the continuation::1.58496250072
train a rule-based::1.58496250072
extracting nested collocations::1.58496250072
relationships that capture::1.58496250072
quantify each type::1.58496250072
developed to infer::1.58496250072
relatedness using wikipedia-based::1.58496250072
expertise of contributors::1.58496250072
contrast to esa::1.58496250072
elaboration or application::1.58496250072
development of conceptual::1.58496250072
keeping in mind::1.58496250072
larger subject domain::1.58496250072
subjects for applications::1.58496250072
category by means::1.58496250072
tf-idf the tf-idf::1.58496250072
measures that solve::1.58496250072
create a ground::1.58496250072
mind these aspects::1.58496250072
headings or sub-headings::1.58496250072
potential document relatedness::1.58496250072
stacks and queues::1.58496250072
terms and documents::1.58496250072
based on non-textual::1.58496250072
inform and fulfill::1.58496250072
feature common terms::1.58496250072
node left child::1.58496250072
similar d-span scores::1.58496250072
calculated balanced f-score::1.58496250072
document similarity measures::1.58496250072
liberty to choose::1.58496250072
quantify the degree::1.58496250072
generic similarity relation::1.58496250072
defined or mentioned::1.58496250072
extended to build::1.58496250072
topic terms binary::1.58496250072
media in question::1.58496250072
word sense disambiguation::1.58496250072
term features two::1.58496250072
digital libraries jeyavaishnavi::1.58496250072
functional languages base::1.58496250072
understand this lecture::1.58496250072
texttiling for document::1.58496250072
choice of feature::1.58496250072
evaluate the performance::1.58496250072
vidhya @ cb.amrita.edu::1.58496250072
hash tables queue::1.58496250072
tables queue scaled::1.58496250072
document is reduced::1.58496250072
documents were chosen::1.58496250072
explore the contents::1.58496250072
described in balagopalan::1.58496250072
meta-data are presented::1.58496250072
prototype system returns::1.58496250072
featured more prominently::1.58496250072
linguistic and statistic::1.58496250072
learning syntax pointers::1.58496250072
application measure serves::1.58496250072
longer candidate phrases::1.58496250072
sample sets out::1.58496250072
d-span for measuring::1.58496250072
higher d-span values::1.58496250072
document have higher::1.58496250072
syst of modeling::1.58496250072
based on similarities::1.58496250072
d-span of common::1.58496250072
good d-span score::1.58496250072
estimated by applying::1.58496250072
terms supervised learning::1.58496250072
studies are ongoing::1.58496250072
generalized search trees::1.58496250072
f-score and nmi::1.58496250072
science research student::1.58496250072
demonstrate considerable similarity::1.58496250072
pairs were classified::1.58496250072
hand data set::1.58496250072
quantifying the application::1.58496250072
function for relevance::1.58496250072
cosine similarity calculated::1.58496250072
consumers of scientific::1.58496250072
personal and group-based::1.58496250072
browsing a repository::1.58496250072
examples of continuation::1.58496250072
initial term-document matrix::1.58496250072
features is informative::1.58496250072
frequency of occurrence::1.58496250072
tf-idf weighting cosine::1.58496250072
context free grammar::1.58496250072
featuring similar subjects::1.58496250072
shows specific examples::1.58496250072
feeling and valuing::1.58496250072
documents that fall::1.58496250072
instance a discussion::1.58496250072
featured in document::1.58496250072
consist of information::1.58496250072
documents was presented::1.58496250072
subtopic being applied::1.58496250072
identification of concept::1.58496250072
specific feature score::1.58496250072
content they share::1.58496250072
keyword or keyphrase::1.58496250072
metric for wikipedia::1.58496250072
zealand computer science::1.58496250072
concept is insufficiently::1.58496250072
compare our system::1.58496250072
application and elaboration::1.58496250072
concept linked lists::1.58496250072
background or subtopics::1.58496250072
strong continuation relation::1.58496250072
give formal definitions::1.58496250072
measure also identifies::1.58496250072
document pairs balanced::1.58496250072
important in helping::1.58496250072
standard data sets::1.58496250072
models in collaborative::1.58496250072
constitutes our relatedness::1.58496250072
guidance to users::1.58496250072
analyzes the statistical::1.58496250072
document was provided::1.58496250072
feature in information::1.58496250072
item similarity types::1.58496250072
personalised video retrieval::1.58496250072
applying the bayes::1.58496250072
documents are related::1.58496250072
text document clustering::1.58496250072
discussion on tower::1.58496250072
truth actually prefer::1.58496250072
-sp an value::1.58496250072
ieee international conference::1.58496250072
scientific research publishing::1.58496250072
alue = log2::1.58496250072
elaboration average precision::1.58496250072
content and flow::1.58496250072
presented that consist::1.58496250072
exhibit some level::1.58496250072
documents are presented::1.58496250072
identification of additional::1.58496250072
relationships between concepts::1.58496250072
similarity of common::1.58496250072
varied data sets::1.58496250072
arbitrarily by making::1.58496250072
straightforward to train::1.58496250072
frequencies or tf-idfs::1.58496250072
identify inter-document relationships::1.58496250072
mit open courseware::1.58496250072
instance a lecture::1.58496250072
higher and wider::1.58496250072
digital library scenario::1.58496250072
sri ananda seelan1::1.58496250072
semantic relatedness metric::1.58496250072
minimum required d-span::1.58496250072
relatedness between scientific::1.58496250072
enable the learner::1.58496250072
degree of importance::1.58496250072
interested in determining::1.58496250072
person seeking information::1.58496250072
technological document repository::1.58496250072
compare our results::1.58496250072
document as described::1.58496250072
identifies the relatedness::1.58496250072
visualisation with xfind::1.58496250072
provide vidhya balasubramanian::1.58496250072
tf-idf c-value d-span::1.58496250072
content identifying patterns::1.58496250072
good continuing document::1.58496250072
discuss base patterns::1.58496250072
theses and videos::1.58496250072
naive bayes classifier::1.58496250072
documents is shown::1.58496250072
related work section::1.58496250072
based on distinct::1.58496250072
medium to high::1.58496250072
results for sample::1.58496250072
c-value or term::1.58496250072
survey by browsing::1.58496250072
probability of relevance::1.58496250072
smaller sample sets::1.58496250072
formalize different classes::1.58496250072
aid the users::1.58496250072
extensive experimental results::1.58496250072
type of indirect::1.58496250072
applications and elaborations::1.58496250072
learning functional languages::1.58496250072
create ground truth::1.58496250072
domain or sub::1.58496250072
model in order::1.58496250072
based on wikipedia::1.58496250072
exhibiting this relation::1.58496250072
describing extensive experimental::1.58496250072
characterized by specific::1.58496250072
document relatedness score::1.58496250072
technique to automatically::1.58496250072
defined in balagopalan::1.58496250072
represents the topic::1.58496250072
estimate the likelihood::1.58496250072
stop word removal::1.58496250072
application average user::1.58496250072
relationship maybe considered::1.58496250072
implementation of birch::1.58496250072
motivates the presence::1.58496250072
analyze the performance::1.58496250072
identifying additional document::1.58496250072
relationship is weak::1.58496250072
shown the results::1.58496250072
structured text documents::1.58496250072
wikipedia hyperlinks gouws::1.58496250072
infer concept level::1.58496250072
quantify different types::1.58496250072
reducing the noise::1.58496250072
tf-idf vs d-span::1.58496250072
consensus the document::1.58496250072
classification and clustering::1.58496250072
approach where user::1.58496250072
types of semantic::1.58496250072
narendranath vijayakumar1 vidhya::1.58496250072
clustered after points::1.58496250072
right continuing table::1.58496250072
occur between documents::1.58496250072
plenty of models::1.58496250072
subset of documents::1.58496250072
lsa is defined::1.58496250072
c-value over tf-idf::1.58496250072
provide better document::1.58496250072
factors into account::1.58496250072
springer science+business media::1.58496250072
motivate a definition::1.58496250072
statistical patterns exhibited::1.58496250072
ontologybased information retrieval::1.58496250072
documents was limited::1.58496250072
covered multiple document::1.58496250072
metrics with content-based::1.58496250072
jaccard similarity coefficients::1.58496250072
free grammar quick::1.58496250072
society for information::1.58496250072
solve the problem::1.58496250072
feature a semantic::1.58496250072
discussed our inter-document::1.58496250072
implementation and elaboration::1.58496250072
ananda seelan1 narendranath::1.58496250072
relationship between two::1.58496250072
provide such document::1.58496250072
relatedness continuity elaboration::1.58496250072
test our measures::1.58496250072
model for identifying::1.58496250072
title of document::1.58496250072
document gets benefited::1.58496250072
nmi were calculated::1.58496250072
measures like c-value::1.58496250072
taxonomy of science::1.58496250072
provide useful directions::1.58496250072
argued that continuation::1.58496250072
quantifies the relevance::1.58496250072
explicit user ratings::1.58496250072
discussion do affect::1.58496250072
set of occurrences::1.58496250072
c-value was helpful::1.58496250072
case of elaboration::1.58496250072
wikipedia document corpus::1.58496250072
design novel applications::1.58496250072
included document pairs::1.58496250072
repository of technical::1.58496250072
methods to test::1.58496250072
sixth new zealand::1.58496250072
similarity between short::1.58496250072
simple document browser::1.58496250072
user to browse::1.58496250072
number of technical::1.58496250072
two documents means::1.58496250072
pairs were clustered::1.58496250072
identifying the characteristic::1.58496250072
find the degree::1.58496250072
count the difference::1.58496250072
child quick sort::1.58496250072
requirements for evaluating::1.58496250072
information and learning::1.58496250072
application average precision::1.58496250072
kinds of difficulties::1.58496250072
share similar background::1.58496250072
vijayakumar1 vidhya balasubramanian1::1.58496250072
natural language processing::1.58496250072
choose to create::1.58496250072
synonymy and polysemy::1.58496250072
exhibit these types::1.58496250072
morgan kaufmann publishers::1.58496250072
retrieval digital libraries::1.58496250072
relevance distancea stable::1.58496250072
pairs will feature::1.58496250072
addressing this problem::1.58496250072
collected user ratings::1.58496250072
processing to find::1.58496250072
context and relevance::1.58496250072
extraction and pos::1.58496250072
original data set::1.58496250072
taking term distribution::1.58496250072
context of usage::1.58496250072
defined in section::1.58496250072
form the topic::1.58496250072
represents a starting::1.58496250072
augment these patterns::1.58496250072
similarity and relatedness::1.58496250072
background topic term::1.58496250072
single continuous flow::1.58496250072
trend of higher::1.58496250072
eliminating document pairs::1.58496250072
lecture on queues::1.58496250072
ratings were table::1.58496250072
hanoi applies recursion::1.58496250072
suggestions and meta-data::1.58496250072
result for nxn::1.58496250072
graph-based or knowledge-based::1.58496250072
continuation and elaboration::1.58496250072
documents that hold::1.58496250072
continuity elaboration application::1.58496250072
maximum margin classifier::1.58496250072
extracted after common::1.58496250072
find the similarity::1.58496250072
making relevance decisions::1.58496250072
grammar quick sort::1.58496250072
document an automated::1.58496250072
suggestions of related::1.58496250072
introduced elaboration measure::1.58496250072
mccormack and yager::1.58496250072
normalized compression distance::1.58496250072
domain-specific keyphrase extraction::1.58496250072
extended to identify::1.58496250072
group-based trust models::1.58496250072
conclude in section::1.58496250072
series and parallel::1.58496250072
inter-document semantic relationships::1.58496250072
application or elaboration::1.58496250072
elaboration positive cdiff::1.58496250072
recognition of multi-word::1.58496250072
infrequently as part::1.58496250072
ground truth creation::1.58496250072
pairs of documents::1.58496250072
making a histogram::1.58496250072
type of queries::1.58496250072
term or phrase::1.58496250072
previously introduced elaboration::1.58496250072
individually and privately::1.58496250072
desirable to infer::1.58496250072
phrases to develop::1.58496250072
making a literature::1.58496250072
characterize the degree::1.58496250072
automated system modeled::1.58496250072
identifying similar documents::1.58496250072
behavior of topic::1.58496250072
acm sigmod record::1.58496250072
patterns that characterize::1.58496250072
document graph linking::1.58496250072
spline interpolation hash::1.58496250072
weighting cosine index::1.58496250072
define each type::1.58496250072
truth creation process::1.58496250072
dsim or cdiff::1.58496250072
additional document relationships::1.58496250072
type of relation::1.58496250072
scores for document::1.58496250072
identify other relationships::1.58496250072
degree of similarity::1.58496250072
make the measures::1.58496250072
documents and lead::1.58496250072
moderate d-span background::1.58496250072
relatedness using distributional::1.58496250072
identifying semantic relationships::1.58496250072
set of concepts::1.58496250072
document for giving::1.58496250072
aggregate d-span similarity::1.58496250072
number of document::1.58496250072
identifying semantic relatedness::1.58496250072
ground truth includes::1.58496250072
effect of terms::1.58496250072
evidence for elaboration::1.58496250072
definition of topic::1.58496250072
technical documents show::1.58496250072
syst similarity measures::1.58496250072
boost the effect::1.58496250072
d-span similarity patterns::1.58496250072
terms with similar::1.58496250072
experts who generated::1.58496250072
provide scores based::1.58496250072
c-value for common::1.58496250072
decide what documents::1.58496250072
evaluation and development::1.58496250072
higher relevance defines::1.58496250072
prototype system works::1.58496250072
works like huang::1.58496250072
domains like electronics::1.58496250072
argued by denning::1.58496250072
electronics as shown::1.58496250072
weighting for comparison::1.58496250072
order to identify::1.58496250072
improved by taking::1.58496250072
chosen data set::1.58496250072
common topic terms::1.58496250072
content-based recommender applications::1.58496250072
feature based filter::1.58496250072
ground truth generation::1.58496250072
validated in section::1.58496250072
gabrilovich and markovitch::1.58496250072
approach for modeling::1.58496250072
characterize the relationships::1.58496250072
learner s perspective::1.58496250072
ongoing to determine::1.58496250072
left child quick::1.58496250072
identifying the usage::1.58496250072
widely a term::1.58496250072
documents as discussed::1.58496250072
helps the user::1.58496250072
study on similarity::1.58496250072
lists some types::1.58496250072
bean and green::1.58496250072
approach that analyzes::1.58496250072
capture document relationships::1.58496250072
imagining and creating::1.58496250072
represents a `continuation::1.58496250072
|ia | dispersion::1.58496250072
rafi and shaikh::1.58496250072
including common terms::1.58496250072
potentially help identify::1.58496250072
continuation average precision::1.58496250072
explore and discover::1.58496250072
f-score normalized::1.0
extensive experimentation::1.0
c-value proves::1.0
document based::1.0
documents means::1.0
computer architecture::1.0
enhanced learning::1.0
identify similarity::1.0
false positives::1.0
typical scientific::1.0
examples shown::1.0
relationships identified::1.0
bottom-left cluster::1.0
identifying feature::1.0
weighting feature::1.0
`standard deviation::1.0
model proposed::1.0
taking term::1.0
hanoi applies::1.0
vidhya balasubramanian1::1.0
provide suggestions::1.0
relatedness category::1.0
helps counteract::1.0
learning science::1.0
child quick::1.0
consuming process::1.0
syst similarity::1.0
involve computing::1.0
search result::1.0
determined based::1.0
feature values::1.0
two approaches::1.0
right cluster::1.0
proper justification::1.0
section introduces::1.0
video lectures::1.0
share similar::1.0
keywords relatedness::1.0
arbitrarily lowered::1.0
educational media::1.0
score patterns::1.0
vijayakumar1 vidhya::1.0
length |ta::1.0
greedy algorithms::1.0
distinct statistical::1.0
work relatedness::1.0
research publishing::1.0
suggestions based::1.0
muralikumar1 sri::1.0
document corpus::1.0
first identify::1.0
applying document::1.0
recent corpus-based::1.0
elaboration average::1.0
jeyavaishnavi muralikumar1::1.0
relevance defines::1.0
system modeled::1.0
research requirements::1.0
core topic::1.0
automatic keyphrase::1.0
features topics::1.0
normalized compression::1.0
important measure::1.0
user profiling::1.0
out results::1.0
relatedness continuity::1.0
d-span measure::1.0
measure described::1.0
data clustering::1.0
high distribution::1.0
document vectors::1.0
syst information::1.0
d-span d-span::1.0
continuing table::1.0
application estimated::1.0
dominating relationship::1.0
domain-specific keyphrase::1.0
algorithmic complexity::1.0
tf-idf term::1.0
elaboration table::1.0
users ground::1.0
gathering information::1.0
traversal cubic::1.0
minimum required::1.0
programming languages::1.0
term topic::1.0
library scenario::1.0
scientific research::1.0
two aspects::1.0
dramatically improves::1.0
covered multiple::1.0
28th annual::1.0
lecture videos::1.0
formally analyze::1.0
correspondingly answer::1.0
concepts based::1.0
terms present::1.0
hyperlinks gouws::1.0
empirically determined::1.0
clustering method::1.0
information visualization::1.0
potential continuation::1.0
experimental study::1.0
external sources::1.0
hash functions::1.0
multilevel indexing::1.0
learning functional::1.0
lsa account::1.0
right dataset::1.0
precision score::1.0
sort trees::1.0
larger n-grams::1.0
scores based::1.0
implementation perspective::1.0
higher value::1.0
find similarity::1.0
amrita vishwa::1.0
earth mover::1.0
application relationship::1.0
inter-document relatedness::1.0
defining types::1.0
word removal::1.0
nested collocations::1.0
filtering involve::1.0
functional languages::1.0
continuation document::1.0
decimal scaled::1.0
defined relatedness::1.0
seeking information::1.0
concept helps::1.0
relevance decisions::1.0
shows recommended::1.0
original data::1.0
semantic aspects::1.0
generating graphs::1.0
maximum margin::1.0
document play::1.0
processing multilevel::1.0
previously introduced::1.0
expert user::1.0
relationship helps::1.0
logic-based approach::1.0
ratings aggregated::1.0
spread uniformly::1.0
characterizing continuation::1.0
features means::1.0
semantic knowledge::1.0
shows specific::1.0
technological document::1.0
content-based recommender::1.0
varying context::1.0
linking research::1.0
pearson coefficient::1.0
type helps::1.0
prominently i.e::1.0
personalised video::1.0
work focuses::1.0
tables queue::1.0
methodology serves::1.0
moderate tf-idf::1.0
regular intervals::1.0
channelized series::1.0
query refinement::1.0
quantifying semantic::1.0
curves query::1.0
two pieces::1.0
graph based::1.0
results shown::1.0
determined arbitrarily::1.0
graph shows::1.0
logical level::1.0
recommended continuations::1.0
scaled scores::1.0
identify interesting::1.0
insufficiently described::1.0
rank suggestions::1.0
education literature::1.0
normalized mutual::1.0
-sp an1::1.0
-sp an2::1.0
multiple document::1.0
aggregate dsim::1.0
-sp ann::1.0
model defines::1.0
link analysis::1.0
lsa results::1.0
generalized search::1.0
processing document::1.0
retrieval digital::1.0
item similarity::1.0
quantifying application::1.0
good d-span::1.0
top-left cluster::1.0
low dsim::1.0
experience remains::1.0
technical documents::1.0
relatedness presents::1.0
balasubramanian1 received::1.0
briefly mentions::1.0
morgan kaufmann::1.0
two methods::1.0
constant factor::1.0
measure serves::1.0
strong continuation::1.0
learning grammar::1.0
yager model::1.0
patterns play::1.0
unstructured text::1.0
group arrived::1.0
pattern represented::1.0
common grams::1.0
d-span rank::1.0
uncertain expertise::1.0
main theme::1.0
data set3::1.0
data set2::1.0
readily calculated::1.0
presents method::1.0
mentioned earlier::1.0
statistical modeling::1.0
computing similarity::1.0
association relations::1.0
relation scores::1.0
short snippets::1.0
high recall::1.0
singular value::1.0
root node::1.0
two basic::1.0
create datasets::1.0
identifying similarity::1.0
relatedness characterized::1.0
trees document::1.0
main concept::1.0
provide ranked::1.0
vectors representing::1.0
recommender applications::1.0
implicit feedback::1.0
included document::1.0
introduce measures::1.0
educational content::1.0
user experience::1.0
involve presenting::1.0
automatic recognition::1.0
lower d-span::1.0
parallel hash::1.0
sets represented::1.0
manually created::1.0
features two::1.0
list root::1.0
quantifying types::1.0
high frequency::1.0
sufficient knowledge::1.0
feature scores::1.0
truth creation::1.0
person seeking::1.0
equivalent scope::1.0
independent users::1.0
target documents::1.0
libraries jeyavaishnavi::1.0
document repository::1.0
electrical engineering::1.0
science teacher::1.0
term weights::1.0
reliable measures::1.0
universal hashing::1.0
features extensive::1.0
concept-based document::1.0
domain knowledge::1.0
corpus-based measure::1.0
calculated balanced::1.0
international workshop::1.0
content similarity::1.0
relation data::1.0
identifies types::1.0
group-based trust::1.0
programming specific::1.0
bring out::1.0
including common::1.0
documents tested::1.0
larger terms::1.0
acm sigir::1.0
narendranath vijayakumar1::1.0
core content::1.0
interpreting tf-idf::1.0
fundamental measures::1.0
chosen subset::1.0
efficient data::1.0
directly relate::1.0
patterns type::1.0
term-document matrix::1.0
knowledge based::1.0
contextual relevance::1.0
describe clustering::1.0
based filter::1.0
wikipedia document::1.0
additional document::1.0
american society::1.0
point belonging::1.0
identify inter-document::1.0
literature proposed::1.0
remaining dsim::1.0
mentioned features::1.0
good candidates::1.0
common pre-processing::1.0
evaluation based::1.0
right document::1.0
provide services::1.0
relation helps::1.0
candidate phrases::1.0
first state::1.0
relationships automatically::1.0
exhibit higher::1.0
expert opinion::1.0
stronger instance::1.0
include semantic::1.0
types serve::1.0
applied computing::1.0
term frequencies::1.0
learning syntax::1.0
interpolation hash::1.0
start point::1.0
concept defined::1.0
identifying additional::1.0
audio lectures::1.0
world wide::1.0
science research::1.0
quantifying elaboration::1.0
characterization constitutes::1.0
15th annual::1.0
trust models::1.0
experimentally determined::1.0
applies concepts::1.0
address logical::1.0
cubic spline::1.0
ieee international::1.0
comprehensive view::1.0
mentions linked::1.0
necessarily make::1.0
feature common::1.0
simple document::1.0
syntax pointers::1.0
prefer applications::1.0
ananda seelan1::1.0
documents featuring::1.0
graph linking::1.0
directly infer::1.0
nmi value::1.0
rating type::1.0
detailed insight::1.0
stop word::1.0
relatedness metric::1.0
work section::1.0
capacitor dictionaries::1.0
closely related::1.0
content identifying::1.0
additional patterns::1.0
relatedness based::1.0
document formats::1.0
dsim negative::1.0
bayesian probabilities::1.0
suggested work::1.0
widely studied::1.0
statistical approach::1.0
document data::1.0
weighting cosine::1.0
base address::1.0
application document::1.0
collected user::1.0
single continuous::1.0
node left::1.0
high-level applications::1.0
set2 continuation::1.0
16th conference::1.0
studying patterns::1.0
introduced elaboration::1.0
high ranks::1.0
commonly observed::1.0
aspects i.e::1.0
tables elaboration::1.0
measures based::1.0
zealand computer::1.0
query type::1.0
categorize terms::1.0
application data::1.0
document browser::1.0
level classroom::1.0
knowledge sources::1.0
comprehensive approach::1.0
directly corresponds::1.0
syst frantzi::1.0
modeling inter-document::1.0
scientific publications::1.0
classroom lectures::1.0
longer candidate::1.0
scholarly articles::1.0
larger subject::1.0
formally define::1.0
measure quantifies::1.0
intended measures::1.0
created data::1.0
language processing::1.0
elaboration relationship::1.0
articles related::1.0
large databases::1.0
work represents::1.0
acm transactions::1.0
probability function::1.0
elaboration equation::1.0
documents demonstrate::1.0
information search::1.0
directly opt::1.0
conceivable relationship::1.0
elaborated term::1.0
fundamental relation::1.0
creation process::1.0
context free::1.0
specific relationships::1.0
ideal subjects::1.0
learning context::1.0
terms influencing::1.0
define d-span::1.0
relation exhibited::1.0
recall values::1.0
mutual information::1.0
media files::1.0
learning material::1.0
topic featured::1.0
logical sequences::1.0
set3 continuation::1.0
propositional logic::1.0
context-based relatedness::1.0
average user::1.0
inquisitive user::1.0
model based::1.0
c-values lower::1.0
common concepts::1.0
wikipedia concepts::1.0
low d-spans::1.0
requires concepts::1.0
explicit ratings::1.0
specific contributions::1.0
amrita school::1.0
create ground::1.0
interest-based approaches::1.0
research student::1.0
international acm::1.0
semantic structure::1.0
wider occurrence::1.0
complementary cases::1.0
pointers logical::1.0
specific purposes::1.0
`double-ended queue::1.0
central theme::1.0
high tf-idf::1.0
relevance distancea::1.0
sort subtopic::1.0
syst terms::1.0
strongly related::1.0
measure based::1.0
semantic user::1.0
probabilistic model::1.0
done individually::1.0
approach results::1.0
quantifying continuation::1.0
additional observations::1.0
library recommendation::1.0
indirect application::1.0
major topic::1.0
terms denoting::1.0
left child::1.0
terms increasing::1.0
languages base::1.0
continuing document::1.0
continuation relationship::1.0
recommendations based::1.0
logical notation::1.0
supervised learning::1.0
measuring occurrence::1.0
lectures spanning::1.0
chosen independently::1.0
preliminary measure::1.0
elaboration positive::1.0
free grammar::1.0
documents show::1.0
important sources::1.0
wikipedia article::1.0
science+business media::1.0
min-max normalized::1.0
logical inference::1.0
sub domain::1.0
annual acm::1.0
experimental results::1.0
judged based::1.0
browsing experience::1.0
seelan1 narendranath::1.0
describing extensive::1.0
textual coherence::1.0
detailed explanation::1.0
identifying characteristics::1.0
aggregate d-span::1.0
conceptual document::1.0
applies recursion::1.0
easily estimate::1.0
eliminating document::1.0
ontologybased information::1.0
natural progression::1.0
discuss base::1.0
relevant terms::1.0
wikipedia-based explicit::1.0
established method::1.0
characterizing document::1.0
prominent concept::1.0
remains focused::1.0
terms supervised::1.0
dynamic programming::1.0
measuring factor::1.0
remains unsolved::1.0
amrita university::1.0
automated system::1.0
libraries statistical::1.0
described earlier::1.0
continuity elaboration::1.0
occurs infrequently::1.0
general trend::1.0
trees intro::1.0
wordcount dispersion::1.0
primarily related::1.0
role played::1.0
specific aspects::1.0
bayes rule::1.0
relatedness information::1.0
heterogeneous collection::1.0
learner motivates::1.0
making relevance::1.0
provide scores::1.0
category based::1.0
demonstrate considerable::1.0
identify features::1.0
candidate documents::1.0
kaufmann publishers::1.0
inverse-document frequency::1.0
exhibiting application::1.0
normalized relevance::1.0
rating process::1.0
relatedness modeling::1.0
retrieval systems::1.0
subject domain::1.0
meta-data independent::1.0
wikipedia hyperlinks::1.0
term distribution::1.0
similarity index::1.0
tf-idf values::1.0
margin classifier::1.0
considerable length::1.0
smaller sample::1.0
d-span background::1.0
extensively studied::1.0
approach works::1.0
natural language::1.0
document clustering::1.0
cosine measure::1.0
notation background::1.0
`circular queue::1.0
arxiv:1303.4087 schaefer::1.0
sri ananda::1.0
address mapping::1.0
first evaluate::1.0
background topics::1.0
final goal::1.0
effective filter::1.0
relative d-span::1.0
query document::1.0
document characteristics::1.0
classical probability::1.0
pattern medium::1.0
citation links::1.0
knowledge-based approach::1.0
relatedness correspondingly::1.0
international conference::1.0
initial term-document::1.0
clustering based::1.0
spline interpolation::1.0
document recommendations::1.0
graduate level::1.0
estimating similarity::1.0
distancea stable::1.0
high document::1.0
interesting directions::1.0
1.3x boost::1.0
dictionaries stack::1.0
video transcripts::1.0
c-value d-span::1.0
relatedness score::1.0
article defines::1.0
created document::1.0
explained adequately::1.0
inter-document relationships::1.0
identified patterns::1.0
capture document::1.0
publication recommendations::1.0
document tf-idf::1.0
directly correlates::1.0
similarity patterns::1.0
values higher::1.0
vidhya balasubramanian::1.0
feature based::1.0
important factor::1.0
representing tf-idf::1.0
dictionaries trees::1.0
virtual memory::1.0
primary requirements::1.0
focused manner::1.0
exploration process::1.0
learner overcome::1.0
stack document::1.0
expected results::1.0
structured text::1.0
documents relate::1.0
recommendation results::1.0
references mit::1.0
explicit user::1.0
news recommendation::1.0
similarity relationship::1.0
similar patterns::1.0
modeling document::1.0
starting point::1.0
syst doi::1.0
negative cdiff::1.0
highest c-value::1.0
discourse processes::1.0
define document::1.0
common topic::1.0
potential document::1.0
handling faculty::1.0
video lecture::1.0
measures defined::1.0
wikipedia risks::1.0
sets development::1.0
similar documents::1.0
documents delve::1.0
subjects covered::1.0
comprehensively defined::1.0
dsim value::1.0
term usage::1.0
equal extent::1.0
common content::1.0
mechanical engineering::1.0
serve learning::1.0
conditional probability::1.0
including articles::1.0
97th percentile::1.0
featuring similar::1.0
comprehensive understanding::1.0
continuation average::1.0
experimentally::0.0
typical scientific technological document::0.0
expanded::0.0
ponzetto::0.0
sigmod record::0.0
increasing::0.0
classification::0.0
explained::0.0
brought::0.0
browse::0.0
brings::0.0
hold::0.0
application implementation  directly::0.0
data point belonging::0.0
concepts::0.0
feature::0.0
documents have absolutely::0.0
machine::0.0
methodology::0.0
symposium::0.0
classify::0.0
types::0.0
effective::0.0
feedback::0.0
fig::0.0
represents::0.0
series::0.0
document relatedness correspondingly::0.0
estimate::0.0
similarly::0.0
needed::0.0
intell::0.0
tree::0.0
feeling::0.0
recommender::0.0
recommended::0.0
causing::0.0
collaborative filtering involve::0.0
transactions::0.0
organization::0.0
theme::0.0
livny::0.0
result::0.0
k.l::0.0
wikipedia::0.0
score::0.0
conceptual::0.0
k.t::0.0
glasgow::0.0
extend::0.0
nature::0.0
extent::0.0
refinement::0.0
logic::0.0
chandrasekharan::0.0
extraction::0.0
hyperlinks::0.0
child::0.0
hoang::0.0
played::0.0
characterize::0.0
methods involving::0.0
inverse-document::0.0
-sp::0.0
academic::0.0
alue::0.0
pairs with feature::0.0
c.s.g::0.0
disagreement::0.0
indicative::0.0
clustered::0.0
unique::0.0
right::0.0
communications::0.0
indication::0.0
an2::0.0
gabrilovich::0.0
support::0.0
tf-idf for measuring::0.0
proves::0.0
`exploring  and `using::0.0
role::0.0
intend::0.0
nxn::0.0
learning a concept-based::0.0
chain::0.0
choice::0.0
knapsack::0.0
leave::0.0
occurrence::0.0
current::0.0
totalling::0.0
understanding::0.0
address::0.0
d-span::0.0
commonly::0.0
queue::0.0
prefer::0.0
logical::0.0
inverses::0.0
working::0.0
positive::0.0
scope::0.0
theoretical::0.0
organized::0.0
values::0.0
data::0.0
natural::0.0
definitions::0.0
increasing order linked::0.0
texttiling::0.0
c-values::0.0
constitutes::0.0
patterns within documents::0.0
pairs j intell::0.0
revised::0.0
mima::0.0
kaufmann::0.0
programming::0.0
nested::0.0
textual::0.0
open::0.0
structured::0.0
structures::0.0
representing::0.0
future::0.0
addressing::0.0
opposite::0.0
vishwa::0.0
average::0.0
mit-ocw::0.0
provided through suggestions::0.0
`queue::0.0
16th::0.0
concentrate::0.0
functions  is continued::0.0
cosine::0.0
combined::0.0
prototype::0.0
enable::0.0
observe::0.0
engineering::0.0
technology::0.0
binary::0.0
mccormack::0.0
rest::0.0
prominently::0.0
aspects::0.0
world::0.0
queues::0.0
conditional::0.0
dimensions::0.0
semantically::0.0
schaefer::0.0
acm::0.0
technologies::0.0
detailed::0.0
graduate::0.0
sigmod::0.0
mechanical::0.0
original::0.0
dictionaries and hash::0.0
interpreting::0.0
elaboration and application::0.0
correlates::0.0
insufficiently::0.0
large::0.0
displays::0.0
section::0.0
method::0.0
contrast::0.0
hash::0.0
experience::0.0
infrequently::0.0
objectives::0.0
helps::0.0
tested::0.0
kld::0.0
keeping::0.0
science::0.0
evolved::0.0
stated::0.0
unbiased::0.0
sense::0.0
information::0.0
mapping::0.0
fundamental::0.0
geographic::0.0
paper::0.0
document from dataset::0.0
found::0.0
measurement::0.0
research::0.0
occurs::0.0
definition::0.0
pairs::0.0
exhibited::0.0
major::0.0
number::0.0
introduction::0.0
`knowing::0.0
sort trees trees::0.0
elaboration::0.0
relationship::0.0
determined::0.0
seelan1 narendranath vijayakumar1::0.0
types are chosen::0.0
generalized::0.0
play::0.0
range of domains::0.0
indicator::0.0
closely::0.0
15th::0.0
knowing::0.0
premises::0.0
improved::0.0
sense disambiguation::0.0
improves::0.0
corresponds::0.0
section details::0.0
publishing::0.0
citations::0.0
handling::0.0
uncertain::0.0
reliable::0.0
corpora::0.0
optimization::0.0
evaluating::0.0
formats::0.0
vol::0.0
resulting::0.0
consumers of scientific content::0.0
comprehensive::0.0
stack::0.0
recent::0.0
find answers::0.0
picks::0.0
person::0.0
scientific content identifying patterns::0.0
intrinsic term::0.0
relevance::0.0
inter-document::0.0
formal::0.0
consensus::0.0
continue::0.0
methods::0.0
lecture on query::0.0
metrics::0.0
computational::0.0
results of latent::0.0
nt directly opt::0.0
primarily::0.0
clustering::0.0
specifically::0.0
milne::0.0
link::0.0
considerable::0.0
defined::0.0
defines::0.0
estimation of bayesian::0.0
defined based::0.0
similarity or relatedness::0.0
results::0.0
illustrated::0.0
indicating::0.0
continued::0.0
categories::0.0
implying::0.0
video::0.0
index::0.0
group-based::0.0
led::0.0
gathered::0.0
consideration::0.0
technical::0.0
survey::0.0
opinion::0.0
makes::0.0
understanding  aspect::0.0
mover s distance::0.0
bottom-left::0.0
publications::0.0
fulfill::0.0
process::0.0
purposes::0.0
pieces::0.0
high::0.0
educational::0.0
singular::0.0
demonstrating::0.0
element::0.0
insight::0.0
chosen::0.0
outlines::0.0
nptel::0.0
truth::0.0
subset::0.0
doing::0.0
society::0.0
frequency::0.0
context measuring::0.0
matrix::0.0
greedy::0.0
topic representations::0.0
differing c-values::0.0
occurrences::0.0
ordering::0.0
system::0.0
false::0.0
documents::0.0
elaborations::0.0
studying::0.0
queue  and `double-ended::0.0
accuracy::0.0
stronger::0.0
k.f::0.0
prone to false::0.0
c-value defined::0.0
bring::0.0
identify connections::0.0
meant::0.0
means::0.0
relation data set1::0.0
ananda::0.0
bta::0.0
figures::0.0
conclude::0.0
distributional::0.0
coherence::0.0
graphics::0.0
dsim::0.0
set for evaluation::0.0
concordance::0.0
patterns::0.0
audio::0.0
web::0.0
ramakrishnan::0.0
set3 continuation elaboration::0.0
taking::0.0
identified::0.0
alue of common::0.0
recognition::0.0
biology::0.0
classified as exhibiting::0.0
automatic suggestions::0.0
stage::0.0
relatedness in scientific::0.0
function::0.0
lowered::0.0
count::0.0
compute::0.0
tower of hanoi::0.0
problem::0.0
contribute::0.0
scholarly::0.0
details::0.0
rule::0.0
established in section::0.0
desirable::0.0
expert estimation::0.0
average ratings::0.0
tagging::0.0
progression::0.0
vijayakumar1::0.0
established::0.0
consisting::0.0
obtained::0.0
items::0.0
study::0.0
browsing::0.0
topics or concepts::0.0
total::0.0
experimentation::0.0
clough::0.0
motivate::0.0
negative::0.0
springer::0.0
word::0.0
work::0.0
vidhya::0.0
india::0.0
aaai::0.0
provide::0.0
lai::0.0
earlier::0.0
green::0.0
repository of technical documents::0.0
order::0.0
innovative::0.0
document structures::0.0
classified::0.0
reasonable::0.0
classifier::0.0
techniques in digital::0.0
log2::0.0
effective in generating::0.0
terms with higher::0.0
detecting::0.0
certified::0.0
created::0.0
luong::0.0
implementation  directly correlates::0.0
scientificpapers::0.0
rated::0.0
observations::0.0
muralikumar1::0.0
target::0.0
disambiguation::0.0
manner::0.0
hogenboom::0.0
contents::0.0
strength::0.0
involving::0.0
khoo::0.0
calculated::0.0
quantifying::0.0
notion::0.0
nmi and f-score::0.0
visualisation::0.0
keywords::0.0
latent::0.0
implementation::0.0
guidance::0.0
coimbatore::0.0
explorations::0.0
pearson::0.0
user find::0.0
observed::0.0
discussions::0.0
techniques::0.0
terms::0.0
huang::0.0
metric for measuring::0.0
weight means::0.0
wider::0.0
engines::0.0
applied::0.0
applies::0.0
aid::0.0
characterizing::0.0
cont::0.0
independent::0.0
d-span subtopic::0.0
d.r::0.0
hand::0.0
similarity for common::0.0
scenario::0.0
relationships and applying::0.0
terms increasing order::0.0
visualization::0.0
similarities::0.0
spread::0.0
gonzalez-agirre::0.0
yager::0.0
values are shown::0.0
discover  information::0.0
repository::0.0
illustration::0.0
properties::0.0
scientific learning::0.0
relationship was determined::0.0
balanced::0.0
wan::0.0
compression::0.0
indicator of continuation::0.0
`wordcount::0.0
filtering involve user::0.0
concept-based::0.0
maximum::0.0
computing::0.0
abstract::0.0
paragraphs::0.0
evidence::0.0
expertise::0.0
channelized::0.0
graphs::0.0
interested::0.0
test::0.0
scores::0.0
helping a learner::0.0
concept::0.0
graph::0.0
zhang::0.0
presented::0.0
terms related::0.0
elaboration measure brings::0.0
satisfy::0.0
teacher::0.0
domains::0.0
inference::0.0
traditional recommendation::0.0
weighting::0.0
occur::0.0
discussion::0.0
scientific technological document::0.0
syst::0.0
j.c::0.0
similar extents::0.0
explicit::0.0
automatically::0.0
typical::0.0
topics or subtopics::0.0
statistical::0.0
ieee::0.0
uidis::0.0
introduce::0.0
measure results::0.0
discuss::0.0
wong::0.0
measuring relatedness::0.0
domain::0.0
nt any systems::0.0
counteract::0.0
captures three important::0.0
shown::0.0
reducing::0.0
shows::0.0
benefited::0.0
collaboration technologies::0.0
directly::0.0
indication that clustering::0.0
average nmi::0.0
eliminated::0.0
elementary feature::0.0
browser::0.0
denoting::0.0
successive::0.0
semantic similarity measure::0.0
ecai::0.0
pairwise relationship::0.0
typically::0.0
datasets and ground::0.0
sample feature::0.0
ground::0.0
ratio::0.0
title::0.0
acm sigir conference::0.0
base and compute::0.0
uncertainty in artificial::0.0
analyzes::0.0
article::0.0
measures by extensive::0.0
characterization::0.0
learning::0.0
relatedness::0.0
linguistic::0.0
external::0.0
overcome these kinds::0.0
product of term::0.0
metric::0.0
develop::0.0
media::0.0
document::0.0
semantic knowledge derived::0.0
validate::0.0
brings out results::0.0
similarity and tf-idf::0.0
densest::0.0
h.c::0.0
presented our experimental::0.0
models::0.0
sixth::0.0
equivalent::0.0
nmi::0.0
comparison::0.0
central::0.0
sri::0.0
supervised::0.0
intent::0.0
structures document::0.0
elementary::0.0
weight::0.0
assumed::0.0
start::0.0
low::0.0
library which typically::0.0
describe::0.0
mover::0.0
scientific technological::0.0
obtained results::0.0
repository that consists::0.0
mathematics::0.0
aletras::0.0
semantic::0.0
simple retrieval::0.0
users of digital::0.0
decide::0.0
recommendation model::0.0
snippets::0.0
consumers::0.0
learner::0.0
working irrespective::0.0
answers::0.0
i.h::0.0
information are met::0.0
i.e::0.0
strong::0.0
computational linguistics-volume::0.0
analyzing::0.0
takes::0.0
probabilities::0.0
unspecified number::0.0
detailed discussions::0.0
phrase::0.0
kahani::0.0
t.k::0.0
derived::0.0
libraries is provided::0.0
term weighting::0.0
taxonomy::0.0
large digital::0.0
systems::0.0
set1::0.0
motivated::0.0
motivates::0.0
decimal::0.0
moderate c-value::0.0
base::0.0
american::0.0
two types::0.0
probability::0.0
dominating::0.0
guidance for users::0.0
authors::0.0
minimum tf-idf::0.0
alongside::0.0
xfind::0.0
lie::0.0
lin::0.0
cts::0.0
physics::0.0
wikirelate ! computing::0.0
trees::0.0
international::0.0
exhibiting::0.0
boost::0.0
recommendations::0.0
terms has lead::0.0
relation between documents::0.0
wordcount::0.0
advatages::0.0
improved semantic::0.0
ranked::0.0
capelle::0.0
experimental::0.0
described::0.0
describes::0.0
generated based::0.0
collected::0.0
generating::0.0
transcripts::0.0
landauer::0.0
studied::0.0
coefficients are examples::0.0
interpolation::0.0
ratings::0.0
user::0.0
database::0.0
studies::0.0
distancea::0.0
liu::0.0
defining the continuation::0.0
remaining::0.0
evaluate::0.0
mathematical::0.0
learner browse::0.0
wikirelate::0.0
creation::0.0
r.e::0.0
similarity coefficients::0.0
describing::0.0
run::0.0
processing::0.0
d-span differences::0.0
propositional::0.0
`continuation::0.0
subtopics::0.0
terms to similar::0.0
probabilistic::0.0
heritage::0.0
utl::0.0
heterogeneous::0.0
similar::0.0
aluen::0.0
application::0.0
electrical::0.0
department::0.0
infer the underlying::0.0
independently::0.0
svd::0.0
required::0.0
alue2::0.0
alue1::0.0
frasincar::0.0
requires::0.0
analogize::0.0
unstructured::0.0
based on extensive::0.0
s.p::0.0
typical scientific technological::0.0
experiment::0.0
approaches for identifying::0.0
focuses::0.0
retrieve the related::0.0
fifteenth::0.0
focused::0.0
application implementation::0.0
e-learning repositories::0.0
remains::0.0
formally::0.0
averaged::0.0
meet::0.0
averages::0.0
flow is continuous::0.0
links::0.0
c-value is defined::0.0
sought::0.0
prominent topics::0.0
chitson::0.0
unsolved::0.0
measure of relevance::0.0
including::0.0
`application::0.0
mentioned::0.0
sets for judging::0.0
continuation in data::0.0
number of common::0.0
university::0.0
measure::0.0
related to background::0.0
applications::0.0
determining::0.0
relatedness using wikipedia::0.0
relations::0.0
final::0.0
prone::0.0
lists::0.0
correlate::0.0
providing::0.0
exhibit::0.0
continuation  type helps::0.0
p.w::0.0
instance::0.0
non-textual::0.0
lectures::0.0
knowledge derived::0.0
linguistics-volume::0.0
scientific technological document repository::0.0
intrinsic::0.0
proceedings::0.0
databases::0.0
high-level::0.0
libraries::0.0
usage of topic::0.0
documents that do nt::0.0
quantifies::0.0
processes::0.0
experiments::0.0
differs::0.0
computer::0.0
state::0.0
luk::0.0
importance::0.0
e-learning::0.0
distribution::0.0
corpus-based::0.0
denning::0.0
tf-idf::0.0
boost helps::0.0
tables  are spread::0.0
proposed system::0.0
addition::0.0
shaikh::0.0
terms of varying::0.0
contexts::0.0
involve user profiling::0.0
capture::0.0
generic::0.0
http::0.0
user interfaces::0.0
effect::0.0
concept described::0.0
modeled::0.0
based on topic representations::0.0
`continuation  relation::0.0
domain experts::0.0
sources::0.0
concepts helping::0.0
definitive::0.0
prominent::0.0
stevenson::0.0
dictionaries::0.0
library::0.0
broad::0.0
demonstrated::0.0
journal::0.0
information flow::0.0
involve user::0.0
retrieve::0.0
utility::0.0
additional::0.0
artificial intelligence::0.0
histogram::0.0
highest::0.0
document relation scores::0.0
piece::0.0
universal::0.0
education::0.0
functions::0.0
additionally::0.0
validation::0.0
libraries are fast::0.0
similarity::0.0
dynamic::0.0
consists::0.0
calculate::0.0
segments::0.0
presents::0.0
teaching::0.0
affect::0.0
serve more specific::0.0
c-values higher::0.0
zarrinkalam::0.0
implemented::0.0
coefficient::0.0
relationships::0.0
met::0.0
economics::0.0
elaborated::0.0
term-document::0.0
type::0.0
berlin::0.0
pre-processing::0.0
root::0.0
give::0.0
involve::0.0
answer::0.0
soroa::0.0
scientific and educational::0.0
replacing::0.0
patterns mentioned::0.0
sub-headings::0.0
personal::0.0
overcome::0.0
grammar::0.0
`rank::0.0
document ; similar::0.0
extract::0.0
quantify::0.0
content::0.0
tree traversal cubic::0.0
causing the background::0.0
relationship between stacks::0.0
features::0.0
featured::0.0
subtopic explained::0.0
distance::0.0
keyword::0.0
extracting::0.0
mind::0.0
mint::0.0
learning or research::0.0
provide detailed::0.0
regular::0.0
zealand::0.0
doi::0.0
points::0.0
syntax::0.0
point belonging table::0.0
feature high d-span::0.0
judged::0.0
stop::0.0
scientific content::0.0
documents categorized::0.0
feedback and semantic::0.0
architecture::0.0
reference::0.0
decided::0.0
subject::0.0
similarity between items::0.0
artificial::0.0
simplest::0.0
understanding  learning::0.0
modeling::0.0
suggested::0.0
increasing order::0.0
uncertainty::0.0
contribution::0.0
inquisitive::0.0
basis::0.0
basic::0.0
tf-idfs::0.0
infer their semantic::0.0
make::0.0
potentially::0.0
differing::0.0
left::0.0
identify::0.0
human::0.0
candidate::0.0
opt::0.0
background::0.0
deal::0.0
statistic::0.0
distribution into account::0.0
introduction automated::0.0
acm sigmod::0.0
identified features::0.0
initial::0.0
influencing::0.0
pairs evaluated::0.0
relatedness measures based::0.0
form::0.0
overburden::0.0
techniques identify::0.0
video transcripts or documents::0.0
generally::0.0
digital::0.0
jaccard::0.0
hofmann::0.0
fifteenth conference::0.0
data set3 continuation::0.0
progression of topics::0.0
depend::0.0
technique::0.0
finally::0.0
wordnet-based approaches::0.0
ictee::0.0
item::0.0
uniformly and widely::0.0
talked::0.0
biology and computer::0.0
jocch::0.0
`elaboration  or `application::0.0
patterns for common::0.0
focusing::0.0
nt directly::0.0
rule-based::0.0
direct his study::0.0
sake::0.0
validates::0.0
polysemy::0.0
making::0.0
types elaboration::0.0
sample::0.0
spanning::0.0
validated::0.0
map::0.0
designed::0.0
vidyapeetham::0.0
talk::0.0
lsa::0.0
argued::0.0
group::0.0
interesting::0.0
main::0.0
imagining and feeling::0.0
effectively extract::0.0
terms with differing::0.0
repositories::0.0
categories are continuation::0.0
difference established::0.0
bayes::0.0
language::0.0
sabol::0.0
first::0.0
coefficients::0.0
international acm sigir::0.0
type application::0.0
gathering::0.0
applications for digital::0.0
topics::0.0
normalized mutual information::0.0
subtopic::0.0
efficient::0.0
potential::0.0
performance::0.0
`using::0.0
specific examples::0.0
pair::0.0
continuation scores::0.0
techniques effectively::0.0
terms binary search::0.0
rating::0.0
show::0.0
kwok::0.0
index is applied::0.0
threshold::0.0
data intensive::0.0
language technologies::0.0
extensive evaluation::0.0
ranking::0.0
identify the dominating::0.0
measuring relevance::0.0
median::0.0
relative::0.0
eliminating::0.0
access in digital::0.0
capable::0.0
directly infer concept::0.0
workshop::0.0
judging::0.0
stellenbosch::0.0
journal of computer::0.0
traversal::0.0
bayesian::0.0
mit-ocw featuring::0.0
formal definitions::0.0
analyzing the data::0.0
profiles::0.0
narendranath::0.0
ongoing::0.0
promising::0.0
investigating::0.0
margin::0.0
characteristics::0.0
cluster::0.0
wordnet::0.0
pas::0.0
extended::0.0
ontologybased::0.0
pairs exhibiting application::0.0
solve::0.0
keyphrase::0.0
tf-idf term weights::0.0
aspect::0.0
extensive::0.0
mathematical definition::0.0
identifying::0.0
serves::0.0
matching::0.0
extensively::0.0
base address logical::0.0
moderate::0.0
measuring::0.0
queues have similar::0.0
applies the main::0.0
classes of common::0.0
references::0.0
analyze the continuation::0.0
science+business::0.0
spline::0.0
machine learning syntax::0.0
structure::0.0
expert s classification::0.0
implementation  directly::0.0
science and engineering::0.0
academic documents is hard::0.0
determined using domain::0.0
videos::0.0
citation::0.0
general::0.0
examine::0.0
sets similar::0.0
involve hash::0.0
weights::0.0
balanced f-score normalized::0.0
important::0.0
approach for identifying::0.0
list root node::0.0
starting::0.0
expressions::0.0
keyphrases::0.0
lsa and probabilistic::0.0
ranked suggestions::0.0
intensive systems::0.0
domain-specific::0.0
witten::0.0
fall::0.0
difference::0.0
sets had data::0.0
scores for topic::0.0
elaboration score::0.0
library recommendation engines::0.0
perspective::0.0
terms or phrases::0.0
f-score::0.0
capacitor::0.0
standard::0.0
search::0.0
mentions::0.0
readily::0.0
rafi::0.0
distinct::0.0
user interest-based::0.0
destination::0.0
two::0.0
content-based::0.0
varying::0.0
c-value of terms::0.0
recall::0.0
compare::0.0
share::0.0
statistical term::0.0
minimum::0.0
maps::0.0
faculty::0.0
learner understand::0.0
retrieval::0.0
hypertext::0.0
cultural items::0.0
naacl::0.0
peng::0.0
continuations::0.0
good::0.0
seeking::0.0
selected subset::0.0
97th::0.0
defined similarity::0.0
association::0.0
easily::0.0
|ta::0.0
set is broad::0.0
birch clustering::0.0
earth mover s distance::0.0
d-spans but high::0.0
hard::0.0
idea::0.0
categorize::0.0
addressing the semantic::0.0
multiple topics::0.0
hand data::0.0
done::0.0
parnas::0.0
varying relevance::0.0
international journal::0.0
part::0.0
velikhov::0.0
gouws::0.0
mit open::0.0
provide vidhya::0.0
headings::0.0
categorized::0.0
paths::0.0
built::0.0
majority::0.0
build::0.0
diversified::0.0
significant::0.0
services::0.0
frantzi::0.0
diversified chain::0.0
|ia::0.0
relation::0.0
networks::0.0
distributed::0.0
patterns between documents::0.0
min-max::0.0
notation::0.0
pairs balanced::0.0
common::0.0
tended::0.0
nptel that features::0.0
expert::0.0
foltz::0.0
good indicator::0.0
complementary::0.0
interfaces::0.0
sigir::0.0
sample source::0.0
premise::0.0
annual::0.0
point::0.0
simple::0.0
coefficient and kld::0.0
base our continuation::0.0
simply::0.0
consuming::0.0
create::0.0
made some exploratory::0.0
ensured::0.0
understand::0.0
knowledge is essential::0.0
hopfgartner::0.0
nt inverses::0.0
approaches based::0.0
discourse::0.0
development::0.0
compare the obtained::0.0
aggregate::0.0
ratings are presented::0.0
context-based::0.0
kintsch::0.0
tois::0.0
visualizations::0.0
chemistry::0.0
media new york::0.0
n-gram::0.0
source::0.0
subjects::0.0
hypertext are limited::0.0
traversal cubic spline::0.0
judgement::0.0
selected document::0.0
addressed::0.0
absolutely::0.0
examples::0.0
scale::0.0
recommendation engines::0.0
give formal::0.0
continuing::0.0
subject domains::0.0
readability::0.0
queue scaled::0.0
association for information::0.0
similarity and high::0.0
multilevel::0.0
model that identifies::0.0
evaluate the large::0.0
exploration::0.0
constant::0.0
flow::0.0
single::0.0
system returns::0.0
direction for future::0.0
functionality::0.0
search machine::0.0
aggregated::0.0
implies::0.0
presenting::0.0
difficult to create::0.0
rule-based classifier::0.0
system the architecture::0.0
query::0.0
meta-data::0.0
intensive::0.0
tree traversal::0.0
generating potential::0.0
scientific::0.0
giving::0.0
access::0.0
justification::0.0
human language::0.0
number of terms::0.0
implicit::0.0
weinstein::0.0
find any similar::0.0
user profiles::0.0
terms exhibiting::0.0
flow of concepts::0.0
distancea stable metric::0.0
cb.amrita.edu::0.0
privately::0.0
continue a subtopic::0.0
train::0.0
normalized::0.0
account::0.0
effectively::0.0
feeling deal::0.0
varied::0.0
technologies and systems::0.0
collection::0.0
pieces of text::0.0
candidates for continuation::0.0
bing::0.0
bins::0.0
play a major::0.0
science education literature::0.0
suggestions to enable::0.0
machine learning context::0.0
greater::0.0
studying `` virtual::0.0
february::0.0
direct measure::0.0
bayes classifier::0.0
classify terms::0.0
identifies::0.0
non-textual features::0.0
semantic news::0.0
similarity search::0.0
belonging table::0.0
query-document::0.0
alfonseca::0.0
lecture::0.0
electronics::0.0
frank::0.0
approaches::0.0
kinds of common::0.0
likelihood::0.0
application an application::0.0
system works::0.0
filter based::0.0
unspecified::0.0
rigau::0.0
explanation::0.0
pointers::0.0
curves::0.0
mix::0.0
mit::0.0
preliminary::0.0
courseware::0.0
gather::0.0
1.3x::0.0
valuing::0.0
text::0.0
sigir conference::0.0
knowledge::0.0
bean::0.0
bead::0.0
areas::0.0
work and guidance::0.0
features extensive experimentation::0.0
limited to structured::0.0
database applications::0.0
national::0.0
browsing experience remains::0.0
enhanced::0.0
tf-idf means::0.0
pattern::0.0
difficulties::0.0
continuation  type::0.0
identified between lectures::0.0
equal::0.0
springer science+business::0.0
relevance distance::0.0
relevant::0.0
specifically gathered::0.0
define::0.0
wikipedia-based::0.0
greater likelihood::0.0
received::0.0
wider range::0.0
clusters::0.0
value::0.0
manually::0.0
turdakov::0.0
set2::0.0
set3::0.0
video retrieval::0.0
infer::0.0
elaboration application average::0.0
cubic::0.0
discover::0.0
observed that studying::0.0
sets::0.0
data sets development::0.0
underlying::0.0
based on texttiling::0.0
amrita::0.0
works::0.0
test documents::0.0
classical::0.0
recommendation::0.0
proper::0.0
esa::0.0
noise::0.0
introduces::0.0
introduced::0.0
functional::0.0
dataset::0.0
major role::0.0
gleaned::0.0
x.j::0.0
directions for information::0.0
researchers have defined::0.0
generated the ground::0.0
literature documents::0.0
query-document retrieval::0.0
elaboration  depend::0.0
quick sort subtopic::0.0
order linked::0.0
metric for computing::0.0
virtual::0.0
important aspects::0.0
helps a learner::0.0
multi-word::0.0
limited::0.0
jeyavaishnavi::0.0
continuation have tended::0.0
query processing multilevel::0.0
rise::0.0
school::0.0
graph-based::0.0
n-gram extraction::0.0
guidelines::0.0
direct::0.0
estimated::0.0
selected::0.0
liberty::0.0
wordnet-based::0.0
underlying relationship::0.0
represented::0.0
path::0.0
term in two::0.0
hanoi::0.0
y.x::0.0
naive::0.0
correspondingly::0.0
top-left::0.0
involving hypertext::0.0
wordnet and bing::0.0
guarantee::0.0
end::0.0
straightforward::0.0
multi-level::0.0
similarity among common::0.0
implies that common::0.0
parallel::0.0
complexity::0.0
algorithms::0.0
recursion::0.0
balasubramanian1::0.0
extents::0.0
c-value method::0.0
synonymy::0.0
exhibits::0.0
hienert::0.0
pairs exhibiting elaboration::0.0
wide web::0.0
defined relatedness measures::0.0
td-idf value::0.0
indicating a natural::0.0
measure working::0.0
feature multiple::0.0
annual acm symposium::0.0
resistor::0.0
influencing this relationship::0.0
academic documents::0.0
filter::0.0
researcher::0.0
expert judgement::0.0
primary::0.0
rank::0.0
pairs in video::0.0
top::0.0
automated guidance::0.0
corpus::0.0
multilevel indexing expressions::0.0
consists of advanced::0.0
serve::0.0
concept linked::0.0
extensive analysis::0.0
weight the d-span::0.0
classes::0.0
index method::0.0
learning science education::0.0
dsim negative cdiff::0.0
effectiveness::0.0
plenty::0.0
random::0.0
solutions::0.0
earth::0.0
aspects of scientific::0.0
continuity::0.0
research articles related::0.0
automatic::0.0
approach::0.0
weak::0.0
news::0.0
patterns in d-span::0.0
variance::0.0
terms that exhibit::0.0
trust::0.0
conference::0.0
similarity in term::0.0
expected::0.0
briefly covered::0.0
set2 continuation elaboration::0.0
shows some sample::0.0
dsim is high::0.0
shown in tables::0.0
experts::0.0
multi-word terms::0.0
data set1 continuation::0.0
model that serves::0.0
numerical::0.0
positives::0.0
rank documents::0.0
build further relatedness::0.0
clustering of nxn::0.0
proposed::0.0
acm symposium::0.0
technological::0.0
cultural::0.0
present a comprehensive::0.0
advanced::0.0
comprehensive set::0.0
specific::0.0
informative::0.0
word sense::0.0
indirect::0.0
ratings for results::0.0
huynh::0.0
feature vectors representing::0.0
core::0.0
respect to scientific::0.0
larger data::0.0
ensure::0.0
type between two::0.0
presence::0.0
agirre::0.0
application score pattern::0.0
rely::0.0
feeling deal with factors::0.0
vishwa vidyapeetham::0.0
concepts featured::0.0
formalize::0.0
nt::0.0
node::0.0
classifier to classify::0.0
uniformly::0.0
hashing::0.0
stacks::0.0
focus::0.0
leads::0.0
inverse::0.0
discovering::0.0
frequencies::0.0
level::0.0
quick::0.0
trend::0.0
algorithmic::0.0
statistic features::0.0
result visualisation::0.0
number of clusters::0.0
morgan::0.0
based::0.0
chalmers::0.0
exploratory visualizations::0.0
part of larger::0.0
n-grams::0.0
continuous::0.0
memory::0.0
doing a scientific::0.0
suggestions::0.0
scientific content identifying::0.0
figure::0.0
requirements::0.0
interest-based::0.0
representations::0.0
classroom::0.0
briefly mentions linked::0.0
imagining::0.0
subtopic terms supervised::0.0
education literature proposed::0.0
lectures from data::0.0
total number::0.0
points where aggregate::0.0
term::0.0
collaborative citation::0.0
system shows::0.0
individually::0.0
horning::0.0
weighted::0.0
average c-value::0.0
measure brings::0.0
programme on technology::0.0
adequately::0.0
intended::0.0
`exploring::0.0
factors::0.0
balagopalan::0.0
markovitch::0.0
defines measures::0.0
relevance of terms::0.0
necessarily::0.0
returns::0.0
exploring::0.0
wide::0.0
require::0.0
query processing document::0.0
ann::0.0
medium::0.0
characterized by moderate::0.0
exploratory::0.0
sciences::0.0
ideal::0.0
counteract the effect::0.0
differences::0.0
multiple::0.0
set1 continuation::0.0
an1::0.0
low tf-idf::0.0
considered::0.0
densest bins::0.0
transactions on information::0.0
documents demonstrate considerable::0.0
digital library recommendation::0.0
investigating item::0.0
strube::0.0
connections::0.0
organization of knowledge::0.0
review::0.0
concept in document::0.0
tf-idf c-value::0.0
fulfill the knowing::0.0
filtering::0.0
continuation::0.0
features in order::0.0
pos::0.0
featuring::0.0
direction::0.0
extended to include::0.0
case::0.0
irrespective::0.0
feature vectors::0.0
knowledge vol::0.0
score pattern medium::0.0
ijcai::0.0
estimation::0.0
means a greater::0.0
model::0.0
researchers::0.0
jaccard similarity::0.0
captures::0.0
captured::0.0
required d-span similarity::0.0
samples::0.0
prominently featured::0.0
accepted::0.0
tower::0.0
reduced::0.0
sample document data::0.0
table::0.0
similarity calculated::0.0
provided::0.0
feature high::0.0
similarity and jaccard::0.0
compression distance::0.0
resulting documents::0.0
extracting nested::0.0
discussed::0.0
discusses::0.0
categories of learning::0.0
determine::0.0
strictly::0.0
dispersion::0.0
28th::0.0
longer::0.0
datasets::0.0
applying::0.0
strongly::0.0
contributors::0.0
intro::0.0
interpreting tf-idf term::0.0
r.w.p::0.0
helps the learner::0.0
d-span for instance::0.0
balasubramanian::0.0
deviation::0.0
briefly::0.0
collaborative::0.0
includes::0.0
included::0.0
basic premises::0.0
calls::0.0
work or datasets::0.0
method based::0.0
follow::0.0
decisions::0.0
terms as topic::0.0
techniques for estimating::0.0
removal::0.0
bing similarities::0.0
patterns exhibited::0.0
belonging::0.0
pos tagging::0.0
right continuing::0.0
distribution similarity::0.0
evaluation::0.0
list::0.0
d-spans::0.0
programme::0.0
subtopic topic::0.0
design::0.0
abstract e-learning::0.0
feature score patterns::0.0
sub::0.0
set of data::0.0
segmentation::0.0
positive cdiff::0.0
andrews::0.0
directions::0.0
proceed::0.0
root node left::0.0
equation::0.0
school of engineering::0.0
topic maps::0.0
set and category::0.0
goal::0.0
`standard::0.0
subtopic and background::0.0
stemming::0.0
inter-document semantic::0.0
similarity types::0.0
higher d-span::0.0
reflect::0.0
short::0.0
developed::0.0
topics in computer::0.0
successive clusters::0.0
style::0.0
annual review::0.0
examples of elaboration::0.0
user feedback::0.0
potential results::0.0
mccormak::0.0
similarity or association::0.0
ananiadou::0.0
experience these aspects::0.0
characterized::0.0
generation::0.0
varied data::0.0
expect::0.0
`circular::0.0
common subtopics::0.0
gottron::0.0
sets out::0.0
relate::0.0
measures for text::0.0
linking::0.0
score patterns type::0.0
free::0.0
modeled to provide::0.0
background terms term::0.0
imagining and feeling deal::0.0
pairwise::0.0
risks::0.0
c-value::0.0
transcripts of classroom::0.0
experience remains focused::0.0
empirically::0.0
measures::0.0
supervised learning functional::0.0
scores defined::0.0
measured::0.0
grams::0.0
search machine learning::0.0
c-value d-span rank::0.0
traditional::0.0
reasonable precision::0.0
continuation we first::0.0
logical notation background::0.0
moser::0.0
develop a statistical::0.0
identifying and characterizing::0.0
unbiased experts::0.0
contextual::0.0
knowledge-based::0.0
intelligence::0.0
tf-idf dramatically::0.0
profiling::0.0
creating::0.0
terms term::0.0
domain characterized::0.0
recommendation using wordnet::0.0
relying::0.0
previously::0.0
relations between documents::0.0
context::0.0
arbitrarily::0.0
enhanced education::0.0
estimated probability::0.0
series of document::0.0
relatedness and provide::0.0
identifying the application::0.0
data set2 continuation::0.0
text fragments::0.0
terms binary::0.0
precision::0.0
evaluated::0.0
behavior::0.0
simply estimated::0.0
documents that exhibit::0.0
annual international::0.0
based on collaborative::0.0
snippets of text::0.0
widely::0.0
higher::0.0
syst we created::0.0
literature::0.0
arrived::0.0
birch::0.0
lower::0.0
analysis::0.0
numerical methods::0.0
intervals::0.0
comprehensively::0.0
application rank::0.0
enable the user::0.0
tables::0.0
extracted::0.0
case of academic documents::0.0
conceptual relationship::0.0
helpful::0.0
context of term::0.0
high minimum::0.0
brings out::0.0
essential::0.0
understood::0.0
`double-ended::0.0
notation background terms::0.0
fragments::0.0
based on c-value::0.0
percentile::0.0
range::0.0
computer science research::0.0
conference on research::0.0
open courseware::0.0
damodar::0.0
video and audio::0.0
lectures and scientific::0.0
sequence::0.0
question::0.0
multi-level indexing::0.0
fast::0.0
specific feature::0.0
conceivable::0.0
analyze::0.0
files::0.0
consist::0.0
potential documents::0.0
characteristic::0.0
architecture of proposed::0.0
seelan1::0.0
determined by analyzing::0.0
quantification::0.0
set of relations::0.0
efficient data clustering::0.0
geographic information::0.0
digital libraries statistical::0.0
arxiv:1303.4087::0.0
research articles::0.0
users::0.0
helping::0.0
generated::0.0
vectors::0.0
done using statistical::0.0
c.s::0.0
truth includes::0.0
demonstrates::0.0
similarity between two::0.0
c.h::0.0
logic-based::0.0
retrieval model::0.0
scaled cont::0.0
contributions::0.0
cases::0.0
issues::0.0
languages::0.0
kravalova::0.0
focuses on relationships::0.0
stable::0.0
include::0.0
dramatically::0.0
describe measures::0.0
subset of test::0.0
deals::0.0
indexing expressions::0.0
documents based::0.0
instance for data::0.0
model that captures::0.0
smaller::0.0
database repository::0.0
find::0.0
chose::0.0
degree::0.0
document similarity metrics::0.0
sources for gathering::0.0
explore::0.0
computing semantic similarity::0.0
innovative visualizations::0.0
tf-idf is empirically::0.0
similar background::0.0
larger::0.0
support automatic::0.0
journal on digital::0.0
text documents::0.0
scaled::0.0
length::0.0
documents or text::0.0
sort::0.0
account common::0.0
factor::0.0
application  are higher::0.0
topic::0.0
augment::0.0
application implementation and elaboration::0.0
proof::0.0
libraries jeyavaishnavi muralikumar1::0.0
similarity metrics::0.0
libraries statistical modeling::0.0
similar work::0.0
unique statistical::0.0
base patterns::0.0
videos  our experiments::0.0
relationship types::0.0
linguistics::0.0
collocations::0.0
estimating::0.0
discovering information::0.0
choose::0.0
covered::0.0
defining::0.0
measure is fundamental::0.0
formats and structures::0.0
material::0.0
indexing::0.0
binary search trees::0.0
articles::0.0
tran::0.0
chosen data::0.0
documents must feature::0.0
product::0.0
related::0.0
out::0.0
category::0.0
citation networks::0.0
york::0.0
weights as making::0.0
phrases::0.0
feasible::0.0
characteristic relationship::0.0
measures that involve::0.0
gauch::0.0
set::0.0
publication::0.0
measure between documents::0.0
low c-value::0.0
stable metric::0.0
graphs of related::0.0
sets by explicit::0.0
transcripts from nptel::0.0
july::0.0
relying on external::0.0
created data sets::0.0
linked::0.0
indicating higher::0.0
inform::0.0
collaboration::0.0
delve::0.0
value matrix::0.0
extensive experimental::0.0
gain::0.0
areas of information::0.0
parallel hash tables::0.0
candidates::0.0
continuation the `continuation::0.0
words::0.0
approach that identifies::0.0
queries::0.0
view::0.0
td-idf::0.0
person making::0.0
identification::0.0
continuous flow::0.0
person doing::0.0
publishers::0.0
a.j::0.0
strictly require::0.0
shows the average::0.0
indexing computer::0.0
demonstrate::0.0
terms whereas documents::0.0
coherence with latent::0.0
generic similarity::0.0
based on user::0.0
sequences::0.0
respect::0.0
data clustering method::0.0
sufficient::0.0
good continuing::0.0
present::0.0
f-score values::0.0
distribution or occurrence::0.0
lackner::0.0
graduate level classroom::0.0
connection::0.0
difficult::0.0
l.l::0.0
student::0.0
student conference::0.0
dictionaries stack document::0.0
theses::0.0
personalised::0.0
cdiff::0.0
users rated::0.0
distributional and wordnet-based::0.0
system that identifies::0.0
hall::0.0
usage::0.0
infer concept::0.0
science our prototype::0.0
scientificpapers based::0.0
high dsim negative::0.0
covered in document::0.0
lead::0.0
standard data::0.0
examples of statistical::0.0
obtained when cosine::0.0
occurrence or term::0.0
pre-processing techniques::0.0
vectors representing tf-idf::0.0
exhibiting elaboration::0.0
resistors::0.0
var::0.0
required d-span::0.0
probabilistic lsa::0.0
automated::0.0
made::0.0
record::0.0
relationships in digital::0.0
advanced scientific::0.0
mutual::0.0
`elaboration::0.0
modeling document relatedness::0.0
conclusion::0.0
kinds::0.0
national programme::0.0
m.s::0.0
important concept::0.0
coupling::0.0
ranks::0.0
moderation::0.0
