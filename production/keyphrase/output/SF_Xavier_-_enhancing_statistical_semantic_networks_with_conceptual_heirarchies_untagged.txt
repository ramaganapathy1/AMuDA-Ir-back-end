seediscussions  stats  andauthorprofilesforthispublicationat  https  //www.researchgate.net/publication/282787968 enhancingstatisticalsemanticnetworkswith concepthierarchies conferencepaperaugust2015 doi:10.1109/icacci.2015.7275792 reads 48 3authors  including  vidhyabalasubramanian amritavishwavidyapeetham 20publications100citations seeprofile allin-textreferencesunderlinedinbluearelinkedtopublicationsonresearchgate  lettingyouaccessandreadthemimmediately  availablefrom  vidhyabalasubramanian retrievedon:27may2016 enhancing statistical semantic networks with concept hierarchies sofia francis xavier  lakshmi priyanka selvaraj and vidhya balasubramanian department of computer science and engineering  amrita school of engineering  coimbatore  amrita vishwa vidyapeetham  university   abstract  with the emergence of the semantic web  effective knowledge representation has gained importance  statistically generated semantic networks are simple representations whose semantic power is yet to be completely explored  though  these semantic networks are created with simple statistical measures without much overhead  they have the potential to express the semantic relationship between concepts  in this paper  we explore the capability of such networks and enhance them with concept hierarchies to serve as better knowledge representations  the concept hierarchies are built based on the level of importance of concepts  the level of importance/coverage of a concept within the given set of documents has to be taken into account to build an effective knowledge representation  in this paper  we provide a domain-independent  graph based approach for identifying the level of importance of each concept from the statistically generated semantic network which represents the entire document set  insights about the depth of every concept is obtained by analysing the graph theoretical properties of the statistically generated semantic network  a generic concept hierarchy is created using a greedy strategy  and the original semantic network is reinforced with this concept hierarchy  experiments over different data sets demonstrate that our approach works effectively in classifying concepts and generating taxonomies based on it  thereby effectively enhancing the semantic network  i i ntroduction representation of knowledge in the form of concepts and their inter-relationships is important for various applications like automated processing of information content  information retrieval and document summarization  constant efforts have been made to improve the efficiency of knowledge representations  information content  in most domains is vast  and is constantly changing i.e  new concepts and relationships between concepts are continuously being updated  therefore generating effective knowledge representation is a challenging process  currently  knowledge representations use simple bagof-words or statistical models like vector space models  21  or graph based models like ontologies  12   while the former models use statistics to identify important concepts  they do not explicitly define the relationships between them  the latter on the other hand use graph representations to explicitly relate concepts in a domain  such graph based representations can range from simple semantic networks that use word co-occurrence to correlate terms to complex concept graph representations like ontologies  while ontologies are the most expressive representations  and hence desirable  they are very complex to generate  requires domain knowledge and involve lot of manual intervention for generation  since graphs are naturally suitable to represent knowledge  it would be desirable to extract more semantic information from simple semantic networks to make them more expressive  therefore  our work aims to enhance the basic semantic networks generated using co-occurrence and word distance metrics  29   31   by extracting and superimposing concept hierarchies over such representations  the advantage of the such graphs is that they are easy to generate and do not require prior knowledge about the domain or natural language processing  nlp  to establish relationships  our work builds on the premise that the graphs generated using co-occurrence and word distance  distance between concepts in a document  naturally capture interesting patterns reflecting different semantic aspects of the domain like concept hierarchy  topic based clusters etc  in order to achieve the above firstly  we generate a semantic network for a corpus of documents representing a single domain or multiple domains  in our work  concept identification is not the focus  and hence existing techniques are used to extract the key concepts from the corpus  to enhance the representation we address two major aspects  1 while key concepts of a domain may be available  the level of importance of a concept to a domain  and the level of coverage in a domain is rarely captured  this information is essential to categorize concepts into topics  subtopics  and supporting concepts  each of these can further be categorized into multiple levels  in this work we extract the level of importance/coverage of a concept with respect to a domain  using the properties of the initially generated semantic network  2 once the level of a concept is identified  a formal concept hierarchy in the form of a tree structure is generated  which connects the right concepts across levels  this step also uses the properties of the original semantic network along with the extracted concept levels  this enhanced semantic network can help in different information retrieval problems like knowledge representation  taxonomy extraction  finding document similarity etc  we will motivate the need for this work in the next section  and explain our methodology in the consequent sections  ii  r elated work knowledge representation  kr  focuses on extracting and representing knowledge from the given documents in a meaningful way  to enable intelligent systems to perform better  the available methods for representing knowledge include statistical approaches  graph theoretic approaches  semantic approaches and a hybrid of these approaches  the statistical 978-1-4799-8792-4/15/ $ 31.00 c 2015 ieee 1298 approaches to kr include bag of words model  vector space model and scalar value decomposition  21   although  these techniques capture the important concepts discussed in the given text  they do not capture the exact nature of relationships between them  currently the most commonly used krs are graph based  3   the most common of these being ontologies  11   graph based techniques are capable of expressing relationships between concepts and this power has been used for various applications  such graph representations range from semantic networks generated using statistical approaches   31   25   15  which implicitly relate concepts to concept graphs  which have both concept nodes and relationship nodes  9   27   concept graphs like ontologies have been widely used for information retrieval  topic labelling  recommendation systems etc  16   17   there are various automatic  32  and semi automatic methods  13  for ontology construction  for building ontologies accurately  domain expertise is mandatory  and extensive nlp techniques are needed  though ontologies are comprehensive  ontologies are domain specific and the effort required to construct ontologies for a broader domain is enormous and highly complex  the other type of graph based krs include semantic networks  which have also been widely used to model semantic knowledge  31   30   these networks represent concepts as nodes  but the relationships between them are not explicitly defined  semantic networks that are statistically generated represent relationships using statistical weights  and are also commonly used  31   statistical measures such as word-distance  absolute frequency  relative frequency  and cooccurrence have been widely used to create semantic networks  29   31   8   these types of networks have been used in a wide range of information retrieval applications  28   23   and keyphrase extraction systems  19   amongst these statistical measures  it has been observed that the networks created with co-occurrence  23   25  and word-distance  15   8  are capable of quantifying the association between concepts to an appreciable extent  2   though these are simple statistical measures  they are able to express the relationship between concepts with considerable accuracy  however they suffer from the lack of expressivity and there is scope for enhancing these representations to improve their semantic expressivity  for any knowledge representation  concept identification is an important task  concept identification has been widely studied and there are several approaches for the same including statistical  22   machine learning  6   4  and graph theoretic approaches  20   however most of these approaches do not classify these concepts based on their dominance or coverage within a corpus  the classification of the concepts based on their level of coverage/importance in the given documents can greatly influence the effectiveness of kr  in  14   phrases have been classified into two types i.e  topic and theme phrases based on their frequency of occurrence  however more work is needed to classify the level of importance of a term to a document  and in this paper we classify concepts based on the level of importance using both statistical and graph theoretic techniques  to improve the semantic expressivity of the statistical se mantic networks  it is essential to augment them with the concept hierarchy established by classifying the concepts as mentioned above  concept hierarchies have generally been generated in the form of taxonomies which relate terms using is-a  type-of  kind-of  part-of  hypernymy-hyponymy hierarchies  33   26   these taxonomies restrict the connections to certain relationships  and are not general in nature  for instance  while a 'stack ' is-a 'data structure '  'push ' and 'pop ' which are in the next level of hierarchy do not exhibit this relationship  it is therefore desirable to connect concepts at different levels even if they do not fall under a specific category of relationship  this can help in identifying topic-subtopic relationships  and the relationships between major topics and background topics  once a generic hierarchy is generated  the exact nature of relationships can be found more easily  our goal is to create a generic hierarchy of concepts within a subject domain  finding the exact relationships is beyond scope of this work  the next section will outline our semantic network generation  iii  s tatistical s emantic n etwork  c onstruction as mentioned in the previous section  our goal is to represent knowledge using statistical semantic networks and analyze the semantic properties of the same  in this section  we discuss the construction of this graph and analyze its basic graph theoretic properties  a semantic network is a graph structure that provides intuitive and useful representations for modelling semantic knowledge  31   in our work  we aim to construct a semantic network using statistical approaches like word-distance and co-occurrence  this semantic network is constructed from a corpus of documents representing a topic of interest  here a topic can be a very broad topic like computer science or some specific topic like binary trees  the corpus is assumed to represent all aspects of the topic  given this corpus  a statistical network is defined as a graph of concepts within this topic  where nodes are concepts  and the edges represent a mapping between the concepts representing the relationship between the concepts  this network is a weighted graph where each edge has a numeric value associated with it indicating the strength of the relationship between the incident concepts  in statistical semantic networks  the strength of a relationship between the concepts is statistically derived  measures like co-occurrence  word distance  n-distance  absolute frequency and relative frequency have been used to characterize this relationship  the most common of them being cooccurrence and word distance  for instance  two concepts are assumed to be closely related if they co-occur together in a document  23   if the number of documents they cooccur in is higher  the strength is proportionally higher  and the correspondingly generated graphs become co-occurrence graphs  the number of terms separating two concepts in a document is word-distance  the closer the two terms  the stronger the relationship between them  such graphs are worddistance graphs  there has been lot of attempts at using both these types of graphs for information retrieval tasks like keyword extraction  text summarization etc  from the related 2015 international conference on advances in computing  communications and informatics  icacci  1299 work  we can see that these two measures are simple to compute  and intuitively connect conceptually similar terms  hence we use them both as a basis for our semantic network  in most works  both these measures are combined as follows  the strength is defined based on the number of times two terms co-occur within a specific window size  in word distance   but many a time  this method misses important co-occurrences or includes spurious ones  therefore the edge weight should factor in the frequency of co-occurrence and word distance of the incident nodes  terms  irrespective of the window size  the next paragraphs will elaborate the steps involved in our technique for graph construction that combine these metrics  the input for the graph is a set of technical documents of a particular topic  as mentioned earlier  the topic can be as broad as 'computer science ' or as narrow as 'binary search tree '  the first step in the construction of statistical semantic network is to extract the key-phrases from the given technical documents  n-gram keyphrases have been extracted with the keyphrase extraction method discussed in  4   these keyphrases are taken as the concepts and they form the nodes of the graph  the edges are constructed with the help of co-occurrence and worddistance metrics  we first apply the word distance metric  where the distance between these two concepts is given by the average of the number of words between the two concepts  over all the occurrences present in the documents  next we apply co-occurrence over this  co-occurrence is used to eliminate spurious or weak relationships  for instance  two terms might be closely occurring in a document but may not be conceptually related  for e.g  words in the index of a book  to account for this possibility  we calculate the number of times they co-occur within a document and across the corpus  this co-occurrence value is combined with the worddistance measure  hence two terms are closely related if they co-occur frequently and have low word distance  the final edge weight is given by a normalized value of both the word distance and the co-occurrence values  let g=  v  e  be the graph generated over the document collection d  where v =  v1  v2    vn  represents the vertices and e is the set of edges  e  i  j  represents the edge connecting concepts  nodes  vi and vj  let w  i  j  represent the word distance between concepts vi and vj and c  i  j  be the number of times concepts vi and vj co-occur within the corpus  let h  i  j  be the heuristic i.e  the weight assigned to each edge e  i  j  considering both word distance and co-occurrence measures as given by the following equation  two related concepts have high co-occurrence value and a low worddistance value  there is a necessity to balance the influence of both these metrics so as to obtain the final relationship measure h  i  j   this is derived as follows  h  i  j  = w  i  j   cm  c  i  j    cm   1  table i  comparison on word distance  co-occurrence and heuristic measures vertex 1 complete binary tree self balancing tree array vertex 2 height worst case pointer word distance 60 60 60 coheuristic occurrence value 4 5.868 2 1 5.934 5.967 though they have the same word distance  this completely depends on the data-set under consideration  while all three pairs have semantic relationships  the pair with least heuristic value exhibits the closest relationship  the graph g=  v  e  so obtained using the heuristic values h is our semantic network  fig.1 shows a sample semantic network generated over three topics  which has been visualized using the gephi tool  5   as we can see from the graph  such semantic networks generated by using word-distance and co-occurrence metrics have interesting semantic properties  also  the nodes under a similar topic were found to cluster together  the following section elaborates how a concept hierarchy is generated using this statistical semantic network  iv  c oncept hierarchy generation using the properties of the semantic network we have so far explained in detail  how the statistical semantic network is generated for a given set of documents  the concept hierarchy generation involves two steps 1  concept classification 2  creating concept hierarchy a concept classification concept classification involves identifying the level of importance of each concept  the level of importance of a concept determines how influential or dominant it is in the given set of documents  not all concepts are equally important  consider a document about 'stacks '  the main topic/concept is the data structure 'stack '  concepts such as 'push '  'pop ' are its subtopics and then concepts like 'stack empty exception '  which occur sparingly can be placed under 'pop '  we classify concepts into the following classes based on the level of discussion and level of importance to the domain  1  topics  these contain the concepts that outline the major topic of discussion  2  sub topics  for each major topic discussed  the subtopics that are covered are categorized here  subtopics can be further classified into multiple levels based on their level of discussion  3  background topics  these topics outline the allied subjects that can help in understanding of the main topics and subtopics  however the document focus is not these topics  where cm is the maximum value of the co-occurrence measure over all the edges in the graph  the lower the heuristic value the higher the strength of the relationship  the table i shows an example corpus where the heuristic value of the edges change depending on the co-occurrence values even 1300 2015 international conference on advances in computing  communications and informatics  icacci  fig  1 statistical semantic network to classify the concepts  it is necessary to understand the properties of the concepts under consideration and for this we analyse the properties of the generated graph  since our goal in this work is to classify concepts based on their importance and level of contribution to the domain or corpus  we primarily focus on the graph based measures that provide insights into the importance of concepts  to obtain a rough idea of the role played by each concept  we use centrality measures as our basic features  19   specifically we choose the nine centrality measures that are defined in  19   the measures are degree  is the number of edges that are connected to the node  closeness centrality  is the reciprocal of the sum of the distances from the given node to all the other nodes in the graph  betweenness centrality  measures how often the node gets traversed in the shortest path between two other nodes  eigenvector centrality  assesses how well an individual node is connected to other important nodes of the network  strength  is sum of the weights of all the edges that are connected to the node  hits  a popular ranking algorithm by kleinberg  18  gives rise to two measures namely  1  authority  measures authoritativeness of the node 's content on a specific topic  hub  measures how well a node is connected to many authoritative nodes  pagerank  measures how often a user performing a random walk from one node to another in a network would visit that node  clustering coefficient  indicates how the node is embedded in its neighborhood  it has been observed that in general the concepts in the topic cluster have high values for all the centrality measures but this need not be the case always  for example  consider the two topic nodes 'binary tree ' and 'stack '  'binary tree ' has a high value for all the centrality measures whereas 'stack ' has high value for degree  betweenness  authority  hub and pagerank but has low value for strength  clustering coefficient  closeness and eigenvector centrality  similarly the subtopic 'load factor ' has a high strength  betweenness and clustering coefficient but low degree  authority  hub  pagerank  eigenvector and closeness centrality measures  considering just one or two of these centrality measures will result in spurious identification of the topics  hence there is a necessity to consider all the centrality measures to identify the topics  subtopics and the background topics accurately  therefore  we first cluster the nodes using these centrality measures and then label the clusters as topics  subtopics and background topics using a filtering approach  for concept clustering  the most suitable algorithms are k-means and expectation maximization  em   since both the algorithms are found to work well for large domains  1   2  2015 international conference on advances in computing  communications and informatics  icacci  1301 expectation maximization  em  is a distance-based algorithm that uses statistical models with latent variables and computes the distribution parameters which maximizes a model 's loglikelihood measure  1   k-means clustering algorithm is a simple partitioning algorithm which partitions m nodes into k clusters where each node belongs to the cluster with the nearest centroid  1   in order to analyse which clustering algorithm produces better results  both k-means and em are applied to the nodes in our statistical semantic network  taking into account the level of coverage of topics  we have considered 4 classes for classification  i.e  two classes for subtopics  one for topics and the other for background topics  each concept is represented by its feature vectors which is a measure of all the nine centrality metrics  the clustering algorithm is applied to the feature vectors using the weka tool  7  and the clusters are obtained  once the concepts are grouped into four clusters  we need to identify which cluster represents topics  subtopics and background topics  the nodes with a high degree tend to be topics  and those with lower degrees are generally background topics  hence by sorting the clusters based on the average degree of each cluster we will be able to identify the topic  subtopic and the background topic clusters  the clusters are then named from level 0 to level 3  with level 0 being the topic cluster with the highest average degree and level 3 being the background topic cluster with the lowest average degree  b creating concept hierarchy once the different levels of importance are identified  a greedy hierarchy generation algorithm is applied over the semantic network and the identified clusters  let l l l v l =  v1  v2    vp  be the list of vertices at each level l and n be the list of edges corresponding to the concept hierarchy generated  l is the number of levels of importance  level 0 corresponds to major topics and level l  1 corresponds to the background topic   then v l v l there exists an edge n  x  y  l l -1 connecting the nodes vx from level l and vy from level l  1 l l -1 such that the distance between vx and vy is minimum in the network  the algorithm to create the concept hierarchy can be defined formally as given below  algorithm 1 greedy hierarchy generation algorithm l1 for l < number of levels of importance do for all vx v l do temp n one minimumdistance for all vy v l-1 do if shortestp ath  vx  vy  < minimumdistance then minimumdistance shortestp ath  vx  vy  tempvy end if end for n  vx  temp  minimumdistance end for end for the concept hierarchies obtained using the above mentioned algorithm consist of different connected components  with each component representing a hierarchy of the major topics of discussion  in the subsequent sections we will evaluate both the concept classification and the hierarchy generation algorithms  c evaluation of concept classification and concept hierarchies now that we have classified concepts and generated their hierarchies  we need to asses the algorithms ' performance  there are two methods of assessing the classification  the first of which  is to evaluate it based on a ground truth  ground truth can be obtained from wordnet  24   or generated manually  wordnet provides a shallow hierarchy of the concepts in a technical domain  and so most of the nodes present in the semantic network are not present in wordnet  hence ground truth has to be generated manually  which is a difficult task for large datasets  hence for this type of evaluation we use expert generated classifications for small datasets on topics like 'stacks '  'binary trees ' etc  the ground truth consists of four clusters with topics  subtopics  sub-subtopics and background topics represented as g0  g1  g2 and g3 respectively  similarly  the clusters obtained using our algorithm over the three data-sets are represented as m0  m1  m2 and m3  given the groundtruth  we use the following metrics of evaluation  1  precision  recall and f-measure  precision is defined as the measure of the number of concepts that have been correctly identified in each cluster out of the total number of concepts present in the cluster  using the ground truth the precision can be mathematically calculated using the equation pi = n  g i mi  n  mi   2  where pi is the precision obtained for cluster i  n  gi mi  is the number of concepts of gi in mi and n  mi  is the number of concepts in mi  recall is a measure of the number of concepts that have been correctly identified in each cluster out of the number of concepts present in the ground truth and is mathematically calculated as follows ri = n  g i mi  n  gi   3  where ri is the recall obtained for cluster i  n  gi  is the number of concepts in gi  f-measure is the harmonic mean of precision and recall and can be calculated as 2 pi ri  4  fi = pi + r i where fi is the f-measure for cluster i to calculate the overall performance of the classification we take the weighted average of the f-measures calculated for each cluster and can be given by n  gi  fi f =  5  n i 1302 2015 international conference on advances in computing  communications and informatics  icacci  table ii  precision values for the data subsets data-set stack binary tree hashing k-means 0.6572 0.5666 0.4755 precision em 0.7656 0.6067 0.7040 table iii  recall values for the data subsets data-set stack binary tree hashing k-means 0.5666 0.5263 0.4431 recall em 0.6923 0.5714 0.5735 where n is the total number of concepts in the ground truth  similarly the overall precision and recall of the classification is calculated by taking the weighted average of their corresponding measures  since generation of ground truth is difficult in many cases  user rating is often a commonly chosen method  user evaluation of the concept hierarchies based on five parameters are used to evaluate the concept hierarchies  the five parameters as defined in  10  are 1  cohesiveness  judge whether the concepts in the hierarchy are semantically similar  2  isolation  judge whether the concepts at the same level in the hierarchy are distinguishable and do not subsume one another  3  hierarchy  judge whether the hierarchies are traversed from broader concepts to narrower concepts  4  navigation balance  judge whether the concepts in the hierarchy fan-out appropriately at each level  5  readability  judge whether it is easy to locate the concepts of hierarchies at all levels with the composed hierarchies and instances  the concept hierarchies that have been generated using our greedy hierarchy generation algorithm over the three datasets are given to a set of 5 users  the users rate the concept hierarchies generated on a scale of 0 to 5 where 0 means very poor  given these two evaluation techniques  the former will be applied for concept classification  and the latter for the hierarchy generated  the next subsections deal with the performance of our techniques  2  evaluation of proposed concept classification  to analyse the performance of the concept classification  we have used three data-sets on stacks  binary tree and hashing which is table iv  f-measure values for the data subsets data-set stack binary tree hashing k-means 0.5747 0.5284 0.4346 f-measure em 0.6990 0.5702 0.5998 fig  2 concept hierarchy for stacks generated using k-means table v  user evaluation of concept hierarchies for 'stacks ' parameters cohesion isolation hierarchy navigation balance readability k-means 3.6398 3.7225 3.5 3.7225 3.7225 em 4.167 3.75 4.167 4.583 4.33 a subset of the overall data-set that is based on data structures  each data-set consists of approximately 8 documents  using these data-sets  classification of the concepts have been performed using the proposed algorithm  metrics such as fmeasure  precision and recall were then calculated  since such a classification has not been attempted to the best of our knowledge  we do not have previous techniques to compare with  hence we evaluate the two classification algorithms  em and k-means to see which performs better  the precision  recall and f-measures for the data subsets  as stated before  using the two classification algorithms em and k-means can be seen in tables ii  iii and iv  the results demonstrate that our method of using graph properties for classification results in good accuracies using both techniques for different topics  amongst these two techniques  both work well in text classification   the em classifier performs better than the kmeans classifier consistently  since em classification gives more importance to the probability of concepts occurring together  in such a concept classification scheme  it works better  3  evaluation of proposed concept hierarchy generation  once the concepts are classified  the concept hierarchy is generated using our greedy approach  a sample hierarchy has been generated using both the k-means and em clustering algorithms over the 'stack ' data-set and can be seen in fig.2 and fig.3  as observed from the figures we can see the levels of hierarchy and how the concepts like push and pop are related to stack  and stack full exception 2015 international conference on advances in computing  communications and informatics  icacci  1303 table vi  user evaluation of concept hierarchies for 'hash tables ' parameters cohesion isolation hierarchy navigation balance readability k-means 3.33 4 3.334 3.5 3.417 em 4 4.33 4 4.167 4.167 the enhancement is done by enhancing properties of both the nodes and edges of the semantic network  node enhancement  the nodes in the semantic network are weighted based on its level of importance in the concept classification  the concepts with the highest level of importance i.e  the topics are assigned with a weight of 1 the nontopic concepts are assigned with weights based on the level it occupies in the hierarchy  the weighting of the nodes can be mathematically represented as l  li  6  l where ui is the assigned weight of the vertex vi in the semantic network g =  v  e   l is the number of levels of importance considered in concept classification  and li is the level occupied by vertex vi in the hierarchy  here 'level 0 ' represents the topics  the ui value assigned for concepts in different levels of importance are shown in table viii  ui = table viii  ui values for four levels of hierarchy table vii  user evaluation of concept hierarchies for 'binary trees ' parameters cohesion isolation hierarchy navigation balance readability k-means 3.833 4 4.0833 4.166 3.8333 em 4.5 4.1666 4.5 4.333 4.5 for the evaluation of the generated hierarchies the latter method of user ratings is used  the hierarchies are generated over results from both classifiers and given to 5 users for rating on different aspects  the average rating has been tabulated and shown in tables v  vi and vii  the results show that our approach generates accurate hierarchies  and are acceptable to users  on average  users have given a rating of about 4.0 for the hierarchies generated from different datasets  here too  the em classification results in better hierarchies and is preferred by the users  we can see that the dataset binary tree has higher accuracy  this is due to the variety of documents available covering different aspects of binary trees  v e nhancement of the s emantic n etwork levels of importance topics subtopics sub-subtopics background topics ui values assigned 1 0.75 0.50 0.25 the semantic network that has been generated from the previous sections is enhanced using the concept hierarchies  edge enhancement  every edge in the semantic network is enhanced by a factor which depends on the type of link it has in the concept hierarchy  an edge in the semantic network falls under one of the following three cases 1  for an edge in the semantic network  the incident vertices belong to the same component in the hierarchy and have a direct hierarchical edge  2  for an edge in the semantic network  the incident vertices belong to the same component in the hierarchy but do not have a direct hierarchical edge  3  for an edge in the semantic network  the incident vertices belong to different components in the concept hierarchy  for the first two cases the edge enhancement is done by reducing the edge weight by a factor  the factor is given by the fraction of the path length between the two vertices in the concept hierarchy to the maximum path length between any two concepts in the hierarchy  can be mathematically defined as p  i  j  =  7  pm where p  i  j  is the path length between the vertices vi and vj in the concept hierarchy and pm is the maximum path length between any two vertices in the concept hierarchy  pm given by 2  l  1   where l is the number of levels of importance considered  in the third case the edge weight remains unaltered  hence is taken to be 1 in this case  the enhancement of the edge weight for three sample edges is shown in table ix  the edge weight of each edge in the semantic network is then enhanced as h  i  j  = h  i  j   8  fig  3 concept hierarchy for stacks generated using em 1304 2015 international conference on advances in computing  communications and informatics  icacci  references fig  4 enhanced semantic network where h  i  j  is the heuristic edge weight between the vertices vi and vj  in addition these edges are also specially labelled as hierarchical edges  table ix  enhanced edge weights for different types of edges in hierarchy vertex 1 stack stack stack vertex 2 pop linked stack array based stack edge weight 6.8067 10.8658 1.9512 value 0.1667 0.3333 0.5 enhanced edge weight 1.1344 3.6219 0.6504 the semantic network thus enhanced is shown in the fig.4  this graph consists of concepts from 'stacks '  'binary trees ' and 'hash tables '  we can observe that the clusters are more pronounced and the important nodes are enhanced  as are the edges  as compared to the original graph in figure 1 the hierarchies are also clearly visible within each cluster  vi  c onclusion the semantic network based on their level of importance  our novel approach of using the graph theoretic properties of these semantic networks as features in an em clustering algorithm is effective in classifying concepts  we have demonstrated how this approach can effectively classify concepts as topics  subtopics and background topics  to enhance the expressivity of these semantic networks  a hierarchy created over the classified concepts is superimposed over it  the enhanced semantic network consists of weighted nodes indicating the importance of the node in the semantic network  the edge weight between two concepts that are more semantically related have been further reduced thereby bringing the two concepts more closer in the network  this enhanced semantic network serves as a better knowledge representation when compared to the initially generated semantic network and hence can be used for efficient information retrieval  since the concept hierarchies have been generated without any prior knowledge about the importance of the concept in the domain  it can be used to identify the thematic structure in a constantly changing document collection  future work involves deeper analysis into the properties of these graphs for information retrieval tasks  r eferences osama abu abbas et al  `` comparisons between data clustering algorithms  '' in  int  arab j inf  technol  5.3  2008   pp  320325 in this paper  we proposed an approach to generate semantic networks using statistical properties such as co-occurrence and word distance  we have observed that these semantic networks have interesting properties which can be exploited for different purposes  we use these properties to classify the concepts of  1  2015 international conference on advances in computing  communications and informatics  icacci  1305 references  2   3   4   5   6   7   8   9   10   11   12   13   14   15   16   17  asad et al  `` automated generation of concept graphs ''  in   2013   antonio badia and mehmed kantardzic  `` graph building as a mining activity  finding links in the small ''  in  proceedings of the 3rd international workshop on link discovery  acm  2005  pp  1724 arun balagopalan et al  `` automatic keyphrase extraction and segmentation of video lectures ''  in  technology enhanced education  ictee   2012 ieee international conference on  ieee  2012  pp  110 mathieu bastian  sebastien heymann  mathieu jacomy  et al  `` gephi  an open source software for exploring and manipulating networks  '' in  icwsm 8  2009   pp  361 362 vishwanath bijalwan et al  `` knn based machine learning approach for text and document mining ''  in  international journal of database theory and application 7.1  2014   pp  6170 remco r bouckaert et al  `` weka  experiences with a java open-source project ''  in  the journal of machine learning research 11  2010   pp  25332541 ramon ferrer i cancho and richard v sol e `` the small world of human language ''  in  proceedings of the royal society of london b  biological sciences 268.1482  2001   pp  22612265 michel chein and marie-laure mugnier  `` conceptual graphs are also graphs ''  in  graph-based representation and reasoning  springer  2014  pp  118 shui-lung chuang and lee-feng chien  `` taxonomy generation for text segments  a practical web-based approach ''  in  acm transactions on information systems  tois  23.4  2005   pp  363396 li ding et al  `` using ontologies in the semantic web  a survey ''  in  ontologies  springer  2007  pp  79113 david faure and claire n edellec  `` a corpus-based conceptual clustering method for verb frames and ontology acquisition ''  in  lrec workshop on adapting lexical and corpus resources to sublanguages and applications  vol  707  728  1998  p 30 blaz fortun and mladeni dunja  `` semi-automatic ontology construction ''  phd thesis  doctoral dissertation  polavtomatska gradnja ontologij  doktorska disertacija   ljubljana  slovenia  2011 alexander haubold  `` analysis and visualization of index words from audio transcripts of instructional videos ''  in  multimedia software engineering  2004 proceedings  ieee sixth international symposium on  ieee  2004  pp  570573 david hawking  paul thistlewaite  et al  `` relevance weighting using distance between term occurrences ''  in  computer science technical report tr-cs-96-08  australian national university  1996   ioana hulpus et al  `` unsupervised graph-based topic labelling using dbpedia ''  in  proceedings of the sixth acm international conference on web search and data mining  acm  2013  pp  465474 wei jin and rohini k srihari  `` graph-based text representation and knowledge discovery ''  in  proceedings of  18   19   20   21   22   23   24   25   26   27   28   29   30   31   32  the 2007 acm symposium on applied computing  acm  2007  pp  807811 jon m kleinberg  `` authoritative sources in a hyperlinked environment ''  in  journal of the acm  jacm  46.5  1999   pp  604632 shibamouli lahiri  sagnik ray choudhury  and cornelia caragea  `` keyword and keyphrase extraction using centrality measures on collocation networks ''  in  arxiv preprint arxiv:1401.6571  2014   marina litvak and mark last  `` graph-based keyword extraction for single-document summarization ''  in  proceedings of the workshop on multi-source multilingual information extraction and summarization  association for computational linguistics  2008  pp  1724 christopher d manning  prabhakar raghavan  and hinrich sch utze  introduction to information retrieval  vol  1 cambridge university press cambridge  2008 yutaka matsuo and mitsuru ishizuka  `` keyword extraction from a single document using word co-occurrence statistical information ''  in  international journal on artificial intelligence tools 13.01  2004   pp  157169 alexander mehler  `` large text networks as an object of corpus linguistic studies ''  in  corpus linguistics  an international handbook of the science of language and society  2008   pp  328382 roberto navigli  paola velardi  and stefano faralli  `` a graph-based algorithm for inducing lexical taxonomies from scratch ''  in  ijcai  2011  pp  18721877 rogelio nazar  jorge vivaldi  and leo wanner  `` cooccurrence graphs applied to taxonomy extraction in scientific and technical corpora ''  in  procesamiento del lenguaje natural 49  2012   pp  6774 simone paolo ponzetto and michael strube  `` taxonomy induction based on a collaboratively built knowledge repository ''  in  artificial intelligence 175.9-10  2011   pp  17371756 miguel riesco  mari an d fond on  and dar io alvarez  `` designing degrees  generating concept maps for the description of relationships between subjects ''  in  concept mapping  connecting educators  proc  of the third int  conference on concept mapping  tallinn  estonia & helsinki  finland  tallinn university  2008 cornelis joost van rijsbergen  `` a theoretical basis for the use of co-occurrence data in information retrieval ''  in  journal of documentation 33.2  1977   pp  106119 adam schenker  `` graph-theoretic techniques for web content mining ''  in   2003   john f sowa  `` principles of semantic networks ''  in   1991   mark steyvers and joshua b tenenbaum  `` the largescale structure of semantic networks  statistical analyses and a model of semantic growth ''  in  cognitive science 29.1  2005   pp  4178 wilson yiksen wong  learning lightweight ontologies from text across different domains using the web as background knowledge  university of western australia  2009  1306 2015 international conference on advances in computing  communications and informatics  icacci   33  t yildiz and s yildirim  `` association rule based acquisition of hyponym and hypernym relation from a turkish corpus ''  in  innovations in intelligent systems and applications  inista   2012 international symposium on  ieee  2012  pp  15  2015 international conference on advances in computing  communications and informatics  icacci  1307 