optical localization of passive uhf rfid tags with integrated leds alanson p sample  craig macomber  liang-ting jiang  and joshua r smith department of computer science & engineering university of washington seattle washington  usa email  alanson @ u.washington.edu  jrs @ cs.washington.edu abstractthe ability to accurately localize passive uhf rfid tags in uncontrolled and unstructured environments is limited by multi-path propagation  therefore  in order to increase the spatial resolution of rf based localization methods we propose to combine them with additional sensing capabilities  in this work we enhance passive uhf rfid tags with leds  using the wireless identification and sensing platform  wisp   this allows both humans and computer systems  with cameras  to optically locate tagged items with millimeter accuracy  in order to show the effectiveness of this approach  a pr2 robot is equipped with an epc gen2 rfid reader and camera  using the rfid reader alone  the pr2 is able to identify and coarsely locate tagged items in an unstructured environment  once the robot has navigated to the vicinity of the led-enhanced passive rfid tags  it uses the optical location method to precisely locate and autonomously grasp tagged items from a table  i i ntroduction rfid technology promises to enable an electronically identifiable world  in which individual objects can be automatically identified and located in unstructured and uncontrolled environments  reading a conventional rfid tag today provides coarse location information  since a read event indicates that the tag is in range of the reader  for many applications  more precise location information is desirable  for example  a natural extension of the inventory application that has driven the design of rfid protocols and hardware is item retrieval  in this application  a human or robot needs to find the location of the item precisely enough to retrieve it  even if there are many other tagged objects nearby  another variant is location assurance  in which the system must verify that merchandise  safety equipment  or medical equipment are in pre-specified locations  in an effort to provide more precise tag localization  many researchers have explored more sophisticated rf-based tag localization  by for example  examining signal strength measured between the tag and multiple reader antennae  this paper proposes a more precise  robust  and reliable technique  in which the passive tag is augmented with an led  and the reader is augmented with a camera that is carefully synchronized to the tag flash  in the subsection below  we review previous tag localization efforts  we believe that the method presented here provides a better combination of precision and robustness to multi-path effects in uncontrolled environments  while still using entirely passive  battery-free  tags  a prior work on rfid tag localization initial work on rfid tag localization utilized the digital nature of the tag response to estimate distance  we will use the binary method to refer to the implicit tag localization that occurs with every read event  this term is used because every tag is either inside or outside the interrogation field of the rfid reader  the problem with this method is that the spatial resolution is limited to 10 meters and even that coarse information is ambiguous due to reflection and multipath effects  a modification to the binary detection method is to control the output power level of the reader to allow for simple range estimation when the tag is determined to be on the edge of detection zone  it has been shown that using this method along with directional antenna can provide 0.5-1.0 meters of spatial resolution under most circumstance  1   in a further refinement  2  combined many separate binary tag read events to localize a moving  robot-mounted reader with two antennae  more sophisticated techniques use the rfid readers ability to measure the rf channel and tag modulation properties in the form of received signal strength and phase information  in the best case scenarios position accuracy can be on the order of several centimeters  3    4   however  the success of these techniques depends on how well controlled the rf environment is so that multi-path effects are eliminated or at least well defined  in many real world scenarios the use of anechoic chambers and well-structured portals is not feasible  since multi-path phenomena can drastically affect rf-based methods  both magnitude and phase   there is a inherent tradeoff between how well structured the tags environment is  and how accurately the location of a tag can be estimated  one notable exception was demonstrated by meisen et al  which moves the reader antenna along a known trajectory  while repeatedly measures a static tags  5   in a sense this method  like  2   trades accuracy for acquisition time  finally  another proposed technique combined a video projector and light detector tag to localize objects   6  this paper used a large  battery-powered  active  tag  the required projector represents a substantial increase in complexity and power for the mobile system  b proposed work compared to prior work this paper proposes augmenting passive rfid tags with leds  which will allow for both humans and computer systems  with cameras  to optically locate the item  this method shifts some of the technical burden of localization off of the rfid reader and back to the tag  ultimately  this will reduce the total system complexity and increasing accuracy  under this paradigm a mobile rfid reader  either humanborne or robot-mounted  can use conventional rfid localization techniques  such as power modulation and received signal strength  to coarsely locate a tagged item  once in the general vicinity of the passive tag  its led can be individually addressed and commanded to flash  even though this light pulse is brief  both humans and camera systems can reliably see it and the location of the tag can be estimated within a few millimeters  although this technique does require line-of-sight from the human/camera to the tag  this layered approach of rf and optical localization combines the best of both worlds  furthermore  for a majority of usage scenarios that involve individual item identification as well as grasping  manipulating and sorting  line-of-site between the tagged objects and the human/robot is implicit  ii  led e nhanced passive rfid tag in order to quickly build and evaluate the performance of an optical localization system based on passive rfid tags enhanced with leds the wireless identification and sensing platform  wisp  was chosen for prototyping  the wisp is a programmable battery-free sensing and computational platform designed to explore sensor-enhanced rfid applications  the wisp uses a 16-bit  ultra-low-power microcontroller to emulate the epc gen2 protocol and performs sensing and computation tasks while operating exclusively from harvested rf energy  a full discussion of the wisps design and performance is presented in  7   the operation of the led-enhanced rfid tag is straightforward  in its default mode the tag acts as a standard epc gen2 tag  when the rfid reader issues a special command the tag flashes its led  in this work we used a standard off the shelf rfid reader and triggered the led by using the epc write command to write to a specific location in memory  in order to ensure that the brightness of the led is not depended on the distance from the reader  i.e  the received instantaneous rf power  the tag stores a small amount of charge on a capacitor and discharges that fixed amount of energy into the led  therefore as long as the tag can be powered  it will produce a strong and consistent led flash  the trade off is that the rate of the flashing is dependent on range  however  this was not an issue for our human or computer vision tests  although to date  the incorporation of a leds in to rfid ics is not readily available  recent work in semiconductor optics has shown promising results  the authors in  8    9  have developed cmos compatible leds operating at 23 volts  it is important to note that even with a cmos power & data epc id passive rfid tag uhf rfid reader  epc gen2  power & blink cmd flash led fig  1 diagram of a passive rfid tag enhanced with an led  along with an rfid reader and user tasked with locating a tagged item  when an rfid reader singulates an individual tag it sends a command that instructs the tag to flash its led  this provides visual feedback to the user  allowing him/her to quickly and easy find the tagged item  compatible process  additional packaging and charge storage issues would have to be overcome  alternatively  a three-component solution consisting of a custom rfid ic  surface mount led  and a small surface mount capacitor could easily be implemented today if so desired  one possibility is to extend the functionality of the rfid ic mounting strap  which is widely used in the rfid industry to include the additional components  for instance the strap would consist of an ultra thin pcb for mounting the ic  led  and capacitor onto  then the enhanced strap could be bonded to the rfid antenna in the same high volume manner as typically used in the rfid manufacturing process  iii  v isual f eedback a ided l ocalization one of the most common tasks in rfid enabled asset management and shipping application is the retrieval of tagged items by personnel  in this scenario the combination of both traditional rf based localization and optical localization methods can provide an effective solution  figure 1 shows a block diagram of the process  first the tagged item is coarsely located using either the binary  read / no read  method or a combination of rf power control and received signal strength to estimate tag range  these methods are robust enough that mobile  handheld readers can be used to locate passive tags to with in a 1-2 meters in unstructured multi-path environments  next the rfid reader issues a command to repeatedly flash the tags led  in our implementation  after receiving the write command the wisp goes into a low power state for 20ms in order to harvest additional power and insure that the capacitor is sufficiently charge  from a humans perspective the tag flash is nearly instantaneous after write command is issued  this visual indicator is very effective at aiding personnel in quickly locating tagged objects  as an example figure 2 shows books tagged with the led-wisp prototypes on a bookshelf  power & data uhf rfid reader  epc gen2  epc id epc protocol sniffer passive rfid tag power & blink cmd event trigger flash led fig  3 system architecture  the epc protocol sniffer is a wisp whose state mirrors that of the target led wisp ; it triggers the camera capture to ensure synchronization  a camera synchronization fig  2 demonstration of an enhanced passive rfid tag flashing its led when commanded to by an rfid reader  the wisp 4.1 platform is used for prototyping  the pop out shows a detailed view of the led flashing  which is clearly visible to spectators at distances over 10 meters  once the tag is flashing the book being targeted is clearly identifiable from nearly any location in our lab environment  finally it is important to note that there is no noticeable difference between the wisps read range versus the wisps led flash range  which is 4 meters  iv  overview of c amera s ynchronization and s ystem a rchitecture using the led-wisp  an automated system for locating tags with a rfid reader and camera has been developed  the system is able to query and locate a given led-wisp by its epc id and calculates a direction vector to that tag and confidence score  once the general vicinity of the rfid tags is identified using standard rf localization techniques  the camera takes two images of each led rfid tag  one with the led illuminated and one with the led off  these images are used to create a difference map  and since the only change between the images is the led flash  it is easy to identify the pixel location of the target led  this pixel location corresponds the direction vector emanating from the center of the camera towards the rfid tag  in order to determine range information several techniques have been employed as described in section v  vi  vii  the remainder of this section will focus on the methods and system architecture developed for capturing and computing the individual direction vectors for a population of tags  the basic task of identifying an illuminated led in a camera image is a fairly straightforward  however  due to the wirelessly power nature of the led enhanced rfid tags it is difficult to synchronize the brief flashes of light with the camera  for best signal to noise ratio  the camera exposure time window should coincide as much as possible with the led flash  in the naive approach of simply attempting to read the led wisp repeatedly  and taking a picture each time  the large majority of images would contain no flash at all  similarly an un-synchronize video camera is not able to reliably capture the 1ms pulse of light  to solve the synchronization problem  the rfid communication channel is used to communicate the tag power level to the reader  and a second packet sniffer wisp  whose state mirrors that of the led wisp  is used to trigger the camera  fig  3 shows the system architecture  including the sniffer wisp  first  the rfid reader issues a query command to the target tag  if the target tag has sufficient power to flash the led  it responds to the reader  the reader then issues a write command  upon receiving the write command  the target tag waits for a fixed time delay  then blinks  the packet sniffer wisp tag is wired to the cameras frame trigger  the sniffer wisp listens to the communication channel  waiting for write commands  when it hears a write command  it waits for the same time delay as the led wisp  minus an offset for the cameras latency   and then triggers a camera capture  by raising an output line that is wired to the cameras trigger input   it then triggers a second frame capture  in which the led is guaranteed to be off  b system architecture the system architecture for tag acquisition  camera synchronization  and data processing is depicted in figure 4 the function and interaction of these blocks are as follows  the host  the host provides the black box interface for the client  it communicates over ethernet with the rfid reader using the llrp protocol  it also listens for data from the camera  which is broadcast over ethernet via udp  when the host gets a request to locate a tag  fig  4 system networking diagram showing the camera synchronization and data processing blocks  it configures the reader to issue a write command to that tag  it then waits for a response from the camera  if a response is received  it is verified that a write command was issued to the target tag while waiting  and the location is returned  it also keeps track of pings sent out by the camera to monitor that the camera is operating correctly  the smart camera  the camera is triggered by the sniffer wisp  when triggered  it captures an image  the camera collects images in pairs  one led on  one off   performs the difference computation on board  and locates the maximum brightness change  it broadcasts its results over udp  currently these results consist of the location and magnitude of the brightest pixel from the difference image  and the magnitude of the most negative pixel  for our system  a ni 1764 smart camera was used for its high resolution  external frame trigger  and on-board processing capability  the rfid reader  the reader issues write commands as requested by the host  and provides power for the target tag  it also informs the host when it has performed the requested write commands  the sniffer wisp  the sniffer wisp sends a pair of triggers to the camera whenever is observes a write command from the reader  these are timed to allow the camera to capture the blink  and immediately after it  the target tag  the target tag charges itself from the reader  if it has enough power to blink  it will respond to the query command  once it receives a write command  it waits a fixed delay  then blinks  c theoretical camera precision the system provides a very precise direction vector towards the tag  for a tag in a fixed location  the system consistently chooses the same pixel  the average deviation from the mean position was only 0.16 pixels  this means the precision is limited by the cameras resolution and lens distortion  not by errors in measurement consistency  the current system uses a the ni 1764 camera in 1280 by 512 mode  this makes the resolution 1.3mm per meter to the target  the led wisps used operated out to a range of about 3.5 meters  making the maximum precision error from the resolution only 2.6mm  finally it should be noted that none of the cameras used have been calibrated to correct for the optical distortion of fig  5 still image from a single camera as the system localizes the led enhanced passive tag on the bookshelf  in this scenario two marker tags with known heights and separation are used to estimate the distance and pose of the bookshelf  this allows the rfid localization system to locate the tags in 3d space assume all tags line on the plane of the bookshelf  the lens  although advanced camera calibration is commonly used in computer vision it is beyond the scope of this work  which focused on proving the functionality and utility of led enhanced passive uhf rfid tags  thus the results present here represents a lower bounds on location performance  v p lanar 3d rfid tag l ocalization u sing m arker tags one common application scenario for rfid localization is the automated identification and localization of tagged inventory on shelves  this can take the form of warehouse storage  retail displays  and/or hospital supply rooms where it is important to insure that items are in the correct location so they can be quickly and easily accessed  the advantage of the shelving scenario is that line-of-sight from the rfid reader / camera system is generally implicit  as long as the tags are place on the outside facing surface of the item  figure 5 shows an image captured during the localization process  which consists of tagged books and boxes on a metal shelf in a lab environment  the led enhanced wisps are marked with red arrows  it is important to remember that in these images it is difficult for humans to readily identify the one or two pixels that represent an led flash  the camera takes two images  the first with the led on  the second not  approximately 100ms apart and then computes the differencemap to identify the correct pixel  in this experiment the rfid reader and single camera are placed 2 meters away from the bookshelf  this location represents a reasonable distance and bearing  from the reader to the tags  that can be achieved using rf only localization methods such as rssi and power modulated distance estimation  during the localization process the rfid reader inventories the tags and commands the individual wisps to blink their leds  for each led flash a single camera captures two table i m easured results for the single camera  3d planer tag localization method tag id 410* 416* 411 546 516 517 localization error in mm  x  y  z  camera position 1 camera position 2  -7.9  n/a  -14.1   -3.2  n/a  24.9   -7.8  n/a  -7.9   18.3  n/a  5.17   -5.8  -7.9  -11.9   5.5  -8.7  18.6   -7.5  1.4  -11.7   4.7  1.6  17.2   -5.5  8.6  -10.3   11.2  4.1  13.6   -8.3  8.4  -11.0   2.8  3.0  14.1  avarge precent error  from camera to tag  0.91 % 2.01 % 8.03 % 3.20 % 3.55 % 2.40 % * tags 410 and 416 are marker tags which provide a vertical reference point that aids in calculating the 3d location of the shelf and tags relative to the camera  fig  6 image of the reconstructed 3d tag locations  the green square represents the camera location along with the tag position vectors measured by a single camera  the black grid presents the estimated plane of the shelf which is calculated using two known marker tags  the red dots are the calculated tag positions and the blue circles are the measured location of the tags  images and calculates the position vectors  this is shown in figure 6  where the camera is represented as a green square and the position vectors are shown pointing towards the tags  at this stage the camera has only computed the 2d location of the tags  represented as angles  theta and phi   to extrapolate the 3d position of the rfid tags  two marker tags are place on the corners of the shelf with known heights from the ground  and known separation distance  the rationale for the marker tags is that they only need to be installed on the infrastructure once and provide a level of ground truth that helps with tag localization  furthermore  the marker tags can store the ground truth information in memory so that the rfid system does not have to query a database for the ground truth  if the camera height and angle from the horizon is known then the distance from the camera to each of the marker tags can easily be calculated  once the positions of the corners of the shelf are known then the pose and distance of the shelf to the camera can be computed in 3-d space  in figure 6 the plane of the shelf is represented by the black grid  assuming that all tag items lie on the plane of the bookshelf  it is straightforward to calculate the intersection of the plane and the position vector for the unknown tags  figure 6 shows the estimated position of the tags as red dots and the ground truth as blue circles  it should be noted that the actual position of the tags was not necessarily in the plane of the shelf  the ground truth measurements  i.e  blue circles  represent the actual 3d location of the tags  the results of this approach are quantified in table v the first sets of columns show the localization error for each tag in millimeters  the experiment was done for two camera positions  one facing the shelf and the second rotated and translated off to the side  it is believed that the predominate sources of error is caused by inaccuracies in estimating the distance of the marker tags to the camera  small errors such as the camera not being level and lens dispersion not being calibrated out cause larger errors in tag location estimation over the 2 meter distance from the shelf to the camera  furthermore  it is estimated that the accuracy of the ground truth measurements is only +/ 1.6 mm  tags 410 and 416 are the marker tags  since the height of these tags is known their error in the y  vertical  dimension is zero and this data is not applicable  n/a  for error analysis  over all the percent error from the camera position to the location of the tags is between 1-3 %  although it is believed that the accuracy of this localization scheme can be greatly improved by camera calibration these results show that it is possible to estimate the position of an led enhanced passive tag to within approximately 10 mm  to show the utility of this approach consider the rows of books on the shelf as shown in figure 5 on the center top of the shelf are side-by-side books that are tagged with led enhanced wisps  figure 6 and table v clearly shows that the relative position of these two books can be determined  this means that in a library situation it is not only possible to identify and coarsely locate books  but with this technique it is also possible to electronically ensure that the books are in the correct order  vi  f ull 3d tag l ocalization u sing s tereo c ameras there are many classes of rfid localization applications that require full 3d position estimation and thus can not rely on the planar 3d solution described in the previous section  examples include the tracking of moving objects  precision navigation based on rfid beacons/markers  and robotic grasping manipulation of objects in the home setting  to address these applications we propose to use externally triggered stereo cameras  each camera will simultaneously capture the rfid led flash and compute their respective direction vectors  the intersection of these vectors represents the 3-d location of the tags relative to the camera  stereo cameras are widely used in computer vision applications  however  the addition of individually addressable led enhanced rfid tags creates several unique benefits  to begin with one of the major challenges to implementing effective computer vision systems is the identification of corresponding points in the left and right images that are captured by the fig  7 left and right stereo camera images of tagged objects placed on the table  the led enhanced passive rfid tags are marked with red dots  stereo cameras  this is a very computationally intensive task that frequently fails  because conventional stereo techniques often fail to find the required point correspondences  the resulting depth images tend to be noisy and contain many regions with no depth data  in contrast  since the passive rfid tags presented here can flash their leds when commanded  corresponding points can be identified in the two camera images with extremely high reliability  in this scenario  two cameras  left and right  would each use the same synchronization method and pixel map detection technique described earlier  to identify the same led  i.e  point in space  between the two images  another challenge for computer vision systems is the segmentation of individual objects in the images  although it is possible to find corresponding features from one frame to the next using the techniques such as the scale-invariant features transform  sift   object identification is still an open research topic  however  with the use of an rfid reader and led enhanced rfid tags it is possible to simply query the scene and determine that there are six objects in a given region and that those objects are located at coordinates  x  y  z   figure 7 shows an image of tagged objects on a table  the led enhanced wisps are marked with red dots  in this experiment the checkerboard grid underneath the objects is not used for localization but instead is used to help measure the ground truth position of the tagged objects for later comparison to the calculated distances  once again the rf environment is unstructured  consisting of metal bookshelves and workbenches that create rf reflections  in fact the image shows that one of the tagged objects is a metal fire extinguisher  all of these unstructured metal objects make it difficult to locate the individual tags with millimeter resolution if out of band sensing mechanisms are not used  at the time of this publication two externally triggered cameras were not available  therefore  a single ni 1764 smart camera was simply moved to the left and right stereo camera positions in order to record the stereo data  this may result in some error in computing the tag location because the baseline distance between the left and right images may vary slightly when the cameras moved from position to position  the base line for this system  camera separation  is 200mm  furthermore ; the camera was not calibrated for optical distortion in the lens and image plane  figure 8 shows the reconstructed 3-d locations of the tags fig  8 image of the reconstructed 3d tag locations  the red and green squares represents the left and right stereo camera locations respectively  tag direction vectors for each tag are shown emanating from the camera locations  the red dots are the calculated tag positions and the blue circles are the measured location of the tags  and cameras/rfid reader  the red square represents the left camera position and the green square represents the right camera position  the direction vectors for each tag are shown as vectors emanating from the corresponding cameras  again the lengths of the vectors are arbitrarily scaled for the purposes of presentation  in order to determine the 3-d location of the tagged objects the intersection of each tags direction vector from the left and right camera is computed  the calculated position of the rfid tags are represented by red dots  the measured ground truth is shown by the blue circles  in this experiment no marker tags are used  thus each tag id represents a uniquely tagged object  the experiment was repeated for three camera locations  positioned at 0  16  and 32 degrees as rotated around the vertical axis of the table  the radius was approximately 1.5-2 meters  the location errors for each tag are shown in table vi  the results show that individual tags can be located within 10-20 mm  the overall percent error from the center of the stereo camera position to the location of the tags is between 1-6 %  these results show that it is possible to locate led passive rfid tags with greater accuracy then rf only methods previously reported  however  further refinements and imtable ii m easured results for the stereo camera  f ull 3d tag localization method tag id 546 416 411 410 517 516 localization error in mm  x  y  z  camera position 1 camera position 2 camera position 3  4.4  2.4  -10.5   -0.2  -8.3  -12.1   3.0  2.0  -7.3   -15.1  2.0  6.7   -18.1  -4.6  11.4   -9.6  4.4  8.1   2.7  8.1  -10.2   2.9  6.0  -7.6   4.1  2.8  -0.7   -2.1  -2.7  2.6   -1.3  0.1  0.8   -0.2  -2.6  2.9   -3.3  13.5  20.8   2.6  -9.5  4.6   -7.8  10.6  -1.9   2.0  -20.1  -3.2   -6.8  -13.9  12.3   0.2  -4.6  5.7  avarge precent error  from camera to tag  0.46 % 0.99 % 4.26 % 2.53 % 5.22 % 1.43 % provements in location accuracy is still possible using more sophisticated cameras and image processing techniques  vii  a pplication  robotic g rasping robot grasping in the unstructured human environment has been one of the critical bottleneck during the development of personal robotics  one of the difficult tasks for personal robots is to locate and grasp a particular object in the cluttered environment  rfid-enabled localization techniques such as rssi map have been proposed to facilitate object searching  however  scan can take a significant time to complete and signal strength fluctuation can cause problem  therefore  a more efficient and highly precise localization techniques is desired  in this section  we demonstrate the use of our proposed system to localize an object with the passive uhf rfid tag with integrated leds to enabled the fast and reliable object searching and grasping in the cluttered environment  a system setup we integrated our localizing system on the standardized hardware and software of the willow garage pr2 robot  figure 9 shows the ni 1764 smart camera and a rfid antenna are mounted on the pr2s head next to the existing depth sensor  microsoft kinect   all host software is implemented as a robot operating system  ros  node to control the camera  the rfid reader  and the sniffer wisp  b experiment our goal was to enable the robot to recognize and locate individual tags object clustered on table at human-like speeds  without servoing for the peak signal in rssi  the robot will find the target object with the led enhanced passive rfid tag from a pile of objects on the table  and then grasp it  the steps are described below  1  the rgb-d type sensor on the pr2s head  kinect  is used to create a 3-d point cloud of the all the objects on the table  fig  10  a  shows the image seen from the kinects view  in this example  there are 19 objects on the table  fig  10  b  shows the 3-d environment perceived by the robot using kinect sensor visualized by rviz  a 3-d visualization tool in ros  although  the point cloud is segmented into different blobs of points  it is difficult for the robot identify unique objects  2  next the robot initializes the rfid localization method as described in section iv  when commanded to the led enhanced wisp flashes its led and the ni 1764 camera locates the tag and returns a direction vectors to ros  the blue line in 10  a   b  indicate the direction vector to the led wisp  only the detection with confidence scores over a certain threshold is used  the robot will redo the detection until a valid detection is found  3  a ros service node is used to select the desired object cluster  given all the object clusters and the direction vector  it selects the object closest to the direction vector by finding the centroid of each object on the table and compute the distance between the centroids and the fig  9 willow garage pr2 robot equipped with the rfid antenna  the sniffer wisp  and the ni 1764 smart camera on the head provide the capability for localizing the led enhanced passive rfid tags  the rgbd type sensor  microsoft kinect  provides the 3-d pointcloud as the basis of robot perception  direction vector  due to the different views of the kinect cameras and the ni smart camera  we calibrate the poses of the two camera frames and transform the 3-d point cloud obtained by the kinect to the smart cameras frame before all the data processing  4  after the desired object is correctly selected  the robot plan a feasible grasp for the selected object  fig  10  c  show a successful grasp result  c results in order to examine the accuracy of this object localization method the target object is placed at 20 different positions on the table  which is in the view of both the kinect and ni 1764 cameras and the rfid reader  during the experiment 19 out of 20 trials resulted in successful object detection  this means that in one trial an error occurred when determining the intersection of the tag direction vector and the point cloud  after object detection was completed the robot moved onto the task of grasping the object  where 17 out of 19 trials where successful  the results show our system enables the robot to quickly and accurately find the desired object by optically localizing the passive uhf rfid tags with integrated leds  viii  c onclusion this paper addresses the issue of locating passive rfid tags in uncontrolled and unstructured environments by augmenting the tags with an led that can be flashed when commanded by an rfid reader  this passive  i.e  battery free  solution overcomes the multi-path issue faced by traditional rfid location methods and provides greater position accuracy then previously reported methods  a prototype of a passive  led enhanced rfid tag is presented using the wisp platform  and methods for manufacturing a low cost  high volume version are discussed  in its most basic form the led enhanced tag provides a highly effective method for guiding people to tagged objects that can be individually address with an rfid reader  more sophisticated methods of computerized tag localization are demonstrated using both  a single camera approach for 3d planer tag estimation and stereo cameras for full 3d tag localization  both of these methods use an external protocol sniffer to trigger the cameras to capture the brief led flashes from the rfid tags  these techniques show that the tags can me localized to with in 10-20 mm accuracy  a final demonstration of the utility of this new capability is shown using the pr2 robot from willow garage  in this example tagged objects on a table are individually commanded to blink and there location is identified by the camera system on the robot  using this information the pr2 robot is then able to efficiently and repeatedly pick up objects from the table  r eferences fig  10   a  the image acquired using the microsoft kinect overlayed with the direction vector  the blue line  of the target object detected by the system  the green block indicates the planned grasp pose which the robot attempts to perform   b  the 3d world perceived by the robot sensors  the different clusters with colors showing different segmented objects on the table   c  the resulting grasping on the object with the led wisp on it   1  a chattopadhyay and a harish  analysis of low range indoor location tracking techniques using passive uhf rfid tags  in radio and wireless symposium  2008 ieee  jan 2008  pp  351 354   2  d hahnel  w burgard  d fox  k fishkin  and m philipose  mapping and localization with rfid technology  in robotics and automation  2004 proceedings  icra 04  2004 ieee international conference on  vol  1  april-1 may 2004  pp  1015 1020 vol.1   3  p nikitin  r martinez  s ramamurthy  h leland  g spiess  and k rao  phase based spatial identification of uhf rfid tags  in rfid  2010 ieee international conference on  april 2010  pp  102 109   4  s sarkka  v viikari  m huusko  and k jaakkola  phase-based uhf rfid tracking with non-linear kalman filtering and smoothing  sensors journal  ieee  vol  pp  no  99  p 1  2011   5  r miesen  f kirsch  and m vossiek  holographic localization of passive uhf rfid transponders  in rfid  rfid   2011 ieee international conference on  april 2011  pp  32 37   6  r raskar  p beardsley  j van baar  y wang  p dietz  j lee  d leigh  and t willwacher  rfig lamps  interacting with a self-describing world via photosensing wireless tags and projectors  in acm siggraph 2004 papers  ser  siggraph 04 new york  ny  usa  acm  2004  pp  406415   online   available  http  //doi.acm.org/10.1145/1186562.1015738  7  a sample  d yeager  p powledge  a mamishev  and j smith  design of an rfid-based battery-free programmable sensing platform  instrumentation and measurement  ieee transactions on  vol  57  no  11  pp  2608 2615  nov 2008   8  l snyman  m du plessis  and e bellotti  photonic transitions  1.4 ev  2.8 ev  in silicon p+ np+ injection-avalanche cmos leds as function of depletion layer profiling and defect engineering  quantum electronics  ieee journal of  vol  46  no  6  pp  906 919  june 2010   9  k chilukuri  m j mori  c l dohrman  and e a fitzgerald  monolithic cmos-compatible algainp visible led arrays on silicon on lattice-engineered substrates  soles   semiconductor science and technology  vol  22  no  2  p 29  2007   online   available  http  //stacks.iop.org/0268-1242/22/i=2/a=006 