j intell inf syst doi 10.1007/s10844-016-0423-6 a statistical approach for modeling inter-document semantic relationships in digital libraries jeyavaishnavi muralikumar1 sri ananda seelan1 narendranath vijayakumar1 vidhya balasubramanian1 received  7 february 2016 / revised  1 july 2016 / accepted  3 july 2016 springer science+business media new york 2016 abstract e-learning repositories and digital libraries are fast becoming important sources for gathering information and learning material  such systems must therefore provide services to support the learning needs of their users  when a retrieval system shows how its documents relate to each other semantically  a user gets the liberty to choose from different material  and direct his/her study in a focused manner  this calls for a model that identifies types of document relationships  that need to address different aspects of learning  this article defines three such types and a unique statistical model that can automatically identify them in technical/scientific documents  the model defines measures to quantify the degree of relatedness based on distinct statistical patterns exhibited by the common terms in a pair of documents  this approach does not strictly require a knowledge base or hypertext for identifying the characteristic relationship between two documents  such a statistical model can be extended to build further relatedness types and can be used alongside various other techniques in digital library recommendation engines  our experiments over a large number of technical documents show that our techniques effectively extract the different types of relationships between documents  keywords relatedness information retrieval digital libraries statistical modeling 1 introduction automated guidance for users of digital libraries is provided through suggestions based on the content similarity of the documents  citations  or by matching other meta-data like authors  keywords  topics  etc  however  retrieval over such libraries must also provide vidhya balasubramanian b vidhya @ cb.amrita.edu 1 department of computer science and engineering  amrita school of engineering  coimbatore  amrita vishwa vidyapeetham  amrita university  coimbatore  india j intell inf syst information in a way that the learning objectives of a person seeking information are met  and ensure that the browsing experience remains focused  this applies especially to scientific documents  such as in the case of a person doing a scientific literature survey  several such learning objectives that must be addressed have been proposed  with respect to scientific literature  the model proposed by mccormak and yager  frantzi et al  2000   outlines the different aspects of learning like `knowing '  `exploring ' and `using '  services that can support automatic suggestions to enable the user experience these aspects are desirable in a digital library  keeping in mind these aspects of scientific learning  we first identify different aspects or dimensions in which documents are related so that it will be helpful for a learner  we consider three factors that are important in helping a learner browse through a repository of technical/engineering documents  when exploring a new set of concepts  the user might not have sufficient knowledge to  decide what documents to look at next in the sequence know where to look for a more detailed explanation of a concept  when the concept is insufficiently described in the current document see where the concept may be applied if this information is not present in the current document an automated system modeled to provide such document suggestions  that can enable the learner overcome these kinds of difficulties is desirable  such a system must be able to identify the nature of connection or relationship that occurs between the content of documents  and present appropriate suggestions at each stage of the learning process  while there are plenty of models for identification of concept and semantic relatedness  definition of document relationships has been less extensively studied  khoo and na 2006   this gives rise to the need for a novel relatedness model for identifying semantic relationships between documents from a learner s perspective  our work focuses on relationships that capture the above three requirements  specifically we are interested in determining if a document di  or a part of it  represents a `continuation '  `elaboration ' or `application ' of a document dj  or a part of it   there are two approaches for identifying these relationships between two documents  one is to use a knowledge based approach  where the concepts and their relationships are modeled  and the other is to use a statistical approach  in the former  known relationships between concepts in the documents have to be used to infer the underlying relationship between the documents  knowledge based approaches can be used to directly infer concept level relationships ; however  techniques have to be developed to infer the above relationships from concept level relationships  for instance  consider a document a that is about stacks  that briefly mentions linked lists from an implementation perspective  while there is a conceptual relationship between stacks and linked lists  the presence of the concept linked lists in another document  say b  does not necessarily make it the right document for giving a detailed insight into linked lists  unless we can be certain that linked lists is indeed the major topic in document b  in addition  knowledge sources are only available for some domains and for many other domains are not comprehensively defined or are yet to be generated  therefore  a technique to automatically identify the dominating relationship  s  between two documents and to quantify the strength of the relationships without much domain knowledge is essential  it is desirable to infer these relationships from the documents themselves  and hence we use that j intell inf syst as a start point for addressing this problem  in this article  we intend to present a comprehensive approach that identifies such requirements without relying on external knowledge  in future it can be extended to include semantic knowledge derived from external sources  in order to identify the inter-document relationships  we use an approach that analyzes the statistical patterns within documents and uses these to infer their semantic relationship  we approach this problem of identifying and characterizing document relationships  with a premise that the semantic structure of a document is brought out by the occurrence patterns of terms and their context of usage in the document  quantification of these aspects can be done using statistical measures  for example  measures like c-value and tf-idf  frantzi and ananiadou 1996 ; balagopalan et al  2012  characterize the degree of importance of a term in a document  we characterize the relationships between two documents using such features  such a characterization constitutes our relatedness model to identify and quantify the different kinds of relationships between documents  the final goal of this relatedness model is to provide scores based on these measures that indicate the strength of such relationships between documents  such scores can be used to provide suggestions of related work and guidance to users of digital libraries  along with an indication of how the suggested work is related  such functionality would further the development of recommendation systems and innovative visualizations  that can aid the users of a digital library  our specific contributions in this paper are the following  defining types of document relatedness that would serve learning needs of consumers of scientific/technical content identifying patterns between documents that characterize different relationships  based on extensive analysis of sample document data sets development of measures to quantify different types of relationships using the identified features extensive experimentation and evaluation as that validates the above the rest of this article is organized as follows  section 2 outlines the related work and the following section introduces the three relationships and describes the approach taken to identifying characteristics of these relationships  that can contribute to detecting/quantifying them  in section 4 we give formal definitions of these relationships  and also introduce measures to quantify the strength of these relationships for a particular instance  these are validated in section 5 by describing extensive experimental results  finally  we conclude in section 6  2 related work relatedness has been widely studied in the context of concepts  paragraphs  terms and documents  and there have been many measures that solve the problem of quantifying semantic similarity and semantic relatedness  the most fundamental relation that can occur between documents is the similarity relation  cosine similarity and jaccard similarity coefficients are examples of statistical measures that can be used to find the similarity between documents or text fragments  the cosine measure is fundamental  as it is used in other techniques for estimating similarity  such as those that rely on external knowledge  as well as those that do n't  i.e  lsa   j intell inf syst similarity measures that involve computing semantic similarity or relatedness through analysis of an external knowledge base sometimes use a reference corpora  the normalized relevance distance  schaefer et al  2014  is one such recent corpus-based measure  built on the normalized compression distance  otherwise  they typically use a graph such as wordnet  agirre et al  2009 ; capelle et al  2013  or wikipedia  or the world wide web  a well established method is the explicit semantic analysis  esa   gabrilovich et al in gabrilovich and markovitch  2007  use esa with the wikipedia document corpus as the knowledge base and compute the relatedness measure between documents using cosine similarity  other approaches based on wikipedia hyperlinks gouws  2010   strube and ponzetto  2006   turdakov and velikhov  2008   while using wikipedia has its advatages  as argued by denning et al   2005   using such a knowledge base has its own risks like uncertain expertise of contributors  in contrast to esa  latent semantic analysis  lsa   foltz et al  1998  is used in natural language processing to find the degree of similarity between two pieces of text without an external knowledge base  here the similarity is found by using the cosine index method  probabilistic latent semantic analysis  hofmann 1999   another method that evolved from lsa uses a probabilistic model to find similarity between documents  both lsa and probabilistic lsa account for issues such as synonymy and polysemy but are used to determine only similarity or association relations whereas a more comprehensive set of relations is required in a digital library scenario  user interest-based approaches like collaborative filtering involve user profiling in recommendation systems  hopfgartner 2010 ; lai et al  2013 ; huynh et al  2012  and may account for relations beyond similarity  though such techniques identify connections between different documents  the problem of quantifying the different types of context-based relatedness between them remains unsolved  citation links have been widely used to capture document relationships   zarrinkalam and kahani m 2012  is one example   but do not always guarantee a semantic relation  bean and green 2001   also  methods involving hypertext are limited to structured text documents and can not be used for unstructured text  video/audio transcripts or documents such as lectures which do not have citations  links  headings or sub-headings  similarity measures have also been used for the classification and clustering of documents  it has been stated that the fundamental measures such as the cosine similarity  pearson coefficient and kld are effective at identifying similar documents  works like huang  2008   chalmers and chitson  1992  and andrews et al   2001  describe clustering of similar documents  researchers have defined similarity measures that are based on topic/concept representations of the documents as discussed in rafi and shaikh  2013  and huang et al   2012   works like wan and peng  2005  and wan  2007  define document similarity measures that are based on similarities between different segments of the document  thus taking term distribution into account  much of the above work focuses on the generic similarity relation between documents  gonzalez-agirre et al   2015  lists some types of semantic similarity between documents  these works  similar to aletras et al   2012   concentrate on digital libraries with cultural items  however  work on types of relatedness in an educational context for the particular case of academic/educational documents is hard to come across  in this article  we define a relatedness model that serves the learning needs of users in such a context  which is generic enough to be meta-data independent  we do n't directly opt for a graph-based or knowledge-based approach since  it may not always be feasible to analogize a document to a particular concept or a wikipedia article  not least because said piece of literature may feature multiple topics  therefore  we go for a statistical model that j intell inf syst uses the context of term usage and other intrinsic term features to identify inter-document relationships  3 relatedness modeling our goal in this section is to model the different types of relatedness using different statistical measures  the scope of this paper is to meet the needs of a user in a digital library which typically is a heterogeneous collection of educational content such as scholarly articles  video and audio lectures  our measures should be generic so as to work for all of these types of content  additionally  digital libraries are often intended for learning or research requirements  and the relationship types between documents must serve such requirements  therefore the relatedness types are chosen so that they correlate with the five aspects of teaching and learning science education literature proposed by mccormak and yager  frantzi et al  2000   which are 1  knowing and understanding 2  exploring and discovering 3  imagining and creating 4  feeling and valuing and 5  using and applying  while there are several models that refer to aspects of teaching and learning  for scientific documents  the yager model is the most appropriate  we map three of these categories of learning objectives which can be primarily related to information access  to the potential document relatedness categories  these relatedness categories are continuation  application/ implementation and elaboration  the other aspects i.e  imagining/creating and feeling/valuing deal with factors beyond the scope of information access in digital libraries and hence are not considered  a person making a literature survey by browsing a repository of documents tries to `` explore and discover '' information through a series of logical sequences or paths  any such path can lead to discovering information  however  we focus on providing a channelized series of document suggestions  the simplest would be when the information flow is continuous  this type of an exploration process of a learner motivates the presence of the `` continuation '' type between two documents  i.e  when there is a natural progression from the content of a document to another  `` application/ implementation '' directly correlates to the `` using/applying '' category  this relationship helps the learner to know about how a particular concept defined or mentioned in a document is applied or used in another document  an inquisitive user who needs a comprehensive understanding about the concept that is discussed in a document gets benefited when documents are presented that consist of information which are `` elaboration '' of that particular concept  this directly corresponds to the `` knowing and understanding '' aspect  while the `` continuation '' type helps the user to browse through a set of documents that reflect a single continuous flow of concepts  the latter two types serve more specific purposes which involve presenting a diversified chain of concepts helping the learning process  in short these three types of document relatedness correspondingly answer the following queries of the user  `` i understand this lecture/material  what document do i look at next ? '' `` i have understood the concept described in this lecture/document  but where and how is it actually used ? '' `` i need a better understanding of this concept in this document  where can i find more information on it ? '' in the rest of this section  we discuss base patterns that help quantify the strength of these relationships  j intell inf syst 3.1 statistical term features two documents are related by the content they share  including common terms or phrases  we use these common terms or phrases to develop a statistical model for identifying the type of relation they may have  to do so  we consider the following properties of such terms  the relevance of a term or phrase to each document  the distribution or occurrence pattern of a particular term in each document  the relevance of a term indicates how significant it is  and how much it represents the topic featured in the document  this is important in the identification of the specific relation between the documents  in addition  each relation is defined by using the occurrence patterns of these terms rather than just their occurrence or term frequency  we therefore identify features that quantify either of these properties  these features are the c-value and tf-idf for measuring relevance  and d-span for measuring occurrence patterns  they are defined as follows  c-value we make use of the c-value defined in frantzi and ananiadou  1996   this measure quantifies the relevance of a term to the subject of its document  mccormack and yager  1989  discusses how to use c-value as a context measuring factor for terms present in a document  c-value looks at both linguistic and statistic features to determine if a term is potentially a keyword or keyphrase  a term has a high c-value if it has high frequency and occurs infrequently as part of longer candidate phrases  which makes it very relevant to the main theme of the document as described in balagopalan et al   2012   for a term a  c-value is defined based on its length |a |  frequency f  a  and the set of larger terms that contain a  ta with length |ta |   the mathematical definition of c-value is given by  1   c -v alue = log2 |a | f  a   1  log2 |a |  f  a    |t a| if a is not nested f  b     otherwise bta  1  tf-idf the tf-idf is an elementary feature in information retrieval and defines the relevance of a term to a document as a product of term frequency and inverse-document frequency  d-span d-span is a measure of both how widely a term is distributed in a document  and the frequency of occurrence of the term in the document  to measure how well a term a is spread across a document we use the feature `` dispersion ''  defined in balagopalan et al   2012   the occurrences of a term a are represented as ia  with each element in ia being the number of words between successive clusters of the occurrence of a  each cluster is the set of occurrences of a within k words of each other  where k is experimentally determined  dispersion  then  is defined as the ratio of the length of ia   |ia |  to the variance of ia  var  ia    |ia | dispersion  a  =  2  var  ia  we define d-span as follows  d -sp an = wordcount dispersion  3   4  wordcount = t f  a   t f  t  t in ta in this equation  `wordcount ' is the term frequency  after eliminating the occurrences of the terms as part of larger n-grams  terms that occur throughout and often in a document have higher d-span values  j intell inf syst 3.2 identifying patterns in term features in order to provide a starting point for the definition of our intended measures of the types of relatedness  we made some exploratory visualizations and we observed that studying patterns in d-span and c-value was helpful  we start with two basic premises  documents featuring similar subjects use the same terms to similar extents  and hence will have common terms with similar d-span values  documents that have related  but not similar subjects would have the same terms  but in different contexts  hence  they will feature common terms with differing c-values  let us consider two documents d1 and d2  having a collection of t common terms  t  every i th term in t is present in both d1 and d2 and has a d-span and c-value in both d1 and d2  consequently  every term in t has a difference or similarity in its d-spans or c-values in the two documents  this difference or similarity would indicate the varying context in which this term is used  and could potentially help identify how d1 and d2 are related  we consider the average c-value difference and the aggregate d-span similarity for all terms in t  and see if these are indicative of any type of relatedness  for a set of n documents  we would have n n pairs of documents  each pair of documents have t common terms  with d -sp ann  i  being the d -sp an of common term i in document n  and c -v aluen  i  being the c -v alue of common term i in document n each such document pair   d1  d2  is then characterized by  dsim  cdiff   where  t dsim = i =1 1  |d -sp an1  i   d -sp an2  i  |  5  cdiff = 1 t t c -v alue1  i   c -v alue2  i  1  6  fig  1 birch clustering of nxn document pairs j intell inf syst table 1 evaluation of clustering result for nxn document pairs balanced f-score normalized mutual information 0.59 0.6 after eliminating document pairs with feature values below a certain threshold  the remaining dsim and cdiff values are min-max normalized and run through an implementation of birch  zhang et al  1996   with an unspecified number of clusters  the result for an original data set of 123 documents is shown in fig  1 we do not include all n n document pairs in our visualizations  since it can hardly be expected that all 1232 pairs will feature a semantic relation  as a means of reducing the noise  we only included document pairs which had dsim or cdiff values higher than the majority of the data points  the filter was determined arbitrarily by making a histogram  and eliminating the densest bins  for evaluation  we took smaller sample sets out of the n n document pairs  and calculated balanced f-score and nmi  each of the sample sets had data points for one particular document  and had about 15 document pairs  based on expert estimation  the document pairs were classified as exhibiting continuation  elaboration or application  and f-score and nmi were calculated between the expert 's classification and the clustering result  the average nmi and f-score values are shown in table 1  and are promising  the nmi value is an indication that clustering based on these features is informative as to determining the relationship between d1 and d2  however  the moderation of the nmi and the f-score is also an indication that precision of the classification should be improved  and it is necessary to augment these patterns and to come up with reliable measures  consider a document pair d1  d2 with d1 as the source document  and d2 being its continuation  application or elaboration  our particular observations are as follows  document pairs exhibiting continuation have tended to end up in the far right cluster  consisting of data points where aggregate dsim is high document pairs exhibiting elaboration have been observed in the bottom-left cluster  with negative cdiff  indicating higher c-value of common terms in the elaboration document  d2  document pairs exhibiting application have been commonly observed in the top-left cluster  where cdiff is positive  indicating higher c-value for common terms in the source document  d1  for the set of documents tested here  their pairwise relationship was determined using domain experts  this serves as the basis for the above analysis  the likelihood that a particular relationship r  say  continuation  is characterized by the corresponding pattern  in this case  high d-span similarity among common terms   can be simply estimated by applying the bayes rule for a random set  let us consider a set of data points with the above mentioned features  the classical probability of a data point belonging table 2 estimation of bayesian probabilities that types of relatedness characterized by specific feature score patterns type of relatedness continuity elaboration application score pattern medium to high dsim negative cdiff ; c-values higher in the elaboration positive cdiff ; c-values lower in the application estimated probability 0.75 0.65 0.59 j intell inf syst to a particular cluster c1 can be readily calculated  similarly  the conditional probability that a data point in c1 exhibits r can also be calculated  doing the same for the complementary cases  we can easily estimate the likelihood that the score pattern represented by the c1  such as high dsim or low cdiff  indicates the relationship  these probabilities  estimated for a random set  can be found in table 2 this random set had 20 different documents  and 37 document pairs were clustered after points with low dsim and low cdiff were eliminated  the relation exhibited by a particular pair  was decided by an expert user  these figures indicate that our relatedness measures may be built on these particular patterns  although further validation needs to be done  we now extend our observations to more formally define these relations in the next section  we also describe measures to quantify each type of relatedness and provide ranked suggestions to the user  motivated by the identified patterns and some additional observations  later  we validate these measures by extensive evaluation on their performance on varied data sets  4 defining and quantifying types of relatedness before we define each type of relatedness  we first state the idea that it is not always the most relevant terms that contribute to the relationship between a pair of documents  it is particularly important to keep this notion in mind when we deal with the types elaboration and application  for instance when looking for elaborations  users are usually looking for elaborations of less prominent topics or concepts featured in the media in question  which we may expect not to be represented by the term in the document with the highest c-value or term frequency  therefore  there is a need to formalize different classes of common terms that can play a role in the definition of these relatedness types  we categorize terms in a document based on their contribution to the content of the document  the role played by a term in a document can be determined based on its context and relevance  from the definitions in section 3  it can be understood that a term having high c-value tends to be more contextual to the core content of the document  similarly  high tf-idf means the term is very relevant and particular to that document  even if it does not directly relate to its core topic  a good d-span score indicates that the term is used well throughout the document at regular intervals  topic  a term can fall under this category if it is the subject of a discussion  lecture or an article  and is characterized by high c-value  high tf-idf and high d-span subtopic  subtopic term is also a subject of a discourse  but not the most prominent one  this term is characterized by moderate c-value  moderate tf-idf and low or moderate d-span background  a background topic term does not define the central theme but is generally a concept that is used to support the discussion of the topic  a background term is characterized by relatively low c-value and low tf-idf and low or moderate d-span for instance  in a lecture on queues  `queue ' would be a topic term  terms such as `circular queue ' and `double-ended queue ' would be subtopics if they were talked about for a while  and terms denoting  say  algorithmic complexity or liked lists may be background terms  it is straightforward to train a rule-based classifier to classify terms as topic  subtopic or background  table 3 shows some more examples of such terms and their classes  we now proceed to define the three relationships  which we will define on a logical level  as well as based on these categories of terms  we also motivate a definition of measures to j intell inf syst table 3 sample feature scores for topic  subtopic and background terms term topic terms binary search machine learning context free grammar quick sort subtopic terms supervised learning functional languages base address logical notation background terms increasing order linked list root node left child quick sort trees trees trees 0.07 0.06 0.05 0.09 0.08 0.06 0.05 0.09 0.08 0.03 0.03 0.04 intro to machine learning syntax pointers logical inference 0.23 0.23 0.43 0.26 0.35 0.3 0.36 0.24 0.14 0.11 0.14 0.13 binary search trees intro to machine learning grammar quick sort 1 1 0.78 1 0.92 0.78 1 1 0.21 0.24 0.45 0.47 title of document tf-idf c-value d-span rank documents based on these relationships  by using the patterns mentioned in section 3.1 to characterize their strength  4.1 defining and quantifying continuation the `continuation ' relation provides answers to the query type `` what must i study next ? ''  here we expect a document d2 that follows d1 to lie within the larger subject domain of d1  and thereby exhibit some level of similarity in both content and flow of the content  when we say that document d2 is a continuation of document d1  we consider two aspects  d2 can continue the same topic as d1  i.e  two documents demonstrate considerable similarity with respect to the usage of topic terms  for instance a lecture on `` hashing and hash functions '' is continued by the lecture on `` universal hashing ''  here topic terms like `` hashing ''  `` hash tables '' are spread uniformly and widely in both lectures  d2 can also continue a subtopic explained towards the end of d1  here again there is considerable similarity in the subtopic terms  d2 and d1 can talk about the same domain characterized by similarity in background terms  hence indicating a natural progression of topics within the same domain  for instance  a lecture on `` dynamic programming '' can be a potential continuation for a lecture on `` greedy algorithms ''  they would use common concepts such as optimization  analysis  etc which are background topics or common subtopics like `` knapsack '' if both documents delve into the same examples  we base our continuation measure on both the spread of the common terms and the importance of the common terms to the document pair  i.e  the d-span and tf-idf of common terms  as shown in section 3.2  similarity in d-span values can be an indicator of the continuation relation  continuation therefore differs from similarity measures like cosine similarity or lsa  these measures usually only consider the similarity in term frequencies or tf-idfs  but not the occurrence patterns of the term  j intell inf syst for characterizing continuation  d-span is an important measure  the d-span score is a measure of term usage of a document ; similar d-span scores for a term in two documents means that the term is used to an equal extent and with equivalent scope in both documents  while the spread of common terms is a good indicator of continuation  the relevance of the common terms to the target documents is also an important factor to be considered  experimentally  we have seen that the effectiveness of the d-span measure is further improved by taking into consideration the td-idf value  which has been widely used as a term weighting feature in query-document retrieval  therefore we consider the tf-idf as a direct measure of relevance  though tf-idf is not always directly used as a probability function for relevance  it is considered as a measure of the probability of relevance  wu et al   2008   schaefer et al   2014    the use of a tf-idf weight means that the high distribution similarity of more relevant terms indicates a stronger instance of the continuation relation  this is illustrated with an example in fig  2 the combined use of these features means that the d-span similarity of terms with higher relevance defines the continuation relation  for a strong continuation relation  the documents must feature high d-span similarity for common terms of varying relevance  as measured by the tf-idf value of the terms in these documents   whereas documents that do not exhibit this relation are expected to have a high d-span similarity only in common terms of low relevance  in terms of behavior of topic  subtopic and background terms  documents that are related by continuation have a high d-span similarity in all these kinds of common terms whereas documents that do n't  may only be expected to have a high d-span similarity in the background terms  taking these factors into account  we define the continuation measure as  n 1 rc = ri  7  n ri = mint f -i df  i  dsim  i   8  in the above equation  dsim  i  is the dsim value for the i th common term between the two documents  and mint f -i df  i  is the minimum of the tf-idf values of the i th common term in the two documents  n is the number of common terms  to boost the effect of terms with high d-span similarity and high minimum tf-idf  ri can be further weighted by a constant factor  minimum required d-span similarity and tf-idf is empirically determined by analyzing the data sets  we used a 1.3x boost for such 1 fig  2 tf-idf vs d-span similarity patterns for `` dictionaries '' and `` hash tables ''  which are closely related  left  and `` hash tables '' and `` virtual memory ''  which are related by application  right  j intell inf syst terms  using such a boost helps counteract the effect of having a large number of terms of low relevance and low d-spans but high d-span similarity  that actually do not contribute to the continuation relation  4.2 defining and quantifying elaboration this relation helps the user find answers to the type of queries which can be represented as `` where can i find more information about this ? ''  usually  the user does not have such a query about the main topic as it would have been explained well in the same document  however  the same may not be the case with the background topics or subtopics  in such cases  elaborations would be those documents in which terms related to background or subtopics are featured more prominently i.e  are topic terms  for example  consider a learner who is studying `` virtual memory ''  there may be references to `` hash tables '' which are commonly used for address mapping  here  a lecture on `` hashing '' would help gain the necessary background knowledge  when a document d2 serves to provide this background knowledge for some concept that has been briefly covered in document d1  d2 is an elaboration of d1  since the elaboration relation  by definition  requires concepts to be featured more prominently in d2  this implies that common terms are both more relevant and have a higher and wider occurrence in d2  we have seen in section 3.2 that a general trend of higher c-value in d2 is evidence for elaboration  this indicates a higher relevance of some terms in d2  since we want these terms to have been explained adequately as to inform and fulfill the 'knowing and understanding ' learning need of the user  it follows that the d-span of these terms must be greater in d2  in other words  the elaboration relation is defined by the presence of common terms which are background or subtopic terms in d1  but have a higher relevance in d2  from our definition of topic  subtopic and background terms  elaboration is characterized by the following features  since a background topic in d1 is a topic in d2  the c-value of the elaborated term will be lower in d1  therefore  we consider common terms with a higher c-value in d2  since d2 is the elaboration  the common terms are used to a greater extent in it  therefore d-span of common terms will be greater in d2  where they would be topic terms  we count the difference in d-span as a measure of the elaboration relation  hence we examine the d-span differences of those common grams which have a higher c-value in d2 and define the elaboration measure as follows  n re = i =1 d -sp an 2  i   d -sp an 1  i  terms with c -v alue2  i   c -v alue1  i  > 0  9  equation 9 is meant to be an estimate of the strength of the elaboration relationship  a higher value of re means a greater likelihood of the document pair to be exhibiting this relation  that is  the destination document will have a higher d -sp an value for terms that exhibit higher c -v alue in the destination document  j intell inf syst 4.3 defining and quantifying application an application of a concept helps a learner understand where it is actually used  we can consider documents d1 and d2 as being related by application if they satisfy one of the following cases  document d2 or part of it applies the main concept or a subtopic in a document d1  here topic/subtopic terms in d1 are usually background terms in d2 since it is assumed that d2 is from a different domain or sub domain  for example  `` query processing '' is an application of `` dictionaries ''  however a discussion on `` query processing '' will not give much importance to dictionaries  hence  `` dictionaries '' becomes a background topic in `` query processing ''  both d1 and d2 share similar background terms  while d2 applies concepts in d1  that is  the application is not explicit  causing the background terms to be present in the applying document  for instance a discussion on tower of hanoi applies recursion  thereby also implying an application of a document on stacks  this type of indirect application is not considered in this paper  since we expect that the concept being applied is represented by terms that are less prominent in the application  we can expect it to have a lower d-span in d2  coupling this factor with the c-value difference established in section 3.2 leads us to a definition of the application measure that is very like the opposite of the previously introduced elaboration measure  even though they are n't inverses of each other  n ra = i =1 d -sp an 1  i   d -sp an 2  i  terms with c -v alue1  i   c -v alue2  i  > 0  10  when the relative c-value of terms is very high and so is the relative d-span  it indicates that the main topic in d1 is applied in d2  on the other hand  when both the relative c-value and d-span is moderate  it indicates a subtopic being applied  based on the equation  the identifying feature of application is the presence of common terms which are topic terms in d1  but subtopic terms in d2  equation 10 is an inverse of the elaboration equation  since it does not consider all aspects of the application relation  it is a preliminary measure  which must be expanded with more features  currently  we leave this as a direction for future work  nevertheless  it is rather effective in identifying the application relation  as shown in the next section  5 experimentation and results we have so far discussed our inter-document relatedness model that captures three important aspects of relatedness in scientific document  in this section  we analyze the performance of this model  to evaluate the relatedness model and the measures defined  we develop a prototype system that identifies the relatedness between each pair of documents in a data set  j intell inf syst fig  3 architecture of proposed system 5.1 prototype system the architecture of this system is shown in fig  3 the prototype system works on a database repository that consists of over 1600 media files  including articles  theses and videos and associated transcripts of classroom lectures  candidate keyphrases from the documents are extracted after common pre-processing techniques such as stop word removal  stemming  n-gram extraction and pos tagging  based on the feature vectors representing tf-idf  c-value  and d-span scores for the candidate keyphrases  balagopalan et al  2012   the document relation scores defined in section 4 are calculated between each pair of documents  a simple retrieval system is implemented which can retrieve the related documents for a query document  based on these scores  a simple document browser is included  which allows the user to view a selected document  and also displays the results for each category by means of a visualization  5.2 datasets and ground truth one of the primary requirements for evaluating our relatedness model is to choose the right dataset  however  we were not able to find any similar work or datasets  focusing on these specific aspects of relatedness  as mentioned in the related work section  many solutions are available to identify similarity between short snippets of text  our system  on the other hand  is designed for scientific and educational media  which have considerable length  therefore  we choose to create datasets for our experiments that take these aspects into account  j intell inf syst we created data sets similar to what would be a typical scientific/ technological document repository that can be found in digital libraries  we specifically gathered a mix of graduate level classroom lecture video transcripts taken from nptel  nptel 2012  and mit-ocw  mit 2012   scientific literature documents  theses  etc  we ensured that the data sets represented several subject domains  they covered multiple document formats and structures  such as classroom lectures and scientific publications  a repository of over 1600 documents was thus created  from which we chose the following data sets  1 dataset 1  a set of 120 lecture videos  transcripts   featuring topics such as database systems  data structures and machine learning and numerical methods  from nptel and mit-ocw 2 dataset 2  contains the transcripts in dataset 1  as well as a number of scientific publications in the areas of information retrieval  database applications and geographic information systems  totalling over 300 documents  3 dataset 3  a set of 1200 lecture transcripts from nptel that features topics in computer science  mathematics  mechanical engineering  electrical engineering  chemistry etc  4 dataset 4  a set of 275 lecture transcripts from mit-ocw featuring topics in economics  physics  chemistry  biology and computer science our prototype system returns a document relatedness score for each pair of documents  and for each category of relatedness  this relatedness score was used to rank suggestions of related documents from the repository  we use two methods to test our measures  create a ground truth for the data set with the help of unbiased experts and compare the obtained results against it gather user feedback from the prototype system and analyze how well the results are in concordance with the intent of users ground truth generation for data sets 1 and 4  a ground truth was generated based on expert judgement  for a chosen subset of documents in these sets  ground truth was determined by generating potential results for sample documents that fall under the different categories of relatedness  while some document pairs are good candidates for continuation and elaboration  they may not be ideal subjects for applications  hence  the candidate documents were chosen independently for each category based on the data set available and subjects covered  for instance for data set1  the ground truth includes 3 lectures from data structures  2 from computer architecture  2 from computer graphics and 1 each from all other topics  we have therefore ensured that all topics from the data set and different types of lectures  some mathematical  some programming specific  some theoretical  have been chosen  the number of documents was limited so as not to overburden the users with the ground truth generation  which is a time consuming process  the ground truth was generated by a group of five users for each source document  all of the users have a knowledge of the topic  with an understanding of topics to follow and one of the users was an expert  generally a course handling faculty  or researcher  for each relatedness category the set of documents that hold the particular relationship with the given document was provided by the users after discussion  the users were given time to explore the contents of the lectures in the data set to help with the ground truth creation process  j intell inf syst table 4 examples of continuation document 1 resistor  capacitor dictionaries stack document 2 resistors in series and parallel hash tables queue scaled cont  score 9.8 7.03 4.02 rank 1 1 2 when there was a disagreement  the expert opinion was sought  in general only when the group arrived at a consensus the document is chosen  to compare our results against the ground truth  we use precision  no  of relevant results/no  of results obtained  and recall  no  of relevant results/no  of expected results  metrics  the second approach where user rating is used to evaluate the results is needed for large data sets  for which it would be difficult to create ground truth  also  to our knowledge  there are n't any systems or standard data sets for judging these specific relations between documents  which we can compare our system with  therefore  we also evaluate by user ratings  we gather user feedback by getting explicit ratings for the recommendation results  a sample from each topic is chosen from the data set for evaluation  and some topics could have more than one sample  here  for each document di the resulting documents categorized under each relatedness type is given to 5 users  each user gives a rating of 0 to 5  based on the following guidelines  5  indicates that document d2 is definitely related to d1 through the specific relationship  4  indicates that document d2 is strongly related to d1 via the relationship 3  indicates that the specific relationship maybe considered but is not definitive 2  indicates that this relationship is weak between the two documents 1  indicates that the two document definitely do not have the specific relationship but they do have common content 0  indicates that the two documents have absolutely nothing in common and there is no conceivable relationship between them this rating is done individually and privately  and average ratings are presented  the rest of this section details the results of our evaluation  5.3 evaluation of continuation we first evaluate the performance of the continuation relation  based on the results obtained using our data sets  table 4 shows some sample documents for which the right continuing table 5 evaluation of continuation average precision rc with tf-idf weighting rc without tf-idf weighting cosine index 0.83 0.47 0.59 average recall 0.75 0.72 0.76 j intell inf syst table 6 examples of elaboration document 1 multi-level indexing computer graphics  curves query processing document 2 tree traversal cubic spline interpolation hash tables elaboration score 9.99 4.28 4.72 rank 1 2 3 document has been given the high ranks by our measure  these are the document pairs that have been certified by our experts as having the continuation relationship  by `rank '  we mean the ordering according to the continuation score  the scores have been decimal scaled for the sake of readability  as it does not affect the ranking of the results  the scaled scores are between 0.2 and 22  with a median of 1.15 and the 97th percentile being 4.32 while dictionaries and hash tables have similar patterns for common topic terms  stacks and queues have similar patterns in subtopic and background terms  this is a case of our measure working irrespective of the types of terms influencing this relationship  and indicating the effectiveness of our approach  the measure also identifies a good continuing document in other domains like electronics as shown  to formally analyze the continuation relation  the continuation scores for document pairs in video lecture transcripts in data set 1 have been studied  the average precision and recall that were observed is shown in table 5 as we can see  our measure results in high recall and the use of tf-idf to weight the d-span similarity of common terms has lead to a better precision  we have shown the results of analyzing the measure without the tf-idf weighting for comparison  it can be argued that continuation can be characterized using the similarity relationship  therefore we evaluate the results obtained when when cosine similarity index  huang 2008  is applied for the same documents  average precision of the results obtained when cosine similarity index is applied  is much lower as seen in the table  while recall is quite similar  the results show that both similarity in occurrence pattern  which is captured by our continuation measure   and the relevance of terms exhibiting these patterns play a role in defining the continuation relationship  therefore  we are characterizing the continuation relation by the measure described in section 4  5.4 evaluation of elaboration table 7 shows the average precision and recall values for our approach as evaluated with the ground truth  we can see that our approach results in a reasonable precision and recall for this dataset  the elaboration measure uses a filter based on c-value  i.e  it only takes into account common terms with a higher c-value in the elaboration document  as described by  9   as proper justification for this choice of feature based filter  we tested the performance of the measure  after replacing the c-value in  9  with tf-idf  even though both table 7 evaluation of elaboration average precision re with c-value as filter re with tf-idf as filter 0.53 0.22 average recall 0.53 0.18 j intell inf syst table 8 evaluation of application average precision ra with c-value as filter ra with tf-idf as filter 0.48 0.37 average recall 0.52 0.24 c-value and tf-idf seem to bring out the relevance  the degree of contextual relevance is brought out better by c-value as explained in the definition of these measures  this experiment is a proof for the above premise  the use of c-value over tf-idf dramatically improves the results of this measure  demonstrating that the common terms that are relevant to the subject of the document play a major role in this relationship  table 6  shows specific examples of our results and the scores using the measure  we can see that the elaboration measure brings out results where a less important concept in document 1 is prominently featured in document 2 for instance  the particular lecture on query processing  document 1  deals with few techniques that involve hash tables  though hashing is mentioned often  it is not the most prominent concept in this lecture  making it a background topic in document 1  while it is the main topic term in document 2  `` hashing and hash tables ''  table 7   5.5 evaluation of application from the results shown in tables 8 and 9  we can observe the utility of the measure in quantifying the application relationship  as in the case of elaboration  we compare the results when c-value is used over tf-idf and it is again seen that c-value proves to be the more effective filter  from the results we can see that the application measure serves to identify interesting applications  in the examples shown  it has been particularly effective in identifying the usage of the data structures that form the topic of the source document  however  we see from the precision score that it is also prone to false positives  to a greater extent than the elaboration measure  this is because the application measure is rather general and picks up any case where a topic in one document is reduced to a subtopic/background topic in another  while our experts who generated the ground truth actually prefer applications that are novel with respect to the topic being applied  to counteract this effect  identification of additional patterns is necessary  which is a direction for future work  5.6 evaluation based on user rating as mentioned earlier  we evaluate the large data sets by explicit user ratings  based on the ratings aggregated from 5 independent users  we calculate the average rating given for the top k results for each document of a selected subset of test documents  the ratings were table 9 examples of application document 1 dictionaries trees trees document 2 query processing multilevel indexing expressions  programming languages  application score 24.5 17.35 8.92 rank 1 1 5 j intell inf syst table 10 explicit user rating type of relation data set1 continuation elaboration application data set2 continuation elaboration application data set3 continuation elaboration application average user rating 3.34 3.2 2.56 3.34 3.71 3.54 4.07 3.15 3.33 standard deviation 0.35 0.66 0.4 0.28 0.21 0.22 0.21 0.30 0.32 no  samples 50 28 30 25 25 25 30 25 25 given on a scale of 0 to 5 these averages are shown in table 10  `standard deviation ' is the standard deviation between the users  in terms of rating points  averaged over the total number of document pairs evaluated for that data set and category  it is seen that the results for `` application '' and `` elaboration '' depend on the chosen data set  here  the scores for `` application '' are higher for the larger data sets  this is because the number of potential documents that exhibit these types of relatedness is very low in the data set 1 on the other hand data set 2 consists of advanced scientific literature  which provide detailed discussions as well as high-level applications  this led to relationships identified between lectures and documents  a few examples are mentioned in table 11 data set 3 has lectures spanning a wider range of domains  we have also collected user ratings for results of latent semantic analysis  with the same samples as the evaluation of continuation in data set 2 the initial term-document matrix was of the dimensions 9900 317 after svd  rank of the singular value matrix was arbitrarily lowered to 200  and cosine similarity calculated for the document vectors  the rating process was as described earlier  however  the users rated for similarity  as lsa is defined for identifying similarity  and not specific relationships in the educational context  the average rating for the lsa results was 3.04 with a standard deviation of 0.5 rating points  since it is a similarity measure and judged based on it  we see that lsa needs to be extended to identify other relationships  table 11 results between different document structures document 1 ml naive bayes and maximum margin classifier  lecture  propositional logic  lecture  document 2 `` domain-specific keyphrase extraction ''  publication ; presents method based on the naive bayes classifier  `` a logic-based approach for query refinement in ontologybased information retrieval systems ''  publication  trees  lecture  type application rank 1 application 2 '' generalized search trees for database systems ''  publication  elaboration 2 j intell inf syst fig  4 document graph linking research articles related to `` segmentation of videos '' our experiments have demonstrated that our measures are capable of identifying these relationships between documents and lead to the identification of interesting applications  which could provide useful directions for information search  figure 4 shows an illustration  which is a manually created document graph based on a sample source document from dataset 2  a research article on `` segmentation of videos ''  this graph shows recommended continuations  applications and elaborations from the dataset  and represents the extent of the information that can be gleaned from the measures defined in section 4 this method j intell inf syst of modeling document relatedness presents a more comprehensive view of the available literature  apart from providing more information than a traditional recommendation model  where only suggestions and meta-data are presented  this demonstrates how such a novel relatedness model can help design novel applications for digital libraries  6 conclusion in this article  an approach for identifying semantic relatedness between documents was presented  we described three categories of semantic relatedness  continuation  application and elaboration  and statistical patterns that characterize them  we also defined relatedness measures based on this discussion  and presented our experimental study on their effectiveness  we also demonstrated how such a relatedness model can be effective in generating graphs of related documents  this work represents a starting point for defining different types of semantic relatedness between scientific documents in a digital library  our methodology serves to identify the three relationships automatically  while the approach works well when the data set is broad  document characteristics and the style of discussion do affect the accuracy  addressing the semantic aspects of common terms will make the measures more reliable  and studies are ongoing to determine how to include these in our model in order to provide better document recommendations  identifying additional document relationships and applying them in novel ir applications are interesting directions for future work  references mit  2012   mit open courseware  http  //ocw.mit.edu/  nptel  2012   national programme on technology enhanced learning  nptel  http  //nptel.iitm.ac.in/  agirre  e  alfonseca  e  hall  k  kravalova  j  pas ca  m  & soroa  a   2009   a study on similarity and relatedness using distributional and wordnet-based approaches  proceedings of human language technologies  naacl  association for computational linguistics  pp  1927   aletras  n  stevenson  m  & clough  p  2012   computing similarity between items in a digital library of cultural heritage  journal on computing and cultural heritage  jocch   5  4   16 andrews  k  g utl  c  moser  j  sabol  v  & lackner  w  2001   search result visualisation with xfind  user interfaces to data intensive systems  2001 uidis 2001 proceedings  second international workshop on  ieee  pp  5058   balagopalan  a  balasubramanian  l.l  balasubramanian  v  chandrasekharan  n  & damodar  a   2012   automatic keyphrase extraction and segmentation of video lectures  technology enhanced education  ictee   2012 ieee international conference on  ieee  pp  110   bean  a  & green  r  2001   relationships in the organization of knowledge vol  2 berlin  springer  capelle  m  hogenboom  f  hogenboom  a  & frasincar  f  2013   semantic news recommendation using wordnet and bing similarities  proceedings of the 28th annual acm symposium on applied computing  acm  pp  296302   chalmers  m  & chitson  p  1992   bead  explorations in information visualization  proceedings of the 15th annual international acm sigir conference on research and development in information retrieval  acm  pp  330337   denning  p  horning  j  parnas  d  & weinstein  l  2005   wikipedia risks  communications of the acm  48  12   152152 foltz  p.w  kintsch  w  & landauer  t.k   1998   the measurement of textual coherence with latent semantic analysis  discourse processes  25  23   285307 frantzi  k.t  & ananiadou  s  1996   extracting nested collocations  proceedings of the 16th conference on computational linguistics-volume 1  pp  4146   j intell inf syst frantzi  k  ananiadou  s  & mima  h  2000   automatic recognition of multi-word terms   the c-value/ncvalue method  international journal on digital libraries  3  2   115130 gabrilovich  e  & markovitch  s  2007   computing semantic relatedness using wikipedia-based explicit semantic analysis  ijcai   vol  7 pp  16061611   gonzalez-agirre  a  rigau  g  agirre  e  aletras  n  & stevenson  m  2015   why are these similar ? investigating item similarity types in a large digital library  journal of the association for information science and technology  gouws  s  2010   evaluation and development of conceptual document similarity metrics with content-based recommender applications  stellenbosch  university of stellenbosch  hofmann  t  1999   probabilistic latent semantic analysis  in proceedings of the fifteenth conference on uncertainty in artificial intelligence  pp  289296   morgan kaufmann publishers inc hopfgartner  f  2010   personalised video retrieval  application of implicit feedback and semantic user profiles  university of glasgow  huang  a   2008   similarity measures for text document clustering  proceedings of the sixth new zealand computer science research student conference  pp  4956   huang  l  milne  d  frank  e  & witten  i.h   2012   learning a concept-based document similarity measure  journal of the american society for information science and technology  63  8   15931608 huynh  t  hoang  k  do  l  tran  h  luong  h  & gauch  s  2012   scientific publication recommendations based on collaborative citation networks  collaboration technologies and systems  cts   2012 international conference on  pp  316321   khoo  c.s.g  & na  j.c  2006   semantic relations in information science  annual review of information science and technology  40  157228 lai  c.h  liu  d.r  & lin  c.s   2013   novel personal and group-based trust models in collaborative filtering for document recommendation  information sciences  239  0   3149 mccormack  a.j  & yager  r.e   1989   a new taxonomy of science education  science teacher  56  2   4748 rafi  m  & shaikh  m.s   2013   an improved semantic similarity measure for document clustering based on topic maps  arxiv:1303.4087 schaefer  c  hienert  d  & gottron  t  2014   normalized relevance distancea stable metric for computing semantic relatedness over reference corpora  ecai  strube  m  & ponzetto  s.p   2006   wikirelate ! computing semantic relatedness using wikipedia  aaai   vol  6 pp  14191424   turdakov  d  & velikhov  p  2008   semantic relatedness metric for wikipedia concepts based on link analysis and its application to word sense disambiguation  wan  x   2007   a novel document similarity measure based on earth mover 's distance  information sciences  177  18   37183730 wan  x.j  & peng  y.x   2005   a new retrieval model based on texttiling for document similarity search  journal of computer science and technology  20  4   552558 wu  h.c  luk  r.w.p  wong  k.f  & kwok  k.l   2008   interpreting tf-idf term weights as making relevance decisions  acm transactions on information systems  tois   26  3   13 zarrinkalam  f  & kahani m  2012   a new metric for measuring relatedness of scientificpapers based on non-textual features  scientific research publishing  zhang  t  ramakrishnan  r  & livny  m  1996   birch  an efficient data clustering method for very large databases  acm sigmod record   vol  25 pp  103114   